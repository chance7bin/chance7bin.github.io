[{"content":"","permalink":"https://chance7bin.github.io/posts/map/mapbox-style-specification/","summary":"","title":"Mapbox Style Specification"},{"content":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile)\n在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类成矢量数据和栅格数据的两种类型。\n其中栅格数据以二维矩阵的形式来表示地理空间信息的数据结构，其中数据的最小存在单元是以像素的形式存在，可以理解为和图片的组织结构类似，以分辨率等特征作为精度的定义标准。\n而矢量数据则是试图利用点、线、面等几何要素来表现这个世界，其数据结构紧凑精准，数据图形质量好，有利于地理信息检索与网络传输等。其中矢量数据的最小单元是以点的形式存在，点构成线，线组成面，面构造出体。所以，我个人看来矢量数据应该更贴近于信息的精准分析与计算，而栅格数据则偏重于信息的表达（主要受制于当前图像处理技术的瓶颈）。\n栅格数据\r矢量数据数据\r为了带来更好更快的用户体验，目前许多主流WebGIS应用都采用了栅格切片技术，通过缓存切片的形式使得地图数据的浏览体验更顺畅。打开浏览器，F12出控制台，进入任意一家地图供应商提供的地图应用，你会发现大部分的地图数据都是以切片的形式请求获得的。栅格地图的切片应用是很广泛，可在我们的日常工作中遇到的需求往往要比这些功能需求较浅的商业性地图复杂，有的时候用户甚至会提出需要地图配色的编辑修改功能这样的需求，这是商业主流地图所达不到的，因为栅格切片在完成切图之后，所能控制的最小单位是一张图片，失去了对图片上地理信息的交互能力。\n总结来看，栅格切片存在以下的几个缺点：\n地图数据一次渲染，无法修改 无交互能力 那可否用WFS来替代呢？直接用WFS请求获取矢量数据，这样不就获得了交互能力吗？当然，如果在你的应用中矢量数据量不大的情况下，这样做也是可行的，但是一旦数据量大了起来，前端对于数据的请求和响应处理渲染会提高客户端的硬件门槛，而频繁的交互操作也会对服务器产生压力。\n直接加载的矢量数据与对栅格地图进行切片这两种方式看起来好像有些互补，如果能将这二者结合起来的话应该会很美好： 矢量+切片=矢量切片。\n什么是矢量切片？ 和栅格切片一样的思路，以金字塔的方式切割矢量数据，只不过切割的不是栅格图片，而是矢量数据的描述性文件，目前矢量切片主要有以下三种格式：GeoJSON，TopoJSON和MapbBox Vector Tile(MVT)。\n栅格切图后文件存储形式 ：\n矢量切图后文件存储形式：\n切片中的数据结构：\n从上面的两张图可以看出，其实思路是一致的，因此，矢量切图结合了矢量数据与栅格切图的优势互补：\n前端缓存切片，提高地图使用的体验 粒度上来看，矢量切图继承了矢量数据的特性，以要素为单位进行管理，加强了细节上的把控能力 在保证体验的前提下，为用户提供地图数据样式动态修改的功能，加强了地图定制化的程度 数据的实时性 如何生成矢量切片？ 矢量切片生成方式共有以下几种：\n1）ArcGIS 系列产品：利用ArcGIS Pro生成矢量切片，然后发布在ArcGIS Online上；\n2）Mapbox，目前已经提出了一套开放的矢量切片标准，并被多个开源团队所接受；\n3）GeoServer，在2.11beta版中出现了对矢量切片的支持，主要依赖于开源插件geoserver-2.11-SNAPSHOT-vectortiles-plugin以及内嵌的GeoWebcahce完成切片工作。\n==本文采取Mapbox的方式==\nMapbox的矢量瓦片 MVT简介 Mapbox的矢量瓦片（mapbox vector tile）是一种轻量级的数据格式，用于存储地理空间矢量数据，例如点、线和多边形。\n矢量瓦片以 Google Protobufs（PBF）进行编码，这允许对结构化数据进行序列化。\nMapbox矢量瓦片使用的是.mvt的文件后缀。\nMapbox矢量瓦片标准 Mapbox矢量瓦片标准\nVector tiles standards\n几何编码 Encoding geometry\n几何编码将点、线和多边形编码为相对于网格左上角的x/y坐标对，如下图所示\nMoveTo：起点\nLineTo：画线\nClosePath：闭环\n属性编码 Encoding attributes\n属性编码是采用键值对的方式，压缩重复的属性值，将属性的键值对与矢量瓦片的键值对一一对应\n有了矢量瓦片标准，对于在Web里面来说，利用WebGL的moveTo/lineTo之类的API，可以将矢量瓦片绘制出来。\n使用PostGIS生成mvt WebMecator投影瓦片计算规则 在生成mvt前，需要先了解一下瓦片的计算规则\n参考链接：\nhttps://zhuanlan.zhihu.com/p/548171000\nhttps://www.cnblogs.com/beniao/archive/2010/04/18/1714544.html\n墨卡托投影（Mercator Projection），又名“等角正轴圆柱投影”，荷兰地图学家墨卡托（Mercator）在1569年拟定，假设地球被围在一个中空的圆柱里，其赤道与圆柱相接触，然后再假想地球中心有一盏灯，把球面上的图形投影到圆柱体上，再把圆柱体展开，这就是一幅标准纬线为零度（即赤道）的“墨卡托投影”绘制出的世界地图。\n由于赤道半径为6378137米，则赤道周长为2 * PI * r = 40075016.685578486162，因此X轴的取值范围：[-20037508.3427892,20037508.3427892]。当纬度φ接近两极，即90°时，Y值趋向于无穷。因此通常把Y轴的取值范围也限定在[-20037508.3427892,20037508.3427892]之间。因此在墨卡托投影坐标系（米）下的坐标范围是：最小为(-20037508.3427892, -20037508.3427892 )到最大坐标为(20037508.3427892, 20037508.3427892)。\n基础值\n1 2 3 4 地球半径：EARTH_RADIUS = 6378137; X和Y的最大值： worldMercMax = π*EARTH_RADIUS = 20037508.3427892 X和Y的最小值： worldMercMin = -1 * worldMercMax 地球赤道周长： worldMercSize = worldMercMax - worldMercMin= 2 * π * EARTH_RADIUS = 40075016.68557848616 谷歌的瓦片地图规范已经实行多年，并深受认可，Bing、OSM、高德、天地图等都使用谷歌的瓦片地图规范，谷歌瓦片地图规范坐标原点为东经180°，北纬85.05°，==x轴向右，y轴向下==。\n瓦片被切成256*256像素的图片，在不同的zoom等级，\nt瓦片数量为： $2^{level}$\n例如，zoom level为3时，横轴和纵轴方向瓦片数量均为8，瓦片对应坐标如下图所示。\n生成mvt的ST函数 参考链接：\nhttps://www.jianshu.com/p/e15ca286546c\nhttps://blog.csdn.net/qq_35241223/article/details/106439268\n主要函数：\nST_AsMvtGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nST_TileEnvelope（3.0以上支持） 根据行列号获取Envelope\n辅助函数：\nST_Transform 坐标转换函数，用它可以做到支持任何坐标系的矢量瓦片\nST_Simplify 简化，用它来做线或者面的简化\nST_SimplifyPreserveTopology 与简化类似\nST_AsMvtGeom 应该将geom转到墨卡托坐标下，4326坐标下制作矢量瓦片有横向的压扁\nST_AsMVT 用于将基于MapBox Vector Tile坐标空间的几何图形转换为MapBox VectorTile二进制矢量切片\nrow —— 至少具有一个geometry列的行数据。 name —— 图层名字，默认为\u0026quot;default\u0026quot;。 extent —— 由MVT规范定义的屏幕空间（MVT坐标空间）中的矢量切片范围。 geom_name —— row参数的行数据中geometry列的列名，默认是第一个*geometry类型的列。 feature_id_name —— 行数据中要素ID列的列名。如果未指定或为NULL，则第一个有效数据类型（smallint, integer, bigint）的列将作为要素ID列，其他的列作为要素属性列。 ST_AsMVTGeom 用于将一个图层中位于参数box2d范围内的一个几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标。\ngeom —— 被转换的几何图形信息。 bounds—— 某个矢量切片的范围对应的空间参考坐标系中的几何矩形框（没有缓冲区）。 extent—— 是按规范定义的矢量切片坐标空间中的某个矢量切片的范围。如果为NULL，则默认为4096（边长为4096个单位的正方形）。 buffer—— 矢量坐标空间中缓冲区的距离，位于该缓冲区的几何图形部位根据clip_geom参数被裁剪或保留。如果为NULL，则默认为256。 clip_geom—— 用于选择位于缓冲区的几何图形部位是被裁剪还是原样保留。如果为NULL，则默认为true。 PostGIS生成MVT矢量切片的步骤 使用ST_AsMVTGeom函数将几何图形的所有坐标转换为MapBox Vector Tile坐标空间里的坐标，这样就将基于空间坐标系的几何图形转换成了基于MVT坐标空间的几何图形。 使用ST_AsMVT函数将基于MVT坐标空间的几何图形转换为MVT二进制矢量切片。 可以通过\u0026quot;||\u0026ldquo;操作符调用多次这个函数来同时创建多个图层的同一位置的矢量切片。\nPostGIS ST函数 1 2 3 4 5 6 7 8 9 10 11 WITH bounds AS ( SELECT ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241) AS geom, ST_Segmentize(ST_MakeEnvelope(13071343.332991, 3678761.297309, 13149614.849955, 3757032.814273, 3857),19567.879241)::box2d AS b2d ), mvtgeom AS ( SELECT ST_AsMVTGeom(ST_Transform(t.geom, 3857), bounds.b2d) AS geom, * FROM js_city_point_u_6492c1048429434b637f1be5 t, bounds WHERE ST_Intersects(t.geom, ST_Transform(bounds.geom, 4326)) ) SELECT ST_AsMVT(mvtgeom.* , \u0026#39;js_city_point_u_6492c1048429434b637f1be5\u0026#39; ) FROM mvtgeom 这段 PostGIS SQL 语句就是用于生成 MVT（Mapbox Vector Tiles）数据。\n让我们逐步解释这段 SQL 语句的意思：\n首先，使用 WITH 子句创建一个名为 bounds 的临时表，其中包含一个几何对象和一个边界框（box2d）。这个几何对象是通过使用 ST_MakeEnvelope 函数创建的，该函数根据提供的坐标范围**（tileToEnvelope函数计算得到）**和坐标系生成一个矩形。然后，使用 ST_Segmentize 函数对几何对象进行分段，以确保生成的矢量瓦片在显示时具有一定的细节和精度。\n接下来，使用 mvtgeom 作为名称创建另一个临时表。在这个临时表中，使用 ST_Transform 函数将 t.geom（js_city_point_u_6492c1048429434b637f1be5 表中的几何列）从源坐标系（4326）转换为目标坐标系（3857）。然后，使用 ST_AsMVTGeom 函数将转换后的几何对象与 bounds.b2d 边界框进行相交（使用 ST_Intersects 函数），从而获得符合条件的几何对象。在结果中，还包含原始表 t 的所有列。\n最后，使用 SELECT 语句从 mvtgeom 表中选择几何对象，并使用 ST_AsMVT 函数将这些几何对象转换为 MVT 格式的瓦片。'js_city_point_u_6492c1048429434b637f1be5' 是指定瓦片的图层名称。\n简而言之，这个 SQL 查询的目的是生成包含符合条件的几何对象的 MVT 瓦片数据。它利用了 PostGIS 的空间函数和转换功能来处理几何对象的坐标系转换和分段，然后将结果转换为 MVT 格式的瓦片数据。\nST_MakeEnvelope需要的范围是如何确定的呢？\n有了前面瓦片的计算规则的基础，就不难理解所求瓦片的x/y最大值最小值范围的计算方法了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } Java代码实现 接口返回的数据是==MVT二进制矢量切片==\nController 1 2 3 4 5 6 7 8 9 @GetMapping(value = \u0026#34;/mvt/{tableName}/{zoom}/{x}/{y}.pbf\u0026#34;) public void getMvt(@PathVariable(\u0026#34;tableName\u0026#34;) String tableName, @PathVariable(\u0026#34;zoom\u0026#34;) int zoom, @PathVariable(\u0026#34;x\u0026#34;) int x, @PathVariable(\u0026#34;y\u0026#34;) int y, HttpServletResponse response) { pgService.getMvt(zoom, x, y, tableName, response); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public void getMvt(int zoom, int x, int y, String tableName, HttpServletResponse response) { try { String sql = getMvtSql(zoom, x, y, tableName); if (sql == null) { return; } log.info(\u0026#34;DefaultPgSource: \u0026#34; + zoom + \u0026#34;, \u0026#34; + x + \u0026#34;, \u0026#34; + y + \u0026#34;:\u0026#34; + sql); byte[] mvtByte = mvtRepository.getMvtFromDefaultPg(sql); returnMvtByte(mvtByte, zoom, x, y, response); } catch (Exception e) { log.error(e.getMessage()); } } public String getMvtSql(int zoom, int x, int y, String tableName) { if (!MvtUtils.tileIsValid(zoom, x, y)) { return null; } HashMap\u0026lt;String, Double\u0026gt; envelope = MvtUtils.tileToEnvelope(zoom, x, y); String sql = MvtUtils.envelopeToSQL(envelope, tableName); return sql; } public void returnMvtByte(byte[] mvtByte, int zoom, int x, int y, HttpServletResponse response) throws IOException { response.setHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); response.setHeader(\u0026#34;Content-type\u0026#34;, \u0026#34;application/vnd.mapbox-vector-tile\u0026#34;); String mtvFileName = String.format(\u0026#34;%d_%d_%d.mvt\u0026#34;, zoom, x, y); response.setHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + new String(mtvFileName.getBytes(\u0026#34;UTF-8\u0026#34;), \u0026#34;iso-8859-1\u0026#34;)); OutputStream os = response.getOutputStream(); os.write(mvtByte); } Repository 1 2 3 4 5 6 7 8 9 public byte[] getMvtFromDefaultPg(String sql) { try { byte[] reByte = jdbcTemplate.queryForObject(sql, (rs, rowNum) -\u0026gt; rs.getBytes(\u0026#34;st_asmvt\u0026#34;)); return reByte; } catch (Exception e) { log.error(\u0026#34;默认数据库瓦片获取失败\u0026#34; + e.getMessage()); return null; } } MVT工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 public class MvtUtils { public static Boolean tileIsValid(int zoom, int x, int y) { Double size = Math.pow(2, zoom); if (x \u0026gt;= size || y \u0026gt;= size) { return false; } if (x \u0026lt; 0 || y \u0026lt; 0) { return false; } return true; } public static HashMap\u0026lt;String, Double\u0026gt; tileToEnvelope(int zoom, int x, int y) { double worldMercMax = 20037508.3427892; double worldMercMin = -1 * worldMercMax; double worldMercSize = worldMercMax - worldMercMin; double worldTileSize = Math.pow(2, zoom); double tileMercSize = worldMercSize / worldTileSize; HashMap\u0026lt;String, Double\u0026gt; env = new HashMap\u0026lt;String, Double\u0026gt;(); env.put(\u0026#34;xmin\u0026#34;, worldMercMin + tileMercSize * x); env.put(\u0026#34;xmax\u0026#34;, worldMercMin + tileMercSize * (x + 1)); env.put(\u0026#34;ymin\u0026#34;, worldMercMax - tileMercSize * (y + 1)); env.put(\u0026#34;ymax\u0026#34;, worldMercMax - tileMercSize * y); return env; } public static String envelopeToBoundsSQL(HashMap\u0026lt;String, Double\u0026gt; env) { int DENSIFY_FACTOR = 4; env.put(\u0026#34;segSize\u0026#34;, (env.get(\u0026#34;xmax\u0026#34;) - env.get(\u0026#34;xmin\u0026#34;)) / DENSIFY_FACTOR); String sqlTemp = String.format(\u0026#34;ST_Segmentize(ST_MakeEnvelope(%f, %f, %f, %f, 3857),%f)\u0026#34;, env.get(\u0026#34;xmin\u0026#34;), env.get(\u0026#34;ymin\u0026#34;), env.get(\u0026#34;xmax\u0026#34;), env.get(\u0026#34;ymax\u0026#34;), env.get(\u0026#34;segSize\u0026#34;)); return sqlTemp; } public static String envelopeToSQL(HashMap\u0026lt;String, Double\u0026gt; env, String tableName) { // lines_pg gis_osm_transport_free_1 HashMap\u0026lt;String, String\u0026gt; table = new HashMap\u0026lt;String, String\u0026gt;(); table.put(\u0026#34;table\u0026#34;, tableName); table.put(\u0026#34;srid\u0026#34;, \u0026#34;4326\u0026#34;); table.put(\u0026#34;geomColumn\u0026#34;, \u0026#34;geom\u0026#34;); table.put(\u0026#34;attrColumns\u0026#34;, \u0026#34; * \u0026#34;); table.put(\u0026#34;env\u0026#34;, envelopeToBoundsSQL(env)); String mvtsql = MessageFormat.format(\u0026#34;WITH\u0026#34; + \u0026#34; bounds AS ( SELECT {0} AS geom, {0}::box2d AS b2d),\u0026#34; + \u0026#34; mvtgeom AS (\u0026#34; + \u0026#34; SELECT ST_AsMVTGeom(ST_Transform(t.{1}, 3857), bounds.b2d) AS geom, {2}\u0026#34; + \u0026#34; FROM {3} t, bounds\u0026#34; + \u0026#34; WHERE ST_Intersects(t.{1}, ST_Transform(bounds.geom, {4}))\u0026#34; + \u0026#34; )\u0026#34; + \u0026#34; SELECT ST_AsMVT(mvtgeom.* , \u0026#39;\u0026#39;{3}\u0026#39;\u0026#39; ) FROM mvtgeom\u0026#34;, table.get(\u0026#34;env\u0026#34;), table.get(\u0026#34;geomColumn\u0026#34;), table.get(\u0026#34;attrColumns\u0026#34;), table.get(\u0026#34;table\u0026#34;), table.get(\u0026#34;srid\u0026#34;)); return mvtsql; } } ","permalink":"https://chance7bin.github.io/posts/map/mapbox-vector-tile-%E8%AF%A6%E8%A7%A3/","summary":"矢量瓦片 GIS中的矢量与栅格数据 矢量切片(Vector tile) 在GIS中的数据分类有很多种方式，其中最常用的一种是根据数据组织结构方式的不同而分类","title":"mapbox vector tile 详解"},{"content":"1.mbtiles简介 mapbox Docs : MBTiles\nMbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。\nMBTiles瓦片存储规范的制定主要是为了解决、优化传统瓦片的存储方案存在的两个问题：\n可移植性差，无法在移动端上做离线应用 存储量大，大家都知道，因为互联网上的地图都以“瓦片”的形式存在，高层级的瓦片存储数量往往是海量的。例如，对于“Web 墨卡托”投影的瓦片金字塔来说，第15层数据有 4^15 = 1073741824个瓦片。 参见文档，Mbtiles其实本质是一个SQLite3文件，大家知道，SQLite有它天然的可移植特性（整个数据库就是一个sqlite3文件，当然可移植性够好）。这个解决了1的问题。\n下面简单解读一下规范，该规范描述了这个sqlite3文件的表必须符合以下规定：\n必须要一个名叫“metadata”的table（表）或者view（视图），这个表其实就是“元数据”表，用来描述存储的数据。这个表必须要有两列，一列是\u0026quot;name\u0026quot;，一列是“value”，这两列都是text类型的。这个表必须包含一些特定的row,例如name=\u0026ldquo;name\u0026rdquo;,value=\u0026ldquo;数据集名称\u0026rdquo;；name: \u0026ldquo;format\u0026rdquo; ,value: \u0026ldquo;pbf\u0026quot;代表存储的瓦片格式；name: \u0026ldquo;center\u0026rdquo; ,value: -122.1906,37.7599,1代表这个数据集存储的数据中心在这个经纬度处。对于Mapbox矢量瓦片集，有特殊的json字段，用来描述矢量瓦片集。\n必须要有一个名字叫“tiles”的表。建表语句\nCREATE TABLE tiles (zoom_level integer, tile_column integer, tile_row integer, tile_data blob);\n它可能会有一个索引：\nCREATE UNIQUE INDEX tile_index on tiles (zoom_level, tile_column, tile_row);\n这个表主要存了x/y/z和对应的瓦片数据（BLOB)\n2.金字塔模型 要了解mbtiles是怎么存储的，首先需要先了解瓦片地图的金字塔模型\n众所周知，对于Web而言，将矢量图层渲染为栅格数据是一个昂贵的计算过程。对于不经常修改的矢量图层，重复描绘同样线条会极大浪费CPU资源。继Google Maps推出瓦片地图后，各大地图网站都转而采取预先渲染标注好的海量图片并分割为256*256像素瓦片的策略，从而使得浏览器能快速地缓存小尺寸且不会更名的瓦片。\n瓦片地图是一个三维的概念，即金字塔模型，其每增大一级，会在上一级瓦片的基础上一分为四，随着分辨率的提升，显示的内容也渐显丰富。通常使用xyz三维坐标系来对一张瓦片进行精准定位，其中z用于表示地图的层级，xy表示某个层级内的瓦片平面。该瓦片平面可被视为数学上常见的笛卡尔坐标系，只要确定了横轴坐标x和纵轴坐标y，便可以唯一确定在这个瓦片平面上的每一个瓦片，如图所示。\n3.mbtiles结构 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\nmbtiles中几个比较重要的表：\nmap：存储层级以及行列号**（金字塔模型**），以及瓦片id images：存储瓦片id以及对应的图片数据 metadata：存取地图的元数据信息 3.1 metadata表 3.2 tiles视图 视图构建SQL：\n1 2 3 4 5 6 7 SELECT map.zoom_level AS zoom_level, map.tile_column AS tile_column, map.tile_row AS tile_row, images.tile_data AS tile_data FROM map JOIN images ON images.tile_id = map.tile_id 通过sql语句我们可以知道tiles视图其实就是把map表里面的瓦片层级信息与images表的瓦片图片数据关联起来\n视图基本结构：\n4.Java加载Mbtiles发布地图服务 示例数据2017-07-03_planet_z0_z14.mbtiles，下载地址：https://data.maptiler.com/downloads/tileset/osm/\n4.1 加载mbtiles 加载sqlite驱动\n1 2 3 4 5 6 \u0026lt;!-- sqlite驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sqlite-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.34.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 连接数据库\n1 2 3 4 5 6 7 8 9 10 11 try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); 封装为bean\n地图服务的接口每次都需请求上百张图片，如果每次请求都重新连接数据库会导致程序崩溃，所以需将其封装为bean，暴露出连接mbtiles的Connection，这样只需项目启动时连接一次数据库即可\n注意：连接数据库 返回连接数据库的Connection 不能返回执行SQL语句的statement，因为每个Statement对象只能同时打开一个ResultSet对象，高并发情况下会出现 rs.isOpen() on exec 的错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Slf4j @Configuration public class SqliteConfig { @Bean(name = \u0026#34;mbtilesConnection\u0026#34;) Connection mbtilesConnection() throws SQLException { String path = \u0026#34;Z:/2017-07-03_planet_z0_z14.mbtiles\u0026#34;; // mbtiles路径 return getConnection(\u0026#34;jdbc:sqlite:\u0026#34; + path); } public static Connection getConnection(String conurl) throws SQLException { try { Class.forName(\u0026#34;org.sqlite.JDBC\u0026#34;); } catch (ClassNotFoundException e) { // e.printStackTrace(); log.warn(\u0026#34;Database driver not found!\u0026#34;); } // 得到连接 会在你所填写的文件夹建一个你命名的文件数据库 Connection conn; // String conurl = \u0026#34;jdbc:sqlite:E:/mapArchiveFiles/tianditu/img_c.mbtiles\u0026#34;; conn = DriverManager.getConnection(conurl,null,null); // 设置自己主动提交为false conn.setAutoCommit(false); //推断表是否存在 ResultSet rsTables = conn.getMetaData().getTables(null, null, \u0026#34;tiles\u0026#34;, null); if(!rsTables.next()){ log.warn(\u0026#34;{} does not exist!\u0026#34;, conurl); } else { log.info(\u0026#34;{} successfully connected!\u0026#34;, conurl); } return conn; // return conn.createStatement(); } } 4.2 查询mbtiles 根据请求的层级z以及行列号x、y到数据库的tiles表查找对应的瓦片数据\n**注意：**由于mapbox只能加载未压缩的pbf格式数据，直使用tippecanoe生成的pbf是经过gzip压缩的数据，不执行解压缩，mapbox加载数据会报：“Unimplemented type: 3” 错误，所以必须对得到的tile_data解压缩：FileUtils.gzipUncompress(imgByte)\n是否需要解压缩要根据生成mbtiles时对瓦片采取的操作而定，例如使用mbutil工具实现地图切片向mbtiles文件格式的转换，其生成mbtiles时图片并没有经过压缩，所以在获取到tile_data时就不需要解压缩，如下是mbutil生成mbtiles时的部分代码片段，可以看到mbutil只是对图片二进制处理，并没有压缩\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 private void queryMbtilesWithUncompress( TilesDTO tilesDTO, Connection connection, HttpServletResponse response){ try { Statement statement = connection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM tiles WHERE zoom_level = \u0026#34;+ tilesDTO.getZoom_level() + \u0026#34; AND tile_column = \u0026#34;+ tilesDTO.getTile_column() + \u0026#34; AND tile_row = \u0026#34;+ tilesDTO.getTile_row() ; ResultSet rs = statement.executeQuery(sql); if(rs.next()) { byte[] imgByte = (byte[]) rs.getObject(\u0026#34;tile_data\u0026#34;); // 解压缩 byte[] bytes = FileUtils.gzipUncompress(imgByte); InputStream is = new ByteArrayInputStream(bytes); OutputStream os = response.getOutputStream(); try { int count = 0; byte[] buffer = new byte[1024 * 1024]; while ((count = is.read(buffer)) != -1) { os.write(buffer, 0, count); } os.flush(); } catch (IOException e) { // e.printStackTrace(); } finally { os.close(); is.close(); } } else{ log.debug(\u0026#34;sql: {}\u0026#34;,sql); log.debug(\u0026#34;未找到瓦片!\u0026#34;); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ // e.printStackTrace(); } } GZIP解压\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //GZIP解压 public static byte[] gzipUncompress(byte[] bytes) { if (bytes == null || bytes.length == 0) { return null; } ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); try { GZIPInputStream ungzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n; while ((n = ungzip.read(buffer)) \u0026gt;= 0) { out.write(buffer, 0, n); } } catch (IOException e) { log.error(\u0026#34;gzip uncompress error.\u0026#34;, e); } return out.toByteArray(); } 4.3 接口编写 controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @ApiOperation(value = \u0026#34;得到mapbox瓦片\u0026#34; ) @GetMapping(\u0026#34;/mapbox/{z}/{x}/{y}.pbf\u0026#34;) public void getMapboxTiles( @ApiParam(name = \u0026#34;z\u0026#34;, value = \u0026#34;zoom_level\u0026#34;) @PathVariable int z, @ApiParam(name = \u0026#34;x\u0026#34;, value = \u0026#34;tile_column\u0026#34;) @PathVariable int x, @ApiParam(name = \u0026#34;y\u0026#34;, value = \u0026#34;tile_row\u0026#34;) @PathVariable int y , HttpServletResponse response){ TilesDTO tilesDTO = new TilesDTO(); tilesDTO.setTile_column(x); tilesDTO.setTile_row((int)(Math.pow(2,z)-1-y)); tilesDTO.setZoom_level(z); tilesService.getMapboxTiles(tilesDTO, response); } 5.mapbox加载地图服务 5.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ...e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/light-v10\u0026#39;, zoom: 5, center: [118.447303, 30.753574] }); map.on(\u0026#34;load\u0026#34;, () =\u0026gt; { map.addSource(\u0026#34;testMapLine\u0026#34;, { type: \u0026#34;vector\u0026#34;, tiles: [\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf }); map.addLayer({ id: \u0026#34;testMapLineLayer\u0026#34;, type: \u0026#34;fill\u0026#34;, source: \u0026#34;testMapLine\u0026#34;, // ST_AsMVT() uses \u0026#39;default\u0026#39; as layer name \u0026#34;source-layer\u0026#34;: \u0026#34;water\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;all\u0026#34;, [\u0026#34;!=\u0026#34;, \u0026#34;brunnel\u0026#34;, \u0026#34;tunnel\u0026#34;]], minzoom: 0, maxzoom: 22, \u0026#34;paint\u0026#34;: { \u0026#34;fill-color\u0026#34;: \u0026#34;rgb(158,189,255)\u0026#34;, \u0026#34;fill-opacity\u0026#34;: [\u0026#34;literal\u0026#34;, 1] } }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5.2 效果展示 可以看到水体被加载出来了\n6.发布osm-liberty形式的地图服务 mapbox还有一种直接请求osm-liberty.json的方式加载地图服务\n6.1 地图服务接口 接口层\n1 2 3 4 5 @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/liberty.json\u0026#34;) public JSONObject getMapboxLibertyJson(){ return tilesService.getMapboxLibertyJson(); } Service层\n首先加载原始的osm_liberty.json，将自定义tiles.json接口地址更新至osm_liberty.json中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public JSONObject getMapboxLibertyJson() { try { File file = ResourceUtils.getFile(resourcePath + \u0026#34;/osm_liberty.json\u0026#34;); Map map = FileUtils.readJson(file); JSONObject jsonObject = new JSONObject(map); String sourceUrl = \u0026#34;http://localhost:9000/tiles/mapbox/metadata/tiles.json\u0026#34;; ((Map)((Map) jsonObject.get(\u0026#34;sources\u0026#34;)).get(\u0026#34;openmaptiles\u0026#34;)).put(\u0026#34;url\u0026#34;, sourceUrl); return jsonObject; }catch (Exception e){ e.printStackTrace(); } return null; } tiles.json接口\n1 2 3 4 5 6 7 8 // \u0026#34;https://api.maptiler.com/tiles/v3/tiles.json?key=XAapkmkXQpx839NCfnxD\u0026#34; @ApiOperation(value = \u0026#34;得到mapbox元数据json\u0026#34; ) @GetMapping(\u0026#34;/mapbox/metadata/tiles.json\u0026#34;) public JSONObject getMapboxTilesMetadataJson(){ return tilesService.getMapboxTilesMetadataJson(); } getMapboxTilesMetadataJson方法中，可以看到我们用到了mbtiles中metadata表里面的数据，同时，tiles.json的tiles就是我们[4.3](# 4.3 接口编写)编写的接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public JSONObject getMapboxTilesMetadataJson() { JSONObject result = new JSONObject(); try { Statement statement = mapboxConnection.createStatement(); // 得到结果集 String sql = \u0026#34;SELECT * FROM metadata\u0026#34;; ResultSet rs = statement.executeQuery(sql); while (rs.next()) { String name = (String) rs.getObject(\u0026#34;name\u0026#34;); String value = (String) rs.getObject(\u0026#34;value\u0026#34;); JSONObject jsonObject = formatMetadata(name, value); result.put(jsonObject.getString(\u0026#34;name\u0026#34;),jsonObject.get(\u0026#34;value\u0026#34;)); } rs.close(); //statement在每次执行之后都要关了 statement.close(); }catch (Exception e){ e.printStackTrace(); } result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;http://localhost:9000/tiles/mapbox/{z}/{x}/{y}.pbf\u0026#34;)); // result.put(\u0026#34;tiles\u0026#34;, Arrays.asList(\u0026#34;https://api.maptiler.com/tiles/v3/{z}/{x}/{y}.pbf?key=XAapkmkXQpx839NCfnxD\u0026#34;)); return result; } 6.2 mapbox加载osm-liberty.json 6.2.1 html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add a vector tile source\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1,maximum-scale=1,user-scalable=no\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v2.8.2/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; const map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#34;http://localhost:9000/tiles/mapbox/liberty.json\u0026#34;, zoom: 5, center: [118.447303, 30.753574] }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 6.2.2 效果展示 可以看到所有数据（边界轮廓等）都加载出来了\n","permalink":"https://chance7bin.github.io/posts/map/%E4%BD%BF%E7%94%A8mbtiles%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.mbtiles简介 mapbox Docs : MBTiles MbTiles 是一种用于在 sqllite 数据库中存储任意瓦片地图数据用于即时使用和高效传输的规范。 MBTiles瓦片存储规范的制定主要","title":"使用mbtiles发布地图服务"},{"content":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现\n参考链接\nSpringSecurity-从入门到精通\n1 Spring Security Spring Security 是 Spring 家族中的一个安全管理框架。相比与另外一个安全框架Shiro，它提供了更丰富的功能，社区资源也比Shiro丰富。\n一般来说中大型的项目都是使用SpringSecurity 来做安全框架。小项目有Shiro的比较多，因为相比与SpringSecurity，Shiro的上手更加的简单。\n一般Web应用的需要进行认证和授权。\n认证：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户\n授权：经过认证后判断当前用户是否有权限进行某个操作\n而认证和授权也是SpringSecurity作为安全框架的核心功能。\n1.1 Spring Security原理初探 认证基本流程：\n根据username, password封装一个Authentication对象authenticationToken，并加入到SecurityContextHolder的context中 调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证 在第2步调用authenticate方法时，它实际会执行实现了UserDetailsService接口的loadUserByUsername方法，认证用户的逻辑就写在该方法中 在loadUserByUsername方法中，从AuthenticationContextHolder获取第一步传入的username, password，与数据库的密码做对比，验证用户密码是否正确，若正确，则把用户信息封装到实现了UserDetails接口的类中 步骤1扩展\n认证过滤器UsernamePasswordAuthenticationFilter：它的作用是拦截登录请求并获取账号和密码，然后把账号密码封装到认证凭据 UsernamePasswordAuthenticationToken 中，然后把凭据交 给特定配置的 AuthenticationManager去作认证。\n步骤2扩展\nAuthenticationManager 的实现 ProviderManager 管理了众多的 AuthenticationProvider 。每 一个 AuthenticationProvider都只支持特定类型的 Authentication ，然后是对适配到的 Authentication 进行认证，只要有一个 AuthenticationProvider认证成功，那么就认为认证成功，所有的都没有通过才认为是认证失败。认证成功后的 Authentication 就变成授信凭据，并触发认证成功的事件。认证失败的就抛出异常触发认证失败的事件。\n1.2 Spring Secutity核心内容 1.2.1 Spring Secutity中的用户信息 1.UserDetailsService：\n该方法很容易理解： 通过用户名来加载用户 。这个方法主要用于从系统数据中查询并加载具体的用户到 Spring Security中。\n在开发中我们一般定义一个这个接口的实现类，自定义loadUserByUsername方法，实现从数据源获取用户，加载用户信息。也可以在其中实现一些校验用户逻辑。\n2.UserDetails:\n从上面 UserDetailsService 可以知道最终交给Spring Security的是UserDetails 。该接口是提供用户信息的核心接口。该接口实现仅仅存储用户的信息。后续会将该接口提供的用户信息封装到认证对象Authentication 中去。\nUserDetails中默认提供：\n用户的权限集， 默认需要添加 ROLE_ 前缀 用户的加密后的密码， 不加密会使用 {noop} 前缀 应用内唯一的用户名 账户是否过期 账户是否锁定 凭证是否过期 用户是否可用 在我们自己的项目中，我们要定义个用户类实现该接口，在该用户类中我们可以扩展更多的用户信息，比如手机、邮箱等等\n1.2.2 Spring Security的配置 自定义SecurityConfig\n首先要继承WebSecurityConfigurerAdapter，其次最常用的是实现configure(AuthenticationManagerBuilder auth)、configure(WebSecurity web)、configure(HttpSecurity http)三个方法实现我们对Spring Security的自定义安全配置。\nvoid configure(AuthenticationManagerBuilder auth) 用来配置认证管理器 AuthenticationManager。 void configure(WebSecurity web)用来配置 WebSecurity 。而 WebSecurity是基于Servlet Filter用来配置 springSecurityFilterChain。而 springSecurityFilterChain 又被委托给了 Spring Security 核心过滤器 Bean DelegatingFilterProxy 。 相关逻辑可以在 WebSecurityConfiguration 中找到。我们一般不会过多来自定义 WebSecurity , 使用较多的使其 ignoring() 方法用来忽略 Spring Security 对静态资源的控制。 void configure(HttpSecurity http) 这个是我们使用最多的，用来配置 HttpSecurity 。 HttpSecurity用于构建一个安全过滤器链 SecurityFilterChain。 SecurityFilterChain 最终被注入核心过滤器 。HttpSecurity有许多我们需要的配置。我们可以通过它来进行自定义安全访问策略。 1.2.3 认证过程 详见 [1.1 Spring Security原理初探](# 1.1 Spring Security原理初探)\n1.2.4 过滤器和过滤链 SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。\nSpring Security 以一个单 Filter(FilterChainProxy)存在于整个过滤器链中，而 这个 FilterChainProxy 实际内部代理着众多的 Spring Security Filter 。\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\nUsernamePasswordAuthenticationFilter:负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter： 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor： 负责权限校验的过滤器。\n我们可以通过Debug查看当前系统中SpringSecurity过滤器链中有哪些过滤器及它们的顺序。\n向项目中添加过滤器：\n在配置文件的configure(HttpSecurity httpSecurity)方法中：\n4个方法分别是：addFilter–添加过滤器；addFilterAfter–把过滤器添加到某过滤器之后；addFilterAt–替代某过滤器；addFilterBefore–把过滤器添加到某过滤器之前\n1.2.5 权限相关 一、基于配置表达式控制 URL 路径\n在继承WebSecurityConfigurerAdapter的配置类中的configure(HttpSecurity http)中进行配置。\n1 2 3 4 5 6 7 8 protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;admin\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).hasAnyRole(\u0026#34;admin\u0026#34;, \u0026#34;user\u0026#34;) .anyRequest().authenticated() .and() ... } 二、基于注解的接口权限控制\n我们可以在任何 @Configuration实例上使用 @EnableGlobalMethodSecurity注解来启用全局方 法安全注解功能\n1 2 3 4 5 6 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true,jsr250Enabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { ... ... } 设置 prePostEnabled为 true ，则开启了基于表达式 的方法安全控制。 2 认证 2.1 登录校验流程 2.2 登录功能核心代码 在SpringBoot项目中使用SpringSecurity我们只需要引入依赖即可。\n1 2 3 4 5 \u0026lt;!-- spring security 安全认证 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 1.根据username, password封装一个Authentication对象authenticationToken，调用AuthenticationManager接口的authenticate(authenticationToken)方法进行认证\nAuthentication类中：principal属性对应用户名；credentials属性对应密码\n若是需要根据邮箱登录的话把email放到principal，\nloadUserByUsername方法的参数就是这个email\n在接口中我们通过AuthenticationManager的authenticate方法来进行用户认证，所以需要在SecurityConfig中配置把AuthenticationManager注入容器。\n1 2 3 4 5 6 7 8 9 10 public String login(String username, String password, String code, String uuid) { // 用户验证 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, password); AuthenticationContextHolder.setContext(authenticationToken); // 该方法会去调用UserDetailsServiceImpl.loadUserByUsername Authentication authentication = authenticationManager.authenticate(authenticationToken); // 生成token return tokenService.createToken(loginUser); } 密码加密存储\n实际项目中我们不会把密码明文存储在数据库中。\n一般使用SpringSecurity为我们提供的BCryptPasswordEncoder。\n我们只需要使用把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验\n部分SecurityConfig配置（[完整配置](# 2.4 配置SecurityConfig)）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http //关闭csrf .csrf().disable() //不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 对于登录接口 允许匿名访问 .antMatchers(\u0026#34;/user/login\u0026#34;).anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.创建一个service，实现UserDetailsService接口，并重写loadUserByUsername方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Service public class UserDetailsServiceImpl implements UserDetailsService{ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user); } } 3.实现密码验证逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void validate(SysUser user){ Authentication usernamePasswordAuthenticationToken = AuthenticationContextHolder.getContext(); String username = usernamePasswordAuthenticationToken.getName(); String password = usernamePasswordAuthenticationToken.getCredentials().toString(); if (!matches(user, password)) { throw new ServiceException(\u0026#34;密码错误\u0026#34;); } } public boolean matches(SysUser user, String rawPassword){ return matchesPassword(rawPassword, user.getPassword()); } /** * 判断密码是否相同 * * @param rawPassword 真实密码 * @param encodedPassword 加密后字符 * @return 结果 */ public boolean matchesPassword(String rawPassword, String encodedPassword) { BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); return passwordEncoder.matches(rawPassword, encodedPassword); } 4.验证成功后，创建令牌，存入redis中，并将token返回给前端（实现步骤1中的createToken方法）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 /** * 创建令牌 * * @param loginUser 用户信息 * @return 令牌 */ public String createToken(LoginUser loginUser) { String token = UUID.fastUUID().toString(); loginUser.setToken(token); refreshToken(loginUser); Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(Constants.LOGIN_USER_KEY, token); return createToken(claims); } /** * 刷新令牌有效期 * * @param loginUser 登录信息 */ public void refreshToken(LoginUser loginUser) { loginUser.setLoginTime(System.currentTimeMillis()); loginUser.setExpireTime(loginUser.getLoginTime() + expireTime * MILLIS_MINUTE); // 根据uuid将loginUser缓存 String userKey = getTokenKey(loginUser.getToken()); // \u0026#34;login_tokens:\u0026#34; + uuid; redisCache.set(userKey, loginUser, expireTime, TimeUnit.MINUTES); } /** * 从数据声明生成令牌 * * @param claims 数据声明 * @return 令牌 */ private String createToken(Map\u0026lt;String, Object\u0026gt; claims) { String token = Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS512, secret).compact(); return token; } 2.3 校验功能核心代码 访问系统资源时，如果每次都需要去数据库验证密码是十分消耗资源的，[2.2](# 2.2 登录功能核心代码)中，最后返回了一个token，可基于该token实现保存登录状态的功能\n1.前端将后端返回的token存入Cookie中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 login(userInfo) { const username = userInfo.username.trim(); const password = userInfo.password; return new Promise\u0026lt;void\u0026gt;((resolve, reject) =\u0026gt; { login(username, password) .then((res: any) =\u0026gt; { setToken(res.token); this.token = res.token; resolve(); }) .catch((error) =\u0026gt; { reject(error); }); }); } 1 2 3 4 5 6 import Cookies from \u0026#34;js-cookie\u0026#34;; const TokenKey = \u0026#34;Admin-Token\u0026#34;; export function setToken(token: string) { return Cookies.set(TokenKey, token); } 2.请求接口时都附上token，验证用户是否登录\nrequest.ts\n1 2 3 4 5 6 7 8 9 // request拦截器 service.interceptors.request.use( (config: any) =\u0026gt; { // 是否需要设置 token const isToken = (config.headers || {}).isToken === false; if (getToken() \u0026amp;\u0026amp; !isToken) { // 让每个请求携带自定义token 请根据实际情况自行修改 config.headers[\u0026#34;Authorization\u0026#34;] = \u0026#34;Bearer \u0026#34; + getToken(); } 3.定义Jwt认证过滤器 JwtAuthenticationTokenFilter，验证token有效性\n因为redis设置了登陆令牌的过期时间，所以如果令牌过期了，redis中就不存在token解析后的redisKey，会直接返回null，这种其概况就要重新登录了。\n添加依赖\n1 2 3 4 5 6 \u0026lt;!-- Token生成与解析--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jwt.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JwtAuthenticationTokenFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * token过滤器 验证token有效性 * * @author 7bin */ @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private TokenService tokenService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { LoginUser loginUser = tokenService.getLoginUser(request); if (StringUtils.isNotNull(loginUser) \u0026amp;\u0026amp; StringUtils.isNull(SecurityUtils.getAuthentication())) { // 验证令牌有效期，相差不足20分钟，自动刷新缓存 tokenService.verifyToken(loginUser); // 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser, null, loginUser.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 通过验证，在Spring Security上下文中写入用户登录相关所有信息 SecurityContextHolder.getContext().setAuthentication(authenticationToken); } chain.doFilter(request, response); } } 如何根据token获取登录用户信息\n核心：从request解析token获取其中的userId，到redis中根据userId获取用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 获取用户身份信息 * * @return 用户信息 */ public LoginUser getLoginUser(HttpServletRequest request) { // 获取请求携带的令牌 String token = getToken(request); if (StringUtils.isNotEmpty(token)) { try { Claims claims = parseToken(token); // 解析对应的权限以及用户信息 String uuid = (String) claims.get(Constants.LOGIN_USER_KEY); String userKey = getTokenKey(uuid); LoginUser user = redisCache.get(userKey); return user; } catch (Exception e) { log.error(e.getMessage()); } } return null; } /** * 令牌前缀 */ public static final String TOKEN_PREFIX = \u0026#34;Bearer \u0026#34;; /** * 获取请求token * * @param request * @return token */ private String getToken(HttpServletRequest request) { String token = request.getHeader(header); if (StringUtils.isNotEmpty(token) \u0026amp;\u0026amp; token.startsWith(Constants.TOKEN_PREFIX)) { token = token.replace(Constants.TOKEN_PREFIX, \u0026#34;\u0026#34;); } return token; } /** * 从令牌中获取数据声明 * * @param token 令牌 * @return 数据声明 */ private Claims parseToken(String token) { return Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); } 2.4 配置SecurityConfig 在SecurityConfig中注入：\nLogoutSuccessHandlerImpl 自定义实现的UserDetailsService JwtAuthenticationTokenFilter AuthenticationEntryPoint CorsFilter \u0026hellip; 以及相关权限控制configure\n完整spring security配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 /** * spring security配置 * * @author 7bin */ @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 认证失败处理类（抛出AuthenticationException异常走这里） */ @Autowired private AuthenticationEntryPointImpl unauthorizedHandler; /** * 退出处理类 */ @Autowired private LogoutSuccessHandlerImpl logoutSuccessHandler; /** * token认证过滤器 */ @Autowired private JwtAuthenticationTokenFilter authenticationTokenFilter; /** * 跨域过滤器 */ @Autowired private CorsFilter corsFilter; /** * 允许匿名访问的地址 */ @Autowired private PermitAllUrlProperties permitAllUrl; /** * 解决 无法直接注入 AuthenticationManager * * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } /** * anyRequest | 匹配所有请求路径 * access | SpringEl表达式结果为true时可以访问 * anonymous | 匿名可以访问 * denyAll | 用户不能访问 * fullyAuthenticated | 用户完全认证可以访问（非remember-me下自动登录） * hasAnyAuthority | 如果有参数，参数表示权限，则其中任何一个权限可以访问 * hasAnyRole | 如果有参数，参数表示角色，则其中任何一个角色可以访问 * hasAuthority | 如果有参数，参数表示权限，则其权限可以访问 * hasIpAddress | 如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问 * hasRole | 如果有参数，参数表示角色，则其角色可以访问 * permitAll | 用户可以任意访问 * rememberMe | 允许通过remember-me登录的用户访问 * authenticated | 用户登录后可访问 */ @Override protected void configure(HttpSecurity httpSecurity) throws Exception { // 注解标记允许匿名访问的url ExpressionUrlAuthorizationConfigurer\u0026lt;HttpSecurity\u0026gt;.ExpressionInterceptUrlRegistry registry = httpSecurity.authorizeRequests(); permitAllUrl.getUrls().forEach(url -\u0026gt; registry.antMatchers(url).permitAll()); httpSecurity // CSRF禁用，因为不使用session // 关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 .csrf().disable() // 认证失败处理类 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() // 基于token，所以不需要session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 过滤请求 .authorizeRequests() // anonymous() :匿名访问, 仅允许匿名用户访问, 如果登录认证后, 带有token信息再去请求, 这个anonymous()关联的资源就不能被访问， // permitAll() :登录能访问,不登录也能访问, 一般用于静态资源js等 // 对于登录login 注册register 验证码captchaImage 允许匿名访问 .antMatchers(\u0026#34;/login\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/captchaImage\u0026#34;,\u0026#34;/docker/**\u0026#34;).anonymous() // 静态资源，可匿名访问 .antMatchers(HttpMethod.GET, \u0026#34;/\u0026#34;, \u0026#34;/*.html\u0026#34;, \u0026#34;/**/*.html\u0026#34;, \u0026#34;/**/*.css\u0026#34;, \u0026#34;/**/*.js\u0026#34;, \u0026#34;/profile/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/swagger-ui.html\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/*/api-docs\u0026#34;, \u0026#34;/druid/**\u0026#34;).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and() .headers().frameOptions().disable(); // 添加Logout filter httpSecurity.logout().logoutUrl(\u0026#34;/logout\u0026#34;).logoutSuccessHandler(logoutSuccessHandler); // 添加JWT filter httpSecurity.addFilterBefore(authenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); // 添加CORS filter httpSecurity.addFilterBefore(corsFilter, JwtAuthenticationTokenFilter.class); httpSecurity.addFilterBefore(corsFilter, LogoutFilter.class); } /** * 强散列哈希加密实现 */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } /** * 身份认证接口 */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 数据库验证 // Spring Security 提供了BCryptPasswordEncoder类, // 实现Spring的PasswordEncoder接口使用BCrypt强哈希方法来加密密码 auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder()); } } 2.5 思考 什么时候会走到认证失败的处理类呢（还不知道）\nhttpSecurity.exceptionHandling().authenticationEntryPoint(unauthorizedHandler)\nAuthenticationException异常详解\n3 授权 3.1 RBAC权限模型 RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n3.1.1 数据库表结构 如下图是RBAC权限模型各表的基本属性\n当判断某个用户是否拥有某个权限的时候，可根据user_role表获取到该user关联的role，之后可根据role_menu表获取到该role能够访问的menu（权限）\n3.1.2 如何获取用户具有哪些权限？ 在用户登录的时候（loadUserByUsername方法中），将权限信息写入LoginUser中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { SysUser user = userService.selectUserByUserName(username); if (StringUtils.isNull(user)) { log.info(\u0026#34;登录用户：{} 不存在.\u0026#34;, username); throw new ServiceException(\u0026#34;登录用户：\u0026#34; + username + \u0026#34; 不存在\u0026#34;); } else if (UserStatus.DELETED.getCode().equals(user.getDelFlag())) { log.info(\u0026#34;登录用户：{} 已被删除.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已被删除\u0026#34;); } else if (UserStatus.DISABLE.getCode().equals(user.getStatus())) { log.info(\u0026#34;登录用户：{} 已被停用.\u0026#34;, username); throw new ServiceException(\u0026#34;对不起，您的账号：\u0026#34; + username + \u0026#34; 已停用\u0026#34;); } passwordService.validate(user); return createLoginUser(user); } public UserDetails createLoginUser(SysUser user) { return new LoginUser(user.getUserId(), user, permissionService.getMenuPermission(user)); } PermissionService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 获取菜单数据权限 * * @param user 用户信息 * @return 菜单权限信息 */ public Set\u0026lt;String\u0026gt; getMenuPermission(SysUser user) { Set\u0026lt;String\u0026gt; perms = new HashSet\u0026lt;String\u0026gt;(); // 管理员拥有所有权限 if (user.isAdmin()) { perms.add(\u0026#34;*:*:*\u0026#34;); } else { List\u0026lt;SysRole\u0026gt; roles = user.getRoles(); if (!roles.isEmpty() \u0026amp;\u0026amp; roles.size() \u0026gt; 1) { // 多角色设置permissions属性，以便数据权限匹配权限 for (SysRole role : roles) { Set\u0026lt;String\u0026gt; rolePerms = menuService.selectMenuPermsByRoleId(role.getRoleId()); role.setPermissions(rolePerms); perms.addAll(rolePerms); } } else { perms.addAll(menuService.selectMenuPermsByUserId(user.getUserId())); } } return perms; } Mapper\n1 2 3 4 5 6 7 8 \u0026lt;select id=\u0026#34;selectMenuPermsByUserId\u0026#34; parameterType=\u0026#34;Long\u0026#34; resultType=\u0026#34;String\u0026#34;\u0026gt; select distinct m.perms from sys_menu m left join sys_role_menu rm on m.menu_id = rm.menu_id left join sys_user_role ur on rm.role_id = ur.role_id left join sys_role r on r.role_id = ur.role_id where m.status = \u0026#39;0\u0026#39; and r.status = \u0026#39;0\u0026#39; and ur.user_id = #{userId} \u0026lt;/select\u0026gt; 3.2 @PreAuthorize SpringSecurity为我们提供了基于注解的权限控制方案，这也是我们项目中主要采用的方式。我们可以使用注解去指定访问对应的资源所需的权限。\n但是要使用它我们需要先开启相关配置。\n1 @EnableGlobalMethodSecurity(prePostEnabled = true) 然后就可以使用对应的注解：@PreAuthorize\nSpringBoot - @PreAuthorize注解详解\n3.3 自定义权限 3.2.1 注解如何使用？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 状态修改 */ @PreAuthorize(\u0026#34;@ss.hasPermi(\u0026#39;system:user:edit\u0026#39;)\u0026#34;) @Log(title = \u0026#34;用户管理\u0026#34;, businessType = BusinessType.UPDATE) @PutMapping(\u0026#34;/status\u0026#34;) public ApiResponse changeStatus(@RequestBody SysUser user) { userService.checkUserAllowed(user); SysUser sysUser = new SysUser(); sysUser.setUserId(user.getUserId()); sysUser.setStatus(user.getStatus()); user.setUpdateBy(getUsername()); return affectRows(userService.updateUserStatus(user)); } 3.2.2 自定义权限实现 @PreAuthorize(\u0026quot;@ss.hasPermi('system:user:edit')\u0026quot;)的意思是什么？\nA. ss 是一个注册在 Spring容器中的Bean；\nB. hasPermi 是PermissionService类中定义的方法；\nC.当Spring EL 表达式返回True，则权限校验通过；\n在hasPermi方法中，获取当前用户权限loginUser.getPermissions()，与传入的permission作比较，看传入的permission是否在loginUser的permissions集合中\nPermissionService.java的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service(\u0026#34;ss\u0026#34;) public class PermissionService{ /** 所有权限标识 */ private static final String ALL_PERMISSION = \u0026#34;*:*:*\u0026#34;; /** 管理员角色权限标识 */ private static final String SUPER_ADMIN = \u0026#34;admin\u0026#34;; private static final String ROLE_DELIMETER = \u0026#34;,\u0026#34;; private static final String PERMISSION_DELIMETER = \u0026#34;,\u0026#34;; /** * 验证用户是否具备某权限 * * @param permission 权限字符串 * @return 用户是否具备某权限 */ public boolean hasPermi(String permission) { if (StringUtils.isEmpty(permission)) { return false; } LoginUser loginUser = SecurityUtils.getLoginUser(); if (StringUtils.isNull(loginUser) || CollectionUtils.isEmpty(loginUser.getPermissions())) { return false; } PermissionContextHolder.setContext(permission); return hasPermissions(loginUser.getPermissions(), permission); } } 3.2.3 如何使用原生的权限？ 3.4 前端权限校验 3.4.1 自定义指令-Directives 使用vue的自定义指令-Directives实现前端根据权限决定是否渲染操作组件\n创建操作权限Directive以及角色权限Directive\n根据用户拥有的permissions以及roles决定是否渲染被相应自定义组件标注的操作组件\nsrc/directive/permission/index.ts\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import type { Directive, DirectiveBinding } from \u0026#34;vue\u0026#34;; import useUserStore from \u0026#34;@/stores/modules/user\u0026#34;; /** * 操作权限处理 */ export const hasPermi: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const all_permission = \u0026#34;*:*:*\u0026#34;; const store = useUserStore(); const permissions = store.permissions; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const permissionFlag = value; const hasPermissions = permissions.some((permission: string) =\u0026gt; { return all_permission === permission || permissionFlag.includes(permission); }); if (!hasPermissions) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置操作权限标签值`); } } }; /** * 角色权限处理 */ export const hasRole: Directive = { mounted(el: HTMLElement, binding: DirectiveBinding) { const { value } = binding; const super_admin = \u0026#34;admin\u0026#34;; const store = useUserStore(); const roles = store.roles; if (value \u0026amp;\u0026amp; value instanceof Array \u0026amp;\u0026amp; value.length \u0026gt; 0) { const roleFlag = value; const hasRole = roles.some((role: string) =\u0026gt; { return super_admin === role || roleFlag.includes(role); }); if (!hasRole) { el.parentNode \u0026amp;\u0026amp; el.parentNode.removeChild(el); } } else { throw new Error(`请设置角色权限标签值\u0026#34;`); } } }; 3.4.2 全局注册自定义指令 src/directive/index.ts\n1 2 3 4 5 6 7 8 import { hasRole, hasPermi } from \u0026#34;./permission\u0026#34;; import type { App } from \u0026#34;@vue/runtime-core\u0026#34;; export default function directive(app: App) { app.directive(\u0026#34;hasRole\u0026#34;, hasRole); app.directive(\u0026#34;hasPermi\u0026#34;, hasPermi); } main.ts\n1 2 3 const app = createApp(App); import directive from \u0026#34;./directive\u0026#34;; // directive directive(app); 3.4.3 使用自定义指令 例如 v-hasPermi=\u0026quot;['system:role:add']\u0026quot;\n会根据当前用户是否具有 'system:role:add' 操作权限来决定是否渲染button\n1 2 3 4 5 6 7 8 \u0026lt;el-button type=\u0026#34;primary\u0026#34; plain icon=\u0026#34;Plus\u0026#34; style=\u0026#34;margin-right: 30px\u0026#34; @click=\u0026#34;handleAdd\u0026#34; v-hasPermi=\u0026#34;[\u0026#39;system:role:add\u0026#39;]\u0026#34; \u0026gt;新增角色\u0026lt;/el-button\u0026gt; ","permalink":"https://chance7bin.github.io/posts/design/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0/","summary":"0 引言 该篇文章是对Spring Security学习的总结，以及系统中认证授权的代码实现 参考链接 SpringSecurity-从入门到精通 1 Spring","title":"权限管理模块实现"},{"content":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象\n（2）创建工作区，有则不创建\n（3）创建数据源和发布图层服务\n（4）mapbox加载WMS服务\n3. Java代码 3.1 geoserver创建连接信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 String url = \u0026#34;http://172.21.212.240:8008/geoserver\u0026#34;; //geoserver的地址 String un = \u0026#34;admin\u0026#34;; //geoserver的账号 String pw = \u0026#34;geoserver\u0026#34;; //geoserver的密码 String workspace = \u0026#34;shapefile\u0026#34;; //工作区名称 String storename = \u0026#34;test\u0026#34;; //数据源名称 String layername = \u0026#34;bus_point\u0026#34;; //发布的图层名称，此名称必须和压缩包的名称一致 //shp文件压缩包，必须是zip压缩包，且shp文件(.shp、.dbf、.shx等)外层不能有文件夹，且压缩包名称需要与shp图层名称一致 String zipFilePath = \u0026#34;E:\\\\GIS_Data\\\\chengdu\\\\bus_point.zip\u0026#34;; // 1、获取geoserver连接对象 GeoServerRESTManager manager = null; try { manager = new GeoServerRESTManager(new URL(url) , un , pw); System.out.println(\u0026#34;连接geoserver服务器成功\u0026#34;); }catch (Exception e){ e.printStackTrace(); System.out.println(\u0026#34;geoserver服务器连接失败\u0026#34;); return; } 3.2 manager中重要的几个类对象 geoserver-manager中几个重要的类对象\n1.GeoServerRESTManager该对象是一个最大的管理者可以获取以下两个对象，创建数据存储\n2.GeoServerRESTPublisher，发布对象，用来发布各种数据和创建工作空间（主要用来创建对象）\n3.GeoServerRESTReader，获取数据存储、图层、样式、图层组等（主要用来获取信息）\n1 2 3 GeoServerRESTReader reader = manager.getReader(); GeoServerRESTPublisher publisher = manager.getPublisher(); GeoServerRESTStoreManager storeManager = manager.getStoreManager(); 3.3 创建工作区 1 2 3 4 5 6 7 8 9 // 2、判断是否有工作区，没有则创建 boolean b2 = reader.existsWorkspace(workspace); if(!b2){ boolean b = publisher.createWorkspace(workspace); if(!b){ System.out.println(\u0026#34;工作区创建失败\u0026#34;); return; } } 3.4 添加style样式 1 2 3 4 5 6 7 8 9 10 // style样式 String styleName = \u0026#34;styletest\u0026#34;; String styleSld; // 判断是否已经发布了style if (!reader.existsStyle(workspace, styleName)) { String styleFilePath = \u0026#34;Z:\\\\GIStone\\\\SuperMap\\\\Server\\\\webapps\\\\iserver\\\\WEB-INF\\\\config\\\\region.sld\u0026#34;; File styleFile = new File(styleFilePath); publisher.publishStyleInWorkspace(workspace, styleFile, styleName); } styleSld = reader.getSLD(workspace, styleName); style样式引入的sld文件。SLD是风格化图层描述器（Styled Layer Descriptor）的简称。SLD描述了如何在WMS规范的基础上进行扩展使之支持用户对要素数据进行自定义的符号化显示。SLD是一种基于XML语言的OGC标准。这表示SLD文件会被GeoServer创建并且能够被任何一种支持WMS的服务器软件所支持。我们不想限制大家渲染地图的方式，因此我们使用OGC标准规定的SLD作为GeoServer的渲染系统的核心。\n3.5 创建数据源 3.6 发布图层服务 创建数据源 和 发布图层服务可以一步进行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 3、判断是否有数据源，没有则创建 // 4、发布图层，如果存在就不发布 // 创建数据源 和 发布图层服务可以一步进行 RESTDataStore datastore = reader.getDatastore(workspace, storename); RESTLayer layer = reader.getLayer(workspace, layername); if(layer == null \u0026amp;\u0026amp; datastore == null){ File file = new File(zipFilePath); // 进行发布；参数依次为：工作区名称、数据源名称、图层名称、shp文件压缩文件对象、坐标系 boolean b = false; try { b = publisher.publishShp(workspace , storename , layername , file , GeoServerRESTPublisher.DEFAULT_CRS); } catch (FileNotFoundException e) { e.printStackTrace(); } if(!b){ System.out.println(\u0026#34;shp图层发布失败\u0026#34;); } else { System.out.println(\u0026#34;shp图层发布成功\u0026#34;); } } 3.7 发布完成 3.8 注意事项 layer图层的名称一定要与shp文件的名称一样。\n如果需要用到压缩文件，压缩文件只能为zip格式，不能是rar格式否则会报错，而且压缩文件的路径是全路径。\n参考链接\nJava将shp文件发布为geoserver服务\nJava实现GeoServer通过rest发布shp至WMS服务\n4. mapbox加载WMS WMS服务地址：\nworkspace：geoserver工作空间\nlayername：图层名称（与zip包以及其中的shp文件名称一直）\n1 \u0026#34;http://localhost:8008/geoserver/\u0026#34; + workspace + \u0026#34;/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=\u0026#34; + workspace + \u0026#34;:\u0026#34; + layername + \u0026#34;\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34;; html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXR...BIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ // \u0026#34;http://127.0.0.1:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;tiled=true\u0026amp;srsname=EPSG:4326\u0026#34; \u0026#39;http://localhost:8008/geoserver/shapefile/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=shapefile:bus_point\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#39; ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 效果预览\n参考链接\nMapBox加载GeoServer发布的WMS地图服务\nMapbox GL 加载GeoServer发布的WMS地图服务及点击查询\nopenLayers 坐标转换 EPSG:3857和EPSG:4326区别\n","permalink":"https://chance7bin.github.io/posts/map/java%E4%BD%BF%E7%94%A8geoserver%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1. 引入geoserver依赖 1 2 3 4 5 6 \u0026lt;!--geoserver依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;nl.pdok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geoserver-manager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0-pdok2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 流程 （1）创建geoserver连接对象","title":"Java使用Geoserver发布地图服务"},{"content":" XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。\nXSS 简介 举一个简单的例子，就是留言板。我们知道留言板通常的任务就是把用户留言的内容展示出来。正常情况下，用户的留言都是正常的语言文字，留言板显示的内容也就没毛病。然而这个时候如果有人不按套路出牌，在留言内容中丢进去一行\n1 \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; 那么留言板界面的网页代码就会变成形如以下：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Board\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;board\u0026#34;\u0026gt; \u0026lt;script\u0026gt;alert(\u0026#34;aaa\u0026#34;)\u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 那么这个时候问题就来了，当浏览器解析到用户输入的代码那一行时会发生什么呢？答案很显然，浏览器并不知道这些代码改变了原本程序的意图，会照做弹出一个信息框。\n既然能够执行脚本，那么，这些脚本完全可以是：\n链接劫持 1 \u0026lt;script\u0026gt;window.location.href=\u0026#34;http://www.baidu.com\u0026#34;;\u0026lt;/script\u0026gt; 盗取cookie 1 \u0026lt;script\u0026gt;alert(\u0026#34;document.cookie\u0026#34;);\u0026lt;/script\u0026gt; 对于攻击者来说，能够让受害者浏览器执行恶意代码的唯一方式，就是把代码注入到受害者从网站下载的网页中, 这就是xss攻击。\nXSS 攻击类型 通常XSS攻击分为：反射型xss攻击, 存储型xss攻击 和 DOM型xss攻击。同时注意以下例子只是简单的向你解释这三种类型的攻击方式而已，实际情况比这个复杂，具体可以再结合最后一节深入理解。\n反射型xss攻击 反射型的攻击需要用户主动的去访问带攻击的链接，攻击者可以通过邮件或者短信的形式，诱导受害者点开链接。如果攻击者配合短链接URL，攻击成功的概率会更高。\n在一个反射型XSS攻击中，恶意文本属于受害者发送给网站的请求中的一部分。随后网站又把恶意文本包含进用于响应用户的返回页面中，发还给用户。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\n存储型xss攻击 这种攻击方式恶意代码会被存储在数据库中，其他用户在正常访问的情况下，也有会被攻击，影响的范围比较大。\n1、攻击者通过评论表单提交将\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;提交到网站\n2、网站后端对提交的评论数据不做任何操作，直接存储到数据库中\n3、其他用户访问正常访问网站，并且需要请求网站的评论数据\n4、网站后端会从数据库中取出数据，直接返回给用户\n5、用户得到页面后，直接运行攻击者提交的代码\u0026lt;script\u0026gt;alert(‘aaa’)\u0026lt;/script\u0026gt;，所有用户都会在网页中弹出aaa的弹窗\nDOM型xss攻击 基于DOM的XSS攻击是反射型攻击的变种。服务器返回的页面是正常的，只是我们在页面执行js的过程中，会把攻击代码植入到页面中。\n1、用户误点开了带攻击的url : http://xxx?name=\u0026lt;script\u0026gt;alert('aaa')\u0026lt;/script\u0026gt;\n2、网站给受害者的返回中正常的网页\n3、用户的浏览器收到文本后执行页面合法脚本，这时候页面恶意脚本会被执行，会在网页中弹窗aaa\n这种攻击方式发生在我们合法的js执行中，服务器无法检测我们的请求是否有攻击的危险\nXSS 攻击的危害 通过document.cookie盗取cookie 使用js或css破坏页面正常的结构与样式 流量劫持（通过访问某段具有window.location.href定位到其他页面） Dos攻击：利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器响应。 利用iframe、frame、XMLHttpRequest或上述Flash等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作。 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。 DOS（拒绝服务）客户端浏览器。 钓鱼攻击，高级的钓鱼技巧。 劫持用户Web行为，甚至进一步渗透内网。 蠕虫式挂马攻击、刷广告、刷浏量、破坏网上数据 通过xss盗用cookie危害是什么？ csrf攻击其实是不能盗用cookie的，它只是以当前的名义进行恶意操作；而xss攻击是可以直接盗用cookie。\n那盗用cookie的危害是什么？比如拿到用户的cookie信息，然后传送到攻击者自己的服务器，从cookie中提取敏感信息，拿到用户的登录信息，或者攻击者可以通过修改DOM在页面上插入一个假的登陆框，也可以把表单的action属性指向他自己的服务器地址，然后欺骗用户提交自己的敏感信息。\n这就是为什么cookie也是要防御的\nXSS 攻击的防御 XSS攻击其实就是代码的注入。用户的输入被编译成恶意的程序代码。所以，为了防范这一类代码的注入，需要确保用户输入的安全性。对于攻击验证，我们可以采用以下两种措施：\n编码，就是转义用户的输入，把用户的输入解读为数据而不是代码 校验，对用户的输入及请求都进行过滤检查，如对特殊字符进行过滤，设置输入域的匹配规则等。 具体比如：\n对于验证输入，我们既可以在服务端验证，也可以在客户端验证 对于持久性和反射型攻击，服务端验证是必须的，服务端支持的任何语言都能够做到 对于基于DOM的XSS攻击，验证输入在客户端必须执行，因为从服务端来说，所有发出的页面内容是正常的，只是在客户端js代码执行的过程中才发生可攻击 但是对于各种攻击方式，我们最好做到客户端和服务端都进行处理。 其它还有一些辅助措施，比如：\n入参长度限制： 通过以上的案例我们不难发现xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过限制长度强制截断来进行防御。 设置cookie http-only为true 验证输入 自定义@Xss注解，将定义的Xss注解放在字段或者方法的上方\n@Xss注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 自定义xss校验注解 * * @author 7bin */ @Retention(RetentionPolicy.RUNTIME) @Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER }) @Constraint(validatedBy = { XssValidator.class }) public @interface Xss { String message() default \u0026#34;不允许任何脚本运行\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } 自定义校验器XssValidator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 自定义xss校验注解实现 * * @author 7bin */ public class XssValidator implements ConstraintValidator\u0026lt;Xss, String\u0026gt; { private static final String HTML_PATTERN = \u0026#34;\u0026lt;(\\\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt;\u0026#34;; @Override public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext) { if (StringUtils.isBlank(value)) { return true; } return !containsHtml(value); } public static boolean containsHtml(String value) { Pattern pattern = Pattern.compile(HTML_PATTERN); Matcher matcher = pattern.matcher(value); return matcher.matches(); } } 使用自定义Xss注解\n实体类\n1 2 3 4 5 6 7 8 9 10 public class SysUser extends BaseEntity { .... @Xss(message = \u0026#34;用户账号不能包含脚本字符\u0026#34;) @NotBlank(message = \u0026#34;用户账号不能为空\u0026#34;) @Size(min = 0, max = 30, message = \u0026#34;用户账号长度不能超过30个字符\u0026#34;) public String getUserName() { return userName; } } Controller\n在Controller的方法上，给参数SysUser类加上@Validated来修饰，这样校验就可以生效了\n1 2 3 4 5 @PutMapping public ApiResponse edit(@Validated @RequestBody SysUser user) { ... } escapeHTML 在服务端添加XSS的Filter，用于正确处理转义字符，产生正确的Java、JavaScript、HTML、XML和SQL代码\nFilterConfig：注册XSS过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Configuration public class FilterConfig { @Value(\u0026#34;${xss.excludes}\u0026#34;) private String excludes; @Value(\u0026#34;${xss.urlPatterns}\u0026#34;) private String urlPatterns; @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean @ConditionalOnProperty(value = \u0026#34;xss.enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;) public FilterRegistrationBean xssFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setDispatcherTypes(DispatcherType.REQUEST); registration.setFilter(new XssFilter()); registration.addUrlPatterns(StringUtils.split(urlPatterns, \u0026#34;,\u0026#34;)); registration.setName(\u0026#34;xssFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.HIGHEST_PRECEDENCE); Map\u0026lt;String, String\u0026gt; initParameters = new HashMap\u0026lt;String, String\u0026gt;(); initParameters.put(\u0026#34;excludes\u0026#34;, excludes); registration.setInitParameters(initParameters); return registration; } } XssFilter：使用自定义XssHttpServletRequestWrapper替换默认的request\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /** * 防止XSS攻击的过滤器 * * @author 7bin */ public class XssFilter implements Filter { /** * 排除链接 */ public List\u0026lt;String\u0026gt; excludes = new ArrayList\u0026lt;\u0026gt;(); @Override public void init(FilterConfig filterConfig) throws ServletException { String tempExcludes = filterConfig.getInitParameter(\u0026#34;excludes\u0026#34;); if (StringUtils.isNotEmpty(tempExcludes)) { String[] url = tempExcludes.split(\u0026#34;,\u0026#34;); for (int i = 0; url != null \u0026amp;\u0026amp; i \u0026lt; url.length; i++) { excludes.add(url[i]); } } } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; if (handleExcludeURL(req, resp)) { chain.doFilter(request, response); return; } XssHttpServletRequestWrapper xssRequest = new XssHttpServletRequestWrapper((HttpServletRequest) request); chain.doFilter(xssRequest, response); } private boolean handleExcludeURL(HttpServletRequest request, HttpServletResponse response) { String url = request.getServletPath(); String method = request.getMethod(); // GET DELETE 不过滤 if (method == null || HttpMethod.GET.matches(method) || HttpMethod.DELETE.matches(method)) { return true; } return StringUtils.matches(url, excludes); } @Override public void destroy() { } } XssHttpServletRequestWrapper\nxss过滤（清除所有HTML标签，但是不删除标签内的内容）：json = EscapeUtil.clean(json).trim();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 /** * XSS过滤处理 * * @author 7bin */ public class XssHttpServletRequestWrapper extends HttpServletRequestWrapper { /** * @param request */ public XssHttpServletRequestWrapper(HttpServletRequest request) { super(request); } @Override public String[] getParameterValues(String name) { String[] values = super.getParameterValues(name); if (values != null) { int length = values.length; String[] escapesValues = new String[length]; for (int i = 0; i \u0026lt; length; i++) { // 防xss攻击和过滤前后空格 escapesValues[i] = EscapeUtil.clean(values[i]).trim(); } return escapesValues; } return super.getParameterValues(name); } @Override public ServletInputStream getInputStream() throws IOException { // 非json类型，直接返回 if (!isJsonRequest()) { return super.getInputStream(); } // 为空，直接返回 String json = IOUtils.toString(super.getInputStream(), \u0026#34;utf-8\u0026#34;); if (StringUtils.isEmpty(json)) { return super.getInputStream(); } // xss过滤 json = EscapeUtil.clean(json).trim(); byte[] jsonBytes = json.getBytes(\u0026#34;utf-8\u0026#34;); final ByteArrayInputStream bis = new ByteArrayInputStream(jsonBytes); return new ServletInputStream() { @Override public boolean isFinished() { return true; } @Override public boolean isReady() { return true; } @Override public int available() throws IOException { return jsonBytes.length; } @Override public void setReadListener(ReadListener readListener) { } @Override public int read() throws IOException { return bis.read(); } }; } /** * 是否是Json请求 * */ public boolean isJsonRequest() { String header = super.getHeader(HttpHeaders.CONTENT_TYPE); return StringUtils.startsWithIgnoreCase(header, MediaType.APPLICATION_JSON_VALUE); } } http-only 如果某一个Cookie 选项被设置成 HttpOnly = true 的话，那此Cookie 只能通过服务器端修改，JS 是操作不了的，对于 document.cookie 来说是透明的。\nhttp-only 的应用场景是防止 XSS 攻击。\n举例：\n例如我在评论区写了一段 hack JS，服务端因存在 XSS 漏洞，没有对 \u0026lt; 进行转义。导致这段 JS 在其他人打开此页面的时候也被执行了。\n如果我上面的 hack JS 中写了获取所有 cookie，并发送到我的服务器上，这样用户的登录信息就泄漏了。\n如果 cookie 开启了 http-only 之后，我的hack js 无法获取到用户的 cookie，它们的登录信息就无法泄漏了。\n以 Google 翻译为例子，初次打开时，Cookie里面是这样的一共有4条记录，注意第二个最右侧倒数第三个字段有一个√， 这个对勾表明这条记录是 HttpOnly = true 的，对于Js，你是拿不到的。\n服务端设置Cookie\n1 2 3 4 5 6 7 8 9 10 @RequestMapping(\u0026#34;/login\u0026#34;) @ResponseBody public void login(HttpServletRequest request, HttpServletResponse response) throws IOException { Cookie cookie = new Cookie(\u0026#34;access_token\u0026#34;, UUID.randomUUID().toString()); cookie.setHttpOnly(true); // 这里 cookie.setPath(\u0026#34;/\u0026#34;); cookie.setDomain(\u0026#34;localhost\u0026#34;); response.addCookie(cookie); response.sendRedirect(\u0026#34;http://localhost:8088/index.html\u0026#34;); } xss攻击和csrf攻击配合 一般攻击可能不是单一的行为，而是可能会组合攻击；比如xss攻击一般还可以配合csrf攻击进行配合攻击，这里给个例子，方便你理解；注意，只是仅仅方便你理解，实际不是这么简单。\n假设你可以通过如下GET请求方式进行修改密码，这是典型的csrf攻击方式：开发安全 - CSRF 详解\n1 2 http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change 那么你可以通过如下方式xss攻击添加脚本\n1 2 \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;http://127.0.0.1/test/vulnerabilities/csrf/? password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change#\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 参考链接\n开发安全 - XSS 详解\n","permalink":"https://chance7bin.github.io/posts/design/xss/","summary":"XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为X","title":"xss"},{"content":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\nCache Aside Pattern（旁路缓存模式） Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n缓存一致性问题 并发引发的一致性问题 2 个线程并发「读写」数据：\n缓存中 X 不存在（数据库 X = 1） 线程 A 读取数据库，得到旧值（X = 1） 线程 B 更新数据库（X = 2) 线程 B 删除缓存 线程 A 将旧值写入缓存（X = 1） 最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。\n这种情况「理论」来说是可能发生的，其实概率「很低」，这是因为它必须满足 3 个条件：\n缓存刚好已失效 读请求 + 写请求并发 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5） 为了避免这种情况的发生，采取写数据库时「加锁」的方式，防止其它线程对缓存读取和更改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); map.clear(); return rows; } finally { lock.writeLock().unlock(); } } public T queryOne(Class\u0026lt;T\u0026gt; beanClass, String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加读锁, 防止其它线程对缓存更改 lock.readLock().lock(); try { T value = map.get(key); if (value != null) { return value; } } finally { lock.readLock().unlock(); } // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { // get 方法上面部分是可能多个线程进来的, 可能已经向缓存填充了数据 // 为防止重复查询数据库, 再次验证 T value = map.get(key); if (value == null) { // 如果没有, 查询数据库 value = genericDao.queryOne(beanClass, sql, params); map.put(key, value); } return value; } finally { lock.writeLock().unlock(); } } 通过上述加锁的逻辑，采取「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的\n删除缓存失败引发的一致性问题 「先更新数据库 + 再删除缓存」中第二步执行「失败」导致数据不一致的问题\n如何保证两步都执行成功？\n答案是：重试。\n最佳实线是采取异步重试的方案\n把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。\n或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。\n删除缓存操作投递到消息队列中 所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：\n代码实现\n采取的是RabbitMQ作为消息队列\n更新业务\n清除缓存操作交给rabbitmq listener处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); // map.clear(); MqUtils.sendRedisKeyToMq(key); // 清除缓存操作交给rabbitmq listener处理 return rows; } finally { lock.writeLock().unlock(); } } MqUtils\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class MqUtils { /** * redis键 * @param redisKey redis键 * @author 7bin **/ public static void sendRedisKeyToMq(String redisKey){ // 1.准备消息 Message message = MessageBuilder .withBody(redisKey.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.NON_PERSISTENT) .build(); // 2.发送消息 RabbitTemplate rabbitTemplate = SpringUtils.getBean(\u0026#34;rabbitTemplate\u0026#34;); rabbitTemplate.convertAndSend(\u0026#34;redis.queue\u0026#34;, message); } } RabbitMqListener\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(queues = \u0026#34;redis.queue\u0026#34;) public void listenRedisQueue(String msg) { log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, msg); redisCache.del(msg); } } yml配置\n开启重试机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spring: rabbitmq: host: 172.21.212.177 # rabbitMQ的ip地址 port: 5672 # 端口 username: binbin password: binbin virtual-host: / # 虚拟主机 listener: simple: prefetch: 1 # 每次从MQ中取出一条消息进行消费 acknowledge-mode: auto # 自动确认 retry: enabled: true # 开启重试机制 initial-interval: 1000 # 重试间隔时间 multiplier: 3 # 重试倍数 max-attempts: 4 # 最大重试次数 数据库更新日志投递到消息队列中 那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？\n方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。\n具体来讲就是，我们的业务应用在修改数据时，==「只需」修改数据库，无需操作缓存==。\n那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。\n拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。\n订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：\n无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列 canal代码示例\n代码实现\nrabbitmq+canal\n首先配置Mysql整合rabbit\n参考链接：https://blog.csdn.net/qq_37487520/article/details/126078570\nmq队列监听代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Slf4j @Component public class RabbitMqListener { @Autowired private RedisCache redisCache; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;canal.queue\u0026#34;), exchange = @Exchange(name = \u0026#34;canal.fanout\u0026#34;, type = ExchangeTypes.FANOUT), key = {\u0026#34;canal\u0026#34;} )) public void listenCanalQueue(Message mqMessage, Channel channel) { String message = new String(mqMessage.getBody(), StandardCharsets.UTF_8); // 解析message转换成CanalMessage对象 CanalMessage canalMessage = JSONUtil.toBean(message, CanalMessage.class); String type = canalMessage.getType(); if (type == null) { log.info (\u0026#34;unknown type {}\u0026#34;, canalMessage.getType()); return; } if (type.equals(\u0026#34;INSERT\u0026#34;) || type.equals(\u0026#34;UPDATE\u0026#34;) || type.equals(\u0026#34;DELETE\u0026#34;)) { handleRedisCache(canalMessage.getTable(), canalMessage.getData()); } else { log.info(\u0026#34;ignore type {}\u0026#34;, canalMessage.getType()); } } private void handleRedisCache(String tableName, Object data) { // 根据表名和字段名获取缓存key String key = getKey(tableName, data); redisCache.del(key); log.info(\u0026#34;清除缓存: [ key: {} ]\u0026#34;, key); } String getKey(String tableName, Object data) { // 构建redis key的逻辑 } } 下面是不走消息队列，直接通过cannal监听MySQL的变化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @Slf4j @Component public class MysqlDataListening { private static final ThreadFactory springThreadFactory = new CustomizableThreadFactory(\u0026#34;canal-pool-\u0026#34;); private static final ExecutorService executors = Executors.newFixedThreadPool(1, springThreadFactory); @Autowired RedisCache redisCache; @PostConstruct private void startListening() { executors.submit(() -\u0026gt; { connector(); }); } void connector(){ log.info(\u0026#34;start listening mysql data change...\u0026#34;); // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(), 11111), \u0026#34;example\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); int batchSize = 1000; int emptyCount = 0; try { connector.connect(); connector.subscribe(\u0026#34;.*\\\\..*\u0026#34;); connector.rollback(); int totalEmptyCount = 120; // while (emptyCount \u0026lt; totalEmptyCount) { while (true) { Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) { // emptyCount++; // System.out.println(\u0026#34;empty count : \u0026#34; + emptyCount); try { Thread.sleep(1000); } catch (InterruptedException e) { } } else { // emptyCount = 0; // System.out.printf(\u0026#34;message[batchId=%s,size=%s] \\n\u0026#34;, batchId, size); printEntry(message.getEntries()); } connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 } // System.out.println(\u0026#34;empty too many times, exit\u0026#34;); } finally { connector.disconnect(); } } private void printEntry(List\u0026lt;Entry\u0026gt; entrys) { for (Entry entry : entrys) { if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) { continue; } RowChange rowChage = null; try { rowChage = RowChange.parseFrom(entry.getStoreValue()); } catch (Exception e) { throw new RuntimeException(\u0026#34;ERROR ## parser of eromanga-event has an error , data:\u0026#34; + entry.toString(), e); } EventType eventType = rowChage.getEventType(); for (RowData rowData : rowChage.getRowDatasList()) { if (eventType == EventType.DELETE || eventType == EventType.UPDATE || eventType == EventType.INSERT) { // 增删改操作删除redis缓存 // printColumn(rowData.getAfterColumnsList()); handleRedisCache(entry.getHeader().getTableName(), rowData.getAfterColumnsList()); } else { // 其他操作 // System.out.println(\u0026#34;-------\u0026amp;gt; before\u0026#34;); // printColumn(rowData.getBeforeColumnsList()); // System.out.println(\u0026#34;-------\u0026amp;gt; after\u0026#34;); // printColumn(rowData.getAfterColumnsList()); } } } } private void printColumn(List\u0026lt;Column\u0026gt; columns) { for (Column column : columns) { log.info(column.getName() + \u0026#34; : \u0026#34; + column.getValue() + \u0026#34; update=\u0026#34; + column.getUpdated()); } } private void handleRedisCache(String tableName, List\u0026lt;CanalEntry.Column\u0026gt; columns) { // 根据表名和字段名获取缓存key String key = getKey(tableName, columns); redisCache.del(key); } } 实现参考\nmysql与缓存数据不一致解决-canal+mq方案\n通过上述的解决方案基本可以实现缓存与数据库的一致性\n参考链接\n缓存和数据库一致性问题，看这篇就够了\n","permalink":"https://chance7bin.github.io/posts/design/redis%E5%92%8Cmysql%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%AE%9E%E7%8E%B0/","summary":"背景 如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的： 但随着业务量的增长，你的项","title":"redis和mysql缓存一致性实现"},{"content":" 本篇文章主要内容是分片上传、断点续传、秒传的实现思路\n前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前端先发送check-file（检查文件MD5）来确认文件是直接秒传还是分片上传，如果计算出文件所有片已经上传完成，则启用秒传（秒传就是不传），如果是新文件，则需要分片上传，由vue-simple-uploader插件将文件按固定大小进行切割，然后逐片上传。\n断点续传： 意思就是一个大文件分了多少片，这些片已经上传了哪些，还有哪些没上传，这些都会记录在文件存储目录下的.conf文件中，当你上传大文件时，传一部分后刷新浏览器或关闭浏览器，这时候传输会中断，然后你再打开页面重新上传该文件，它会先检测还有哪些片没有上传，然后直接上传的上次未传的片，这就是断点续传。\n**秒传：**文件不经过上传的步骤，直接将文件信息保存在服务器中。通过计算文件md5实现\n流程 校验文件上传状态： 前端生成该文件的MD5密文并进行分片，上传之前请求check-md5接口，传入文件名和密文，接口校验文件是未上传 或 上传了一部分 或 已上传完成三个状态，其中未上传返回自定义状态码404，上传一部分则返回状态206+未上传的分片ID，上传完成则返回状态200。 前端逐片上传： 校验完成后，根据校验结果对未上传的分片进行逐个上传，上传分片时参数主要是：总片数、当前片ID、片文件 上传接口： 上传接口会先去获取并解析该文件的conf文件（conf文件是RandomAccessFile，该类是通过提供指针的方式操作文件，文件存储的是一个二进制数组，所以可以用来数组下标标记片ID），使用setLength方法设置conf文件长度，使用seek方法跳到当前上传的片ID的位置，把该位置的值替换成127，然后将该分片使用指针偏移的方式插入到_tmp临时文件（临时文件也是RandomAccessFile文件）中，然后校验是否所有的片都上传完成，是则修改临时文件为正式文件名，至此上传完成，否则直接返回该分片上传完成 上传进度： 前端收到当前片的响应结果后，会根据已上传片数量获取到上传进度 MD5的用法： 用于计算服务器是否已经存在相同md5的文件，用作秒传功能的实现。前端计算文件md5，传入后端进行查找是否已经有相同md5文件，若存在直接返回上传成功，否则走上传的步骤 后端接口 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 /** * 检查文件MD5（文件MD5若已存在进行秒传） * * @param md5 md5 * @param fileName 文件名称 * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/check\u0026#34;) public ApiResponse checkFileMd5(String md5, String fileName) { // Result result = fileService.checkFileMd5(md5, fileName); // return NovelWebUtils.forReturn(result); return ApiResponse.success(); } /** * 断点续传方式上传文件：用于大文件上传 * * @param chunkDTO 参数 * @param request 请求 * @return {@link ApiResponse} * @author 7bin **/ @PostMapping(value = \u0026#34;/breakpoint-upload\u0026#34;, consumes = \u0026#34;multipart/*\u0026#34;, headers = \u0026#34;content-type=multipart/form-data\u0026#34;, produces = \u0026#34;application/json;charset=UTF-8\u0026#34;) public ApiResponse breakpointResumeUpload(Chunk chunkDTO, HttpServletRequest request) { String id = chunkDTO.getIdentifier(); int chunks = Math.toIntExact(chunkDTO.getTotalChunks()); int chunk = chunkDTO.getChunkNumber() - 1; long size = chunkDTO.getCurrentChunkSize(); String name = chunkDTO.getFilename(); MultipartFile file = chunkDTO.getFile(); String md5 = chunkDTO.getIdentifier(); UploadFileParam param = new UploadFileParam(id, chunks, chunk, size, name, file, md5); // return ApiResponse.success(); Result result = fileService.breakpointResumeUpload(param, request); return NovelWebUtils.forReturn(result); } /** * 检查文件MD5（文件MD5若已存在进行秒传） * @param chunkMap * @return {@link ApiResponse} * @author 7bin **/ @GetMapping(value = \u0026#34;/breakpoint-upload\u0026#34;) public ApiResponse breakpointResumeUploadPre( @RequestParam Map\u0026lt;String, String\u0026gt; chunkMap) { String md5 = chunkMap.get(\u0026#34;identifier\u0026#34;); String filename = chunkMap.get(\u0026#34;filename\u0026#34;); Result\u0026lt;JSONArray\u0026gt; result = fileService.checkFileMd5(md5, filename); JSONObject res = new JSONObject(); // 数据库中存在该md5则秒传 if (result == null){ res.put(\u0026#34;skipUpload\u0026#34;,true); return ApiResponse.success(res); } boolean skipUpload = false; if (\u0026#34;200\u0026#34;.equals(result.getCode()) || \u0026#34;201\u0026#34;.equals(result.getCode())) { skipUpload = true; } else if (\u0026#34;206\u0026#34;.equals(result.getCode())) { // 已经上传部分分块 // data中存放的是还未上传的分块 JSONArray data = result.getData(); res.put(\u0026#34;missChunks\u0026#34;,data); } res.put(\u0026#34;skipUpload\u0026#34;,skipUpload); return ApiResponse.success(res); // Result result = fileService.breakpointResumeUpload(param, request); // return NovelWebUtils.forReturn(result); } Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Override public Result\u0026lt;JSONArray\u0026gt; checkFileMd5(String md5, String fileName) { boolean exist = fileMapper.fileIsExist(md5); if (exist){ return null; } Result\u0026lt;JSONArray\u0026gt; result; try { // String realFilename = md5 + \u0026#34;_\u0026#34; + fileName; String realFilename = md5; result = LocalUpload.checkFileMd5(md5, realFilename, confFilePath, savePath); } catch (Exception e) { // e.printStackTrace(); log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } @Override public Result breakpointResumeUpload(UploadFileParam param, HttpServletRequest request) { Result result; try { // 这里的 chunkSize(分片大小) 要与前端传过来的大小一致 // long chunkSize = Objects.isNull(param.getChunkSize()) ? 5 * 1024 * 1024 // : param.getChunkSize(); // 实际存储的文件格式为 [{md5}_{filename}] // String realFilename = param.getMd5() + \u0026#34;_\u0026#34; + param.getName(); String realFilename = param.getMd5(); param.setName(realFilename); result = LocalUpload.fragmentFileUploader(param, confFilePath, savePath, 5242880L, request); // return NovelWebUtils.forReturn(result); } catch (Exception e) { log.error(e.getMessage()); throw new ServiceException(e.getMessage()); } return result; } 前端代码 SimpleUploader.vue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 \u0026lt;template\u0026gt; \u0026lt;div id=\u0026#34;global-uploader\u0026#34;\u0026gt; \u0026lt;uploader class=\u0026#34;uploader-app\u0026#34; :options=\u0026#34;initOptions\u0026#34; :file-status-text=\u0026#34;fileStatusText\u0026#34; :auto-start=\u0026#34;false\u0026#34; @file-added=\u0026#34;onFileAdded\u0026#34; @file-success=\u0026#34;onFileSuccess\u0026#34; @file-progress=\u0026#34;onFileProgress\u0026#34; @file-error=\u0026#34;onFileError\u0026#34; \u0026gt; \u0026lt;uploader-unsupport\u0026gt;\u0026lt;/uploader-unsupport\u0026gt; \u0026lt;uploader-drop\u0026gt; \u0026lt;uploader-btn \u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt; \u0026lt;span style=\u0026#34;margin-left: 10px\u0026#34;\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt; \u0026lt;!--\u0026lt;uploader-btn directory\u0026gt;上传文件夹 \u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;/uploader-drop\u0026gt; \u0026lt;!--\u0026lt;uploader-btn id=\u0026#34;global-uploader-btn\u0026#34; ref=\u0026#34;uploadBtnRef\u0026#34;\u0026gt;选择文件\u0026lt;/uploader-btn\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;span\u0026gt;（支持上传一个或多个文件）\u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;uploader-list\u0026gt; \u0026lt;template #default=\u0026#34;{ fileList }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;file-panel\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;div class=\u0026#34;file-title\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;div class=\u0026#34;title\u0026#34;\u0026gt;文件列表\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;/div\u0026gt;--\u0026gt; \u0026lt;ul class=\u0026#34;file-list\u0026#34;\u0026gt; \u0026lt;li v-for=\u0026#34;file in fileList\u0026#34; :key=\u0026#34;file.id\u0026#34; class=\u0026#34;file-item\u0026#34; \u0026gt; \u0026lt;uploader-file ref=\u0026#34;files\u0026#34; :class=\u0026#34;[\u0026#39;file_\u0026#39; + file.id, customStatus]\u0026#34; :file=\u0026#34;file\u0026#34; :list=\u0026#34;true\u0026#34; \u0026gt;\u0026lt;/uploader-file\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;div v-if=\u0026#34;!fileList.length\u0026#34; class=\u0026#34;no-file\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;Icon icon=\u0026#34;ri:file-3-line\u0026#34; width=\u0026#34;16\u0026#34; /\u0026gt; 暂无待上传文件--\u0026gt; 暂无待上传文件 \u0026lt;/div\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;/uploader-list\u0026gt; \u0026lt;/uploader\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import useCurrentInstance from \u0026#34;@/utils/currentInstance\u0026#34;; import { generateMD5 } from \u0026#34;@/components/Uploader/utils/md5\u0026#34;; import { ElNotification } from \u0026#34;element-plus\u0026#34;; import { addFileToDrive } from \u0026#34;@/api/drive/drive\u0026#34;; import { checkAuth } from \u0026#34;@/api/admin/user\u0026#34;; const { proxy } = useCurrentInstance(); // TODO 上传组件还有bug 上传成功时动作按钮没有隐藏；后端出现错误上传失败时背景色没变红 // props // emits const emits = defineEmits([\u0026#39;uploadSuccess\u0026#39;]); const drivePath = import.meta.env.VITE_APP_DRIVE_API; const initOptions = { target: drivePath + \u0026#34;/file/breakpoint-upload\u0026#34;, chunkSize: \u0026#39;5242880\u0026#39;, forceChunkSize: true, fileParameterName: \u0026#39;file\u0026#39;, maxChunkRetries: 3, // 是否开启服务器分片校验 testChunks: true, // 服务器分片校验函数，秒传及断点续传基础 checkChunkUploadedByResponse: function (chunk, message) { let skip = false // console.log(\u0026#34;checkChunkUploadedByResponse chunk:\u0026#34;, chunk); // console.log(\u0026#34;checkChunkUploadedByResponse message:\u0026#34;, message); try { let objMessage = JSON.parse(message) // console.log(\u0026#34;objMessage:\u0026#34;, objMessage); if (objMessage.code === 200) { if (objMessage.data.skipUpload) { skip = true } else if (objMessage.data.missChunks == null){ skip = false; } else { skip = (objMessage.data.missChunks || []).indexOf(chunk.offset.toString()) \u0026lt; 0 } } } catch (e) {} // console.log(\u0026#34;skip: \u0026#34; + chunk.offset + \u0026#34; \u0026#34; + skip); return skip }, query: (file, chunk) =\u0026gt; { // console.log(\u0026#34;query:\u0026#34;, file); return { ...file.params } } } const customStatus = ref(\u0026#39;\u0026#39;) const fileStatusText = { success: \u0026#39;上传成功\u0026#39;, error: \u0026#39;上传失败\u0026#39;, uploading: \u0026#39;上传中\u0026#39;, paused: \u0026#39;已暂停\u0026#39;, waiting: \u0026#39;等待上传\u0026#39; } // const uploaderRef = ref() // const uploader = computed(() =\u0026gt; uploaderRef.value?.uploader) async function onFileAdded(file) { // 判断用户是否已经登录了，登录才可以添加 await checkAuth(); // 暂停文件 // 选择文件后暂停文件上传，上传时手动启动 file.pause() // console.log(\u0026#34;onFileAdded file: \u0026#34;, file); // panelShow.value = true // trigger(\u0026#39;fileAdded\u0026#39;) // 将额外的参数赋值到每个文件上，以不同文件使用不同params的需求 // file.params = customParams.value // 计算MD5 const md5 = await computeMD5(file) startUpload(file, md5) } function computeMD5(file) { // 文件状态设为\u0026#34;计算MD5\u0026#34; statusSet(file.id, \u0026#39;md5\u0026#39;) // 计算MD5时隐藏\u0026#34;开始\u0026#34;按钮 nextTick(() =\u0026gt; { // document.querySelector(`.file_${file.id} .uploader-file-resume`).style.display = \u0026#39;none\u0026#39; document.querySelector(`.file_${file.id} .uploader-file-actions`).style.display = \u0026#39;none\u0026#39; }) // 开始计算MD5 return new Promise((resolve, reject) =\u0026gt; { generateMD5(file, { onProgress(currentChunk, chunks) { // 实时展示MD5的计算进度 nextTick(() =\u0026gt; { const md5ProgressText = \u0026#39;校验MD5 \u0026#39; + ((currentChunk / chunks) * 100).toFixed(0) + \u0026#39;%\u0026#39; document.querySelector(`.custom-status-${file.id}`).innerText = md5ProgressText }) }, onSuccess(md5) { statusRemove(file.id) resolve(md5) }, onError() { error(`文件${file.name}读取出错，请检查该文件`) file.cancel() statusRemove(file.id) reject() } }) }) } // md5计算完毕，开始上传 function startUpload(file, md5) { file.uniqueIdentifier = md5 file.resume() } function onFileProgress(rootFile, file, chunk) { console.log( `上传中 ${file.name}，chunk：${chunk.startByte / 1024 / 1024} ~ ${ chunk.endByte / 1024 / 1024 }` ) } const onFileError = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#39;error\u0026#39;, file) error(response) } function error(msg) { ElNotification({ title: \u0026#39;错误\u0026#39;, message: msg, type: \u0026#39;error\u0026#39;, duration: 2000 }) } const onFileSuccess = (rootFile, file, response, chunk) =\u0026gt; { // console.log(\u0026#34;上传成功\u0026#34;) // console.log(\u0026#34;rootFile\u0026#34;,rootFile) // file的relativePath是文件夹的相对路径(如果上传的是文件夹的话) // console.log(\u0026#34;file\u0026#34;,file) // console.log(\u0026#34;response\u0026#34;,JSON.parse(response)) // console.log(\u0026#34;chunk\u0026#34;,chunk) // addFileToDrive(file.name, file.uniqueIdentifier, file.size).then(() =\u0026gt; { // proxy.$modal.msgSuccess(\u0026#34;文件上传成功\u0026#34;); // }) // 服务端自定义的错误（即http状态码为200，但是是错误的情况），这种错误是Uploader无法拦截的 let res = JSON.parse(response) console.log(\u0026#34;onFileSuccess res:\u0026#34;, res); if (res.code !== 200) { error(res.message) // 文件状态设为“失败” statusSet(file.id, \u0026#39;failed\u0026#39;) return } emits(\u0026#34;uploadSuccess\u0026#34;, file); } /** * 新增的自定义的状态: \u0026#39;md5\u0026#39;、\u0026#39;merging\u0026#39;、\u0026#39;transcoding\u0026#39;、\u0026#39;failed\u0026#39; * @param id * @param status */ function statusSet(id, status) { const statusMap = { md5: { text: \u0026#39;校验MD5\u0026#39;, bgc: \u0026#39;#fff\u0026#39; }, failed: { text: \u0026#39;上传失败\u0026#39;, bgc: \u0026#39;#e2eeff\u0026#39; } } customStatus.value = status nextTick(() =\u0026gt; { const statusTag = document.createElement(\u0026#39;span\u0026#39;) statusTag.className = `custom-status-${id} custom-status` statusTag.innerText = statusMap[status].text statusTag.style.backgroundColor = statusMap[status].bgc // custom-status 样式不生效 // 由于 style脚本 设置了 scoped，深层的样式修改不了 // 通过给当前组件设置一个id，在该id下设置样式，就可以保证样式不全局污染 // statusTag.style.position = \u0026#39;absolute\u0026#39;; // statusTag.style.top = \u0026#39;0\u0026#39;; // statusTag.style.left = \u0026#39;0\u0026#39;; // statusTag.style.right = \u0026#39;0\u0026#39;; // statusTag.style.bottom = \u0026#39;0\u0026#39;; // statusTag.style.zIndex = \u0026#39;1\u0026#39;; const statusWrap = document.querySelector(`.file_${id} .uploader-file-status`) statusWrap.appendChild(statusTag) }) } function statusRemove(id) { customStatus.value = \u0026#39;\u0026#39; nextTick(() =\u0026gt; { const statusTag = document.querySelector(`.custom-status-${id}`) document.querySelector(`.file_${id} .uploader-file-actions`).style.display = \u0026#39;block\u0026#39; statusTag.remove() }) } \u0026lt;/script\u0026gt; md5.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import SparkMD5 from \u0026#39;spark-md5\u0026#39; /** * 分段计算MD5 * @param file {File} * @param options {Object} - onProgress | onSuccess | onError */ export function generateMD5(file, options = {}) { const fileReader = new FileReader() const time = new Date().getTime() const blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice const chunkSize = 10 * 1024 * 1000 const chunks = Math.ceil(file.size / chunkSize) let currentChunk = 0 const spark = new SparkMD5.ArrayBuffer() const loadNext = () =\u0026gt; { let start = currentChunk * chunkSize let end = start + chunkSize \u0026gt;= file.size ? file.size : start + chunkSize fileReader.readAsArrayBuffer(blobSlice.call(file.file, start, end)) } loadNext() fileReader.onload = (e) =\u0026gt; { spark.append(e.target.result) if (currentChunk \u0026lt; chunks) { currentChunk++ loadNext() if (options.onProgress \u0026amp;\u0026amp; typeof options.onProgress == \u0026#39;function\u0026#39;) { options.onProgress(currentChunk, chunks) } } else { let md5 = spark.end() // md5计算完毕 if (options.onSuccess \u0026amp;\u0026amp; typeof options.onSuccess == \u0026#39;function\u0026#39;) { options.onSuccess(md5) } console.log( `MD5计算完毕：${file.name} \\nMD5：${md5} \\n分片：${chunks} 大小:${file.size} 用时：${ new Date().getTime() - time } ms` ) } } fileReader.onerror = function () { console.log(\u0026#39;MD5计算失败\u0026#39;) if (options.onError \u0026amp;\u0026amp; typeof options.onError == \u0026#39;function\u0026#39;) { options.onError() } } } ","permalink":"https://chance7bin.github.io/posts/design/%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0/","summary":"本篇文章主要内容是分片上传、断点续传、秒传的实现思路 前言 分片： 分片任务是在前端由vue-simple-uploader插件完成，流程：1.前","title":"断点续传"},{"content":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自己进行防止重复提交的逻辑又显得不是十分优雅了，所以，我们就将对应的逻辑抽出来形成一个注解，方便我们的使用。\n设计思路 根据提交的参数跟间隔时间到缓存中查询，判断两次提交的参数是否相同，如果相同且在间隔时间内则算作是重复提交\nRepeatSubmit注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 自定义注解防止表单重复提交 * * @author 7bin * @date 2023/06/13 */ @Inherited @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RepeatSubmit { /** * 间隔时间(ms)，小于此时间视为重复提交 */ public int interval() default 5000; /** * 提示消息 */ public String message() default \u0026#34;不允许重复提交，请稍候再试\u0026#34;; } 定义拦截器 首先我们定义了一个抽象类RepeatSubmitInterceptor，对preHandle方法进行了定义，判断方法上是否存在RepeatSubmit 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Component public abstract class RepeatSubmitInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); RepeatSubmit annotation = method.getAnnotation(RepeatSubmit.class); if (annotation != null) { if (this.isRepeatSubmit(request, annotation)) { ApiResponse ajaxResult = ApiResponse.error(annotation.message()); ServletUtils.renderString(response, JSON.toJSONString(ajaxResult)); return false; } } return true; } else { return true; } } /** * 验证是否重复提交由子类实现具体的防重复提交的规则 * * @param request * @return * @throws Exception */ public abstract boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation); } 子类中实现父类的isRepeatSubmit方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 /** * 判断请求url和数据是否和上一次相同， * 如果和上次相同，则是重复提交表单。 有效时间为5秒内。 */ @Component public class SameUrlDataInterceptor extends RepeatSubmitInterceptor { public final String REPEAT_PARAMS = \u0026#34;repeatParams\u0026#34;; public final String REPEAT_TIME = \u0026#34;repeatTime\u0026#34;; // 令牌自定义标识 @Value(\u0026#34;${token.header}\u0026#34;) private String header; @Autowired private RedisCache redisCache; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) @Override public boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation) { String nowParams = \u0026#34;\u0026#34;; if (request instanceof RepeatedlyRequestWrapper) { RepeatedlyRequestWrapper repeatedlyRequest = (RepeatedlyRequestWrapper) request; nowParams = HttpHelper.getBodyString(repeatedlyRequest); } // body参数为空，获取Parameter的数据 if (StringUtils.isEmpty(nowParams)) { nowParams = JSON.toJSONString(request.getParameterMap()); } Map\u0026lt;String, Object\u0026gt; nowDataMap = new HashMap\u0026lt;String, Object\u0026gt;(); nowDataMap.put(REPEAT_PARAMS, nowParams); nowDataMap.put(REPEAT_TIME, System.currentTimeMillis()); // 请求地址（作为存放cache的key值） String url = request.getRequestURI(); // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; Object sessionObj = redisCache.getCacheObject(cacheRepeatKey); if (sessionObj != null) { Map\u0026lt;String, Object\u0026gt; sessionMap = (Map\u0026lt;String, Object\u0026gt;) sessionObj; if (sessionMap.containsKey(url)) { Map\u0026lt;String, Object\u0026gt; preDataMap = (Map\u0026lt;String, Object\u0026gt;) sessionMap.get(url); if (compareParams(nowDataMap, preDataMap) \u0026amp;\u0026amp; compareTime(nowDataMap, preDataMap, annotation.interval())) { return true; } } } Map\u0026lt;String, Object\u0026gt; cacheMap = new HashMap\u0026lt;String, Object\u0026gt;(); cacheMap.put(url, nowDataMap); redisCache.set(cacheRepeatKey, cacheMap, annotation.interval(), TimeUnit.MILLISECONDS); return false; } /** * 判断参数是否相同 */ private boolean compareParams(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap) { String nowParams = (String) nowMap.get(REPEAT_PARAMS); String preParams = (String) preMap.get(REPEAT_PARAMS); return nowParams.equals(preParams); } /** * 判断两次间隔时间 */ private boolean compareTime(Map\u0026lt;String, Object\u0026gt; nowMap, Map\u0026lt;String, Object\u0026gt; preMap, int interval) { long time1 = (Long) nowMap.get(REPEAT_TIME); long time2 = (Long) preMap.get(REPEAT_TIME); if ((time1 - time2) \u0026lt; interval) { return true; } return false; } } 值得注意的一个地方\n为什么前面要带一个url拼接submitKey（token）呢？\n1 2 3 4 5 // 唯一值（没有消息头则使用请求地址） String submitKey = StringUtils.trimToEmpty(request.getHeader(header)); // 唯一标识（指定key + url + 消息头） String cacheRepeatKey = CacheConstants.REPEAT_SUBMIT_KEY + url + \u0026#34;/\u0026#34; + submitKey; 原因是有的时候并不是所有的请求都有token，这个时候如果我们不对对应的url进行拦截的话，那么他们就可以在未登录的情况下对某些无需登录却十分耗时的页面进行多次请求，而如果对url也进行了拦截，就不会有这个问题了。可以对这个url的访问次数进行限制了。\n注册拦截器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration public class ResourcesConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; /** * 自定义拦截规则 */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(repeatSubmitInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;); } } 注册过滤器 构建可重复读取inputStream的request\nFilterConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class FilterConfig { @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) @Bean public FilterRegistrationBean someFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new RepeatableFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); registration.setName(\u0026#34;repeatableFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE); return registration; } } RepeatableFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /** * Repeatable 过滤器 * * @author 7bin */ public class RepeatableFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ServletRequest requestWrapper = null; if (request instanceof HttpServletRequest \u0026amp;\u0026amp; StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.APPLICATION_JSON_VALUE)) { requestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response); } if (null == requestWrapper) { chain.doFilter(request, response); } else { chain.doFilter(requestWrapper, response); } } @Override public void destroy() { } } RepeatedlyRequestWrapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 /** * 构建可重复读取inputStream的request * * @author 7bin */ public class RepeatedlyRequestWrapper extends HttpServletRequestWrapper { private final byte[] body; public RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException { super(request); request.setCharacterEncoding(Constants.UTF8); response.setCharacterEncoding(Constants.UTF8); body = HttpHelper.getBodyString(request).getBytes(Constants.UTF8); } @Override public BufferedReader getReader() throws IOException { return new BufferedReader(new InputStreamReader(getInputStream())); } @Override public ServletInputStream getInputStream() throws IOException { final ByteArrayInputStream bais = new ByteArrayInputStream(body); return new ServletInputStream() { @Override public int read() throws IOException { return bais.read(); } @Override public int available() throws IOException { return body.length; } @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } }; } } 注解使用 在controller中对需要设置防重复提交的方法加上@RepeatSubmit\n1 2 3 4 5 6 7 8 9 /** * 修改用户 */ @RepeatSubmit @PutMapping(\u0026#34;/profile\u0026#34;) public ApiResponse updateProfile(@RequestBody SysUser user) { ... } ","permalink":"https://chance7bin.github.io/posts/design/%E9%98%B2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/","summary":"日常开发中我们经常会遇到前端多次请求同一个接口的问题，比如前端没有做遮罩层，用户点击了多次按钮。全指望着用户来等待也并不靠谱，如果各个接口自","title":"防重复提交"},{"content":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范围，软件系统可能直接就挂掉了。\n限流可能会导致用户的请求无法被正确处理，不过，这往往也是权衡了软件系统的稳定性之后得到的最优解。\n现实生活中，处处都有限流的实际应用，就比如排队买票是为了避免大量用户涌入购票而导致售票员无法处理\n常见限流算法 固定窗口计数器算法 固定窗口其实就是时间窗口。固定窗口计数器算法 规定了我们单位时间处理的请求数量。\n假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：\n给定一个变量 counter 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。 1 分钟之内每处理一个请求之后就将 counter+1 ，当 counter=33 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。 等到 1 分钟结束后，将 counter 重置 0，重新开始计数。 这种限流算法无法保证限流速率，因而无法保证突然激增的流量。\n就比如说我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了。\n滑动窗口计数器算法 滑动窗口计数器算法 算的上是固定窗口计数器算法的升级版。\n滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片\n漏桶算法 我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。\n实现这个算法，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。\n令牌桶算法 和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。\n限流实现 工具类 1.Google Guava 自带的限流工具类 RateLimiter\nRateLimiter 基于令牌桶算法，可以应对突发流量。\n除了最基本的令牌桶算法(平滑突发限流)实现之外，Guava 的RateLimiter还提供了 平滑预热限流 的算法实现。\n平滑突发限流就是按照指定的速率放令牌到桶里，而平滑预热限流会有一段预热时间，预热时间之内，速率会逐渐提升到配置的速率。\nGuava 地址：https://github.com/google/guava\n2.Bucket4j\nBucket4j 是一个非常不错的基于令牌/漏桶算法的限流库\nBucket4j 地址：https://github.com/vladimir-bukhtoyarov/bucket4j\n3.Resilience4j\nResilience4j 是一个轻量级的容错组件，其灵感来自于 Hystrix。自Netflix 宣布不再积极开发 Hystrixopen in new window 之后，Spring 官方和 Netflix 都更推荐使用 Resilience4j 来做限流熔断。\nResilience4j 地址: https://github.com/resilience4j/resilience4j\n自定义实现 实现固定窗口计数器算法\n**Redis+Lua **\n减少了网络开销：我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。\n原子性：一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。\nRedisConfig 在redis的配置中编写Lua脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Bean public DefaultRedisScript\u0026lt;Long\u0026gt; limitScript() { DefaultRedisScript\u0026lt;Long\u0026gt; redisScript = new DefaultRedisScript\u0026lt;\u0026gt;(); redisScript.setScriptText(limitScriptText()); redisScript.setResultType(Long.class); return redisScript; } /** * 限流脚本 */ private String limitScriptText() { return \u0026#34;local key = KEYS[1]\\n\u0026#34; + \u0026#34;local count = tonumber(ARGV[1])\\n\u0026#34; + \u0026#34;local time = tonumber(ARGV[2])\\n\u0026#34; + \u0026#34;local current = redis.call(\u0026#39;get\u0026#39;, key);\\n\u0026#34; + \u0026#34;if current and tonumber(current) \u0026gt; count then\\n\u0026#34; + \u0026#34; return tonumber(current);\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;current = redis.call(\u0026#39;incr\u0026#39;, key)\\n\u0026#34; + \u0026#34;if tonumber(current) == 1 then\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;expire\u0026#39;, key, time)\\n\u0026#34; + \u0026#34;end\\n\u0026#34; + \u0026#34;return tonumber(current);\u0026#34;; } RateLimiterAspect 定义一个切面，实现基于注解的流量控制\n1 2 3 4 5 6 7 // 在对应的注解中通过传入参数key的名称，限制次数，过期时间，来进行统计 Long number = redisTemplate.execute(limitScript, keys, count, time); if (StringUtils.isNull(number) || number.intValue() \u0026gt; count) { throw new ServiceException(\u0026#34;访问过于频繁，请稍候再试\u0026#34;); } log.info(\u0026#34;限制请求\u0026#39;{}\u0026#39;,当前请求\u0026#39;{}\u0026#39;,缓存key\u0026#39;{}\u0026#39;\u0026#34;, count, number.intValue(), combineKey); 首先获得对应的key当前存储的值，如果当前存储的值大于限制次数，直接返回，如果不大于，那么此值调用incr命令去做加1操作。 如果加1之后current为1，给它设置一个过期时间，从而保证它在限制时间后可以被销毁，从而进行一个新的统计。\n限流注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RateLimiter { /** * 限流key */ public String key() default CacheConstants.RATE_LIMIT_KEY; /** * 限流时间,单位秒 */ public int time() default 60; /** * 限流次数 */ public int count() default 100; /** * 限流类型 */ public LimitType limitType() default LimitType.DEFAULT; } ","permalink":"https://chance7bin.github.io/posts/design/%E9%99%90%E6%B5%81/","summary":"针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。如果说超过了其处理能力的范","title":"限流"},{"content":"Spring AOP 实现 Redis 缓存切面 @EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。\nhttps://blog.csdn.net/micro_hz/article/details/76599632\n参考博客 Spring的面向切面编程（AOP）\nSpring AOP 实现 Redis 缓存切面\nSpringBoot中通过自定义缓存注解(AOP切面拦截)实现数据库数据缓存到Redis\nSpringBoot + Redis：基本配置及使用\nSpring中自定义注解支持SpEl表达式（仅限在AOP中使用）\n添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!--redis--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--spring2.0集成redis所需common-pool2--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aspects --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aspects\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.14.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; yml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 spring: data: redis: repositories: enabled: false redis: # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 database: 0 host: localhost port: 6379 # 连接密码（默认为空） password: # 连接超时时间（毫秒) timeout: 10000ms lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-wait: -1 # 连接池中的最大空闲连接 默认 8 max-idle: 8 # 连接池中的最小空闲连接 默认 0 min-idle: 0 代码 自定义RedisTemplate 使用fastjson进行序列化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package njgis.opengms.portal.config; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.JsonTypeInfo; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; /** * @Description * @Author bin * @Date 2022/07/19 */ @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } redis缓存注解：插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import njgis.opengms.portal.enums.ItemTypeEnum; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description 新增redis缓存 * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEnable { //redis缓存key String key(); //redis缓存存活时间默认值（可自定义） long expireTime() default 3600; //redis缓存的分组 ItemTypeEnum group() default ItemTypeEnum.PortalItem; } redis缓存注解：删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * @Description * @Author bin * @Date 2022/07/19 */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AopCacheEvict { //redis中的key值 String key(); //redis缓存的分组 String group(); } 自定义缓存切面具体实现类 CacheEnableAspect.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 import lombok.extern.slf4j.Slf4j; import njgis.opengms.portal.enums.ItemTypeEnum; import njgis.opengms.portal.service.RedisService; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.Signature; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.core.DefaultParameterNameDiscoverer; import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; import org.springframework.stereotype.Component; import java.lang.reflect.Method; /** * @Description 自定义缓存切面具体实现类 * @Author bin * @Date 2022/07/19 */ @Slf4j @Aspect @Component public class CacheEnableAspect { @Autowired RedisService redisService; /** * 用于SpEL表达式解析. */ private SpelExpressionParser parser = new SpelExpressionParser(); /** * 用于获取方法参数定义名字. */ private DefaultParameterNameDiscoverer nameDiscoverer = new DefaultParameterNameDiscoverer(); /** * Mapper层切点 使用到了我们定义的 AopCacheEnable 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEnable)\u0026#34;) public void queryCache() { } /** * Mapper层切点 使用到了我们定义的 AopCacheEvict 作为切点表达式。 */ @Pointcut(\u0026#34;@annotation(njgis.opengms.portal.component.AopCacheEvict)\u0026#34;) public void ClearCache() { } @Around(\u0026#34;queryCache()\u0026#34;) public Object Interceptor(ProceedingJoinPoint pjp) throws Throwable { // StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;).append(\u0026#34;::\u0026#34;); StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); // 类 // String className = pjp.getTarget().toString().split(\u0026#34;@\u0026#34;)[0]; // redisKeySb.append(className).append(\u0026#34;::\u0026#34;); //获取当前被切注解的方法名 Method method = getMethod(pjp); //获取当前被切方法的注解 AopCacheEnable aopCacheEnable = method.getAnnotation(AopCacheEnable.class); if (aopCacheEnable == null) { return pjp.proceed(); } //获取被切注解方法返回类型 // Type returnType = method.getAnnotatedReturnType().getType(); // String[] split = returnType.getTypeName().split(\u0026#34;\\\\.\u0026#34;); // String type = split[split.length - 1]; // redisKeySb.append(\u0026#34;:\u0026#34;).append(type); //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = aopCacheEnable.key(); // redisKeySb.append(args); String resV = generateKeyBySpEL(key, pjp).toString(); redisKeySb.append(\u0026#34;:\u0026#34;).append(aopCacheEnable.group()).append(\u0026#34;:\u0026#34;).append(resV); //获取方法参数值 // Object[] arguments = pjp.getArgs(); // redisKeySb.append(\u0026#34;:\u0026#34;).append(arguments[0]); String redisKey = redisKeySb.toString(); Object result = redisService.get(redisKey); if (result != null) { log.info(\u0026#34;从Redis中获取数据：{}\u0026#34;, result); return result; } else { try { result = pjp.proceed(); log.info(\u0026#34;从数据库中获取数据：{}\u0026#34;, result); } catch (Throwable e) { throw new RuntimeException(e.getMessage(), e); } // 获取失效时间 long expire = aopCacheEnable.expireTime(); redisService.set(redisKey, result, expire); } return result; } /*** 定义清除缓存逻辑，先操作数据库，后清除缓存*/ @Around(value = \u0026#34;ClearCache()\u0026#34;) public Object evict(ProceedingJoinPoint pjp) throws Throwable { StringBuilder redisKeySb = new StringBuilder(\u0026#34;AOP\u0026#34;); Method method = getMethod(pjp); // 获取方法的注解 AopCacheEvict cacheEvict = method.getAnnotation(AopCacheEvict.class); if (cacheEvict == null) { return pjp.proceed(); } //从注解中获取key //通过注解key使用的SpEL表达式获取到SpEL执行结果 String key = cacheEvict.key(); // redisKeySb.append(args); key = generateKeyBySpEL(key, pjp).toString(); //清楚缓存的group从参数拿 String group = cacheEvict.group(); ItemTypeEnum type = (ItemTypeEnum)generateKeyBySpEL(group, pjp); redisKeySb.append(\u0026#34;:\u0026#34;).append(type).append(\u0026#34;:\u0026#34;).append(key); //先操作db Object result = pjp.proceed(); //根据key从缓存中删除 String redisKey = redisKeySb.toString(); redisService.delete(redisKey); return result; } /** * 获取被拦截方法对象 */ public Method getMethod(ProceedingJoinPoint pjp) { Signature signature = pjp.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); return targetMethod; } public Object generateKeyBySpEL(String spELString, ProceedingJoinPoint joinPoint) { MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); String[] paramNames = nameDiscoverer.getParameterNames(methodSignature.getMethod()); Expression expression = parser.parseExpression(spELString); EvaluationContext context = new StandardEvaluationContext(); Object[] args = joinPoint.getArgs(); for (int i = 0; i \u0026lt; args.length; i++) { context.setVariable(paramNames[i], args[i]); } return expression.getValue(context); } } 注意这里的queryCache和ClearCache，里面切点表达式\n分别对应上面自定义的两个AopCacheEnable和AopCacheEvict。\n然后在环绕通知的queryCache方法执行前后时\n获取被切方法的参数，参数中的key，然后根据key去redis中去查询\nService层 redis服务接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public interface RedisService { void set(String key, Object value); void set(String key, Object value, long expire); Object get(String key); void expire(String key, long expire); void delete(String key); // 由于dao接口同时继承了MongoRepository和GenericItemDao， // 所以这边写接口调用他们防止继承冲突 PortalItem insertItem(PortalItem item, ItemTypeEnum type); PortalItem saveItem(PortalItem item, ItemTypeEnum type); void deleteItem(PortalItem item, ItemTypeEnum type); } AopCacheEnable测试\n1 2 3 4 public interface ModelItemDao extends MongoRepository\u0026lt;ModelItem,String\u0026gt;, GenericItemDao\u0026lt;ModelItem\u0026gt; { @AopCacheEnable(key = \u0026#34;#id\u0026#34;, group = ItemTypeEnum.ModelItem) ModelItem findFirstById(String id); } AopCacheEvict测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Service(\u0026#34;redisService\u0026#34;) public class RedisServiceImpl implements RedisService { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; @Autowired GenericService genericService; @Override public void set(String key, Object value) { redisTemplate.opsForValue().set(key, value); } @Override public void set(String key, Object value, long expire) { redisTemplate.opsForValue().set(key, value, expire, TimeUnit.SECONDS); } @Override public Object get(String key) { return redisTemplate.opsForValue().get(key); } @Override public void expire(String key, long expire) { redisTemplate.expire(key, expire, TimeUnit.SECONDS); } @Override public void delete(String key) { redisTemplate.delete(key); } @Override public PortalItem insertItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.insert(item); return result; } @Override @AopCacheEvict(key = \u0026#34;#item.id\u0026#34;, group = \u0026#34;#type\u0026#34;) public PortalItem saveItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); PortalItem result = (PortalItem)itemDao.save(item); return result; } @Override public void deleteItem(PortalItem item, ItemTypeEnum type) { GenericItemDao itemDao = (GenericItemDao)genericService.daoFactory(type).get(\u0026#34;itemDao\u0026#34;); itemDao.delete(item); } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void aopFindTest(){ for (int i = 0; i \u0026lt; 5; i++) { ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); System.out.println(modelItem); } } @Test public void aopSaveTest(){ ModelItem modelItem = modelItemDao.findFirstById(\u0026#34;3f6857ba-c2d2-4e27-b220-6e5367803a12\u0026#34;); modelItem.setThumbsUpCount(50); redisService.saveItem(modelItem,ItemTypeEnum.ModelItem); } 遇到的问题 问题：\nCould not safely identify store assignment for repository candidate interface 条件： 使用了Spring data jpa 作为持久层框架并同时使用starter引入了Elasticsearch或Redis依赖包。\n原因： RedisRepositoriesAutoConfiguration或ElasticsearchRepositoriesAutoConfiguration 里面的注解@ConditionalOnProperty会判断 spring.data.redis/elasticsearch.repositories.enabled 这个配置项是否存在。若存在会自动扫描继承org.springframework.data.repository.Repository的实体Repository接口。\n解决办法：\n1 2 3 4 5 6 7 8 spring: data: redis: repositories: enabled: false elasticsearch: repositories: enabled: false 问题：\nRedis获取缓存异常 Resolved [java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.alibaba.fastjson.JSONObject]\n出现场景：\nSpringBoot项目中使用Redis来进行缓存。把数据放到缓存中时没有问题，但从缓存中取出来反序列化为对象时报错：“java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx”。（xxx为反序列化的目标对象对应的类。）\n只有这个类里有其他对象字段才会报这个问题，如果这个类里都是初始的类型（比如：Integer，String）则不会报这个错误。\n只要用到Redis序列化反序列化的地方都会遇到这个问题，比如：RedisTemplate，Redisson，@Cacheable注解等。\n原因：\nSpringBoot 的缓存使用 jackson 来做数据的序列化与反序列化，如果默认使用 Object 作为序列化与反序列化的类型，则其只能识别 java 基本类型，遇到复杂类型时，jackson 就会先序列化成 LinkedHashMap ，然后再尝试强转为所需类别，这样大部分情况下会强转失败。\n解决方法：\n出现这种异常，需要自定义ObjectMapper，设置一些参数，而不是直接使用Jackson2JsonRedisSerializer类中黙认的ObjectMapper，看源代码可以知道，Jackson2JsonRedisSerializer中的ObjectMapper是直接使用new ObjectMapper()创建的，这样ObjectMapper会将Redis中的字符串反序列化为java.util.LinkedHashMap类型，导致后续Spring对其进行转换成报错。其实我们只要它返回Object类型就可以了。\n修改RedisTemplate这个bean的valueSerializer，设置默认类型。\n参考博客：\nhttps://blog.51cto.com/knifeedge/5010643\n修改配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; template(RedisConnectionFactory factory) { // 创建RedisTemplate\u0026lt;String, Object\u0026gt;对象 RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 配置连接工厂 template.setConnectionFactory(factory); // redis key 序列化方式使用stringSerial template.setKeySerializer(new StringRedisSerializer()); // redis value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(valueSerializer()); // redis hash key 序列化方式使用stringSerial template.setHashKeySerializer(new StringRedisSerializer()); // redis hash value 序列化方式自定义，使用jackson会出现转换类型的错误 // template.setHashValueSerializer(new GenericFastJsonRedisSerializer()); template.setHashValueSerializer(valueSerializer()); return template; } private RedisSerializer\u0026lt;Object\u0026gt; valueSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 此项必须配置，否则如果序列化的对象里边还有对象，会报如下错误： // java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); // 旧版写法： // objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } } 问题：\n注解不生效 ==注解生效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getItemUserInfoByEmail(String email) { User user = null; JSONObject userJson = new JSONObject(); if (email.contains(\u0026#34;@\u0026#34;)){ user = userDao.findFirstByEmail(email); } else { user = userDao.findFirstByAccessId(email); if (user != null){ email = user.getEmail(); } else { userJson.put(\u0026#34;name\u0026#34;, email); userJson.put(\u0026#34;email\u0026#34;, null); userJson.put(\u0026#34;accessId\u0026#34;, null); userJson.put(\u0026#34;image\u0026#34;, null); return userJson; } } JSONObject userInfo = getInfoFromUserServer(email); userJson.put(\u0026#34;name\u0026#34;, userInfo.getString(\u0026#34;name\u0026#34;)); // userJson.put(\u0026#34;id\u0026#34;, user.getId()); userJson.put(\u0026#34;email\u0026#34;, user.getEmail()); userJson.put(\u0026#34;accessId\u0026#34;, user.getAccessId()); // userJson.put(\u0026#34;image\u0026#34;, user.getAvatar().equals(\u0026#34;\u0026#34;) ? \u0026#34;\u0026#34; : htmlLoadPath + user.getAvatar()); userJson.put(\u0026#34;image\u0026#34;, userInfo.getString(\u0026#34;avatar\u0026#34;)); return userJson; } ==注解失效代码==\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @UserCacheEnable(key = \u0026#34;#email\u0026#34;) public JSONObject getInfoFromUserServer(String email){ // return getInfoFromUserServerPart(email); JSONObject jsonObject = new JSONObject(); try { RestTemplate restTemplate = new RestTemplate(); String userInfoUrl = \u0026#34;http://\u0026#34; + userServer + \u0026#34;/user/\u0026#34; + email + \u0026#34;/\u0026#34; + userServerCilent + \u0026#34;/\u0026#34; + userServerCilentPWD; HttpHeaders headers = new HttpHeaders(); MediaType mediaType = MediaType.parseMediaType(\u0026#34;application/json;charset=UTF-8\u0026#34;); headers.setContentType(mediaType); headers.set(\u0026#34;user-agent\u0026#34;, \u0026#34;portal_backend\u0026#34;); HttpEntity httpEntity = new HttpEntity(headers); ResponseEntity\u0026lt;JSONObject\u0026gt; response = restTemplate.exchange(userInfoUrl, HttpMethod.GET, httpEntity, JSONObject.class); JSONObject userInfo = response.getBody().getJSONObject(\u0026#34;data\u0026#34;); String avatar = userInfo.getString(\u0026#34;avatar\u0026#34;); if(avatar!=null){ // avatar = \u0026#34;/userServer\u0026#34; + avatar; //修正avatar前面加了/userServer // avatar = avatar.replaceAll(\u0026#34;/userServer\u0026#34;,\u0026#34;\u0026#34;); genericService.formatUserAvatar(avatar); } userInfo.put(\u0026#34;avatar\u0026#34;,avatar); userInfo.put(\u0026#34;msg\u0026#34;,\u0026#34;suc\u0026#34;); return userInfo; }catch(Exception e){ log.error(e.getMessage()); // System.out.println(e.fillInStackTrace()); jsonObject.put(\u0026#34;msg\u0026#34;,\u0026#34;no user\u0026#34;); } return jsonObject; } 原因：\nSpring AOP 注解为什么失效？\n如下面几种场景\n1、Controller直接调用Service B方法：Controller \u0026gt; Service A\n在Service A 上加@Transactional的时候可以正常实现AOP功能。\n2、==Controller调用Service A方法，A再调用B方法：Controller \u0026gt; Service A \u0026gt; Service B==\n在Service B上加@Transactional的时候不能实现AOP功能，因为==在Service A方法中调用Service B方法想当于使用this.B()，this代表的是Service类本身，并不是真实的代理Service对象==，所以这种不能实现代理功能。\n所以，如果不是直接调用的方式，是不能实现代理功能的，非常需要注意。\n","permalink":"https://chance7bin.github.io/posts/design/spring-aop-%E5%AE%9E%E7%8E%B0-redis-%E7%BC%93%E5%AD%98%E5%88%87%E9%9D%A2/","summary":"Spring AOP 实现 Redis 缓存切面 @EnableCaching spring boot提供了比较简单的缓存方案。只要使用 @EnableCaching 即可完成简单的缓存功能。 https://blog.csdn.net/micro_hz/article/details/76599632 参考博客 Spring的面向切面编程（AOP） Spring AOP","title":"参考资料"},{"content":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\n1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。\nWindows用户选择windows-amd64.zip\n下载下来的是一个exe文件，需打开cmd进行操作\n1 2 E:\\Projects\\hugo_0.111.2_windows-amd64\u0026gt;hugo version hugo v0.111.2-4164f8fef9d71f50ef3962897e319ab6219a1dad windows/amd64 BuildDate=2023-03-05T12:32:20Z VendorInfo=gohugoio 2. 创建一个新的网站 1 2 // 在命令行输入如下命令会在当前路径下创建一个新的网站文件夹 hugo new site quickstart 3. 添加一个主题 添加主题也可以放在后面\n主题\nhttps://github.com/nanxiaobei/hugo-paper\nhttps://github.com/adityatelange/hugo-PaperMod\nHUGO官方搭建的theme主题站有大量的开源主题可供选择\n基本上所有的主题都自带安装的方法\n这里我选择了一个主题进行演示\nhttps://themes.gohugo.io/themes/hugo-theme-charlolamode/\n在网页下方的说明内，根据步骤安装主题即可\n总结\n1 2 3 cd quickstart git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 在根目录下的 config.toml 文件中添加一行\n1 echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 4. 添加一个新的文章 1 2 hugo new posts/my-first-post.md hugo new test.md 创建的新文章都会放在 content 文件夹下\n5. 启动 Hugo 服务器 使用命令启动服务器\n1 hugo server 在浏览器输入localhost:1313即可查看生成的网站\n注意刚才添加的md并没有显示出来，是因为生成的md是drift，hugo默认忽略drift的文档，需在启动时添加-D参数\n1 hugo server -D --theme 选择哪个皮肤; --buildDrafts 由于想显示我们的内容，包括设置了 draft 草稿状态的内容。 部署 Hugo 作为一个 Github Pages Github Pages 本质上是一个静态网站托管系统，你可以使用它为你的每一个仓库制作一个静态网页入口\n1. 创建一个 Github 仓库 首先再Github上创建一个 Repository，命名为Github名字.github.io，例如我的仓库：GoodmanBin.github.io，这样就可以生成一个用户页面\n2. 在本地构建Hugo静态网站 注意！！！\n在生成静态页面之前要把config.toml文件中的baseURL修改为自己博客的网址\n1 baseURL = \u0026#39;https://GoodmanBin.github.io/\u0026#39; 执行命令\n1 hugo 输入hugo就可以生成public文件夹，这个文件夹可以部署到云服务器或者托管到github上，\n注意：输入hugo的生成方式只会往public文件夹里添加内容，但是不会删除外部已经不存在而public里面还存在的文件\n所以一般用hugo -F --cleanDestinationDir命令，表示每次生成的public都是全新的，会覆盖原来的。\n在命令执行后，出现一个public文件夹，里面就是网站的静态页面文件\n进入public文件夹，将public文件夹的内容上传到github仓库中\n1 2 3 4 5 6 cd public git init ##初始化仓库 git remote add origin https://github.com/GoodmanBin/GoodmanBin.github.io.git ##链接远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master 将public文件夹推送上去之后直接访问GoodmanBin.github.io会显示404，需到项目中勾选上Use your GitHub Pages website才可访问\n在此之后更新文章，使用hugo生成新的静态页面，并使用git push进行同步\n1 2 3 4 5 cd public git add . git status git commit -m \u0026#34;add blog post\u0026#34; git push 3. 解决 hugo 中关于 integrity 的错误 问题描述\n在 Github Pages 上部署 Hugo 博客后，网站样式丢失，打开浏览器 F12 控制台可以发现错误：Failed to find a valid digest in the 'integrity' attribute for resource \u0026quot;xxx.css\u0026quot;, The resource has been blocked.\n解决方法\n在 themes\\PaperMod\\layouts\\partials 文件夹下找到一个 head.html 文件，发现里面确实有 integrity=\u0026quot;{{ $stylesheet.Data.Integrity }}\u0026quot; 这么一句代码，把它改为 integrity=\u0026quot;\u0026quot; 然后重新发布\nHugo引入图片问题 直接使用typora的相对路径在生成静态网站的时候图片无法显示出来\nHugo的图片展示逻辑：\nHugo博客的根目录有一个static目录，这个static目录就是用来存放一些静态文件，比如图片、css、js文件等。 执行hugo命令的时候，会把static目录下的子目录或文件复制到public目录下。比如我在static下添加了一个img子目录，并且在img子目录放了图片，那执行hugo命令后，就会把static\\img文件的内容拷贝到public\\img里面。 大家都知道Hugo博客网站展示的其实是public下的内容，因此markdown文章里引用图片的时候，得引用pubic下的图片才可以。 具体操作非常简单，分2步：\n在static目录下创建img子目录，把markdown要使用的图片放在static\\img目录里。 在markdown文件里，按照如下格式引用图片(这里假设图片名称叫wechat.png)。这样最终public目录下生成的静态页面就可以引用到public\\img下的图片了。 1 ![](/img/wechat.png) 注意：\n严格注意路径：只能写成 /img/imagename.png 的形式（注意 / 和 \\ 的区别)\n可能是当前主题不支持的原因，嵌入图片的代码只能写成这样：![imagename](/img/imagename.png)；\u0026lt;img src=\u0026quot;\u0026quot; alt=\u0026quot;\u0026quot; style=\u0026quot;zoom:50%;\u0026quot; /\u0026gt; 这种格式的修改图片缩放比例的代码也是不能用的\n存放图片的文件夹不能有空格\n还可以用图床\nTypora配置图床 GitHub创建仓库并获取仓库Token 下载PicGo并安装 GitHub配置 设置参数说明：\n设定仓库名：填入你上面创建的仓库名，格式为：用户名/仓库名；\n设定分支名：一般填写 master 即可；\n设定 Token：将上一步 Github 配置中得到的 Token 粘贴进去；\n指定存储路径：图片在 Github 仓库中的存储路径，例如本人是：blog/202303/\n设定自定义域名：此处直接设置 jsDelivr 加速的访问地址，例如本人是：https://cdn.jsdelivr.net/gh/chance7bin/img-repo@main/\ngh 表示来自 Github 的仓库 chance7bin/img-repo 仓库的具体位置 main 仓库的分支 到此，配置过程已完成。\nPicGo配置 腾讯云COS https://cloud.tencent.com/developer/article/1834573 https://cloud.tencent.com/developer/article/2175760?from=15425\n阿里云OSS 阿里云OSS PicGo 配置图床教程 超详细\n配置Typora 偏好设置 → 图像 → 插入图片时：上传图片 → 上传服务设定：上传服务选择PiacGo，PicGo路径选择软件安装路径 → 配置完成\nObisidian配置图床 Obisidian对img的兼容不是很好\n打开 Obsidian 按箭头标识数字顺序：设置 =》 第三方插件 =》 关闭安全模式 =》 浏览社区插件\n搜索：Image auto upload Plugin\n安装后打开选项，默认什么都不要改。\n其中最后一项 PicGo server 也是默认填好的，如果没有，就在 PicGo 设置，默认都不要动。\n","permalink":"https://chance7bin.github.io/posts/tech/%E4%BD%BF%E7%94%A8-hugo-+-github-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","summary":"初见Hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 1. 安装 Hugo 到 Hugo Releases 下载适合你的操作系统的版本。 Wind","title":"使用 Hugo + Github 搭建个人博客"},{"content":" 参考链接：\n快速了解雪花算法详解及spring boot集成\nSpringBoot快速开发（六）【雪花算法（snowflake）自增ID】\n1.介绍 SnowFlow算法是Twitter推出的分布式id生成算法，主要核心思想就是利用64bit的long类型的数字作为全局的id。在分布式系统中经常应用到，并且，在id中加入了时间戳的概念，基本上保持不重复，并且持续一种向上增加的方式。\n在这64bit中，其中第一个bit是不用的，然后用其中的41个bit作为毫秒数，用10bit作为工作机器id,12bit作为序列号.具体如下图所示：\n第一个部分：0,这个是个符号位，因为在二进制中第一个bit如果是1的话，那么都是负数，但是我们生成的这些id都是正数，所以第一个bit基本上都是0 第二个部分：41个bit,代表的是一个时间戳，41bit可以表示的数字多达$2^{41} $-1,也可以表示2^{41}-1 个毫秒值，基本上差不多是69年。 第三个部分：5个bit 表示的是机房id。 第四个部分：5个bit 表示的是机器id。 第五个部分：12个bit 表示的是机房id，表示的序号，就是某个机房某台机器上这一毫秒内同时生成的 id 的序号，0000 00000000，如果是同一毫秒，那么这个雪花值就会递增 简单来说，你的某个服务假设要生成一个全局唯一 id，那么就可以发送一个请求给部署了 SnowFlake 算法的系统，由这个 SnowFlake 算法系统来生成唯一 id。\n这个算法可以保证说，一个机房的一台机器上，在同一毫秒内，生成了一个唯一的 id。可能一个毫秒内会生成多个 id，但是有最后 12 个 bit 的序号来区分开来。\n下面我们就来简单看下这个算法的代码实现部分。\n总之就是用一个64bit的数字中各个bit位置来设置不同的标志位\n2.代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 /** * id自增器（雪花算法） * * @author bin * @date 2022/10/11 */ public class SnowFlake { private final static long twepoch = 12888349746579L; // 机器标识位数 private final static long workerIdBits = 5L; // 数据中心标识位数 private final static long datacenterIdBits = 5L; // 毫秒内自增位数 private final static long sequenceBits = 12L; // 机器ID偏左移12位 private final static long workerIdShift = sequenceBits; // 数据中心ID左移17位 private final static long datacenterIdShift = sequenceBits + workerIdBits; // 时间毫秒左移22位 private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; //sequence掩码，确保sequnce不会超出上限 private final static long sequenceMask = -1L ^ (-1L \u0026lt;\u0026lt; sequenceBits); //上次时间戳 private static long lastTimestamp = -1L; //序列 private long sequence = 0L; //服务器ID private long workerId = 1L; private static long workerMask = -1L ^ (-1L \u0026lt;\u0026lt; workerIdBits); //进程编码 private long processId = 1L; private static long processMask = -1L ^ (-1L \u0026lt;\u0026lt; datacenterIdBits); private static SnowFlake snowFlake = null; static{ snowFlake = new SnowFlake(); } public static synchronized long nextId(){ return snowFlake.getNextId(); } private SnowFlake() { //获取机器编码 this.workerId=this.getMachineNum(); //获取进程编码 RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean(); this.processId=Long.valueOf(runtimeMXBean.getName().split(\u0026#34;@\u0026#34;)[0]).longValue(); //避免编码超出最大值 this.workerId=workerId \u0026amp; workerMask; this.processId=processId \u0026amp; processMask; } public synchronized long getNextId() { //获取时间戳 long timestamp = timeGen(); //如果时间戳小于上次时间戳则报错 if (timestamp \u0026lt; lastTimestamp) { try { throw new Exception(\u0026#34;Clock moved backwards. Refusing to generate id for \u0026#34; + (lastTimestamp - timestamp) + \u0026#34; milliseconds\u0026#34;); } catch (Exception e) { e.printStackTrace(); } } //如果时间戳与上次时间戳相同 if (lastTimestamp == timestamp) { // 当前毫秒内，则+1，与sequenceMask确保sequence不会超出上限 sequence = (sequence + 1) \u0026amp; sequenceMask; if (sequence == 0) { // 当前毫秒内计数满了，则等待下一秒 timestamp = tilNextMillis(lastTimestamp); } } else { sequence = 0; } lastTimestamp = timestamp; // ID偏移组合生成最终的ID，并返回ID long nextId = ((timestamp - twepoch) \u0026lt;\u0026lt; timestampLeftShift) | (processId \u0026lt;\u0026lt; datacenterIdShift) | (workerId \u0026lt;\u0026lt; workerIdShift) | sequence; return nextId; } /** * 再次获取时间戳直到获取的时间戳与现有的不同 * @param lastTimestamp * @return 下一个时间戳 */ private long tilNextMillis(final long lastTimestamp) { long timestamp = this.timeGen(); while (timestamp \u0026lt;= lastTimestamp) { timestamp = this.timeGen(); } return timestamp; } private long timeGen() { return System.currentTimeMillis(); } /** * 获取机器编码 * @return */ private long getMachineNum(){ long machinePiece; StringBuilder sb = new StringBuilder(); Enumeration\u0026lt;NetworkInterface\u0026gt; e = null; try { e = NetworkInterface.getNetworkInterfaces(); } catch (SocketException e1) { e1.printStackTrace(); } while (e.hasMoreElements()) { NetworkInterface ni = e.nextElement(); sb.append(ni.toString()); } machinePiece = sb.toString().hashCode(); return machinePiece; } } 使用\n1 Long id = SnowFlake.nextId(); 3.算法优缺点 优点：\n（1）高性能高可用：生成时不依赖于数据库，完全在内存中生成。\n（2）容量大：每秒中能生成数百万的自增ID。\n（3）ID自增：存入数据库中，索引效率高。\n缺点：\n（1）依赖与系统时间的一致性，如果系统时间被回调，或者改变，可能会造成id冲突或者重复(时钟重播造成的id重复问题)\n","permalink":"https://chance7bin.github.io/posts/tech/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%E5%8F%8Aspringboot%E9%9B%86%E6%88%90/","summary":"参考链接： 快速了解雪花算法详解及spring boot集成 SpringBoot快速开发（六）【雪花算法（snowflake）自增ID】 1.介绍","title":"雪花算法详解及springboot集成"},{"content":"引言 设计工作流的目的：\n实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作\n实现模型的并行化计算：对于一整个计算流程来说，有些计算是可以一起执行的，因此可以根据计算的先后顺序构建出一整个计算流程，缩短一整个计算流程的运行时间\n工作流是一种为满足数据收集、处理、计算、分析需求，按照流程之间的逻辑关系进行描述并使用计算机完成自动或半自动流程运行的过程。\n工作流模型 工作流的执行传递依赖于流程中的数据流，单元与单元之间的依赖关系实际上是一种输入输出数据之间的有向传递关系\n构建工作流时，各计算单元是按一定逻辑组织的，流程中包含顺序、选择、迭代等逻辑结构，各个元素的执行顺序也有先后，需要对流程的运转进行控制。\n在对流程完成定义和构建之后，工作流需要对工作流流程进行分析，对流程中过程进行验证。根据其中的逻辑关系对执行先后顺序进行控制；并针对各功能单元进行解析，对包含计算任务的单元进行调度与运行。\n各计算节点的元素关系 1）串行关系\n2）并行关系\n3）分支关系\n4）选择关系\n5）迭代关系\n结构化描述文档 结构化描述模块示意图\n结构化描述文档\n工作流对象类图\n浏览器的Event Loop 参考链接：\nhttps://juejin.cn/post/7079092748929728548#comment\nJS是单线程还是多线程的？ 答案：JS是单线程。如果您深究为什么是单线程的呢？\n其实这是与它的用途有关，因为JS是一门浏览器脚本语言，主要用途是进行用户操作和操作DOM，所以它只能是单线程的，否则会带来很多复杂的同步问题。\n浏览器是多进程还是单进程 答案：浏览器是多进程的。为什么说是多进程的？ 你说是就是吗？ 凭什么呢？\n当我们浏览网页的时候，有的时候是不是会遇到浏览器卡死的情况。如果我们开了多个会话，就假如我们一边刷力扣，一边开发程序，写循环的时候，写了一个死循环，导致了我们开发的这个会话的崩溃，如果浏览器是单进程的情况下，力扣这个时候也会崩溃。\n当然浏览器肯定不会允许这样的事情发生，它就是多进程的，多个会话互相不影响\n事件循环 首先js代码先执行主线程的代码，也就是同步的代码，从上至下，遇到异步代码交给浏览器，浏览器专门开了一个线程，其中浏览器线程中维护这两个队列，一个微任务队列，一个宏任务队列。\n宏任务队列 Macrotask Queue: ajax、setTimeout、setInterval、Dom监听等 微任务队列 Microtask Queue: Promise的then回调、 Mutation Observer API、queueMicrotask 注意:每一次执行宏任务之前，都是要确保我微任务的队列是空的，也就是说从代码执行的顺序来说微任务优先于宏任务。\n但是存在插队的情况，也就是说当我微任务执行完了，要开始执行宏任务了（有多个宏任务），宏任务队列当队列中的代码执行了，宏任务队列里面又有微任务代码，又把微任务放入到微任务队列当中。\n此时特别注意！！！从严格的意义来说，紧接着是先进行编译的宏任务，但是此时微任务里面有任务，才去执行的微任务队列，而不是直接去执行的。这些异步的代码交给js执行，这样三者形成了一个闭环，我们称之为事件循环。\n流程运行控制引擎 元素执行控制 任务循环机制 借鉴chrome v8等浏览器引擎事件循环（Event Loop）的成熟策略，设计了基于任务循环（Task Loop）的流程运行并发模型和运转控制策略。Task Loop维护一个运行控制线程，核心是队列维护方法query。query维护四个队列，分别对应等待队列waiting list、执行队列running list、完成队列completed list和失败队列failedList，通过对元素进行遍历处理检查状态，并分别压入对应的队列。等待队列中的元素检查数据是否完备、执行条件是否满足，满足则执行；执行队列中的元素向计算节点请求更新状态；完成队列和失败队列则根据各自情况更新输出数据和状态。TaskLoop不断循环，从而检查各个元素状态并更新qurey队列，将条件满足的元素压入执行。而在容错方面，设计了错误滞后策略即多次运行失败认定失败来减小错误影响。\n通过这种控制方法，各个满足执行前提条件的元素可以互不干涉、并发执行，同时将元素的依赖关系和流程的逻辑结构映射为元素的执行条件和数据准备情况，可以满足流程运行控制的要求的前题下简化程序结构、解耦各部分的功能。\n流程说明 （1）每个工作流开辟一个单独的线程不断循环计算（Task Loop）\n（2）每一次循环都遍历等待队列waiting list的所有计算单元，判断其数据是否已经准备完毕（前面步骤是否已经执行完），如果准备完毕则将该计算单元作为任务加入到执行队列running list中，并开始计算（调用服务）\n（3）输入数据的类型分为两种，一种是直接输入（value），一种是前面的流程结果（link），所以在设置输入数据的属性的时候需要根据类型从不同的来源获取到对应的值\n（4）需要迭代的计算单元，对于为link（前面的流程结果）的输入数据，需要重新计算前面流程结果，所以需把关联的计算单元也加入到等待队列waiting list中\n（5）对于条件判断（分支和循环），根据条件的成立与否（true/false）将下一个计算单元加入到等待队列waiting list中\n（6）每个计算单元计算完成后，根据计算状态将计算单元加入到完成队列completed list或失败队列failedList中，输出数据需加入到数据共享池SharedData中，以便后续计算单元从池中获取到前面的计算结果。对于迭代模型，当还未到达最大迭代次数的时候会将当前计算单元重新加入等待队列，同时创建一个临时文件池TempOutput（独立于SharedData），记录最新的运算结果\n（7）当等待队列waiting list以及执行队列running list中没有计算任务时，整个工作流流程结束\n工作流功能实现 工作空间 工作流详情 后端关键代码 Service\n1 2 3 4 5 public String runTask(MultipartFile file, String userName){ // ... TaskLoopHandler taskLoopHandler = new TaskLoopHandler(task); new Thread(taskLoopHandler).start(); } TaskLoopHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class TaskLoopHandler implements Runnable { private Task task; public TaskLoopHandler(Task task){ this.task = task; } @Override public void run() { TaskLoop taskLoop = new TaskLoop(); // 初始化任务 taskLoop.initTaskRun(task); // 初始化等待队列 List\u0026lt;ModelAction\u0026gt; waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); while (true){ taskLoop.query(waitingModels, task); Map\u0026lt;String, Object\u0026gt; checkedList = taskLoop.checkActions(task); waitingModels = ((Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt;)taskLoop.checkActions(task).get(\u0026#34;model\u0026#34;)).get(\u0026#34;waiting\u0026#34;); if(taskLoop.finalCheck(task)){ log.info(\u0026#34;全部运行结束\u0026#34;); break; } } log.info(\u0026#34;线程结束\u0026#34;); } } TaskLoop\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public class TaskLoop { ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; tempOutput; // 临时数据池 ConcurrentHashMap\u0026lt;String, ShareData\u0026gt; shareData; // 共享数据池 // 将准备好的任务推入running list public int query(List\u0026lt;ModelAction\u0026gt; waitingModels, Task task){ int result = 0; for(int i=0;i\u0026lt;waitingModels.size();i++){ ModelAction modelAction = waitingModels.get(i); // 检查数据是否准备好 if(checkData(modelAction,task)){ runModel(modelAction); } } return result; } // 检查集成任务中的所有任务状态 public Map\u0026lt;String,Object\u0026gt; checkActions(Task task) { checkModels(task); // ... } // 检查task中的单模型状态 public Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; checkModels(Task task){ Map\u0026lt;String,List\u0026lt;ModelAction\u0026gt;\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;ModelAction\u0026gt; waitingModel = new ArrayList\u0026lt;\u0026gt;(); // 等待队列 List\u0026lt;ModelAction\u0026gt; completedModel = new ArrayList\u0026lt;\u0026gt;(); // 完成队列 List\u0026lt;ModelAction\u0026gt; runningModel = new ArrayList\u0026lt;\u0026gt;(); // 执行队列 List\u0026lt;ModelAction\u0026gt; failedModel = new ArrayList\u0026lt;\u0026gt;(); // 失败队列 // 一系列操作 checkXxx(); // 检查 updateXxx(); // 更新 judgeCondition(); // 条件判断 // ... result.put(\u0026#34;waiting\u0026#34;,waitingModel); result.put(\u0026#34;running\u0026#34;,runningModel); result.put(\u0026#34;completed\u0026#34;,completedModel); result.put(\u0026#34;failed\u0026#34;,failedModel); } } 前端关键代码 前端使用mxGraph实现\n","permalink":"https://chance7bin.github.io/posts/design/%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","summary":"引言 设计工作流的目的： 实现模型的自动化执行：对于一个需要繁琐步骤，通过多种方法计算的需求来说，通过构建工作流，可以省去一些重复的工作 实现模型","title":"工作流设计与实现"},{"content":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。\n二、域名 应该尽量将API部署在专用域名之下。\nhttps://api.example.com\n如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。\nhttps://example.org/api/\n三、版本（Versioning） 应该将API的版本号放入URL。\nhttps://api.example.com/v1/\n另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。\n四、路径（Endpoint） 路径又称\u0026quot;终点\u0026quot;（endpoint），表示API的具体网址。\n在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的\u0026quot;集合\u0026quot;（collection），所以API中的名词也应该使用复数。\n举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。\nhttps://api.example.com/v1/zoos\nhttps://api.example.com/v1/animals\nhttps://api.example.com/v1/employees\n五、HTTP动词 对于资源的具体操作类型，由HTTP动词表示。\n常用的HTTP动词有下面五个（括号里是对应的SQL命令）。\nGET（SELECT）：从服务器取出资源（一项或多项）。\nPOST（CREATE）：在服务器新建一个资源。\nPUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。\nPATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。\nDELETE（DELETE）：从服务器删除资源。\n还有两个不常用的HTTP动词。\nHEAD：获取资源的元数据。\nOPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。\n下面是一些例子。\nGET /zoos：列出所有动物园\nPOST /zoos：新建一个动物园\nGET /zoos/ID：获取某个指定动物园的信息\nPUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）\nPATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）\nDELETE /zoos/ID：删除某个动物园\nGET /zoos/ID/animals：列出某个指定动物园的所有动物\nDELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物\n六、过滤信息（Filtering） 如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。\n下面是一些常见的参数。\n?limit=10：指定返回记录的数量\n?offset=10：指定返回记录的开始位置。\n?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。\n?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。\n?animal_type_id=1：指定筛选条件\n参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。\n七、状态码（Status Codes） 服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。\n200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。\n201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。\n202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）\n204 NO CONTENT - [DELETE]：用户删除数据成功。\n400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。\n401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。\n403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。\n404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。\n406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。\n410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。\n422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。\n500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。\n状态码的完全列表参见这里。\n八、错误处理（Error handling） 如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。\n{error:\u0026ldquo;Invalid API key\u0026rdquo;}\n九、返回结果 针对不同操作，服务器向用户返回的结果应该符合以下规范。\nGET /collection：返回资源对象的列表（数组）\nGET /collection/resource：返回单个资源对象\nPOST /collection：返回新生成的资源对象\nPUT /collection/resource：返回完整的资源对象\nPATCH /collection/resource：返回完整的资源对象\nDELETE /collection/resource：返回一个空文档\n十、Hypermedia API RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。\n比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。\n{\u0026ldquo;link\u0026rdquo;:\n{\u0026ldquo;rel\u0026rdquo;:\u0026ldquo;collectionhttps://www.example.com/zoos\u0026rdquo;,\n\u0026ldquo;href\u0026rdquo;:\u0026ldquo;https://api.example.com/zoos\u0026quot;,\n\u0026ldquo;title\u0026rdquo;:\u0026ldquo;List of zoos\u0026rdquo;,\n\u0026ldquo;type\u0026rdquo;:\u0026ldquo;application/vnd.yourformat+json\u0026rdquo;\n}}\n上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。\nHypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。\n{\n\u0026ldquo;current_user_url\u0026rdquo;:\u0026ldquo;https://api.github.com/user\u0026quot;,\n\u0026ldquo;authorizations_url\u0026rdquo;:\u0026ldquo;https://api.github.com/authorizations\u0026quot;,\n// \u0026hellip;\n}\n从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。\n{\n\u0026ldquo;message\u0026rdquo;:\u0026ldquo;Requires authentication\u0026rdquo;,\n\u0026ldquo;documentation_url\u0026rdquo;:\u0026ldquo;https://developer.github.com/v3\u0026quot;\n}\n上面代码表示，服务器给出了提示信息，以及文档的网址。\n十一、其他 （1）API的身份认证应该使用OAuth 2.0框架。\n（2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。\n参考博客：https://www.jianshu.com/p/73d2415956bd\n","permalink":"https://chance7bin.github.io/posts/design/restful%E9%A3%8E%E6%A0%BCapi%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97/","summary":"restful风格API 设计指南 一、协议 API与用户的通信协议，总是使用HTTPs协议。 二、域名 应该尽量将API部署在专用域名之下。 https://api.example.com 如果确","title":"restful风格API设计指南"},{"content":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox\nhttps://blog.csdn.net/weixin_44402694/article/details/87794850\nhttps://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\n==uniapp中加载mapbox会出现这个错误==\n\u0026ldquo;TypeError: Cannot read property \u0026lsquo;getElementById\u0026rsquo; of undefined\u0026rdquo;\n原因：微信小程序不支持操作dom元素， dom is not defined\nmapbox 他的Map方法里面就用的document.getElementById ，是封装好的，因此加载不出来，如下图\n2 小程序仅支持加载网络网页，不支持本地html App 平台同时支持网络网页和本地网页，但本地网页及相关资源（js、css等文件）必须放在uni-app 项目根目录-\u0026gt;hybrid-\u0026gt;html文件夹下，如下为一个加载本地网页的uni-app项目文件目录示例：\n加载本地文件加载不了\n1 this.url = `/hybrid/html/map/chooseDev.html` 加载网络文件可以\n1 this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDev.html?lon=119.318580\u0026amp;lat=26.034681\u0026#39; 文章\nhttps://www.jianshu.com/p/adc72eae0593\nhttps://www.cnblogs.com/lizhao123/p/11558674.html\n**注意：**目前通过webview跳转到其他网址支持：\n1、与微信小程序绑定的微信公众号文章地址;\n2、在微信小程序后台配置好业务域名的地址。\n3 查看官方文档，copy实例代码，终于可以加载出来了！！！ https://uniapp.dcloud.io/component/web-view\nuni.postMessage(OBJECT)\n网页向应用发送消息，在 \u0026lt;web-view\u0026gt; 的message事件回调 event.detail.data 中接收消息。\nTips\n传递的消息信息，必须写在data对象中。\nevent.detail.data中的数据，以数组的形式接收每次 post 的消息。\n1 2 3 4 5 6 7 8 // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); }); 代码如下：\n跳转的vue组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;web-view :src=\u0026#34;url\u0026#34; @message=\u0026#34;getMessage\u0026#34;\u0026gt;\u0026lt;/web-view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default{ data(){ return{ url:\u0026#39;\u0026#39; } }, onLoad(option) { console.log(\u0026#34;chooseDev option:\u0026#34;,option) this.url = \u0026#39;http://ip地址:8080/tgmobile/hybrid/html/map/chooseDevTest.html\u0026#39; }, methods:{ getMessage(e){ console.log(\u0026#34;e:\u0026#34;,e) } } } \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt; webview页面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;网络网页\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#34;https://api.mapbox.com/mapbox-gl-js/v1.12.0/mapbox-gl.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } #map { position: absolute; top: 0; bottom: 0; width: 100%; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;map\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.write(\u0026#39;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://res.wx.qq.com/open/js/jweixin-1.4.0.js\u0026#34;\u0026gt;\u0026lt;\\/script\u0026gt;\u0026#39;); \u0026lt;/script\u0026gt; \u0026lt;!-- uni 的 SDK --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://js.cdn.aliyun.dcloud.net.cn/dev/uni-app/uni.webview.1.5.2.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; // 待触发 `UniAppJSBridgeReady` 事件后，即可调用 uni 的 API。 document.addEventListener(\u0026#39;UniAppJSBridgeReady\u0026#39;, function() { uni.postMessage({ data: { action: \u0026#39;message\u0026#39; } }); uni.getEnv(function(res) { console.log(\u0026#39;当前环境：\u0026#39; + JSON.stringify(res)); }); mapboxgl.accessToken = \u0026#39;your accessToken\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, zoom: 14, center: [119.318580, 26.034681], minZoom: 3 }); }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDmapbox%E5%B9%B6%E5%8F%91%E5%B8%83%E6%88%90%E5%B0%8F%E7%A8%8B%E5%BA%8F/","summary":"小程序的踩坑之旅 1 uniapp 本身是加载不了mapbox的 下面两个是在vue环境下导入mapbox https://blog.csdn.net/weixin_44402694/article/details/87794850 https://blog.csdn.net/Isaac_Play/article/details/103890231?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3\u0026amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 ==uniapp中加载mapbox会出现这个错误","title":"uniapp加载mapbox并发布成小程序"},{"content":"报错如下：\n1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution = view.getResolution(); var source = requestLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { console.log(\u0026#34;url:\u0026#34;,url) $.ajax({ url: url, type: \u0026#39;GET\u0026#39;, async: true, contentType: \u0026#39;application/json;charset=utf-8\u0026#39;, success: data =\u0026gt; { console.log(\u0026#34;data:\u0026#34;,data) console.log(\u0026#34;length:\u0026#34;,data.features.length) } }) } 解决方法：\n看了下官方文档，他说如果没有提供QUERY_LAYERS，那么将使用layers参数中指定的layers。\n之前用写死的图层做的时候是不需要提供这个的，但是改成动态添加图层之后没有这个就会报错，原因未知，那就只好加上这个了，无奈，只好在服务的json文件里再加上一个这个layer属性了\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-wms%E7%82%B9%E5%87%BB%E6%9F%A5%E8%AF%A2%E6%8A%A5%E9%94%99/","summary":"报错如下： 1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ServiceExceptionReport version=\u0026#34;1.3.0\u0026#34; xmlns=\u0026#34;http://www.opengis.net/ogc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.opengis.net/ogc http://fzzt.fzjhdn.com:10080/geoserver/schemas/wms/1.3.0/exceptions_1_3_0.xsd\u0026#34;\u0026gt; \u0026lt;ServiceException code=\u0026#34;LayerNotQueryable\u0026#34; locator=\u0026#34;QUERY_LAYERS\u0026#34;\u0026gt; Either no layer was queryable, or no layers were specified using QUERY_LAYERS \u0026lt;/ServiceException\u0026gt; \u0026lt;/ServiceExceptionReport\u0026gt; 代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var view = map.getView(); var viewResolution =","title":"openlayers wms点击查询报错"},{"content":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLoad中调用loadMap打印第一行日志为null） 还有一个问题是script标签要加module\n\u0026lt;script module=\u0026quot;ol\u0026quot; lang=\u0026quot;renderjs\u0026quot;\u0026gt;\n2. openlayer坐标显示不匹配问题 须在view中对坐标系进行转换\n1 2 3 4 5 6 let view = new View({ center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), zoom: 5, maxZoom: 18, minZoom: 1 }); 如果要素显示不出来，那么在url后面加上 srsname=EPSG:4326\n因为 view 设置的 projection: 'EPSG:4326' ，所以此处设置 srsname=EPSG:4326。\n3.postgis导入矢量数据时的SRID设置 SRID设置为多少的一个简便的查看方法是把需要导入的图层先通过geoserver的发布图层预发布，在发布图层的设置中，geoserver会自动的识别该矢量数据的SRS，即为postgis中导入矢量数据时设置的SRID，如果在导入postgis中不设置的话，可能会出现openlayers显示不出图层的问题。（SRID也可在pgAdmin中设置）\n4. uniapp ol样式无法引入文件 App平台 v3 模式暂不支持在 js 文件中引用\u0026quot;ol/ol.css\u0026quot; 请改在 style 内引用\n在App.vue中引入\n1 2 3 4 \u0026lt;style\u0026gt; /*每个页面公共css */ @import \u0026#39;/node_modules/ol/ol.css\u0026#39;; \u0026lt;/style\u0026gt; 5. openlayers加载自定义底图 天地图有7个服务节点，可以不固定使用其中一个节点的服务，而是使用 Math.round(Math.random()*7) 的方式随机决定从哪个节点请求服务，避免指定节点因故障等原因停止服务的风险。\n天地图会出现这个问题\n用高德底图\n6. 统计模块的开发 请求wfs服务获取所有要素的信息来进行统计模块的开发是不可行的\n使用 $.getJSON 以及 uni.request 都有请求大小的限制（当请求的数据过大时会出现 “unexpected EOF”），而且会把请求到的数据的每一个属性都请求下来，对于空间数据，其geom属性对于统计功能来说是没有必要的，由于线、面等数据是通过一个个点构成的，其geom含有大量点坐标信息，因此包含该属性的json数据相当大，若请求的数据较多，其json数据大小会远远超过$.getJSON 以及 uni.request 的限制，导致程序崩溃，因此考虑使用springboot连接postgis数据库，通过选择除了geom的其他字段来大大减小空间json数据的大小。\n7.分屏功能的开发 分屏\nopenlayers地图联动 图层不能共用\n地图渲染 要和页面渲染 同步 不然地图加载不出来\n地图渲染时机：设置延时加载\n创建的图层不能共用！！！ 必须new一个新的\n","permalink":"https://chance7bin.github.io/posts/map/openlayers-uniapp-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","summary":"1.地图无法加载出来的原因 在onLoad方法执行时，map还未渲染出来，无法操作map这个标签的dom，因此地图无法显示出来（也即在onLo","title":"openlayers uniapp 移动端开发问题汇总"},{"content":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 \u0026lt;template\u0026gt; \u0026lt;view\u0026gt; \u0026lt;view id=\u0026#34;map\u0026#34; ref=\u0026#34;rootmap\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view style=\u0026#34;display: flex;\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;moveView\u0026#34;\u0026gt;moveView\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;fitToChengdu\u0026#34;\u0026gt;fitToChengdu\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; import \u0026#39;ol/ol.css\u0026#39;; import Map from \u0026#39;ol/Map\u0026#39;; import View from \u0026#39;ol/View\u0026#39;; import {Vector as VectorLayer,Tile as TileLayer} from \u0026#39;ol/layer\u0026#39;; import {Vector as VectorSource,OSM,XYZ} from \u0026#39;ol/source\u0026#39;; import {GeoJSON} from \u0026#39;ol/format\u0026#39;; import {bbox} from \u0026#39;ol/loadingstrategy\u0026#39; import {Style,Stroke,Circle,Fill} from \u0026#39;ol/style\u0026#39;; import {fromLonLat} from \u0026#39;ol/proj\u0026#39; var map = null export default { name: \u0026#39;OlWFS\u0026#39;, data() { return { }; }, onReady() { this.loadMap() }, methods:{ loadMap(){ //创建wfs资源 let wfsVectorSource = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Aqunaer_data_final\u0026amp;maxFeatures=500\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); let wfsVectorSourcePolygon = new VectorSource({ format: new GeoJSON(), projection: \u0026#39;EPSG:4326\u0026#39;, url: \u0026#39;/api/maptest/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Achina_province\u0026amp;maxFeatures=50\u0026amp;outputFormat=application%2Fjson\u0026#39;, strategy: bbox }); //创建wfs图层，注意需要设置好描边样式，否则不展示效果出来 let wfsVectorLayer = new VectorLayer({ source: wfsVectorSource, style: new Style({ image: new Circle({ radius: 5, fill: new Fill({ color: \u0026#34;#3885ff\u0026#34;, opacity: 0.5 }) }), stroke: new Stroke({ color: \u0026#39;blue\u0026#39;, width: 5 }) }), visible: true }); //view设置 let view = new View({ // center: fromLonLat([105, 34],\u0026#39;EPSG:3857\u0026#39;), center: [105, 34], zoom: 5, maxZoom: 18, minZoom: 5, projection: \u0026#39;EPSG:4326\u0026#39; });\t//创建一个map map = new Map({ layers: [ new TileLayer({ // source: new OSM() //这个会出现底图 source: new XYZ({ url: \u0026#39;http://{a-c}.tile.openstreetmap.org/{z}/{x}/{y}.png\u0026#39; }) }), wfsVectorLayer ], target: \u0026#34;map\u0026#34;, view: view }); map.on(\u0026#39;click\u0026#39;, function(evt) { console.log(\u0026#34;evt:\u0026#34;,evt.pixel) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) } }); }, // 向左移动地图 moveView(){ var view = map.getView(); var mapCenter = view.getCenter(); // 让地图中心的x值增加，即可使得地图向左移动，增加的值根据效果可自由设定 console.log(\u0026#34;mapCenter:\u0026#34;,mapCenter) mapCenter[0] += 50000; view.setCenter(mapCenter); map.render(); }, fitToChengdu() { // 让地图最大化完全地显示区域[104, 30.6, 104.12, 30.74] map.getView().fit([104, 30.6, 104.12, 30.74], map.getSize()); }, } }; \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #map{ width: 100%; height: 90vh; } /*隐藏ol的一些自带元素*/ .ol-attribution, .ol-zoom { display: none; } \u0026lt;/style\u0026gt; 2.点击wfs要素展示数据 ==使用map.forEachFeatureAtPixel==\nhtml\n1 2 3 4 \u0026lt;div id=\u0026#34;popup\u0026#34; class=\u0026#34;ol-popup\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; id=\u0026#34;popup-closer\u0026#34; class=\u0026#34;ol-popup-closer\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;popup-content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // 获取到popup的节点 var container = document.getElementById(\u0026#39;popup\u0026#39;); var content = document.getElementById(\u0026#39;popup-content\u0026#39;); var closer = document.getElementById(\u0026#39;popup-closer\u0026#39;); /** * Add a click handler to hide the popup. * @return {boolean} Don\u0026#39;t follow the href. */ closer.onclick = function () { overlay.setPosition(undefined); closer.blur(); return false; }; // 创建一个overlay, 绑定html元素container var overlay = new Overlay(/** @type {olx.OverlayOptions} */ ({ element: container, autoPan: true, autoPanAnimation: { duration: 250 } })); map.addOverlay(overlay) //点击要素获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // console.log(\u0026#34;evt:\u0026#34;,evt) // displayFeatureInfo(evt.pixel); var feature = map.forEachFeatureAtPixel(evt.pixel, function(feature) { return feature; }); console.log(\u0026#34;feature:\u0026#34;,feature) if(feature != null){ // console.log(\u0026#34;feature getId:\u0026#34;,feature.getId()) // console.log(\u0026#34;feature getKeys:\u0026#34;,feature.getKeys()) // console.log(\u0026#34;feature getProperties:\u0026#34;,feature.getProperties()) var prop = feature.getProperties(); if(feature.getId().indexOf(\u0026#34;qunaer\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h3\u0026gt;\u0026#39; + prop.F_name + \u0026#39;\u0026lt;/h3\u0026gt;\u0026#39; + \u0026#39;\u0026lt;p style=\u0026#34;margin:10px 0\u0026#34;\u0026gt;地址:\u0026#39; + prop.address + \u0026#39;\u0026lt;/p\u0026gt;\u0026#39; + \u0026#39;\u0026lt;img src=\u0026#34;\u0026#39; + prop.picurl + \u0026#39;\u0026#34; height=\u0026#34;150px\u0026#34; /\u0026gt;\u0026#39;; } else if(feature.getId().indexOf(\u0026#34;province\u0026#34;) != -1){ content.innerHTML = \u0026#39;\u0026lt;h2\u0026gt;\u0026#39; + prop.NL_NAME_1 + \u0026#39;\u0026lt;/h2\u0026gt;\u0026#39; } // 设置overlay的位置，从而显示在鼠标点击处 overlay.setPosition(evt.coordinate); } }); css\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 .ol-popup { position: absolute; background-color: white; box-shadow: 0 1px 4px rgba(0,0,0,0.2); padding: 15px; border-radius: 10px; border: 1px solid #cccccc; bottom: 12px; left: -50px; min-width: 250px; } .ol-popup:after, .ol-popup:before { top: 100%; border: solid transparent; content: \u0026#34; \u0026#34;; height: 0; width: 0; position: absolute; pointer-events: none; } .ol-popup:after { border-top-color: white; border-width: 10px; left: 48px; margin-left: -10px; } .ol-popup:before { border-top-color: #cccccc; border-width: 11px; left: 48px; margin-left: -11px; } .ol-popup-closer { text-decoration: none; position: absolute; top: 2px; right: 8px; } .ol-popup-closer:after { content: \u0026#34;✖\u0026#34;; } 3.通过wfs修改数据 加载wfs的时候要指定geometryName\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 wfsVectorLayer = new VectorLayer({ source: new VectorSource({ format: new GeoJSON({ // 因为数据源里面字段the_geom存储的是geometry，所以需要指定 geometryName: \u0026#39;the_geom\u0026#39; }), url: \u0026#39;/api/wfs?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=maptest%3Anyc_roads\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; }), style: function(feature, resolution) { return new Style({ stroke: new Stroke({ color: \u0026#39;red\u0026#39;, width: 2 }) }); } }); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // 保存已经编辑的要素 onSave() { if (modifiedFeatures \u0026amp;\u0026amp; modifiedFeatures.getLength() \u0026gt; 0) { console.log(\u0026#34;modifiedFeatures:\u0026#34;,modifiedFeatures) // 转换坐标 var modifiedFeature = modifiedFeatures.item(0).clone(); // 注意ID是必须，通过ID才能找到对应修改的feature modifiedFeature.setId(modifiedFeatures.item(0).getId()); // 调换经纬度坐标，以符合wfs协议中经纬度的位置 modifiedFeature.getGeometry().applyTransform(function(flatCoordinates, flatCoordinates2, stride) { for (var j = 0; j \u0026lt; flatCoordinates.length; j += stride) { var y = flatCoordinates[j]; var x = flatCoordinates[j + 1]; flatCoordinates[j] = x; flatCoordinates[j + 1] = y; } }); console.log(\u0026#34;modifyWfs:\u0026#34;,modifiedFeature) this.modifyWfs([modifiedFeature]); } }, // 把修改提交到服务器端 modifyWfs(features) { var WFSTSerializer = new WFS(); var featObject = WFSTSerializer.writeTransaction(null, features, null, { featureType: \u0026#39;nyc_roads\u0026#39;, // 注意这个值必须为创建工作区时的命名空间URI featureNS: \u0026#39;http://maptest/test1\u0026#39;, srsName: \u0026#39;EPSG:4326\u0026#39; }); // 转换为xml内容发送到服务器端 var serializer = new XMLSerializer(); var featString = serializer.serializeToString(featObject); console.log(\u0026#34;featString:\u0026#34;,featString) uni.request({ url: \u0026#39;/api/wfs?service=WFS\u0026#39;, method: \u0026#39;POST\u0026#39;, data:featString, header: { // 指定内容为xml类型 \u0026#39;Content-Type\u0026#39;: \u0026#39;text/xml\u0026#39; }, success: (res) =\u0026gt; { console.log(\u0026#34;success res:\u0026#34;,res.data); } }); } 4.加载WMS 点击wms获得信息 使用**==getFeatureInfoUrl==**\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 //加载WMS var wmsLayer = new TileLayer({ source: new TileWMS({ url: \u0026#34;/api/maptest/wms\u0026#34;, params:{ \u0026#39;LAYERS\u0026#39;: this.wmsSource, \u0026#39;TILED\u0026#39;: true }, transition: 0 //渲染时不透明度过渡的持续时间。要禁用不透明度转换 transition: 0 }) }); var view = new View({ projection: \u0026#34;EPSG:4326\u0026#34;, // center: [105, 34], center: [118.006954,25.101685], zoom: 10, maxZoom: 18, minZoom: 4, }) var map = new Map({ // layers: [tileOSM, tileLayer], layers: [tileOSM, wmsLayer, wfsVectorLayer], view: view, target: \u0026#39;map\u0026#39;, }); //点击wms获得信息 map.on(\u0026#39;singleclick\u0026#39;, function(evt) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#34;Loading... please wait...\u0026#34;; var view = map.getView(); var viewResolution = view.getResolution(); var source = wmsLayer.getSource(); var url = source.getFeatureInfoUrl( evt.coordinate, viewResolution, view.getProjection(), { \u0026#39;INFO_FORMAT\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;FEATURE_COUNT\u0026#39;: 50 }); if (url) { // document.getElementById(\u0026#39;nodelist\u0026#39;).innerHTML = \u0026#39;\u0026lt;iframe seamless src=\u0026#34;\u0026#39; + url + \u0026#39;\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026#39;; console.log(\u0026#34;url:\u0026#34;,url) } }); ","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%8A%A0%E8%BD%BD%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"1.加载在线WFS服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59","title":"openlayers加载地图服务"},{"content":"1.官网API https://openlayers.org/en/latest/apidoc/\n2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/\n3.GeoServer安装和发布服务 https://blog.csdn.net/u010166404/article/details/51115862?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\n4.PostgreSQL 10 和postgis10下载安装 https://blog.csdn.net/qq_40323256/article/details/101699490\n5.创建空间数据库 https://blog.csdn.net/qq_35732147/article/details/85226864\n6.加载空间数据 https://blog.csdn.net/qq_35732147/article/details/85228444\n7.利用GeoWebCache实现WebGIS地形图展示的缓存优化 https://www.cnblogs.com/naaoveGIS/p/4195008.html\n","permalink":"https://chance7bin.github.io/posts/map/%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/","summary":"1.官网API https://openlayers.org/en/latest/apidoc/ 2.openlayers教程（花几天时间从头看到尾基本上就可以熟悉openlayers了） http://primer.openlayers.cn/ol3-primer/ 3.GeoServer安装和发布","title":"参考资料"},{"content":"一、GeoServer安装和发布服务 参考链接\n二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！！！\n1.下载安装postgreSQL 进入PostgreSQL 官网，进入下载导航，点击windows系统，或直接打开如下网址：\nhttps://www.enterprisedb.com/downloads/postgres-postgresql-downloads\n下载好后，以管理员身份运行安装包，然后指定安装路径\n然后一路next\n（注意：可能会报错，不过没关系，点击取消就行）\n在程序里找到安装的PostgreSQL 10下面的pgAdmin4运行数据库管理工具\n​\n2.下载安装postgis 可使用Application Stack Builder进行下载，但速度比较慢，而且可能会卡死无响应，因此换一种可以直接下载.exe的方法。\n下载地址：http://download.osgeo.org/postgis/windows/\n==一定一定要先选择对应的PostgreSQL版本！！！==\n注意：上面的安装路径一定要选择postgresql的安装路径！！！切记\n一路next\n重新打开pgadmin，发现出现了postgis数据库了\n三、创建空间数据库 1.打开pgAdmin4，鼠标右击数据库选项并选择新建数据库：\n2.如下图所示，填写“新建数据库”表单，然后单击“确定”：\n**3.**选择nyc这个新建的数据库，并打开它以显示对象树，将会看到public架构（schema）：\n4. 单击下面所示的SQL查询按钮（或转到工具 \u0026gt; 查询工具）。\n5.在查询文本区域中输入以下查询语句以加载PostGIS****空间扩展：\nCREATE EXTENSION postgis;\n6.单击工具栏中的执行查询按钮（或按F5）以\u0026quot;执行查询\u0026quot;。\n**7.**现在，通过运行PostGIS函数来确认是否安装了PostGIS：\nSELECT postgis_full_version();\n至此，已经成功地创建了PostGIS空间数据库！\n四、加载空间数据（记得设置SRID） 1.首先，返回到选项板，并单击PostGIS部分中的PostGIS shapefile工具，PostGIS shapefile工具将启动。\n**2.**填写PostGIS连接部分的连接详细信息，然后单击“ok”按钮。程序将测试连接并在日志窗口中报告。\n如果安装时使用默认的信息，就如下所示：\n**3.**接下来，打开“Add File”按钮并导航到数据目录文件\n4.将文件的SRID（空间参考信息）值更改为4527（数据源的空间参考信息）。请注意，架构、表名和列名已经根据shapefile文件里的信息填充。\n5.单击\u0026quot;Options\u0026ldquo;按钮查看加载选项。加载程序将使用快速“COPY（复制）\u0026ldquo;模式，并在加载数据后默认创建空间索引。\n**6.**最后，单击\u0026rdquo;Import\u0026ldquo;按钮并观察导入过程。\n**7.**加载所有文件后，打开pgAdmin可以看到表已加载到数据库中：数据库\u0026gt;mySDE\u0026gt;架构\u0026gt;public\u0026gt;数据表里。\n五、GeoServer连接PostGIS 1.打开GeoServer，点击数据存储中的新建数据源，选择PostGIS\n2.选择工作区，连接参数中输入PostgreSQL端口号、数据库、用户名、密码，最后点击保存应用\n六、mapbox加载geoserver发布的瓦片服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MapBox加载WMS地图服务\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link href=\u0026#39;https://api.mapbox.com/mapbox-gl-js/v0.50.0/mapbox-gl.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;style\u0026gt; body { margin:0; padding:0; } #map { position:absolute; top:0; bottom:0; width:100%; } /*隐藏logo*/ .mapboxgl-ctrl.mapboxgl-ctrl-attrib{ display: none !important; } .mapboxgl-ctrl-logo{ display: none !important; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#39;map\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script \u0026gt; mapboxgl.accessToken = \u0026#39;pk.eyJ1Ijoid3lqcSIsImEiOiJjbDBnZDdwajUxMXRzM2htdWxubDh1MzJrIn0.2e2_rdU2nOUvtwltBIZtZg\u0026#39;; var map = new mapboxgl.Map({ container: \u0026#39;map\u0026#39;, style: \u0026#39;mapbox://styles/mapbox/streets-v10\u0026#39;, center: [108.438,34.431], zoom: 7 }); let wmsUrl = \u0026#34;http://localhost:8008/geoserver/mapserver/wms?service=WMS\u0026amp;version=1.1.0\u0026amp;request=GetMap\u0026amp;layers=mapserver:bus_line\u0026amp;styles=\u0026amp;bbox={bbox-epsg-3857}\u0026amp;width=256\u0026amp;height=256\u0026amp;srs=EPSG:3857\u0026amp;format=image/png\u0026amp;TRANSPARENT=TRUE\u0026#34; map.on(\u0026#34;load\u0026#34;,function () { map.addLayer({ \u0026#39;id\u0026#39;: \u0026#39;wms-test-layer\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;source\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;raster\u0026#39;, \u0026#39;tiles\u0026#39;: [ wmsUrl ], \u0026#39;tileSize\u0026#39;: 256 }, \u0026#39;paint\u0026#39;: {} }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意\nEPSG要设置为3857而不是4326，不然会出现跨域问题\n","permalink":"https://chance7bin.github.io/posts/map/geoserver%E8%BF%9E%E6%8E%A5postgis%E5%8F%91%E5%B8%83%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/","summary":"一、GeoServer安装和发布服务 参考链接 二、PostgreSQL 和 PostGIS安装 PostGIS要下载和PostgreSQL对应版本！","title":"geoserver连接postgis发布地图服务"},{"content":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个：\n（1）极大地减少了逻辑层（service）和视图层（view）的通讯损耗，提供高性能视图交互能力。纵然逻辑层和视图层分离的好处不容忽视，但例如Android端和小程序的高性能应用制作造成两层之间的通信阻塞迫使我们不得不放弃采用这种技术。由于renderjs运行在视图层，可以直接操作视图层的元素，因此可避免通信折损。\n（2）在视图层操作DOM，运行for web的JS库。官方文档中不建议在uni-app里操作DOM，但可使用renderjs来操作一些dom、window的库。原因在于在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，可以很方便地操作dom和window。\n移动端使用OpenLayers等开源GIS地图库最大的困难在于，若是没有提供相应的SDK将很难进行移动App的开发。由于uni-app不支持操作DOM元素，使得众多开源GIS地图库在开发移动应用时被舍弃。\n如今，有了renderjs技术后，可直接在视图层操作DOM元素，让开发者可以像开发WebGIS一样开发移动端GIS，这极大地降低了开发难度，开发者只需掌握Vue框架的核心内容，而无需掌握Android及IOS的开发技术便可实现移动GIS应用的大部分功能。\n如下为renderjs的使用方式，openlayers的写法跟开发WebGIS相同，写在script中\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 当项目代码越来越多的时候，对代码进行组件化是必须的，网上针对renderjs组件之间通信的资料还比较少，官网给了一个较为简单的示例。\nhttps://ext.dcloud.net.cn/plugin?id=1207\n但是在实际开发中通信时遇到的一些情况网上并没有相关解答，所以我在这里做了总结并给出了相应的解决方案，供大家参考。\n1 renderjs通信示例及解析 HTML\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!-- 顶部导航栏 --\u0026gt; \u0026lt;view class=\u0026#34;top-nav\u0026#34;\u0026gt; \u0026lt;button @click=\u0026#34;ol.queryFeature\u0026#34;\u0026gt;查询\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;!-- 查询菜单 --\u0026gt; \u0026lt;view class=\u0026#34;side-menu\u0026#34;\u0026gt; \u0026lt;scroll-view class=\u0026#34;feature-list\u0026#34; scroll-x=\u0026#34;true\u0026#34; scroll-y=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 监听selectedFeature的变化,把变化传给视图层 --\u0026gt; \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;feature-list-view\u0026#34; @click=\u0026#34;showFeature(item)\u0026#34; v-for=\u0026#34;(item, index) in searchList\u0026#34; :key=\u0026#34;index\u0026#34; \u0026gt; \u0026lt;view class=\u0026#34;list-title\u0026#34;\u0026gt;{{item.values_.objectid}}\u0026lt;/view\u0026gt; \u0026lt;view class=\u0026#34;list-item\u0026#34;\u0026gt;{{item.values_.zt}}\u0026lt;/view\u0026gt; \u0026lt;/view\u0026gt; \u0026lt;/scroll-view\u0026gt; \u0026lt;/view\u0026gt; js （逻辑层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { //接受视图层传过来的信息 setSearchList(e){ console.log(\u0026#34;option:\u0026#34;,e) this.searchList = e.option }, showFeature(item){ console.log(\u0026#34;show feature:\u0026#34;,item); this.selectedFeature = item; } } } \u0026lt;/script\u0026gt; renderjs（视图层）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;script module=\u0026#34;ol\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { data() { return { selectedFeature:{} } }, methods: { queryFeature(event, ownerInstance){ ... // 调用 service 层的方法 ownerInstance.callMethod(\u0026#39;setSearchList\u0026#39;, { option: features }) ... }, toFeature(newValue, oldValue, ownerInstance, instance){ ... console.log(\u0026#34;newValue:\u0026#34;,newValue.values_.objectid) ... } } } \u0026lt;/script\u0026gt; （1）逻辑层到视图层的通信\n在html中写一个监听属性变化的监听器：\n1 \u0026lt;view :prop=\u0026#34;selectedFeature\u0026#34; :change:prop=\u0026#34;ol.toFeature\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; 当点击结果列表中的某一项时，触发点击事件showFeature，执行逻辑层代码this.selectedFeature = item；此时selectedFeature的值发生了变化，从而触发监听selectedFeature的视图层事件ol.toFeature，在监听逻辑层属性变化的视图层函数中有几个参数：newValue、oldValue、ownerInstance、instance，其中的newValue即为改变后的属性值。此即逻辑层向视图层的通信。\n（2）视图层到逻辑层的通信\n首先在HTML中绑定视图层的函数ol.queryFeature，该函数有两个参数event和ownerInstance，使用ownerInstance的callMethod方法可调用逻辑层的方法setSearchList，callMethod的第二个参数为一个对象，逻辑层中setSearchList函数的形参便是视图层传递过来的值。此即视图层向逻辑层的通信。\n2 renderjs通信注意事项 （1）子组件通过事件向上传递值给父组件时，不能直接传值到视图层（renderjs模块），只能传值给逻辑层，因此需在逻辑层监听值的变化来触发视图层中的方法来执行事件或者改变视图层中的变量。\n（2）子组件中不可以通过事件向上传递，在父组件的逻辑层绑定视图层的方法进行调用。一种解决思路是在逻辑层添加一个触发视图层方法的触发器，在Vuex中监听该触发器属性的状态，逻辑层监听到触发器状态变化后便会调用视图层的方法。\n","permalink":"https://chance7bin.github.io/posts/map/uniapp%E5%8A%A0%E8%BD%BDopenlayers%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1%E7%AF%87/","summary":"renderjs是uni-app中一个运行在视图层的JS。可在App端和H5页面上运行。renderjs的主要作用有2个： （1）极大地减少了","title":"uniapp加载openlayers——组件通信篇"},{"content":" uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要通过dom获取到节点进行地图的创建，因此正常的uniapp开发是无法使用开源地图的，需要另辟蹊径。\n查阅相关资料，列举出了以下几种来解决移动端使用开源地图开发的方法，并就其使用方法以及可行性进行说明。\n==uni-app 中，没有 document！！！==\n方式一 使用uniapp中的renderjs进行开发\nhttps://uniapp.dcloud.net.cn/frame?id=renderjs\nrenderjs是一个运行在视图层的js。它比WXS更加强大。它只支持app-vue和h5。\n（WXS是一套运行在视图层的脚本语言，它的特点是运行在视图层。当需要避免逻辑层和渲染层交互通信折损时，可采用wxs。uni-app可以将wxs代码编译到微信小程序、QQ小程序、app-vue、H5上）\nrenderjs的主要作用有2个：\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 在视图层操作dom，运行for web的js库 功能详解\n大幅降低逻辑层和视图层的通讯损耗，提供高性能视图交互能力 逻辑层和视图层分离有很多好处，但也有一个副作用是在造成了两层之间通信阻塞。尤其是小程序和App的Android端阻塞问题影响了高性能应用的制作。\nrenderjs运行在视图层，可以直接操作视图层的元素，避免通信折损。\n在视图层操作dom，运行for web的js库 官方不建议在uni-app里操作dom，但如果你不开发小程序，想使用一些操作了dom、window的库，其实可以使用renderjs来解决。 在app-vue环境下，视图层由webview渲染，而renderjs运行在视图层，自然可以操作dom和window。\n使用方法\n1 2 3 4 5 6 7 8 9 10 \u0026lt;script module=\u0026#34;test\u0026#34; lang=\u0026#34;renderjs\u0026#34;\u0026gt; export default { mounted() { // ... }, methods: { // ... } } \u0026lt;/script\u0026gt; 方式二（不建议） 用 html 5+ 或者 web-view内嵌h5去实现地图\n地图为单独的一个webview界面\nApp端的webview是非常强大的，可以更灵活的控制和拥有更丰富的API。\n数据目录那一块的功能要在内嵌的html上写 或者在uniapp弄一个侧边栏\n方式三（不建议） 由于目前市面上的app大部分是由原生和H5独立或混合编写，可对原生项目进行改造，实现原生(Android)和uni-app以及html5项目混编，使其能在iOS、Android、H5、小程序等多个平台运行，从而实现跨平台开发。\n第一种实现方式：在uni-app宿主项目中添加原生以及H5插件模块\n第二种实现方式：在原生宿主项目中运行uni-app以及H5插件模块\n","permalink":"https://chance7bin.github.io/posts/map/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E7%9A%84%E5%9C%B0%E5%9B%BE%E5%BC%80%E5%8F%91/","summary":"uniapp中的APP开发使用开源地图的困难之处在于的APP端不支持document、window等对象的API，而开源地图的实例化又是需要","title":"移动端的地图开发"},{"content":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一个空的矢量图层，设置样式并添加到当前map中 var vectorSource = new VectorSource(); //设置查询参数与条件 var featureRequest = new WFS().writeGetFeature({ srsName: \u0026#39;EPSG:4326\u0026#39;,//坐标系统 featureNS: \u0026#39;http://onemap/ns\u0026#39;,//命名空间 URI featurePrefix: \u0026#39;onemap\u0026#39;,//工作区名称 featureTypes: [this.wfsSource],//查询图层，可以是同一个工作区下多个图层，逗号隔开 maxFeatures: 5000, outputFormat: \u0026#39;application/json\u0026#39;, filter: new like(\u0026#39;objectid\u0026#39;,\u0026#39;254*\u0026#39;)//前者是属性名，后者是对应值 }); fetch(api.domain + \u0026#39;/geoserver/\u0026#39; + \u0026#39;/onemap/ows?service=WFS\u0026#39;, {//geoserver wfs地址如localhost:8080/geoserver/wfs，我是8081 method: \u0026#39;POST\u0026#39;, body: new XMLSerializer().serializeToString(featureRequest) }).then(function(response) { return response.json(); }).then(function(json) { console.log(\u0026#34;feature json:\u0026#34;,json); }); } 上述代码进行模糊查询一直报错？？\nUncaught (in promise) SyntaxError: Unexpected token \u0026lt; in JSON at position 0 at __uniappview.html:0\nfetch的url写错了 ， 请求的地址和请求wfs资源的一样就不会报错\n1 api.domain + \u0026#39;/geoserver/onemap/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=\u0026#39; + this.wfsSource + \u0026#39;\u0026amp;outputFormat=application%2Fjson\u0026amp;srsname=EPSG:4326\u0026#39; 注意： like 只可以对字符串属性进行模糊查找， 整型不可以\n","permalink":"https://chance7bin.github.io/posts/map/openlayers%E5%AF%B9%E8%A6%81%E7%B4%A0%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/","summary":"要素的查询、通过geserver进行的增删改 都是用到下图这个api，很重要！ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 queryFeature(){ //首先定义一","title":"openlayers对要素服务的增删改查"}]